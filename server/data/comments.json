["@synack and @progrium (among others) both asked for the ability to name containers - which seems like a special case of tagging.\r\n\r\nSo maybe we want this in the core after all?","docker is a manager so it should play index. a pid file approach would suck (means containers have to know their id, be able to write it somewhere). and any third party tool would have to work with docker to figure out the id of every container somehow, and that's already a problem. but that problem would go away if you knew the way to reference a container before you made it. ","I was skeptical of tags. But I think containers should work similarly to images now. I don't know about the name \"repository\" but having a base name and optional tag would be nice to help look up ids. In theory, you should never have to work with ids. Imagine a PaaS and you named containers (using dotcloud terms) \u003c user\u003e/\u003c app\u003e/\u003c server\u003e.\u003c instance\u003e and then tags would be used for deployments. v1, v2, v3 ... they'd all have their own ids and all be unique containers. ","+1, names would let me autoconfigure based on convention, like memcacheXX containers would get written to a memcached.yml, or mysql-master, mysql-replica would get paired together without each knowing about the other.  The devs using my containers would focus on the logical names instead of implementation details like IDs.","Some thoughts about naming, based on our experience at dotCloud...\r\n\r\nEC2 uses tags, and doesn't have a way to name instances (an instance will be `i-42ab69cd`). Oh, right, you can give a `Name` tag, and it will show up in the console in the \"Name\" column; but you can't address instances by name and uniqueness is not enforced. In practice this is nice when you use the console, but overall a bit error-prone, because uniqueness is not enforced. On the dotCloud platform, we set the `Name` tag to be the FQDN of the instance, and we use meaningful names (`admin-8`, `gateway-7`, ...). This is very useful when working under pressure (e.g. when an outage happens), for the following reasons.\r\n1. It's easier to shout across the room \"check foo-55, I think it's blowing up!\" rather than \"check i-42f0a... no wait... i-42f9a... oh crap\" (yes, you can also copy paste on IRC/e-mail)\r\n2. Some well-known resources are \"pinned\" to specific instances. E.g. you can have a large cluster of MySQL instances, but know that your main MySQL database `masterdb` is on instances tagged `db-1` and `db-2`. Most of the time, you don't care, because you have a resource location service that will tell you instantly the exact location of any resource; but when said service is down (and relies on said db), you're very happy to have some fallback.\r\n\r\nFor those reasons, we decided that the naming scheme on the dotCloud platform would be different; i.e. for a given scaled service, each service instance would get an assigned number (0,1,2...) and uniqueness would be enforced. This, however, has other shortcomings.\r\n1. Uniqueness is only local to a machine. Nothing prevents from having two identical containers on two different hosts; and then, of course, you're in trouble.\r\n2. Relying on that \"hard-coded in your brain\" mapping (evoked in the previous paragraph) doesn't work that well, neither. It's nice to know that your super important masterdb is on host db-1, but when it gets migrated, it doesn't work anymore, and you're back to square zero (e.g. having to parallel-ssh to your whole cluster to figure out where the database is, because the naming system is broken).\r\n\r\nI assume that we can't / don't want to ensure global uniqueness of container names (that would require some distributed naming system, and suddenly a herd of zookeepers, doozers, and other weird beasts are hammering to gates to get in!); however, some way to easily find a container \"when the sh*it hits the fan\" would be really great. Picture the following scenario: you need to stop (or enter) a specific instance of a given service, but your global container db (maintained by you, outside of docker) is down. Let's hope that you have some way to locate the docker host running the instance you're looking for. Now, how do you locate the specific container easily (=not with a 4-lines obscure shell pipeline that takes you 5 minutes to grok correctly through SSH), quickly (=not by running a command on each of the hundreds or thousands of containers running on the machine), and reliably (=not yielding 4 false positives of down or unrelated containers before pointing to the right one)? *Even if docker's structures have been corrupted/messed with?*\r\n\r\nAny solution to the last problem gets my immediate buy-in :-)","Hi Jerome, I'm not sure what you're asking or suggesting.\r\n\r\nNames willl be a convenience for single-machine use. They should not be\r\nused to name or lookup containers across multiple hosts.\r\n\r\nOn Friday, April 5, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e Some thoughts about naming, based on our experience at dotCloud...\r\n\u003e\r\n\u003e EC2 uses tags, and doesn't have a way to name instances (an instance will\r\n\u003e be i-42ab69cd). Oh, right, you can give a Name tag, and it will show up\r\n\u003e in the console in the \"Name\" column; but you can't address instances by\r\n\u003e name and uniqueness is not enforced. In practice this is nice when you use\r\n\u003e the console, but overall a bit error-prone, because uniqueness is not\r\n\u003e enforced. On the dotCloud platform, we set the Name tag to be the FQDN of\r\n\u003e the instance, and we use meaningful names (admin-8, gateway-7, ...). This\r\n\u003e is very useful when working under pressure (e.g. when an outage happens),\r\n\u003e for the following reasons.\r\n\u003e 1. It's easier to shout across the room \"check foo-55, I think it's\r\n\u003e blowing up!\" rather than \"check i-42f0a... no wait... i-42f9a... oh crap\"\r\n\u003e (yes, you can also copy paste on IRC/e-mail)\r\n\u003e 2. Some well-known resources are \"pinned\" to specific instances. E.g. you\r\n\u003e can have a large cluster of MySQL instances, but know that your main MySQL\r\n\u003e database masterdb is on instances tagged db-1 and db-2. Most of the time,\r\n\u003e you don't care, because you have a resource location service that will tell\r\n\u003e you instantly the exact location of any resource; but when said service is\r\n\u003e down (and relies on said db), you're very happy to have some fallback.\r\n\u003e\r\n\u003e For those reasons, we decided that the naming scheme on the dotCloud\r\n\u003e platform would be different; i.e. for a given scaled service, each service\r\n\u003e instance would get an assigned number (0,1,2...) and uniqueness would be\r\n\u003e enforced. This, however, has other shortcomings.\r\n\u003e 1. Uniqueness is only local to a machine. Nothing prevents from having two\r\n\u003e identical containers on two different hosts; and then, of course, you're in\r\n\u003e trouble.\r\n\u003e 2. Relying on that \"hard-coded in your brain\" mapping (evoked in the\r\n\u003e previous paragraph) doesn't work that well, neither. It's nice to know that\r\n\u003e your super important masterdb is on host db-1, but when it gets migrated,\r\n\u003e it doesn't work anymore, and you're back to square zero (e.g. having to\r\n\u003e parallel-ssh to your whole cluster to figure out where the database is,\r\n\u003e because the naming system is broken).\r\n\u003e\r\n\u003e I assume that we can't / don't want to ensure global uniqueness of\r\n\u003e container names (that would require some distributed naming system, and\r\n\u003e suddenly a herd of zookeepers, doozers, and other weird beasts are\r\n\u003e hammering to gates to get in!); however, some way to easily find a\r\n\u003e container \"when the sh*it hits the fan\" would be really great. Picture the\r\n\u003e following scenario: you need to stop (or enter) a specific instance of a\r\n\u003e given service, but your global container db (maintained by you, outside of\r\n\u003e docker) is down. Let's hope that you have some way to locate the docker\r\n\u003e host running the instance you're looking for. Now, how do you locate the\r\n\u003e specific container easily (=not with a 4-lines obscure shell pipeline that\r\n\u003e takes you 5 minutes to grok correctly through SSH), quickly (=not by\r\n\u003e running a command on each of the hundreds or thousands of containers\r\n\u003e running on the machine), and reliably (=not yielding 4 false positives of\r\n\u003e down or unrelated containers before pointing to the right o ne)? *Even if\r\n\u003e docker's structures have been corrupted/messed with?*\r\n\u003e\r\n\u003e Any solution to the last problem gets my immediate buy-in :-)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/1#issuecomment-15965238\u003e\r\n\u003e .\r\n\u003e","Sometimes global uniqueness is just scoping. Put the host machine's name in\r\nthe name. That's why I was suggesting we use the hostname option to let you\r\nspecify a referenceable name.\r\n\r\nIMHO, we shouldn't try to address global uniqueness. It should be something\r\nthe user can do on their own, augmented by other systems.\r\n\r\nIn your scenario, I would solve it with a better service discovery system.\r\nOne that doesn't have a central DB. Also one that is not necessarily Doozer\r\nor Zookeeper.\r\n\r\n\r\nOn Fri, Apr 5, 2013 at 9:12 AM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Some thoughts about naming, based on our experience at dotCloud...\r\n\u003e\r\n\u003e EC2 uses tags, and doesn't have a way to name instances (an instance will\r\n\u003e be i-42ab69cd). Oh, right, you can give a Name tag, and it will show up\r\n\u003e in the console in the \"Name\" column; but you can't address instances by\r\n\u003e name and uniqueness is not enforced. In practice this is nice when you use\r\n\u003e the console, but overall a bit error-prone, because uniqueness is not\r\n\u003e enforced. On the dotCloud platform, we set the Name tag to be the FQDN of\r\n\u003e the instance, and we use meaningful names (admin-8, gateway-7, ...). This\r\n\u003e is very useful when working under pressure (e.g. when an outage happens),\r\n\u003e for the following reasons.\r\n\u003e 1. It's easier to shout across the room \"check foo-55, I think it's\r\n\u003e blowing up!\" rather than \"check i-42f0a... no wait... i-42f9a... oh crap\"\r\n\u003e (yes, you can also copy paste on IRC/e-mail)\r\n\u003e 2. Some well-known resources are \"pinned\" to specific instances. E.g. you\r\n\u003e can have a large cluster of MySQL instances, but know that your main MySQL\r\n\u003e database masterdb is on instances tagged db-1 and db-2. Most of the time,\r\n\u003e you don't care, because you have a resource location service that will tell\r\n\u003e you instantly the exact location of any resource; but when said service is\r\n\u003e down (and relies on said db), you're very happy to have some fallback.\r\n\u003e\r\n\u003e For those reasons, we decided that the naming scheme on the dotCloud\r\n\u003e platform would be different; i.e. for a given scaled service, each service\r\n\u003e instance would get an assigned number (0,1,2...) and uniqueness would be\r\n\u003e enforced. This, however, has other shortcomings.\r\n\u003e 1. Uniqueness is only local to a machine. Nothing prevents from having two\r\n\u003e identical containers on two different hosts; and then, of course, you're in\r\n\u003e trouble.\r\n\u003e 2. Relying on that \"hard-coded in your brain\" mapping (evoked in the\r\n\u003e previous paragraph) doesn't work that well, neither. It's nice to know that\r\n\u003e your super important masterdb is on host db-1, but when it gets migrated,\r\n\u003e it doesn't work anymore, and you're back to square zero (e.g. having to\r\n\u003e parallel-ssh to your whole cluster to figure out where the database is,\r\n\u003e because the naming system is broken).\r\n\u003e\r\n\u003e I assume that we can't / don't want to ensure global uniqueness of\r\n\u003e container names (that would require some distributed naming system, and\r\n\u003e suddenly a herd of zookeepers, doozers, and other weird beasts are\r\n\u003e hammering to gates to get in!); however, some way to easily find a\r\n\u003e container \"when the sh*it hits the fan\" would be really great. Picture the\r\n\u003e following scenario: you need to stop (or enter) a specific instance of a\r\n\u003e given service, but your global container db (maintained by you, outside of\r\n\u003e docker) is down. Let's hope that you have some way to locate the docker\r\n\u003e host running the instance you're looking for. Now, how do you locate the\r\n\u003e specific container easily (=not with a 4-lines obscure shell pipeline that\r\n\u003e takes you 5 minutes to grok correctly through SSH), quickly (=not by\r\n\u003e running a command on each of the hundreds or thousands of containers\r\n\u003e running on the machine), and reliably (=not yielding 4 false positives of\r\n\u003e down or unrelated containers before pointing to the right o ne)? *Even if\r\n\u003e docker's structures have been corrupted/messed with?*\r\n\u003e\r\n\u003e Any solution to the last problem gets my immediate buy-in :-)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/1#issuecomment-15965238\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","Well, I was merely explaining my use case (which is the use case\nexperienced by ops on the dotCloud platform): \"sometimes, you need to be\nable to find a given process easily and quickly; i.e. on which host it is,\nand in which container it is exactly\". In my use case, said \"process\" is\nidentified by an arbitrary tag which is set by the operator when the\nprocess start (and in our specific case, this tag is the container\nhostname, but it doesn't need to be).\n\nThen there is a very wide spectrum of possible implementations.\n1. docker doesn't let you set a tag, so you have to retrieve the container\nID when it starts, and store it in some database (zookeeper, redis, dns,\nwhatever lets you do an easy mapping).\n2. docker lets you set a tag, and retrieve it as well, and indexes the tags\nlocally. Now you don't need to store the full container ID anymore, just\nthe host running your container.\n3. docker lets you set a tag, and the tags happen to be stored as flat\nfiles with a well-known layout (or something similar).\n\nNotes:\n(1) seems to be fine and well, until the central database is unavailable /\ncorrupted / inconsistent;\n(2) makes things easier than (1) because as long as containers don't move\narbitrarily, your database doesn't change (and also, you can efficiently\nuse DNS to map containers to hosts);\n(3) makes things easier than (2) when docker breaks, because finding a\ncontainer can be done with simple shell commands.","Container tagging feels like a core concept to me, and seems like a building block for the \"container groups\" feature that @shykes mentioned.","Naming containers worries me.  Even if the feature were implemented, I think that if I found myself tempted to use it, I'd suspect a bad smell and try to redesign to avoid using it.\r\n\r\nDocker is powerful because it removes magic numbers from my life.  It makes it possible for me to run, for example, two instances of nginx on my one host machine, without making a mess.  Now what if I start working in a company that has a script that relies on one of their containers being named \"nginx\"?  Or worse, \"main\"?  Now try to set these up in jenkins or something that's trying to run selfcontained/concurrent tests.  Whoops.\r\n\r\nMaybe it's possible to build scripts around naming to make sure names are generated with unique suffixes to avoid that kind of problem... but I'm not sure it's reasonable to expect people to consistently do so, and even if it is done, then is that any better than just dealing with random IDs as they stand?  If there was support for commands that run on sets of containers based on globbing of names, then I could see a potential gain, but otherwise, I see nothing.","@heavenlyhash so it sounds like you'd prefer tags.","Tentatively scheduling for 0.8","Just a heads up, this is confirmed for release in 0.6.5 tomorrow :)","This has been implemented in Docker 0.6.5. ",":+1:\r\n","More work on tagging/naming: #7576","is there a way for a running container to know its own name, eg via environment var?","There might be (at least) one scenario where you want to have whiteouts: if you ship a layer including some sample code, you might want to remove it (or overwrite it with something else) when you derive the layer.\r\n\r\nOn the current platform, we don't use whiteouts in that case, because this data is on a separate volume (therefore not requiring a whiteout).\r\n\r\nThere are also special cases of whiteouts: permission changes. Those can be useful when you want to give access to some files, or remove access. This was a frequent problem on the current platform (e.g. readability of logs when daemons are installed using system packages instead of the default user).\r\n\r\nThere is no convention in AUFS—just an opaque format. I'd personally advocate against making that part of the API, since it effectively ties the implementation with AUFS, which is probably a Very Bad Thing, but YMMV.\r\n\r\nLast but not least, in some cases (mail servers), you might also want to preserve inode numbers—and in that case, you would have to also preserve the xino translation file of AUFS.\r\n\r\n... Unless we want to support bind-mounted volumes; then those concerns are waived.","On Sun, Jan 20, 2013 at 10:57 PM, jpetazzo \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e There might be (at least) one scenario where you want to have whiteouts:\r\n\u003e if you ship a layer including some sample code, you might want to remove it\r\n\u003e (or overwrite it with something else) when you derive the layer.\r\n\u003e\r\nCould you walk me through an example use case in more detail?\r\n\r\n\u003e There are also special cases of whiteouts: permission changes. Those can\r\n\u003e be useful when you want to give access to some files, or remove access.\r\n\u003e This was a frequent problem on the current platform (e.g. readability of\r\n\u003e logs when daemons are installed using system packages instead of the\r\n\u003e default user).\r\n\u003e\r\nSame question as above.\r\n\r\n\u003e Last but not least, in some cases (mail servers), you might also want to\r\n\u003e preserve inode numbers—and in that case, you would have to also preserve\r\n\u003e the xino translation file of AUFS.\r\n\u003e\r\nSame question as above.\r\n\r\nThanks!","On Sun, Jan 20, 2013 at 10:57 PM, jpetazzo \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e There is no convention in AUFS—just an opaque format. I'd personally\r\n\u003e advocate against making that part of the API, since it effectively ties the\r\n\u003e implementation with AUFS, which is probably a Very Bad Thing, but YMMV.\r\n\r\nWe are in agreement here. Frankly, sticking to vanilla tarballs as the\r\nimage format is something I would like to preserve if at all possible. I know\r\nAndrea feels the same way.","1. Whiteouts Needed To Remove Sample Code.\r\nThe current implementation of dotCloud service ships with some sample code. It is never seen by dotCloud users, since their code replaces it immediately after container deployment (before the container gets a chance to see traffic) — unless code deployment fails; in which case the container is rolled back to its previous version, which happens to be the pristine version of the cloudlet. Of course, we could argue that this sample code could be removed in the first place from the base layer; but it's here for a good reason: to help the service developer to ensure that his service actually works.\r\n\r\n2. Whiteouts Needed To Preserve Permission Changes.\r\nFor a very long time, dotCloud Java service has been plagued by the fact that its logs were readable only by the jetty user, not by the dotCloud user. The files in base layer didn't have to be modified, but their permissions did.\r\n\r\n3. Preserving Inode Numbers.\r\nhttp://grox.net/doc/postfix/html/faq.html#copying\r\n\"Postfix names a queue file after its inode number and after the microsecond part of the time of day. Thus, if a queue file has a name based on someone elses inode number there is a small chance that the file name will collide with another queue file.\"","Ok, after a few off-band discussions: the consensus seems to be that whiteouts and layers are a (very) useful tool, but should not be exposed as a top-level object to the end-user. The main reason being that it would make things unnecessarily complicated (every user needs to acquire the off-band knowledge of which layer works with which, and  it is very easy to shoot yourself in the foot by combining layers that were not meant to be combined). At the same time, there is not much benefit to allowing arbitrary combination of layers: even if you are 99% sure your layer can be safely \"rebased\" to a new base layer, why not run that build script again just to make sure you're right?\r\n\r\nSo, instead, let's use layers (+ their associated whiteouts) as a optimization for storing and transferring images. In other words, the payload for docker is always a tarball. But it may optionally be a *sparse* tarball, which will reference the bottom layers by ID, and only store changes. Of course these sparse tarballs will only be usable to a receiver capable of (a) decoding the sparse format and (b) retrieving the bottom layers from their ID.","I'd love to learn more about this because I think state/data is often one of the biggest challenges of any system and should really be treated special. If stateful (ie databases/datastores) support in containers is builtin *too* directly, it may create a false affordance. ","More detailed proposal here: #111 ","+1 for bind-mount","Is it technically possible for the host to receive traffic to 127.0.0.1 UDP/53 originating from a container? If so, it could elegantly resolve DNS for all containers, making /etc/resolv.conf optional.\r\n","bind-mount has been implemented; closing this ticket. For other DNS-related issues, see #541.","Couldn't reproduce it (tried `docker  run base cat /dev/zero` and `docker run -a -t -i cat /dev/zero`).\r\n\r\nIf you remember how you did it and could try again, that'd be great!","All my notes are in the issue. If you can't reproduce, it's very possible\r\nit was fixed - this bug was approximately 150 commits ago :)\r\n\r\n\r\nOn Thu, Mar 14, 2013 at 6:00 PM, jpetazzo \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Couldn't reproduce it (tried docker run base cat /dev/zero and docker run\r\n\u003e -a -t -i cat /dev/zero).\r\n\u003e\r\n\u003e If you remember how you did it and could try again, that'd be great!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/5#issuecomment-14938663\u003e\r\n\u003e .\r\n\u003e","Boldly closing as \"could not reproduce\", then :-)","In my experience, the most permissive license is the **MIT license**, and I personally think it's a reasonable one - it basically gives anyone \"the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software\". The **revised BSD license** is mostly identical.\r\n\r\nThe **GPL** is probably out of the question since it disallows reselling derivated software. The **LGPL** is an half-assed version of it.\r\n\r\nThere are other ones like the **Mozilla Public License** but they're much less widespread so people could be more wary about these.\r\n\r\nAnd of course there's the option of crafting our own, if we have specific clauses we want to enforce.\r\n\r\nAll in all I would personally support using the **MIT License**","Yeah, I tend to prefer the MIT or BSD licenses because they're short, permissive, and well understood. I'm also not pedantic free software nut, so I don't push (L)GPL ... unless it really makes sense. And agreed on points above about MPL, APL, etc. ","+1 MIT or BSD (with slight preference for BSD just because it's Bay Area native :-)","I highly recommend AL2 for a few reasons.\r\n\r\n1) It has some VERY WEAK patent protections, which MIT and BSD don't.\r\n2) It has VERY WEAK copyleft, which simplifies contributions (contributions made to the library are under AL2 unless otherwise stated, which saves having to collect a CLA or statement of explicit licensing for every little thing).\r\n3) It has all the liberal goodness, to make adoption easy, of MIT or BSD.","@brianm you make a good point on contribution logistics: this gives AL2 the advantage in my view.\r\n\r\nReservations on AL2, anyone?","AL2 one time, AL2 two times... SOLD! Docker is now licensed under Apache 2.0.\r\n\r\na7e9582a53663453d0885b1a0217941ad1fe595f","On Thu, Jan 31, 2013 at 5:56 PM, Andy Rothfusz \u003cnotifications@github.com\u003ewrote:\n\n\u003e If you can manipulate docker from inside docker, what is the\n\u003e authentication model?\n\u003e How do I keep other containers from messing with me, cloning me, starting\n\u003e me, stopping me?\n\u003e Or how do I give them permission to do so?\n\u003e\nWhen we offer an introspection API, it will have to be scoped. That can be\ndone by source IP for example, since Docker controls the networking\ntopology and addressing for all containers.\n\nOptionally, containers could have a \"privileged\" flag which allows them to\nmess with other containers. This would be a great way to extend the\ncapabilities of Docker while staying in \"userland\".","Closing the issue, feel free to continue the conversation on the mailing list.","You're right, the IDs are too short. The UI shows a truncated ID to keep the output readable. The actual checksum is a SHA256 of the full content in tar archive. Going forward that's what we'll use as a canonical identifier.","Containers are unique and cannot copied. To manipulate a specific container, simply reference it by its globally unique ID.\r\n\r\nA container's filesystem state can be committed to a new *image*. Images are immutable and can be copied to any number of Docker hosts, where they are used to start any number of containers.\r\n\r\nEach image also has its own globally unique ID. Docker keeps track of the relationship between images and containers, eg. \"what containers have you started from image X?\" etc.","Ok -- I didn't realize the distinction between the container UUID and the file system image UUID.","\u003e How many layers need to be tracked to resolve the final value of a byte in a file?\r\n\r\nThe granularity of AUFS is the file, not the byte/record/extent/whatever. This means, that the layers are traversed when a file is open. Once you hold a file descriptor, the performance difference should be unnoticeable.\r\n\r\nHowever, there can be two adverse effects if you have many layers, especially with deep-nested directory hierarchies:\r\n- each stat/open/... will traverse all layers, and require a directory entry look-up for each path component, on each layer (until the component is found); i.e., when you try to open /a/b/c/d with layers L1 L2 L3, it will actually look for /a on L3, L2, and L1 (until it finds one); then it will look for /a/b on L3, L2, and L1 again; and so on;\r\n- this means that the dentry cache (managed by the kernel slab allocator) *might* grow bigger than usual (we noticed this on dotCloud).\r\n\r\n\u003e What happens to files/bytes that will never be referenced because they are masked by something that has been written back to the file system?\r\n\r\nNothing. They stay where they are, and they have to, should you want to \"strip\" an upper layer. However, it is possible to merge multiple layers. AUFS even provides tools to do that efficiently (see `aubrsync`).","Closing the issue, feel free to continue the discussion in the mailing list.","Hi jpetazzo,\r\nIn a docker container, I have a lot of stat/open operations for a lot of small files and I found the i/o performance was  bad and impacted the overall throughput. I tried to move all there files into a -v volumes but did not notice performance benefits. DO you know why?","Verified by @niallo \r\n\r\n---------- Forwarded message ----------\r\nFrom: Joffrey F \u003cjoffrey@dotcloud.com\u003e\r\nDate: Mon, Feb 11, 2013 at 10:48 AM\r\nSubject: Docker also runs on Ubuntu 12.04 (LTS)\r\nTo: docker-club@googlegroups.com\r\n\r\n\r\nHi everyone,\r\n\r\nIf you weren't following the conversation on IRC on Friday, Niall tested the current docker version on Ubuntu 12.04 LTS (codename: precise) and it works. Thanks Niall! Obviously this is great news  for all of us who have short term plans for production-level / critical applications on docker!\r\n\r\nBest,\r\n\r\n-- \r\nJoffrey","This causes interactive commands to fail when they rely on the ability to open /dev/tty. For example:\r\n\r\n* git clone on a private repository (when requesting username and password)\r\n\r\n* apt-get install (when requesting information interactively, eg. upon installing mysql-server)\r\n","@andrea and I have played with a few knobs to find the source of the problem, with interesting results.\r\n\r\nKnob 1: call setsid() and set the controlling terminal to fd 0: http://pastie.org/private/z73dibby22bmuiiujwjf1g#10\r\n\r\n--\u003e This causes 'docker run -i -t -a base /bin/bash' to fail, with 'invalid ioctl for device'.\r\n\r\n\r\nKnob 2: leaving knob 1 in place, execute the command directly instead of going through lxc-start: http://pastie.org/private/z73dibby22bmuiiujwjf1g#18\r\n\r\n--\u003e This fixes the problem introduced by knob 1 (but doesn't fix /dev/tty).\r\n\r\n\r\nIn short, it seems that lxc-start itself messes with tty allocation in a non-trivial way, and at the very least we should understand what it does if we hope to fix this /dev/tty issue.\r\n","This part of lxc's source seems relevant: https://github.com/lxc/lxc/blob/staging/src/lxc/conf.c#L671\r\n\r\nIt is called by lxc_start.","This should help some: https://github.com/dotcloud/docker/commit/b00ff47963bb236d9f94fbcd759e4f3fba021d05\r\nI wasn't able to fix the echoing input (yet) though.","Group hug for @creack . Issue solved!","This is still broken on the public code\r\n\r\nzyga@g580:~$ docker run -i -t base /bin/bash\r\n2013/03/26 20:20:30 docker run -i -t base /bin/bash\r\nbash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\nbash: no job control in this shell\r\n","Implemented in 2df0bc6bc0df53c7657404a92fb8f256b7109de0","@shykes this sounds cool. But can you explain how this works ? \r\nthanks ","@rhacker see the `docker logs` command","Assigning to myself for now. I'll draft a spec and then open for comments. Please continue to comment on any design or technology choices as well as possible use cases for it. Thanks.","I'd like either a RESTish HTTP/JSON API or a JSON/MessagePack RPC API. My primary use case is management and distribution of containers on docker nodes, so all container and image management functionality should be exposed.\r\n\r\nIdeally there should be a way to get a single TCP stream containing all STDOUT/STDERR streams from the containers, to facilitate centralized log management via a Logstash/Logplex-type tool.\r\n\r\nAnd finally, there should be an API to get a remote PTY in order to replicate `heroku run`-type functionality.","Agree on all counts :)\r\n\r\nI have a prototype of remote API which I will put up as soon as the dust\r\nsettles after the public launch.\r\n\r\n\r\nOn Tue, Mar 26, 2013 at 11:37 AM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e I'd like either a RESTish HTTP/JSON API or a JSON/MessagePack RPC API. My\r\n\u003e primary use case is management and distribution of containers on docker\r\n\u003e nodes, so all container and image management functionality should be\r\n\u003e exposed.\r\n\u003e\r\n\u003e Ideally there should be a way to get a single TCP stream containing all\r\n\u003e STDOUT/STDERR streams from the containers, to facilitate centralized log\r\n\u003e management via a Logstash/Logplex type tool.\r\n\u003e\r\n\u003e And finally, there should be an API to get a remote PTY in order to\r\n\u003e replicate heroku run type functionality.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/21#issuecomment-15478455\u003e\r\n\u003e .\r\n\u003e","Here's the list of endpoints that I think we should have in the Remote API. This would be a RESTish HTTP/JSON API. Obviously the exact schemas, pagination, and query params need to be specified.\r\n\r\n- `POST /images`\r\n  - Upload image tarball\r\n  - Fetch from URL, registry or other docker instance\r\n  - Create image from container\r\n- `GET /images`\r\n  - List all images\r\n- `GET /images/{id}`\r\n  - Image info and history\r\n  - Download tarball with different `Accept` header specified\r\n- `POST /images/{id}/push`\r\n  - Push image to registry or other docker instance\r\n- `DELETE /images/{id}`\r\n  - Delete image\r\n- `POST /containers`\r\n  - Create container with network and process config, optionally starting it\r\n- `GET /containers`\r\n  - List all containers\r\n- `GET /containers/{id}`\r\n  - Get container info\r\n  - Get stream of STDOUT and/or STDERR with a different `Accept` header specified\r\n- `POST /containers/{id}/start`\r\n  - Stop container\r\n- `POST /containers/{id}/stop`\r\n  - Start container\r\n- `DELETE /containers/{id}`\r\n  - Delete container\r\n- `POST /stream`\r\n  - Get a custom multiplexed stream of multiple containers and events","+1 for the RESTish HTTP/JSON API.","I think we're on the same page for what needs to come first :) A few minor comments:\r\n\r\n* For image API, it probably makes sense to align early on the registry protocol. No sense in having 2 different ways to move images around. @samalba and @kencochrane are working on the registry and can weigh in.\r\n\r\n* Container stuff seems straightforward enough\r\n\r\n* /stream probably needs fleshing out. How would it be configured?\r\n\r\n* In general how do I pass parameters? url query params? json in the body?\r\n\r\n","@shykes \r\n\r\n\u003e For image API, it probably makes sense to align early on the registry protocol.\r\n\r\nYes, completely agree. This API should *be* the registry.\r\n\r\n\u003e /stream probably needs fleshing out. How would it be configured?\r\n\r\nMy thinking is that you would `POST` a JSON object to it describing the streams/configuration that you want (ie the list of containers, events, etc.) and then the TCP connection that you made the request with would turn into the stream.\r\n\r\n\u003e In general how do I pass parameters? url query params? json in the body?\r\n\r\nPagination and filtering via query params, data via JSON request bodies.","Big big :+1: for this, it'll make it much easier to automate things (vs. programmatically running bash commands).","Any chance we could get a simple stack.io/RPC endpoint implementation for remote interaction?","@MatApple What is stack.io? The whole point of this API is for \"remote interaction\".","http://lmgtfy.com/?q=stack+io \r\n\r\nI realize there is no native implementation for Go, but it (or some other RPC interface) is more flexible and quicker to integrate than a fully functioning REST API.","Ah, sorry, I went to http://stack.io and found vapor. I don't see the point in doing a RPC interface instead of a proper REST API.","I started working on this (asking @shin- some questions)\r\n\r\nHere are some questions that need clarification\r\n\r\n### Containers\r\n\r\n*rw* is ok, but if *rootfs* is unmounted we can't display it, for now I did this:\r\n\r\n    ID             IMAGE         COMMAND                CREATED          STATUS          COMMENT     SIZE\r\n    bb8f8d1b2ea0   base:latest   /bin/bash              52 minutes ago   Up 38 seconds               175886K (rw: 16K, rootfs: 175870K)\r\n    2d358ce51d87   base:latest   /bin/bash              3 hours ago      Exit 0                      16K (rw: 16K, rootfs: 0K)\r\n    a13f4ba6204a   base:latest   /bin/bash              3 hours ago      Exit 0                      16K (rw: 16K, rootfs: 0K)\r\n    59bd80f6f359   base:latest   /bin/bash              3 hours ago      Exit 0                      16K (rw: 16K, rootfs: 0K)\r\n    65559fd8e242   base:latest   -i -t /bin/bash        3 hours ago      Exit 127                    16K (rw: 16K, rootfs: 0K)\r\n    a18f1dfef7ca   base:latest   /bin/sh -c while tru   21 hours ago     Exit -127                   20K (rw: 16K, rootfs: 4K)\r\n\r\nas you can see, the only relevent information is when the container is running. so maybe we could display the size only for running containers ?\r\n\r\n### Images\r\n\r\nShould we display the size of the parent images ? on the current one ? both ?\r\nLet's say we want to display the size a dhrp/sshd from examples, should we display the sshd + base ? ","Maybe we can store the running size of the container when it dies before unmounting the fs?\r\n\r\nThe size of the image should be its own size and all its ancester. An image can't be used without its ancester so the size should be the whole tree.\r\n\r\nMaybe as an extra info for both container and image we can display the 'real' size: for the container, the rw folder size and for the image the layer size without its parents.","\u003e Maybe we can store the running size of the container when it dies before unmounting the fs?\r\n:+1: \r\n\r\n\r\nIf I understand correctly you suggest:\r\n\r\ncontainer: 'real' size=rw+rootfs and rw as extra\r\nand\r\nimage: 'real' size=own_layer+ancesters_layer and own_layer as extra\r\n\r\n?\r\n\r\nSeems good to me.","perfect :)","I think what the user is most interested in is \"how much does this actually\r\nuse on disk?\"\r\n\r\nSo for the image that's the layer size, and for the container it's rw.\r\n\r\nThe full tree size is also interesting to have but less crucial (I can\r\nalways run \"df\" or \"du\" in my container)\r\n\r\nOn Friday, April 12, 2013, Guillaume J. Charmes wrote:\r\n\r\n\u003e perfect :)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/22#issuecomment-16297924\u003e\r\n\u003e .\r\n\u003e","\u003e I think what the user is most interested in is \"how much does this actually\r\nuse on disk?\"\r\n\r\nI totally agree on this but, \r\n\r\nregarding the **containers**:\r\n\r\n    ID             IMAGE         COMMAND                CREATED        STATUS      COMMENT     SIZE\r\n    bb8f8d1b2ea0   base:latest   /bin/bash              2 hours ago    Exit -127               171M (rw: 16K, rootfs: 171M)\r\n    2d358ce51d87   base:latest   /bin/bash              5 hours ago    Exit 0                  16K (rw: 16K, rootfs: 0K)\r\n    a13f4ba6204a   base:latest   /bin/bash              5 hours ago    Exit 0                  16K (rw: 16K, rootfs: 0K)\r\n    59bd80f6f359   base:latest   /bin/bash              5 hours ago    Exit 0                  16K (rw: 16K, rootfs: 0K)\r\n    65559fd8e242   base:latest   -i -t /bin/bash        5 hours ago    Exit 127                16K (rw: 16K, rootfs: 0K)\r\n    a18f1dfef7ca   base:latest   /bin/sh -c while tru   23 hours ago   Exit -127               20K (rw: 16K, rootfs: 4K)\r\n\r\nI think you need the rootfs information to know *\"how much does this actually use on disk?\"* because even if the container isn't running it uses some space (here 171Mo)\r\n\r\nAnd for the **images**:\r\n\r\n    REPOSITORY          TAG                 ID                  CREATED             SIZE\r\n    base                ubuntu-12.10        b750fe79269d        2 weeks ago         24K\r\n    base                ubuntu-quantl       b750fe79269d        2 weeks ago         24K\r\n    base                ubuntu-quantal      b750fe79269d        2 weeks ago         24K\r\n    base                latest              b750fe79269d        2 weeks ago         24K\r\n    dhrp/sshd           latest              1bd442970c79        13 days ago         20K\r\n    \u003cnone\u003e              \u003cnone\u003e              fa594d99163a        13 days ago\r\n\r\nWithout the parent, the information isn't really relevant, because even the base image depends on another image, not listed here.","On Fri, Apr 12, 2013 at 9:11 AM, Victor Vieux \u003cnotifications@github.com\u003ewrote:\n\n\u003e I think what the user is most interested in is \"how much does this actually\n\u003e use on disk?\"\n\u003e\n\u003e I totally agree on this but,\n\u003e\n\u003e regarding the *containers*:\n\u003e\n\u003e ID             IMAGE         COMMAND                CREATED        STATUS      COMMENT     SIZE\n\u003e bb8f8d1b2ea0   base:latest   /bin/bash              2 hours ago    Exit -127               171M (rw: 16K, rootfs: 171M)\n\u003e 2d358ce51d87   base:latest   /bin/bash              5 hours ago    Exit 0                  16K (rw: 16K, rootfs: 0K)\n\u003e a13f4ba6204a   base:latest   /bin/bash              5 hours ago    Exit 0                  16K (rw: 16K, rootfs: 0K)\n\u003e 59bd80f6f359   base:latest   /bin/bash              5 hours ago    Exit 0                  16K (rw: 16K, rootfs: 0K)\n\u003e 65559fd8e242   base:latest   -i -t /bin/bash        5 hours ago    Exit 127                16K (rw: 16K, rootfs: 0K)\n\u003e a18f1dfef7ca   base:latest   /bin/sh -c while tru   23 hours ago   Exit -127               20K (rw: 16K, rootfs: 4K)\n\u003e\n\u003e I think you need the rootfs information to know *\"how much does this\n\u003e actually use on disk?\"* because even if the container isn't running it\n\u003e uses some space (here 171Mo)\n\u003e\nI don't think that's correct - in this case the container actually uses 16k\non disk :) the 171M is \"virtual\", since it's actually used by its images.\n\n\u003e And for the *images*:\n\u003e\n\u003e REPOSITORY          TAG                 ID                  CREATED             SIZE\n\u003e base                ubuntu-12.10        b750fe79269d        2 weeks ago         24K\n\u003e base                ubuntu-quantl       b750fe79269d        2 weeks ago         24K\n\u003e base                ubuntu-quantal      b750fe79269d        2 weeks ago         24K\n\u003e base                latest              b750fe79269d        2 weeks ago         24K\n\u003e dhrp/sshd           latest              1bd442970c79        13 days ago         20K\n\u003e \u003cnone\u003e              \u003cnone\u003e              fa594d99163a        13 days ago\n\u003e\n\u003e Without the parent, the information isn't really relevant, because even\n\u003e the base image depends on another image, not listed here.\n\u003e\n\nYou're right that there should be a place showing the total tree size for a\ngiven image+parents. But the size of the last version is also relevant,\nbecause the user wants to know \"how much more space am I using with this\nlast commit I made?\".\n\n--\u003e The fact that the layers are so lightweight is a big advantage of\ndocker, we should make it very obvious :)\n\n\nMaybe we can combine both in the output? Something like:\n\nREPOSITORY          TAG                 ID                  CREATED\n         SIZE\nbase                ubuntu-12.10        b750fe79269d        2 weeks\nago         24K (virtual 170MB)\nbase                ubuntu-quantl       b750fe79269d        2 weeks\nago         24K (virtual 170MB)\n\n\nWhat do you think?","Ok for **24KB (virtual 170MB)** on images, \r\n\r\ndo we do the same on containers, or there is no need to display tha virtual on them ?","Why not doing as OSs do? osX does the oposite, I am pretty sure windows too (command-i on a file shows the file size and the actual disk space used)","Just my 2ct but I'd suggest using not using the word 'combined' or 'total' instead of 'virtual'. Reasoning behind that is that virtual suggests the space is not physically used. For example that the space on disk is freed when the image is not running. \r\n\r\nI think it would be nice if it would look something like the following:\r\n\r\n```\r\nID             IMAGE         COMMAND                CREATED        STATUS      COMMENT     SIZE\r\n bb8f8d1b2ea0   base:latest   /bin/bash              2 hours ago    Exit -127               22K (total 170M)\r\n 2d358ce51d87   base:latest   /bin/bash              5 hours ago    Exit 0                  160K (total 169M)\r\n a13f4ba6204a   base:latest   /bin/bash              5 hours ago    Exit 0                  160K (total 169M)\r\n 59bd80f6f359   base:latest   /bin/bash              5 hours ago    Exit 0                  100K (total 169M)\r\n 65559fd8e242   base:latest   -i -t /bin/bash        5 hours ago    Exit 127                400K (total 169M)\r\n a18f1dfef7ca   base:latest   /bin/sh -c while tru   23 hours ago   Exit -127               169M (total 169M)\r\n```\r\n\r\n","Thatcher, the space is indeed not physically used. Eg. you could deploy 100\r\nsuch containers, it would *not* cause 100*170MB to be written to disk.\r\n\r\n\r\nOn Fri, Apr 12, 2013 at 10:30 AM, Thatcher \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Just my 2ct but I'd suggest using not using the word 'combined' or 'total'\r\n\u003e instead of 'virtual'. Reasoning behind that is that virtual suggests the\r\n\u003e space is not physically used. For example that the space on disk is freed\r\n\u003e when the image is not running.\r\n\u003e\r\n\u003e I think it would be nice if it would look something like the following:\r\n\u003e\r\n\u003e ID             IMAGE         COMMAND                CREATED        STATUS      COMMENT     SIZE\r\n\u003e  bb8f8d1b2ea0   base:latest   /bin/bash              2 hours ago    Exit -127               22K (total 170M)\r\n\u003e  2d358ce51d87   base:latest   /bin/bash              5 hours ago    Exit 0                  160K (total 169M)\r\n\u003e  a13f4ba6204a   base:latest   /bin/bash              5 hours ago    Exit 0                  160K (total 169M)\r\n\u003e  59bd80f6f359   base:latest   /bin/bash              5 hours ago    Exit 0                  100K (total 169M)\r\n\u003e  65559fd8e242   base:latest   -i -t /bin/bash        5 hours ago    Exit 127                400K (total 169M)\r\n\u003e  a18f1dfef7ca   base:latest   /bin/sh -c while tru   23 hours ago   Exit -127               169M (total 169M)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/22#issuecomment-16306137\u003e\r\n\u003e .\r\n\u003e","FWIW, the golden standard of filesystems will display \"USED\" and \"REFER\"\nfor each filesystem.\n\"USED\" = size of rw layer\n\"REFER\" = total size of the data referenced to by the filesystem (~rw +\neverything below)","Why did Solomon Shykes close this without any comment?  Is this resolved?  Is there a way to see container layer sizes?","Hi @sleaze ,\r\n\r\nThis was implemented 3 years ago in #594.","Fixed in fb350e0c7705850cc78e1dc1dc63b56aca06c3cc","The current -r flag is insufficient for a production setup. Docker should *out of the box* auto-detect which containers need to be restarted, without having to start it in a special \"recovery\" mode.\r\n","This is scheduled for 0.7.","@vieux Isn't this fixed by #1832?","@unclejack As far as I know, #1832 is for starting containers that were previously running when starting the Docker daemon. This issue is about restarting containers when they quit.",":+1:\r\nI spend some thoughts around that and I think docker should restart a container at least if the command returned != 0.\r\nTo avoid crash looping, I would suggest to add a restart counter with some limit. This limit should be shown in the ps output and exposed via the api so it can be used for monitoring.","+1 @discordianfish ","+1,000 @discordianfish ... This would would be much more convenient than using supervisor for doing the job! ","@discordianfish one thing I was wondering is how to prevent that for one shot commands that should not be restarted (and perhaps have side effects which even make it harmful to restart them).\r\n\r\nOn Sat, Jan 25, 2014 at 9:08 AM, sreuter \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e +1,000 @discordianfish ... This would would be much more convenient than using supervisor for doing the job! \r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/26#issuecomment-33293871","Some possible scenarios:\r\n\r\n1) running a one-off command in the foreground\r\n2) running a long-running command in the foreground\r\n3) running a one-off command as a daemon\r\n4) running a long-running command as a daemon\r\n\r\nFor (1), you almost definitely don't want it to auto-restart. For (2) you probably don't want to - you are probably running the command inside another process manager such as supervisord or upstart which will manage that for you.\r\n\r\nFor (3) you *might* want it to auto restart if it failed, but you would want it to be opt-in so you can confirm that the command is safe to run twice. For (4) you probably want it to auto-restart.\r\n\r\nIt feels like it should be an optional switch to `docker run`. I don't think it should be the default because there's no way to tell if a daemon is a long running process or not, and restarting a one-off process could potentially be dangerous. It probably shouldn't be tied to the `-d` flag because you might want to use it either in the foreground or as a daemon.","I think we have the following options:\r\n\r\n1) restart every command returning != 0\r\n2) restart every command returning != 0 if running in background\r\n3) restart every command if flag X is given (maybe have another flag to restart only if returning !=0 )\r\n\r\nIf we want to prevent on shot commands in the background from being restarted by default even if they return != 0, we need go for 3).\r\nI don't like that very much since usually you have long running jobs that should be restarted and forgetting about that option could be harmful as well. I guess the question is what's more likely: \r\n- People forgetting to explicitly make their containers restart and harm caused by them being down or \r\n- People forgetting that by default every command which exits != 0 will get restarted and harm caused by that\r\n\r\nBut either way this would be a big improvement.","My mental model of using `docker run` without `-d` is as if I were just running a command in a shell. Automatically restarting would certainly confuse that understanding. These sorts of one-off commands are often repetitively run by a person at a command line and make no sense to automatically restart. They are going to forget to pass a flag.\r\n\r\nAutomatically restarting when running with `-d` and exit code != 0 could work. Though it'd need an extra flag to disable that behaviour.\r\n\r\nIt's also worth thinking about how containers automatically restarting will affect the initial experience of using Docker (\"why does `docker run ubuntu echo hello world` never stop?\"). Even for exit code != 0 (\"why does my process infinitely print out errors?\").","The problem is that on the server side, where we do the restart, we don't know if you passed `-d` on the cli or not.  Attach/detach is a cli only feature and does not change anything on the server side.  It all looks the same.\r\n\r\nIf we were to say only restart processes that are meant to be demonized and returns with a non zero exit code, and that the user did not request to be stopped/killed/whatever, we would have to send a flag to the daemon saying that this container is meant to be attached or not.\r\n\r\nThen we have the problem that you run a container without `-d`  and detach and expect it to keep running and get restarted if it dies.  \r\n\r\nMy vote is to have an `--autorestart` flag, similar to how you have to tell supervisor to autorestart your process if it dies, to tell docker to manage the container.  \r\n\r\nThe default value for this will need to be decided, i think it should be false.  I don't think it is a big deal to force a user to specify that they want this container to be auto restarted because it will reduce a lot more issue than if this were true you don't know why this container keeps on living forever.  ","For auto restarting, I have to wonder whether relying on upstart/systemd to manage this wouldn't be a better option, and a docker command like \"docker install \u003cimage\u003e \u003crun config\u003e -as \u003csystem.unit.filename\u003e\" wouldn't end up being the better path.  Deciding to auto restart feels more like a system service option than a command line option - after all, isn't this what these system processes were designed to do?","@smarterclayton We already have the ability to let process managers monitor the process.  It was part of the host integration PR.  \r\n\r\nI am all for keeping docker as small as possible and integrating with external tools, loggers, process monitors, but I also can see the need for docker to provide good defaults and a feature set to users.\r\n\r\nAs for external process managers I'm using supervisor just fine and we also have a script to auto generate init and systemd configs in the contrib part of the repo.\r\n\r\n\r\n```bash\r\n[program:skydock]\r\ncommand=docker start -a skydock\r\nautostart=true\r\nautorestart=true\r\nstdout_logfile=/var/log/docker/skydock.log\r\nredirect_stderr=true\r\nnumprocs=1\r\n```","I guess I was thinking along a different line - allowing the client or daemon to translate an image definition directly into a systemd unit, such that at \"start\" time of the service docker is used solely to initialize the container namespace, but not be resident or active for the remainder of the service call.  Some of the complexity I'm thinking of is systemd socket activation where docker acting as a network proxy adds a layer of indirection that isn't truly necessary, or needing the daemon to be active all the time (vs being only running on demand to create / commit containers).  \r\n\r\n","I'd like to +1 Michael Crosby's suggestion of adding an ```--autorestart``` option to the run command.\r\n\r\nI currently use supervisor to monitor a container and restart that container if an exit code other than 0 is returned. I accomplish this by creating the container (docker run -n test-container some-image), stopping the container (docker stop test-container) and then starting the container via supervisor:\r\n\r\n```\r\n[program:test-container]\r\ncommand=docker start -a test-container\r\nautostart=true\r\nautorestart=unexpected\r\n```\r\n\r\nThe initial work of starting and stopping the container is the necessary evil that accompanies the use of a process manager in conjunction with docker. While this solutions \"works\" I would argue that \"container management\" is a sufficiently-unique animal that merits its own set of tooling. \r\n\r\nThe ideal solution would be the ability to create a container that auto-restarts. The container should be able to auto-restart if an exit code other than 0 is supplied as follows:\r\n\r\n    docker run -autorestart unexpected -name test-container my-image\r\n\r\nThe container should be able to always auto-restart by supplying \"-autorestart true\", and the container should default to \"-autorestart false\". This would, not only eliminate the need to introduce a process manager for container management, it would also be a much more efficient and elegant solution. \r\n\r\n","@mbonano \r\n\r\nIf docker were to do this for simple cases I think that flag would work but I really am in favor of letting a supervisor do this because that is what they are made for. ","@crosbymichael To me docker is (beside other things) a container supervisor. If we do things like restarting containers after reboot, we should also restart them on containers crashes.\r\n\r\nBeside that, I imaging the docker api to be the only interaction point with a system:\r\nBootstrapping a system and installing docker is trivial and can be easily reproduced ( -\u003e all system are the same). But managing supervisor config (container dependent state outside of a container) on a per host basis (on this host, those supervisor configs need to be written) causes exactly that configuration management nightmare I hope to escape :)","As docker evolves, I believe container management will become an increasing concern, especially if functionality like cluster support is to ever exist in the technology. The day where a cluster of containers running across several docker host machines is supported, the supervisor solution becomes completely unmanageable. Until then, I will have to write a home-grown container management solution and hope that the tooling one day renders my solution obsolete. ","Any proposal for a flag name? `--autorestart` ? ","+1 for ```--autorestart```","+1 from the other side of the table ;-)","+1 for `--autorestart`. Since docker already has the ability to restart containers on machine reboot, restarting containers on unexpected termination fits nicely under the existing management responsibilities of the daemon.","Overly pedantic, perhaps, but how about `--auto-restart`?","The pedant in me also says +1 to that :)","+1","`+1` to `--auto-?restart`; I'm more worried about ensuring it defaults to `false`, even if `-d` was given, than whether or not it has a dash in the name.\r\n\r\nCan we roll in `contrib/host-integration/manager` somehow? \r\n\r\n    --auto-restart=false # default\r\n    --auto-restart=true # docker re-starts the container if it exits without docker being involved\r\n    --auto-restart=supervisord # generate supervisord script and rely on that instead\r\n    --auto-restart=upstart # …\r\n    --auto-restart=initd # …\r\n","Supervisord is great for process management. However, I can see auto restart being useful for something Supervisord can't assist with.\r\n\r\nI'd really like to be able to limit the memory of a container, and have the container restart if the limit has been reached. Currently, when the memory limit is reached, the containers just exit with a non-zero status code. Supervisord wouldn't be able to restart processes in this case because Supervisord itself stops running.\r\n\r\nPerhaps I'm doing something wrong?","I just read some people's posts about managing individual containers outside of Docker using Supervisord on the host. I wasn't aware that was possible. Even so, that seems \"hacky.\"","+1 to this. I'm evaluating Docker and tooling/monitoring around crashing containers is a requirement for any serious production use.","Tentatively scheduling for 0.7.","This has been implemented in 0.6.5. github.com/dotcloud/docker/blob/v0.6.5/CHANGELOG.md","This means that docker must be able to detect if it's already running in daemon mode, and if so, switch to client mode transparently.","Related question: should attached mode (-a) be the default? It would make it simpler to get started in standalone mode. Detached mode would be an advanced feature you discover once you're excited about standalone mode.","`docker` [is already the name of a package](http://packages.ubuntu.com/precise/docker) in the Ubuntu package list, unfortunately. I'm not sure whether PPAs can introduce packages with names colliding with standard packages. So it might have to be a different name.","According to [/deb/debian/control](https://github.com/dotcloud/docker/blob/0e0d76b7acc8d75f518a91d026a57d6b8410d5f3/deb/debian/control), the package name is currently `dotcloud-docker`.","And we are going to change it to lxc-docker :)\r\n\r\n\r\nOn Fri, Mar 22, 2013 at 9:43 AM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e According to /deb/debian/control\u003chttps://github.com/dotcloud/docker/blob/0e0d76b7acc8d75f518a91d026a57d6b8410d5f3/deb/debian/control\u003e,\r\n\u003e the package name is currently dotcloud-docker.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/30#issuecomment-15307586\u003e\r\n\u003e .\r\n\u003e","I saw the following email this morning. copying here for posterity \r\n\r\nAccepted:\r\n OK: lxc-docker_1.orig.tar.gz\r\n OK: lxc-docker_1.debian.tar.gz\r\n OK: lxc-docker_1.dsc\r\n     -\u003e Component: main Section: misc\r\n\r\nlxc-docker (1) precise; urgency=low\r\n\r\n  * Initial release\r\n\r\n--\r\nhttps://launchpad.net/~dotcloud/+archive/lxc-docker\r\nYou are receiving this email because you are the uploader of the above\r\nPPA package.","Hi, I'm a Debian Developer. I'm willing to sponsor this. paultag@debian.org\r\n\r\nThanks!","I'm making this issue the official place to discuss packaging of docker *on Ubuntu*. Packaging on Debian is discussed on #251.\r\n\r\nI changed the title to make this more clear.","Ubuntu is sync'd from Debian. Getting it into Debian gets it into Ubuntu by doing a `requestsync'. I can also help with that; I'm an Ubuntu member too.","I had been working on this somewhat out-of-band from the rest of the participants here, not realizing this issue was logged. I have a working package that passes lintian in this PPA: https://launchpad.net/~synack/+archive/docker, the source repository organized in a way that git-buildpackage recognizes, is available here: https://github.com/synack/docker (with the debian and upstream branches respectively)\r\n\r\nAside from needing to be renamed to lxc-docker, the biggest issue is that it essentially replaces the Makefile with a patch. Not really sure what the right approach to fix that is.","@synack: We are using /packaging to make multi distro packaging clean and modularized. For Ubuntu is /packaging/ubuntu. Take a look at the packaging branch.","With @mzdaniel's last pull request #421, I feel comfortable I will be able to publish .debs to our PPA at each release.\r\n\r\nNext steps:\r\n\r\n1) For new issues or requests related to packaging/ubuntu, please open a new issue\r\n\r\n2) How do we make this an official package? :)","Like I said, through Debian with requestsync.","Yeah, sorry I meant \"let's make a separate issue to track this\". Thanks again for offering help with that part.","This was closed by #49 ","Fixed by pull request #64 \r\nAUFS discard whiteout files (.wh. prefix) on RO branches.\r\nAt the mount, perform a diff on the origin image and apply them on the newly created container","I'll give this one a try.","I'll test this for a little longer then send a pull request.","Thanks for looking at this, @nictuku. I'm interested in support UDP port forwarding too. Thinking about receiving syslogs and SNMP traps in a container.","I don't think I will be able to continue this. The patch I had didn't\nreally work, by the way.","Alright, just had a quick chat with @creack and @samalba, I'm stealing that!\r\n\r\nI think the most straightforward and intuitive way of implementing that is to extend the port notation a little bit:\r\n\r\n- tcp/22;\r\n- udp/69;\r\n- and 22 will be interpreted as tcp/22.","+1.\n\nBy the way, since the \"official\" notation is 22/tcp, maybe we should just\nrecognize both styles. Not a big deal, though.","You know what, I actually checked /etc/services, noticed that and asked people on different IRC channels. proto/port seems more intuitive to me, but it looks like most people don't care.\r\n\r\nAlso, I'm not sure if I should accept actual service name instead of ports numbers (probable yes?).","Yeah, I know, this whole 22/tcp vs. tcp/22 is a bit silly.\nRegarding service names, I don't know. While 99.99% of the machines out\nthere will have a standard /etc/services, it *might* cause problems (i.e.\nbreak repeatability), so maybe we should rather be explicit here. I wonder\nwhat @shykes would think about this?","Yes, explicit is better. We should avoid using /etc/services completely IMO. Otherwise it might break portability of containers.\r\n\r\n\r\nKeep in mind that we're also going to change the port spec to support PUBLIC:PRIVATE. The question is, will it be tcp/22:tcp/22 or tcp/22:22 ?\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Mon, Jun 10, 2013 at 11:48 AM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Yeah, I know, this whole 22/tcp vs. tcp/22 is a bit silly.\r\n\u003e Regarding service names, I don't know. While 99.99% of the machines out\r\n\u003e there will have a standard /etc/services, it *might* cause problems (i.e.\r\n\u003e break repeatability), so maybe we should rather be explicit here. I wonder\r\n\u003e what @shykes would think about this?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/33#issuecomment-19218362","Ok for /etc/services, that makes sense.\r\n\r\nOr 22:22/tcp, I think we can eliminate tcp/22:tcp/22 right away, the protocol can't be different on each side.","Time for a quick update here.\r\n\r\nI finally managed to get a fully working implementation of UDP support, it's in a branch on my fork: [lopter/docker/udp-support](https://github.com/lopter/docker/tree/udp-support).\r\n\r\nI chose the suffix protocol notation, i.e: 22/tcp. The output of `docker inspect` changed as explained [here](https://groups.google.com/d/topic/docker-club/n6SEyH2WCao/discussion) on the mailing list.\r\n\r\nThe next steps are:\r\n\r\n- work on a new docker-ut image that includes socat and is built from a Dockerfile;\r\n- make the code better, network.go is becoming a little bit messy;\r\n- support for proxying on ::1? (unfortunately you can't do dual stack in Go on Linux, the socket option is not exposed).\r\n\r\nI'm also using a doubly linked list to maintain a connection tracking table to correctly proxy UDP traffic. What I really need is a map, where I can use a net.UDPAddr object as the key. If anybody knows something I could use here, I'm interested.","@lopter can you tell us more ? I don't het the `What I really need is a map, where I can use a net.UDPAddr object as the key`","@vieux yes, let me explain what's the deal with the udp proxying problem.\r\n\r\nFirst, the reason why we have to proxy the traffic between localhost:frontend-port and container:backend-port is because Netfilter doesn't work properly on the loopback interface and DNAT iptable rules aren't applied there.\r\n\r\nIn userland, forwarding the traffic between localhost:frontend-port and container:backend-port looks like this:\r\n\r\n```python\r\n\r\nimport socket\r\n\r\nfrontend = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 17)\r\nfrontend.bind((\"127.0.0.1\", 49153))\r\nbackend = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 17)\r\nbackend.connect((\"container\", backend_port))\r\nwhile True:\r\n    buf = frontend.recv(4096)\r\n    backend.send(buf)\r\n```\r\n\r\nThis is straightforward. However, if the process listening on container:backend-port is replying it doesn't work, because the dest address of that packet will be the address on which the backend socket is bound, and from that, there is no way to find the original sender address here.\r\n\r\nThe correct way to do it is to open one socket per sender and keep a mapping between each sender and its socket. Then, the code looks like this:\r\n\r\n```python\r\n\r\nimport gevent\r\nimport gevent.monkey; gevent.monkey.patch_socket()\r\nimport socket\r\n\r\ndef forward_back(frontend, client, backend):\r\n    while True:\r\n        buf = backend.recv(4096)\r\n        frontend.sendto(buf, client)\r\n\r\nfrontend = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 17)\r\nfrontend.bind((\"127.0.0.1\", 49153))\r\nconntrack_table = {}\r\nwhile True:\r\n    buf, sender = frontend.recvfrom(4096)\r\n    if sender not in conntrack_table:\r\n        conntrack_table[sender] = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, 17)\r\n        conntrack_table[sender].connect((\"container\", backend_port))\r\n        gevent.spawn(forward_back, frontend, sender, conntrack_table[sender])\r\n    conntrack_table[sender].send(buf)\r\n```\r\n\r\nIn Go, the key for the connection tracking table would be a net.UDPAddr, but I can't use it in a map. Since the address is always localhost maybe I could just the port. At first, I didn't like the idea because a single port could point to ::1 or 127.0.0.1, but since Go doesn't support dual stack maybe that would just work (with two tables: one for IPv6 traffic and one for IPv4 traffic).\r\n\r\nLet me know if that makes sense!\r\n","Maybe you will think it's ugly, but\r\n\r\n`net.UDPAddr` has `String()` method, you could write a function which builds the `net.UDPAddr` from the string and use the string representation as key for you map","Yes, that sucks. I'm pretty sure something will emerge when I'll re-factor the whole proxy code. With separate tables for udp4 and udp6 I can use the port as the key.","This should be possible in a plugin. I'm noting it as a use case for the 1.0 plugin api.","Or at least a well documented way to use another tool to do this. I'd love to see less features builtin and more orthogonal tools to support this sort of thing.","I agree this would be great, but should be implemented as a 3d-party tool, or as a plugin with the upcoming plugin API. Happy to discuss this further in the mailing list.","I think this would be great, but should be implemented as a plugin rather than in the core. This will be possible in the 1.0 api.","@kencochrane I've developed something which does that if you want to have a lool :\r\n\r\nhttps://github.com/Soulou/acadock-live-lxc\r\n\r\nThis is a small webservice which watches /sys/fs/cgroup/cpu.. and you can request for the CPU load, or memory usage in realtime.","@Soulou cool, I have also built something similar in the past, it would be cool if we could include it into docker via the 1.0 api when it is released.",":thumbsup: :hamburger:  :thumbsup: ","+1 now that docker 1.0 is released","@miki725 Checkout https://github.com/google/cadvisor for now.","best done with TC? but then you need a new bridge for each container..","I'm not 100% sure, but I think that `tc` could be applied to the veth interfaces.\r\n\r\nAnother possibility is to use `iptables -m limit` (in a limited way).","oh, apparently, with cgroup net_cls you can classify traffic from/to each container and let tc shape that class, no need for multiple bridges.. ","Sorry to dig this up - but what exactly is the current best way of doing this from Docker?\r\n\r\nDo we find the `veth` interface for the Docker container, and apply `tc` rules to it?\r\n\r\nOr we can use the cgroup system directly to set net_cls on the containers, and then apply rules to that?\r\n\r\nAre there any plans for tighter integration of Docker with per-container bandwidth controls?","@victorhooi : there are many ways to do it. Ideally it might have to be bound to network strategies (i.e. the new feature in libcontainer that lets containers have multiple interfaces and different interface types), since one will not  use the same technique to limit traffic on a veth and on a macvlan interface  (even though in that case, tc will get us pretty far). I have no experience with `net_cls` but I wonder what would be possible with it?","FYI: net_cls only sets a classid/flag on outgoing packets so that they can be identified in tc or iptables, ie. not usable to control incoming bandwidth.  \r\n\r\nOn Tuesday 25 March 2014 at 07:16, Jérôme Petazzoni wrote:\r\n\r\n\u003e @victorhooi (https://github.com/victorhooi) : there are many ways to do it. Ideally it might have to be bound to network strategies (i.e. the new feature in libcontainer that lets containers have multiple interfaces and different interface types), since one will not use the same technique to limit traffic on a veth and on a macvlan interface (even though in that case, tc will get us pretty far). I have no experience with net_cls but I wonder what would be possible with it?\r\n\u003e  \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub (https://github.com/dotcloud/docker/issues/37#issuecomment-38513506).\r\n\u003e  \r\n\u003e  \r\n\u003e  ","It does it for many other command as well, not just CmdInspect and CmdImages.","Pre-existing base AMI: I wouldn't count on it (unless Ubuntu starts shipping AMIs with AUFS modules).\r\nAuthoring AMIs is also possible, but it's a pain to do it right. You have to release new AMIs for each new Ubuntu update, for all 3 \"EC2 archs\" (EBS PV, ephemeral PV, EBS HVM) in each region.\r\n\r\nLet me check if we can load the modules from the \"extra\" package even with a \"non-extra\" kernel; it might make things easier.","On Ubuntu 12.04 LTS, this works: \r\n\r\n    apt-get install linux-image-extra-$(uname -r)\r\n\r\nNo need to reboot. Then I was able to successfully install \u0026 run docker.\r\n\r\nNow testing on other versions.\r\n","It also works with 12.10!","However, it doesn't work in 13.04, because I assume that they don't care about keeping all the packages for all the kernel versions in the repository.\r\n\r\nThe situation will almost certainly change after the release of 13.04, and the same trick should be usable then.\r\n\r\nOK, now let's see the simplest way to get it running using UEC etc...","End result: start an Ubuntu EC2 instance (or anything supporting cloud-init), and provide the following as user data:\r\n\r\n    #include\r\n    http://get.docker.io/\r\n\r\nThe instance will automatically execute the `contrib/install.sh` script, which installs required packages and starts docker in daemon mode.\r\n\r\nShould we document that in the main README?","+1 for adding to README. IMHO README should contain all of the \"quick start\" deployments","The official install is now basically a two liner as requested here, for those who have already created a compatible EC2 virtual machine.\r\nAnd for those who don't, we have created a Vagrantfile to make spinning up one with docker very smooth.\r\nBoth path's are documented in the documentation.","Here are some rough notes I gathered over time.\r\n\r\n\r\n$ export DOCKERENV=~/docker\r\n\r\n$ mkdir -p $DOCKERENV/bin\r\n$ cd $DOCKERENV\r\n$ export GOPATH=$DOCKERENV\r\n$ go get github.com/dotcloud/docker\r\n$ ls -al\r\ntotal 24\r\ndrwxrwxr-x  4 chooper chooper  4096 Mar 12 18:21 .\r\ndrwxrwxr-x 50 chooper chooper 12288 Mar 12 18:20 ..\r\ndrwxrwxr-x  3 chooper chooper  4096 Mar 12 18:21 bin\r\ndrwxrwxr-x  3 chooper chooper  4096 Mar 12 18:21 pkg\r\ndrwxrwxr-x  3 chooper chooper  4096 Mar 12 18:21 src\r\n$ cd src/github.com/dotcloud/docker/ \r\n$ git checkout master\r\nSwitched to branch 'master'\r\n$ git status\r\n# On branch master\r\nnothing to commit (working directory clean)\r\n\r\n#Show how to add a remote git repo to a fork\r\n$ git remote add FEATURE_BRANCH ssh://git@github.com/USER/docker; git checkout remotes/USER/FEATURE_BRANCH\r\n\r\n# add the go post commit hook, to clean code (from solomon)\r\ncurl -o .git/hooks/pre-commit https://raw.github.com/edsrzf/gofmt-git-hook/master/fmt-check \u0026\u0026 chmod +x .git/hooks/pre-commit\r\n\r\nBuild docker\r\n-------------------\r\n\r\nbuild docker\r\n^^^^^^^^^^^^\r\n$ cd $DOCKERENV/src/github.com/dotcloud/docker/docker\r\n$ go build\r\n$ ls\r\ndocker  docker.go\r\n\r\n\r\nfrom solomon\r\n************\r\n\r\nmkdir ~/go; export GOPATH=~/go; go get github.com/dotcloud/docker; cd ~/go/src/github.com/dotcloud/docker; git remote add pquerna ssh://git@github.com/pquerna/docker; git checkout remotes/pquerna/FEATURE_BRANCH; sudo -E go run ./dockerd; dockerd.go\r\n\r\nrunning tests:\r\nsudo -E /usr/local/go/bin/go test","For contribution guidelines we want something like\r\n\r\n1. Fork the repo\r\n2. Make changes on your fork in a feature branch\r\n3. Write unit tests for your changes (if needed)\r\n4. Run the full test suite against your change and master\r\n5. update/add any relevant documentation\r\n6. run gofmt to make sure code is formated correctly\r\n7. Add your name to the AUTHORS file \r\n8. submit a pull request explaining what changes you made as clearly as possible, including any issues this pull request might have fixed.\r\n\r\n","I also suggest the following:\r\n- If it's a bugfix branch, name it XXX-something where XXX is the number of the issue\r\n- If it's a feature branch, create an enhancement issue to announce your intentions, and name it the same way\r\n- If a pull request addresses multiple issues, reference them in the pull request (with #XXX)\r\n(If the issues are already referenced in the individual commits, it's OK to not re-reference them in the pull request message)","Volunteer wanted for a pull request incorporating all this","@kencochrane I'm walking through the steps outlined and am on `$ go get github.com/dotcloud/docker`.  Should this repo be our own docker repo?  If so, trying this yields the following:\r\n\r\n$ go get github.com/johncosta/docker\r\nUsername for 'https://github.com': johncosta\r\nPassword for 'https://johncosta@github.com': \r\nUsername for 'https://github.com': johncosta\r\nPassword for 'https://johncosta@github.com': \r\ncd .; git clone https://github.com/dotcloud/docker /Users/jcosta/docker/src/github.com/dotcloud/docker\r\nCloning into '/Users/jcosta/docker/src/github.com/dotcloud/docker'...\r\nerror: The requested URL returned error: 403 while accessing https://github.com/dotcloud/docker/info/refs\r\nfatal: HTTP request failed\r\npackage github.com/johncosta/docker\r\n\timports github.com/dotcloud/docker/auth: exit status 128\r\npackage github.com/johncosta/docker\r\n\timports github.com/dotcloud/docker/fs\r\n\timports github.com/dotcloud/docker/fs\r\n\timports github.com/dotcloud/docker/fs: import \"github.com/dotcloud/docker/fs\": cannot find package\r\npackage github.com/johncosta/docker\r\n\timports github.com/dotcloud/docker/fs\r\n\timports github.com/dotcloud/docker/future\r\n\timports github.com/dotcloud/docker/future\r\n\timports github.com/dotcloud/docker/future: import \"github.com/dotcloud/docker/future\": cannot find package\r\npackage github.com/johncosta/docker\r\n\timports github.com/dotcloud/docker/fs\r\n\timports github.com/dotcloud/docker/future\r\n\timports github.com/dotcloud/docker/rcli\r\n\timports github.com/dotcloud/docker/rcli\r\n\timports github.com/dotcloud/docker/rcli: import \"github.com/dotcloud/docker/rcli\": cannot find package\r\n\r\nCould you clarify?","@johncosta \r\nno it should be the master repo 'go get github.com/dotcloud/docker'\r\n\r\nyou should have access to dotcloud/docker after you put your github username and password","I think this has been done reasonably well and can be closed.","/cc @unclejack @johncosta ","This is cool and I want it very bad. Not a core feature of docker though, so I'm closing this issue. 100% supportive of implementing this as a contrib tool or plugin, and discussing it on irc or the mailing list.\r\n","@shykes Do you know of any community projects that are trying to do this?","@shykes any news about this?","Added a wrapper script for building an AMI image based on a Dockerfile. This is a work in progress, judge it as such.\r\n\r\nhttps://github.com/mickep76/docker-build-ami\r\nhttps://pypi.python.org/pypi/docker-build-ami/0.1.3","acknowledge @fernandoneto","why not just normal redirection? ```\u003e /dev/null``` to only see stderr and ```2\u003e/dev/null``` to only see stdout?","yeah, let's be a good unix app and not reinvent standard infrastructure. ","I agree this seems like the way to go.\r\n\r\nWhat about in the future remote API - is there interest in getting\r\n*programmatic* access to stdout without stderr or vice-versa?\r\n\r\n\r\nOn Mon, Mar 11, 2013 at 7:00 PM, Jeff Lindsay \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e yeah, let's be a good unix app and not reinvent standard infrastructure.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/45#issuecomment-14754641\u003e\r\n\u003e .\r\n\u003e","Oh I think absolutely.\r\n\r\n\r\nOn Mon, Mar 11, 2013 at 9:12 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I agree this seems like the way to go.\r\n\u003e\r\n\u003e What about in the future remote API - is there interest in getting\r\n\u003e *programmatic* access to stdout without stderr or vice-versa?\r\n\u003e\r\n\u003e\r\n\u003e On Mon, Mar 11, 2013 at 7:00 PM, Jeff Lindsay \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e\r\n\u003e \u003e yeah, let's be a good unix app and not reinvent standard infrastructure.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/45#issuecomment-14754641\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/45#issuecomment-14754936\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","i would not like to see logs through the remote api, imo it should just be for management, a simple human readable (think redis) api which you could telnet/nc to. using syslog or something should be much more efficient for log distribution, it shouldn't be a part of docker. if you mix logs in there you need a multiplexing/framing protocol..  \r\n\r\n\r\n\r\nOn Tuesday 12 March 2013 at 10:12, Solomon Hykes wrote:\r\n\r\n\u003e I agree this seems like the way to go.  \r\n\u003e  \r\n\u003e What about in the future remote API - is there interest in getting  \r\n\u003e *programmatic* access to stdout without stderr or vice-versa?  \r\n\u003e  \r\n\u003e  \r\n\u003e On Mon, Mar 11, 2013 at 7:00 PM, Jeff Lindsay \u003cnotifications@github.com (mailto:notifications@github.com)\u003ewrote:  \r\n\u003e  \r\n\u003e \u003e yeah, let's be a good unix app and not reinvent standard infrastructure.  \r\n\u003e \u003e  \r\n\u003e \u003e —  \r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/45#issuecomment-14754641\u003e  \r\n\u003e \u003e .  \r\n\u003e  \r\n\u003e  \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub (https://github.com/dotcloud/docker/issues/45#issuecomment-14754936).","I also agree with Carl and would love a simple human readable Redis-style\r\nremote management interface. But I also want access to streams. So this is\r\nhow I think it should work. This is sort of how Heroku works behind the\r\nscenes and was sort of how the old Python Docker prototype worked that I\r\nworked on.\r\n\r\nThe remote interface wouldn't let you interact with a running container's\r\nstreams, but it could \"mount\" a process to a (random) port which you could\r\nthen connect to for raw socket access to a container's stdin/stdout. Note\r\nthat sockets don't map directly to stdin/stdout/stderr, but that in a\r\nterminal you always ultimately only have two anyway. So you can control\r\nwhether you see stdout or stderr by including redirection within the\r\ncommand argument of \"docker run\".\r\n\r\nI personally prefer to think in terms of more general \"streams\" as opposed\r\nto \"logs\", and this provides a very simple and accessible interface that\r\ndoesn't bother with the slightly more complicated and archaic but also\r\n\"log\"-oriented model that you'd get implementing something like syslog.\r\n\r\nDoes that make sense?\r\n\r\n\r\nOn Mon, Mar 11, 2013 at 9:19 PM, Carl Hörberg \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e i would not like to see logs through the remote api, imo it should just be\r\n\u003e for management, a simple human readable (think redis) api which you could\r\n\u003e telnet/nc to. using syslog or something should be much more efficient for\r\n\u003e log distribution, it shouldn't be a part of docker. if you mix logs in\r\n\u003e there you need a multiplexing/framing protocol..\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e On Tuesday 12 March 2013 at 10:12, Solomon Hykes wrote:\r\n\u003e\r\n\u003e \u003e I agree this seems like the way to go.\r\n\u003e \u003e\r\n\u003e \u003e What about in the future remote API - is there interest in getting\r\n\u003e \u003e *programmatic* access to stdout without stderr or vice-versa?\r\n\u003e \u003e\r\n\u003e \u003e\r\n\u003e \u003e On Mon, Mar 11, 2013 at 7:00 PM, Jeff Lindsay \u003cnotifications@github.com(mailto:\r\n\u003e notifications@github.com)\u003ewrote:\r\n\u003e \u003e\r\n\u003e \u003e \u003e yeah, let's be a good unix app and not reinvent standard\r\n\u003e infrastructure.\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e —\r\n\u003e \u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/45#issuecomment-14754641\u003e\r\n\u003e \u003e \u003e .\r\n\u003e \u003e\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub (\r\n\u003e https://github.com/dotcloud/docker/issues/45#issuecomment-14754936).\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/45#issuecomment-14755084\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","Yes, it does make sense to think in terms of streams. In addition to logs,\r\nthe API will need to expose other streams as well: metrics and activity\r\nevents, for example (not to mention inbound stdin streams for interactive\r\nmode). And if possible it should be well integrated with the\r\nrequest-response part of the API. So syslog is not a great primitive.\r\nHowever it should be fairly easy to write a syslog adaptor which consumes\r\ndocker streams.\r\n\r\nI have a specific design in mind for supporting streams in the api, based\r\nstrongly on our experience at dotCloud. It's not exactly what you describe,\r\nJeff, but it's close enough. Until I have time to write something down, I'm\r\nhappy to talk about it over beer :)\r\n\r\n\r\n\r\nOn Mon, Mar 11, 2013 at 7:39 PM, Jeff Lindsay \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I also agree with Carl and would love a simple human readable Redis-style\r\n\u003e remote management interface. But I also want access to streams. So this is\r\n\u003e how I think it should work. This is sort of how Heroku works behind the\r\n\u003e scenes and was sort of how the old Python Docker prototype worked that I\r\n\u003e worked on.\r\n\u003e\r\n\u003e The remote interface wouldn't let you interact with a running container's\r\n\u003e streams, but it could \"mount\" a process to a (random) port which you could\r\n\u003e then connect to for raw socket access to a container's stdin/stdout. Note\r\n\u003e that sockets don't map directly to stdin/stdout/stderr, but that in a\r\n\u003e terminal you always ultimately only have two anyway. So you can control\r\n\u003e whether you see stdout or stderr by including redirection within the\r\n\u003e command argument of \"docker run\".\r\n\u003e\r\n\u003e I personally prefer to think in terms of more general \"streams\" as opposed\r\n\u003e to \"logs\", and this provides a very simple and accessible interface that\r\n\u003e doesn't bother with the slightly more complicated and archaic but also\r\n\u003e \"log\"-oriented model that you'd get implementing something like syslog.\r\n\u003e\r\n\u003e Does that make sense?\r\n\u003e\r\n\u003e\r\n\u003e On Mon, Mar 11, 2013 at 9:19 PM, Carl Hörberg \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e\r\n\u003e \u003e i would not like to see logs through the remote api, imo it should just\r\n\u003e be\r\n\u003e \u003e for management, a simple human readable (think redis) api which you\r\n\u003e could\r\n\u003e \u003e telnet/nc to. using syslog or something should be much more efficient\r\n\u003e for\r\n\u003e \u003e log distribution, it shouldn't be a part of docker. if you mix logs in\r\n\u003e \u003e there you need a multiplexing/framing protocol..\r\n\u003e \u003e\r\n\u003e \u003e\r\n\u003e \u003e\r\n\u003e \u003e On Tuesday 12 March 2013 at 10:12, Solomon Hykes wrote:\r\n\u003e \u003e\r\n\u003e \u003e \u003e I agree this seems like the way to go.\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e What about in the future remote API - is there interest in getting\r\n\u003e \u003e \u003e *programmatic* access to stdout without stderr or vice-versa?\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e On Mon, Mar 11, 2013 at 7:00 PM, Jeff Lindsay \u003c\r\n\u003e notifications@github.com(mailto:\r\n\u003e \u003e notifications@github.com)\u003ewrote:\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e \u003e yeah, let's be a good unix app and not reinvent standard\r\n\u003e \u003e infrastructure.\r\n\u003e \u003e \u003e \u003e\r\n\u003e \u003e \u003e \u003e —\r\n\u003e \u003e \u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e \u003e https://github.com/dotcloud/docker/issues/45#issuecomment-14754641\u003e\r\n\u003e \u003e \u003e \u003e .\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e —\r\n\u003e \u003e \u003e Reply to this email directly or view it on GitHub (\r\n\u003e \u003e https://github.com/dotcloud/docker/issues/45#issuecomment-14754936).\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/45#issuecomment-14755084\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e --\r\n\u003e Jeff Lindsay\r\n\u003e http://progrium.com\r\n\u003e\r\n\u003e —\r\n\u003e\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/45#issuecomment-14755599\u003e\r\n\u003e .\r\n\u003e\r\n\u003e","my idea was not to implement syslog, but rather just pipe the output to \"logger\" or something.. then rsyslog on the host machine can either log it or forward it.. ","Got it. Yes, we will make this possible.\r\n\r\n\r\nOn Mon, Mar 11, 2013 at 9:08 PM, Carl Hörberg \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e my idea was not to implement syslog, but rather just pipe the output to\r\n\u003e \"logger\" or something.. then rsyslog on the host machine can either log it\r\n\u003e or forward it..\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/45#issuecomment-14757593\u003e\r\n\u003e .\r\n\u003e","+1 - [treat logs as streams](http://www.12factor.net/logs), not files. \r\n\r\n@shykes \r\n\u003e I have a specific design in mind for supporting streams in the api, based\r\n\u003e strongly on our experience at dotCloud. [...] Until I have time to write \r\n\u003e something down, [...]\r\n\r\ni'm looking forward to this, as eventually i plan to integrate docker log streaming with [logyard](http://www.activestate.com/blog/2012/11/stackatos-new-and-improved-log-streaming-logyard-20). at minimum, i'd expect something like the following for retrieving logs:\r\n\r\n```\r\n$ HOST=$(docker inspect eb345s | json NetworkSettings.IpAddress)\r\n$ PORT=$(docker inspect eb345s | json Logs.Port)\r\n$ nc -v $HOST $PORT\r\n\u003c\u003c ... stream of process output ... \u003e\u003e\r\n```\r\n\r\na simple tcp client is all that is required to read logs, and further process them (by sending it to external log aggregators, for instance).","This is addressed in #725 (don't mix stdout and stderr in docker run in attached mode)","Merged","Closing ticket, this has been fixed.","I tested running 'echo hello' with different limits, here's what I get.\r\n\r\n```bash\r\nhellolimit() {\r\n    for i in $(seq ${2:-1}); do\r\n        C=$(docker run -m=$1 base:e9cb4ad9173245ac /bin/echo hello);\r\n        docker wait $C;\r\n        docker logs $C;\r\ndone;\r\n }\r\n```\r\n\r\n```bash\r\n$ hellolimit 0\r\n0\r\nhello\r\n```\r\n\r\n```bash\r\n$ hellolimit 65536\r\n255\r\nlxc-start: write /sys/fs/cgroup/memory//lxc/369c05be/memory.limit_in_bytes : Device or resource busy\r\nlxc-start: failed to setup the cgroups for '369c05be'\r\nlxc-start: failed to setup the container\r\nlxc-start: invalid sequence number 1. expected 2\r\nlxc-start: failed to spawn '369c05be'\r\nlxc-start: Device or resource busy - failed to remove cgroup '/sys/fs/cgroup/cpuset//lxc/369c05be'\r\n```\r\n\r\n```bash\r\n$ hellolimit 65537\r\n137\r\n```\r\n\r\n```bash\r\n$ hellolimit 548099 5\r\n0\r\nhello\r\n1\r\n2013/03/12 08:53:04 Unable to set up networking: signal 9\r\n1\r\n2013/03/12 08:53:04 Unable to set up networking: signal 9\r\n0\r\nhello\r\n1\r\n2013/03/12 08:53:06 Unable to set up networking: signal 9\r\n```\r\n\r\n","Thanks for the contribution!\r\n\r\nYou can use ioutil.Discard instead of os.Open(\"/dev/null\") \r\n\r\nIt's in package io/ioutil\r\n","Also, how does it behave when you pin the image version?\r\n\r\n* If I run 'docker run base:NO_SUCH_ID' does it try running it even if another ID is available?","The run fails because \"dotcloud pull\" fails:\r\n\r\n    chooper@chimay:~/projects/docker/bin$ ./docker run -a base:d34db33f echo \"hello world\"\r\n    Downloading from base:d34db33f\r\n    Unpacking to base:d34db33f\r\n    curl: (6) Couldn't resolve host 'base'\r\n    base:d34db33f:e3b0c44298fc1c14\r\n    lxc-start: No such file or directory - failed to mount 'proc' on '/usr/lib/x86_64-linux-gnu/lxc//proc'\r\n    lxc-start: failed to setup the mount entries for '87926c6f'\r\n    lxc-start: failed to setup the container\r\n    lxc-start: invalid sequence number 1. expected 2\r\n    lxc-start: failed to spawn '87926c6f'\r\n\r\nI'll add better error checking for CmdRun and open a separate issue for CmdPull:\r\n\r\n    chooper@chimay:~/projects/docker/bin$ ./docker pull base:d34db33f\r\n    Downloading from base:d34db33f\r\n    Unpacking to base:d34db33f\r\n    curl: (6) Couldn't resolve host 'base'\r\n    base:d34db33f:e3b0c44298fc1c14\r\n","Don't merge this pull request yet. I just noticed that rev 8e0986c breaks the progress bar on \"docker pull\"","This is ready for review","I made those last improvements I wanted to make. I didn't remove \"curl\" from the requirements in the README because we might be telling people to download installer scripts that way.","Still fighting with unit tests, I'll ping you when this is ready for re-review/merge","Unit tests passing, except for layers_test which appears to be broken in master as well.","Turns out this is because non-200 status codes do not result in http.Get returning an error.  Renaming this issue.\r\n\r\nRef: http://golang.org/pkg/net/http/#Client.Get","This will be fixed by #49 ","This was closed by #49 ","With modern filesystems, the only point of hashing is to avoid shocking the careless sysadmin when he issues \"ls\" in the wrong directory :-)\r\n\r\nIn other words, you can have millions of files in a single directory without performance degradation.\r\n\r\nHowever, some kind of indexed database can definitely help.","wait, what? most filesystems don't have a files per directory limit today, and isn't a clean up procedure, or to not log to the filesystem a better idea than to bloat with hashing or sqlite?  \r\n\r\n\r\n\r\nOn Tuesday 12 March 2013 at 11:51, jpetazzo wrote:\r\n\r\n\u003e With modern filesystems, the only point of hashing is to avoid shocking the careless sysadmin when he issues \"ls\" in the wrong directory :-)\r\n\u003e In other words, you can have millions of files in a single directory without performance degradation.\r\n\u003e However, some kind of indexed database can definitely help.\r\n\u003e  \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub (https://github.com/dotcloud/docker/issues/51#issuecomment-14757212).","Ok :-)","To defend the feature, I'd say having several thousands of directories in /var/lib/docker will make debugging super hard (a simple ls will be getting hard to run). And without an index, it's impossible to limit the \"docker ps\" command to the last 50 containers without walking the entire directory for instance.\r\n\r\nDo you guys have suggestion? I'd be glad to open another issue.","there's a limit to how many containers you can ran simultaneous on a server, even with say 128gb ram you can't really have more than one-two thousands containers running, at least not doing anything useful?  \r\n\r\n\r\n\r\nOn Tuesday 12 March 2013 at 12:04, Sam Alba wrote:\r\n\r\n\u003e To defend the feature, I'd say having several thousands of directories in /var/lib/docker will make debugging super hard (a simple ls will be getting hard to run). And without an index, it's impossible to limit the \"docker ps\" command to the last 50 containers without walking the entire directory for instance.\r\n\u003e Do you guys have suggestion? I'd be glad to open another issue.\r\n\u003e  \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub (https://github.com/dotcloud/docker/issues/51#issuecomment-14757532).","The problem here is not really the running containers (and you're right about that btw). The main issue is more for all container and the history of containers listed with the ps command.\r\n\r\nBasically if I run:\r\n\r\n$ repeat 3 docker run -t base:e9cb4ad9173245ac /bin/true\r\n\r\nMy first 3 lines of ps -a will be:\r\n\r\n```\r\n$ docker ps -a\r\nID          IMAGE                             COMMAND                CREATED         STATUS      COMMENT\r\nafd76b15    base:e9cb4ad9173245ac             /bin/true              3 seconds ago   Exit 0\r\n43ae3861    base:e9cb4ad9173245ac             /bin/true              4 seconds ago   Exit 0\r\ne398c0db    base:e9cb4ad9173245ac             /bin/true              5 seconds ago   Exit 0\r\n```\r\n\r\nThe current implementation of the ps command must walk the entire filesystem because of that (whether it runs with `-a' or not). After several months of using docker regularly, the ps command will quickly become useless and/or super slow. We could garbage collect the old containers, but I hate losing historical data if I don't have a strong reason.\r\n\r\nSqlite tends to be a nice candidate for this indexing matter, if you have better idea, I'd be glad to hear.\r\n\r\nYour feedback is super useful, we want to build the best container system for users like you and your comments will help to make the project live soon!\r\n\r\nI am changing the title of the issue since it's not really a filesystem hashing concern, but more to index the containers data.","how interesting are old processes on a individual docker machine? shouldn't it be the job of the component administering docker through the mgmt api to store and use that information?  \r\n\r\nthe lightweightness of the docker today really appeals to me. by adding yet another big dependency such as sqlite defeats that, especially if it's not for a very very good reason. you know how i goes, sqlite has to be compiled with the correct flags, it's upgraded and changes schema format, and what not. debugging is harder for new docker users as they have to know that you use sqlite, and then figure out the schema etc, the sqlite file gets corrupted and you're in a world of pain, which means that you have to have a backup routine for it and yadda yadda..  \r\n\r\n\r\nOn Tuesday 12 March 2013 at 13:52, Sam Alba wrote:\r\n\r\n\u003e The problem here is not really the running containers (and you're right about that btw). The main issue is more for all container and the history of containers listed with the ps command.\r\n\u003e Basically if I run:\r\n\u003e $ repeat 3 docker run -t base:e9cb4ad9173245ac /bin/true\r\n\u003e My first 3 lines of ps -a will be:\r\n\u003e $ docker ps -a ID IMAGE COMMAND CREATED STATUS COMMENT afd76b15 base:e9cb4ad9173245ac /bin/true 3 seconds ago Exit 0 43ae3861 base:e9cb4ad9173245ac /bin/true 4 seconds ago Exit 0 e398c0db base:e9cb4ad9173245ac /bin/true 5 seconds ago Exit 0  \r\n\u003e The current implementation of the ps command must walk the entire filesystem because of that (whether it runs with `-a' or not). After several months of using docker regularly, the ps command will quickly become useless and/or super slow. We could garbage collect the old containers, but I hate losing historical data if I don't have a strong reason.\r\n\u003e Sqlite tends to be a nice candidate for this indexing matter, if you have better idea, I'd be glad to hear.\r\n\u003e Your feedback is super useful, we want to build the best container system for users like you and your comments will help to make the project live soon!\r\n\u003e I am changing the title of the issue since it's not really a filesystem hashing concern, but more to index the containers data.\r\n\u003e  \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub (https://github.com/dotcloud/docker/issues/51#issuecomment-14759729).","I'm not familiar (not yet!) with the directory format; but it could make sense to keep only the last N (10?) entries for each container, and move the older entries to an `attic` directory.\r\n\r\n- You can nuke the `attic` directory without losing recent data.\r\n- You can see older results by adding `--all` or something similar to the docker commands.\r\n\r\n","FWIW, docker already uses sqlite for image metadata (see the fs branch\nwhich is about to be merged).\n\nSqlite definitely feels like an improvement compared to the \"big json blob\"\nsystem that it replaced. I agree that using a binary format and depending\non a 3d-party tool is always something to be cautious about, and I'm not\nsure how much of a problem schema changes will pose. But it beats\nre-inventing our own half-assed embedded database, which would probably\nsuffer from similar problems anyway.\n\nAnother alternative we looked at is LevelDB, but it seemed too low-level,\nand less proven than sqlite.\n\nThis doesn't necessarily mean we want to use sqlite for container metadata\n(container store and image stores are 2 distinct components), but it's\ndefinitely a technical possibility.","oh, ok, yes, if a db is needed, than sqlite is certainly the way to go. \r\n\r\ni was just seeing infront of me that this type of data was stored on a higher level, that to use docker on a single machine was an exception, as to use the CLI. i was thinking of a \"docker orchestrator\" or something that managed multiple docker machines, and that docker machines was more or less stateless and easily replaceable (due to hardware errors etc). and that the orchestrator stored the meta data of images, stored the logs (if it needed them) and so forth..\r\n\r\ni guess it's not mutually exclusive but yeah, had the view that docker in it self would do as little as possible..","We ditched sqlite to get rid of the dependency; so... Maybe this should come back later, if/when performance issues arise? I suggest closing this; what do you think @shykes @creack ?","Agreed, currently performance is acceptable in real-world scenarios, I have\r\n1000+ containers and lookup is still fast since it's either direct key\r\nlookup, or a simple tag lookup.\r\n\r\nWe can revive the indexing scenario when we start needing more advanced\r\nfiltering and search.\r\n\r\nThanks for catching this!\r\n\r\n\r\nOn Tue, Jun 25, 2013 at 5:43 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e We ditched sqlite to get rid of the dependency; so... Maybe this should\r\n\u003e come back later, if/when performance issues arise? I suggest closing this;\r\n\u003e what do you think @shykes \u003chttps://github.com/shykes\u003e @creack\u003chttps://github.com/creack\u003e?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/51#issuecomment-20019466\u003e\r\n\u003e .\r\n\u003e","looks like we have hit this issue\r\n24923 containers == docker ps: real 0m54.406s\r\n29191 containers == docker ps: real 6m42.420s","For now, it should suffice to catch this on Import and on Create","There are a few other commits where I basically reject versions from CmdPush, but I accept them in CmdRun. CmdRun is now smart enough to split the name:version tag to do the auto-pull and not break, even if that version doesn't exist. This will be improved by the work done to complete #54 and #55, one of which I see is assigned to @shin- . With that being said, I think this can be closed upon merging #49 ","Closing for now","Closing this since the graph work covered that afaik. Reopen if necessary","I'll experiment with that and report my findings.","Steps:\r\n- start sshd in `base` image (because otherwise it's a real PITA!)\r\n- add `universe` to `sources.list`\r\n- `apt-get install lxc`: it will fail, but install useful stuff in the process\r\n- `brctl addbr lxcbc0 ; ifconfig lxcbr0 10.42.0.1/24`\r\n- `docker run -a -i base /bin/ls`\r\n\r\nDocker bombs with `2013/03/14 04:16:54 Layer not found for image f7546ca71fc4f2a8`.\r\nAnalyzing with `strace` doesn't give useful hints about that problem, but shows that the `iptables` call silently failed:\r\n\r\n    [pid  3886] write(2, \"iptables v1.4.12: \", 18) = 18\r\n    [pid  3886] write(2, \"can't initialize iptables table \"..., 75) = 75\r\n    [pid  3886] write(2, \"\\n\", 1)           = 1\r\n    [pid  3886] write(2, \"Perhaps iptables or your kernel \"..., 54) = 54\r\n    [pid  3886] exit_group(3)               = ?\r\n\r\nWhich is weird since `network.go` seems to have the proper checks (https://github.com/dotcloud/docker/blob/master/network.go#L69).\r\n\r\nInvestigating further.","... Right, about the `iptables` bug, it looks like we do not use the return value of the `iptables` helper anyway (https://github.com/dotcloud/docker/blob/master/network.go#L110).\r\n\r\nRight?","Note: `iptables` requires (at least) `net_raw` capability.","Note: if `bsdtar` is not found, weird things happen silently.","Note: if something wrong happens during the execution of `bsdtar`, you won't know about it, and the image will be destroyed (but `docker` still pretends that it's here).","Re: bsdtar bug, thanks for the report - I addressed it in #75","Note: even with the `mknod` capability, you cannot `mknod` an arbitrary device. I temporarily disabled error checking in `Untar()`, and I'm down to the next issue: ability to `mount`.\r\n\r\n```\r\ndiff --git a/fs/layers.go b/fs/layers.go\r\nindex dc7e621..74c94da 100644\r\n--- a/fs/layers.go\r\n+++ b/fs/layers.go\r\n@@ -93,7 +93,6 @@ func (store *LayerStore) AddLayer(id string, archive Archive) (string, error) {\r\n                return \"\", fmt.Errorf(\"Mktemp failed: %s\", err)\r\n        }\r\n        if err := Untar(archive, tmp); err != nil {\r\n-               return \"\", err\r\n        }\r\n        layer := store.layerPath(id)\r\n        if !store.Exists(id) {\r\n```","Note: have to give capability `sys_admin`, which opens a whole can of worms. Still trying, though!\r\nNote: the next issue is with AppArmor blocking unauthorized mounts. But I know how to fix it!","Add `mount fstype=aufs,` into `/etc/apparmor.d/lxc/lxc-default` and voilà.\r\nNote: AUFS mounts can't be AUFS branches. I worked around this with `mount -t tmpfs none /var/lib/docker`.\r\nNote: next step is cgroups. We're getting close!","`cgroups-mount` in the container did the trick.\r\n\r\nNow, `lxc-start` complains because it cannot remove capabilities (duh).\r\n\r\n\r\n```\r\ndiff --git a/lxc_template.go b/lxc_template.go\r\nindex 7ae50bc..7257d96 100755\r\n--- a/lxc_template.go\r\n+++ b/lxc_template.go\r\n@@ -80,9 +80,10 @@ lxc.mount.entry = {{.SysInitPath}} {{$ROOTFS}}/sbin/init none bind,ro 0 0\r\n # In order to get a working DNS environment, mount bind (ro) the host's /etc/resolv.conf into the container\r\n lxc.mount.entry = /etc/resolv.conf {{$ROOTFS}}/etc/resolv.conf none bind,ro 0 0\r\n \r\n+lxc.mount.entry = /sys/fs/cgroup {{$ROOTFS}}/sys/fs/cgroup none bind 0 0\r\n \r\n # drop linux capabilities (apply mainly to the user root in the container)\r\n-lxc.cap.drop = audit_control audit_write mac_admin mac_override mknod net_raw setfcap setpcap sys_admin sys_boot sys_module sys_nice sys_pacct sys_rawio sys_resource sys_time sys_tty_config\r\n+#lxc.cap.drop = audit_control audit_write mac_admin mac_override setfcap setpcap sys_boot sys_module sys_nice sys_pacct sys_rawio sys_resource sys_time sys_tty_config\r\n \r\n # limits\r\n {{if .Config.Memory}}\r\n```","So, `lxc-start` tries to remove `CAP_SYS_BOOT` anyway (see this changelog: https://launchpad.net/~juju/+archive/pkgs/+sourcepub/2704379/+listing-archive-extra)\r\n\r\nI'm doing a quick patch to work around this, but it will be painful in the long run if we can't fix it upstream.","In the long run we probably don't want to keep using lxc anyway. There are\r\na few efforts out there for small wrapper libraries around\r\nnamespacing/cgroups. They would be easier to patch than lxc.\r\n\r\nOn Thursday, March 14, 2013, jpetazzo wrote:\r\n\r\n\u003e So, lxc-start tries to remove CAP_SYS_BOOT anyway (see this changelog:\r\n\u003e https://launchpad.net/~juju/+archive/pkgs/+sourcepub/2704379/+listing-archive-extra\u003chttps://launchpad.net/%7Ejuju/+archive/pkgs/+sourcepub/2704379/+listing-archive-extra\u003e\r\n\u003e )\r\n\u003e\r\n\u003e I'm doing a quick patch to work around this, but it will be painful in the\r\n\u003e long run if we can't fix it upstream.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/56#issuecomment-14925769\u003e\r\n\u003e .\r\n\u003e","In the LXC sources, at `src/lxc/start.c` around line 599, there is `SYSERROR(\"failed to remove CAP_SYS_BOOT capability\");`. We want to get rid of that and continue even if we can't remove `sys_boot`.\r\n\r\nOther note: sometimes, `cgroups-mount` doesn't work (didn't find out exactly why), but `umount /sys/fs/cgroup ; cgroups-mount` fixes it all the time.\r\n\r\nThen, we need to disable apparmor. Edit `/etc/apparmor.d/lxc/lxc-default` and change the flags to be `flags=(attach_disconnected,mediate_deleted,complain)` (the key is `complain`, which will log unauthorized operations instead of blocking them).\r\n\r\nThen it works!\r\n\r\nRemember to:\r\n- setup a bridge in the container\r\n- setup a tmpfs over `/var/lib/docker`\r\n- mount cgroups\r\n- have a patched LXC *inside* the container\r\n","This will be implemented with either a chroot backend, or an optional privileged mode (to nest namespaces) in combination with a volume (to work around aufs nesting). I'm closing this issue in favor of more specific issues ones. Jerome your notes might be worth moving to a wiki page?","Wiki page: https://github.com/dotcloud/docker/wiki/Docker-in-Docker \\o/","What are the steps to do this with `libcontainer`?","@Sirupsen docker in docker just works as long as you pass in --privileged.","Note: the bug in question is referenced at https://github.com/dotcloud/docker/issues/24\r\n","The client and server has been merge, not relevant anymore.","It looks like this image is already uploaded:\r\n\r\n    root@ip-10-125-3-216:~# curl -o/dev/null http://get.docker.io/images/minbase\r\n      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                     Dload  Upload   Total   Spent    Left  Speed\r\n    100 34.4M  100 34.4M    0     0  22.3M      0  0:00:01  0:00:01 --:--:-- 22.4M\r\n","I removed the 'docker web' functionality for now. See b97f9e814814892bdd20d0d03b93af1ac2f09cf1","This is by design: we drop the `mknod` capability.\r\n\r\n(Verified: the proposed test case works fine if I remove `mknod` from `lxc_template.go`.)\r\n\r\nSince we deny access to all devices, except those explicitly allowed, I think it's safe to re-enable the mknod capability, unless someone else has objections.","Ok with me. Pull request? :)","I haven't parsed this issue fully, but I think `mknod` might not be benign.\r\n\r\nhttps://buildsecurityin.us-cert.gov/bsi/articles/knowledge/coding/780-BSI.html\r\n\r\nIs there a way to have debootstrap or others skip the creation of devices and/or symlink?","It should be possible to run `debootstrap` with [fakeroot](http://docs.openembedded.ru/fakeroot.html). However, it will (obviously) not create a real device, so the resulting filesystem might be unusable (depending on what you want to do with it).\r\n\r\nRegarding the issue pointed by @vsekhar, I think that it is not relevant here. If we enable `mknod` capability within containers managed by docker, to exploit the attack mentioned, you need:\r\n- shell access within a container managed by docker\r\n- something that triggers `mknod` (on a normal system, I would try PTMX allocation, or some udev trickery; on docker, the latter wouldn't work anyway)\r\n- ... and the `mknod` has to be in a user-writable directory (I can't imagine how would that happen on a sane system, but let's pretend it is!)\r\nIf you achieve this, you end up with a device node on the filesystem, but LXC still won't let you *open* the device (LXC lets you separate `mknod`, `read`, and `write` capabilities).\r\n","If we are going to allow `mknod` for devices you can't `read` or `write`, it seems like the only use case is `debootstrap` or similar tools. In that case, fakeroot might be the better way since you are not creating 'real' (i.e. usable) devices anyway, and explicit is better than implicit.","*Iff* fakeroot works correctly for that use case, I'm fine with it, of course.","I'm closing this since it's a design decision and not a bug of Docker. If we want more flexibility on capabilities (for example a special \"--privileged\" mode), we should discuss it in a separate issue.\r\n","Grabbing","    chooper@chimay:~/projects/docker$ sudo rm -fr /var/lib/docker\r\n    chooper@chimay:~/projects/docker$ sudo ./bin/docker run -a base echo hi\r\n    2013/03/14 01:38:37 mkdir /var/lib/docker/images: no such file or directory\r\n","Fixed in my fork. Tests pass. Pull request inbound.\r\n\r\n    chooper@chimay:~/projects/docker$ sudo rm -fr /var/lib/docker\r\n    chooper@chimay:~/projects/docker$ sudo ./bin/docker run -a base echo hi\r\n    2013/03/14 01:46:03 docker run -a base echo hi\r\n    Downloading from http://s3.amazonaws.com/docker.io/images/base\r\n    Unpacking to base\r\n    88627878/88627878 (100%)\r\n    8b76d03161f3266e\r\n    hi\r\n","Merged","Careful, you mixed in an unrelated commit (3686feacccab68f130a0cf0bda2e800b9731d213).\r\n\r\nI'm merging it in to save time, looks good, thanks.","Fixed in a444327ab6c9b568e87ae9b3d4a1b0a0d050f5e2","Looks good to me!","I replaced it because with the new naming system I wasn't sure there was a strong use-case for it. Thoughts?","I personally need it for 2 reasons:\r\n\r\n1) Temporary images which I store at _/tmp/XXXX\r\n\r\n2) Intermediary build steps which I store at _/builds/XXX/YYYYYY\r\n\r\n","+1 Vagrant is awesome","Complete!","There's already a \"comment\" field for exactly this. Now we need to use it :)\r\n\r\n\r\nOn Thu, Mar 14, 2013 at 12:48 PM, Charles Hooper\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Current usage of docker commit is:\r\n\u003e\r\n\u003e docker commit [OPTIONS] CONTAINER [DEST]\r\n\u003e\r\n\u003e With the addition of the metadata store (sqlite), I think Docker should\r\n\u003e support the addition of commit messages.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/81\u003e\r\n\u003e .\r\n\u003e","Perfect!","I don't know much about lxc internals because docker made it very easy.  It would be very very cool if docker can commit current state(running applications) of container and resume it when it is launched.  is it possible to achieve using lxc-freeze and lxc-unfreeze? I couldn't find any docker command related command for this. ","@Murugan78: checkpoint and restore should be possible but is another story :-)\r\n\r\n@shykes: this has been implemented, right? (Except maybe auto-restart policy, but it might deserve a ticket on its own; do you want me to create it?)","Yes, default values have been implemented, and they are awesome :) I think auto-restart can wait as well.\r\n\r\nThanks for catching.\r\n","@shykes, Sorry, this is a little old, but where was this finally implemented? I am here:\r\n\r\n```\r\nClient version: 0.6.1\r\nServer version: 0.6.1\r\nGit commit: 5105263\r\nGo version: go1.1.2\r\nLast stable version: 0.6.1\r\n```\r\n\r\nAnd I don't see this yet.","Related: someone is working on a new Vagrant \"provider\" for LXC. Could docker be a useful provider?\r\n\r\nNot sure which would be most useful to developers using Vagrant.","It's immediately obvious to me why having a Docker provider would be immensely valuable -- I can imagine near-instant `vagrant up`s and more rapid Vagrant iteration.\r\n\r\nI don't understand the former proposal, though -- how would Docker function as a provisioner? I guess it would provide a nicely integrated way of setting up Docker and an image inside a Vagrant VM?","Looks like provider is indeed the way to go! It would be especially valuable for multi-vm deployments. Multi-vms on a single vm! :)\r\n","Closing in favor of #404","All the tests pass. As discussed @kencochrane I'll wait for confirmation that real-world usage works for a couple people other than you and me.\r\n\r\nLet me know!","I gave it a shot. Two issues...\r\n\r\nThe first one is minor: `docker help login` actually invokes `CmdLogin` and doesn't return any help information. Try adding the following to the top:\r\n\r\n    if err := cmd.Parse(args); err != nil {\r\n        return nil\r\n    }\r\n\r\nWith the second one, I was able to reproduce Solomon's issues, with a little more detail:\r\n\r\n    $ docker login # First time ...\r\n    ...\r\n    $ docker login # Enter at prompt...\r\n    Error: Registration: \r\n    $ docker login # Enter at prompt...\r\n    Error : use of closed network connection\r\n\r\nI did some testing with `strace -f  -s 1024 docker login` and found that:\r\n\r\n* When you receive `Error : Registration:`, it happens when the server returns an HTTP 400\r\n* When you receive `Error : use of closed network connection`, the server has returned an HTTP 200","More information about the `Error : use of closed network connection` error... when this happens, it appears as if the read is cut short (or maybe the write is, I can't tell). Here is the actual system call (which is actually multiple `read()` calls, formatted for readability:\r\n\r\n    [pid  4247] read(51, \"\r\n        HTTP/1.1 200 OK\\r\\n\r\n        server: gunicorn/0.17.2\\r\\n\r\n        date: Fri, 15 Mar 2013 06:40:55 GMT\\r\\n\r\n        connection: close\\r\\n\r\n        expires: -1\\r\\n\r\n        content-type: text/plain\\r\\n\r\n        pragma: no-cache\\r\\n\r\n        cache-control: no-cache\\r\\n\r\n        content-length: 2\\r\\n\r\n        \\r\\n\", 4096) = 201\r\n\r\nAnd here's a response from a `Login succeeded` message:\r\n\r\n    [pid  4342] read(51, \"\r\n        HTTP/1.1 200 OK\\r\\n\r\n        server: gunicorn/0.17.2\\r\\n\r\n        date: Fri, 15 Mar 2013 06:41:24 GMT\\r\\n\r\n        connection: close\\r\\n\r\n        expires: -1\\r\\n\r\n        content-type: text/plain\\r\\n\r\n        pragma: no-cache\\r\\n\r\n        cache-control: no-cache\\r\\n\r\n        content-length: 2\\r\\n\r\n        \\r\\n\r\n        ok\", 4096) = 203\r\n\r\nAt first glance they look very similar, but in the error case, the body of \"ok\" is never received.","I gave it a shot:\r\n\r\n* Minor issues:\r\n * We can create an account with an empty password\r\n* Improvements:\r\n * Hide the password while we type it\r\n\r\nOtherwise, it looks good (beside the issues cited by Charles which are very annoying)","I fixed the issue with no password, and the help message","Any problems left?","We were able to reproduce, it was actually a server issue not a client issue. We are changing the server to fix. this should be good to merge.","Replaced the server by uwsgi. Ready to be retried!","I'm not sure that running everything in a networksetup container is feasible... Many of the types of things you'd want to do require kernel modules, eg. tuntap for openvpn, wireless drivers, routing protocol handlers, etc. In the case of openvswitch it potentially needs datapath and brcompat, which requires unloading the default \"bridge\" module that gets autoloaded when lxc is installed. ","I would actually to prefer to see something like a \"dumb\" networking mode that just slices off an interface and doesn't do anything else (adding it to a bridge would have to happen out-of-band).\r\n\r\nI know that part of the power of docker is that \"it just works,\" but I can imagine a variety of use cases that leave it preferable to manage the networking out of band. I think our job is to make an API that's going to be usable by out-of-band management. Things to consider:\r\n\r\n* Other protocols besides TCP\r\n* Things that don't work well behind NAT\r\n* Applications that require an unknown or arbitrary number of open ports\r\n* Network technologies that could be in use by service providers (think VLANs and so-on)","I have little to add to the discussion that hasn't already been said, however I would like to voice that this enhancement is on the top of my own list before I can leverage docker to its full potential.\r\n\r\nWonderful project, BTW.","Here's something that might be useful to achieve software-defined networking with containers (and therefore, docker): https://gist.github.com/jpetazzo/5493295\r\n","@jpetazzo Seriously cool, exactly what I was looking for! ","Closing the issue for focus. Feel free to continue the discussion on the mailing list, or a wiki page.","Copying @niallo on this one since I know he's working on something similar.","I have a Strider instance building my fork of docker on each commit hosted on dotcloud at https://docker-niallo.dotcloud.com.\r\n\r\nNext steps:\r\n\r\n1) Pull request to add `strider-custom.json` to dotcloud/docker repo. This tells Strider how to build Docker (run `make`)\r\n2) Send Strider invite to someone with `admin` privs on dotcloud/docker repo to setup CI (@shykes ?)\r\n3) Integrate script to upload binaries to S3\r\n","Please check out this pull request: https://github.com/shykes/gorp/pull/1","It doesn't look like sqlite is used anymore, can this be closed?","Yes, thanks.","It's only used for FakeTar in fs tests. Feel free to replace FakeTar(), or move it into the fs package.","Done in https://github.com/dotcloud/docker/commit/6d580247c27da7cddcc6a582b846b1e8bd5bc0d6","Of course, when I was on something else, I had the error all the time and when I start to work on it, I can't manage to reproduce it -_-.\r\nIf someone find a way 100% sure to reproduce, let me know :)\r\n\r\nThe error seems to come from gorp, the ORM, which is kinda weird..","Did pull request #95 solve this?","Nop, it just made sure that go test will really fail and not pass while displaying the error.\r\nI stil haven't been able to reproduce the issue :(","Well, after 4 days without reproducing the issue, I close it as \"cannot reproduce\". Maybe the pull request #95 actually did solve this.","I see tons of changes unrelated to this pull request...\r\n\r\nHow many distinct improvements are in there?","Indeed, I should have done a separate pull request for #92, sorry about that.\r\n\r\nYou have @82188b9, @2839a59 and @137af24 are related to it, it is basically just a move of the TestMount function from fs to docker\r\n\r\n@cb7819c, @4d80958 and @b2cf504 are just trivials changes.\r\n\r\nThe rest is related to the #92 case","Related to #93, merging the error return.\r\nWill try to reproduce the issue later","I don't like a global resolv.conf for containers and think name resolution should be per-container. I think it's reasonable to have a default that auto-detects nameservers based on the host's resolv.conf, but I think this is something that should be able to be overridden somewhere.","For what it's worth, my comments are more for \"post-launch.\" What's the status of the code attached to this commit?","I will push my branch tonight or tomorrow morning.","It would be good to have an option to override it when performing operations which create containers.\r\n\r\nI'm thinking of having something like a -dns=/path/to/a/resolv.conf option for run and other docker commands which create containers.","@creack Does your branch need any other changes or more testing?","This also affects NetworkManager users on Ubuntu Desktops (especially for wifi users). NetworkManager binds to 127.0.0.1 and proxies the request to the dns server. \r\n\r\n/etc/resolv.conf nameserver is then set to 127.0.0.1, triggering the error condition specified in this bug report.","Here's my plan so far:\r\n\r\n* Determine if the hosts /etc/resolv.conf points to 127.0.0.*\r\n* If it doesn't, use it as-is (same as now)\r\n* If it *does*, use a generated resolv.conf instead, which points to 8.8.8.8 (or an equivalent universally-usable default). Also print a clear warning explaining what's going on and to change the default resolver with 'docker -d --resolver=IP\"\r\n* Obviously the --resolver flag needs to be implemented\r\n","Note: better check for 127.* (it's almost the same thing but covers more corner cases).\r\n\r\nAlso, out of curiosity: why not point to the bridge address (if it can be verified that it's also listening on 53/udp)?","We also need a flag to skip this step. If the container already has a resolv.conf, we might want to keep it as it is","The DNS proxy is binding to the loopback address, it most likely won't respond to a bridge address without performing some type of translation.","@fkautz dnsmasq is running both on 127.0.0.1 and 10.0.3.1 on the Ubuntu systems.\r\n\r\nI propose the following order:\r\n1. use the DNS server(s) provided to docker -d via --resolver=IP1 --resolver=IP2 --resolver=IP3 to build a new resolv.conf\r\n2. if no DNS server was provided: check if /etc/resolv.conf uses 127.* as a nameserver\r\n3. use as is if it doesn't\r\n4. if it uses 127.* : use the DNS proxy server from the bridge if there's one bound to its IP\r\n5. if there's no DNS proxy server bound to the IP of the bridge, use a public DNS server such as 8.8.8.8\r\n\r\nUsing an existing resolv.conf from an image isn't a very good idea. A developer might leave in a DNS server entry which works only from their network, push a new image and break builds without knowing,","@unclejack I asked @shykes about how resolv.conf is populated. It's bound on container start and shouldn't be preserved on an image creation so I think we should be ok with that.","Fixed by #390 ","I just ran into this problem as well, because I run dnsmasq on my network.  I fixed it by doing:\r\n\r\n```bash\r\necho \"nameserver 8.8.8.8\" \u003e\u003e /etc/resolv.conf\r\necho \"nameserver 8.8.4.4\" \u003e\u003e /etc/resolv.conf\r\n```\r\n\r\nI didint se this issue until after I changed the resolv.conf (also not sure the latest binary release has the -dns flag is available in the latest binary release, or im just not using it right).  Appending resolv.conf with default nameservers like google's works for me both in case the there is a problem (the hosts runs it's own dns server / 127.* in resolv.conf ), and in case resolv.conf is fine; it will just use the correct setup as long as it works. (however im not sure thats always the case.  there a limit to the number of nameservers in resolv.conf(?), and im sure there may be other edge cases).\r\n\r\nI think the added option of specifying it directly is good.  But it would be better default behaviour to replace 127.0.1.1 and 127.0.0.1 with the bridge adapters address if the host is using them in resolv.conf. This is the correct behaviour right?  127.0.1.1 and 127.0.0.1 reffer to the host itself, so they should refer to the same host in the bridged network.  (alternatively append something like 8.8.8.8 to the file, but its more of a hack and im not sure it would always work.","On Sat, Apr 13, 2013 at 4:04 PM, Thomas Hansen \u003cnotifications@github.com\u003ewrote:\n\n\n\u003e I think the added option of specifying it directly is good. But it would\n\u003e be better default behaviour to replace 27.0.1.1 and 127.0.0.1 with the\n\u003e bridge adapters address if the host is using them in resolv.conf. This is\n\u003e the correct behaviour right? 127.0.1.1 and 127.0.0.1 reffer to the host\n\u003e itself, so they should refer to the same host in the bridged network.\n\u003e\nThis will not work if the host's resolver is configured to listen only on\nthe loopback interface. I don't know if this is the case on typical\nout-of-box distro setups.","Thanks  @hansent I used the same hack on my docker host machine","How do I set DNS when building from a dockerfile? Should I RUN a step the echos the nameserver to /etc/resolv.conf?","Currently /etc/resolv.conf will always be mounted read-only by docker, so there's no easy way to change it from the inside currently.\r\n\r\n\r\n\r\n\r\n\r\n We're still looking for the right way to solve this.\r\n\r\n\r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, Sep 20, 2013 at 3:17 PM, John Jelinek IV \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e How do I set DNS when building from a dockerfile? Should I RUN a step the echos the nameserver to /etc/resolv.conf?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/96#issuecomment-24844832","What should I do if updating my host /etc/resolv.conf doesn't propagate to\r\nmy containers?\r\nOn Sep 20, 2013 6:31 PM, \"Solomon Hykes\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Currently /etc/resolv.conf will always be mounted read-only by docker, so\r\n\u003e there's no easy way to change it from the inside currently.\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e  We're still looking for the right way to solve this.\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e —\r\n\u003e @solomonstre\r\n\u003e @getdocker\r\n\u003e\r\n\u003e On Fri, Sep 20, 2013 at 3:17 PM, John Jelinek IV \u003cnotifications@github.com\u003e\r\n\u003e\r\n\u003e wrote:\r\n\u003e\r\n\u003e \u003e How do I set DNS when building from a dockerfile? Should I RUN a step\r\n\u003e the echos the nameserver to /etc/resolv.conf?\r\n\u003e \u003e ---\r\n\u003e \u003e Reply to this email directly or view it on GitHub:\r\n\u003e \u003e https://github.com/dotcloud/docker/issues/96#issuecomment-24844832\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/96#issuecomment-24848852\u003e\r\n\u003e .\r\n\u003e","If you really need to change /etc/resolv.conf, you can always start the container in privileged mode and unmount it. \r\nBe aware that this container will be privileged and compromise the security of the host. Do not run untrusted code in a privileged container.","I just need it modified during the build. The DNS may change when the\r\ncontainer is run.\r\nOn Sep 20, 2013 7:26 PM, \"Guillaume J. Charmes\" \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e If you really need to change /etc/resolv.conf, you can always start the\r\n\u003e container in privileged mode and unmount it.\r\n\u003e Be aware that this container will be privileged and compromise the\r\n\u003e security of the host. Do not run untrusted code in a privileged container.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/96#issuecomment-24850470\u003e\r\n\u003e .\r\n\u003e","This is complicated by the fact that an Ubuntu desktop has two dnsmasq instances, configured differently (one which manages /etc/resolv.conf and one listening on the LXC bridge). That is not really Docker's fault but it makes it harder to figure out how to achieve what you want.","`docker run -a -p=22 strider-worker-ssh \u003ccmd\u003e` is now consistently crashing docker -d on my system no matter what command I use.\r\n\r\nOther images (e.g. base) run fine.","Additional info:\r\n\r\n- This only occurs with `-p` port mapping option\r\n- If I reboot the system, the issue goes away.\r\n\r\nMy guess is kernel IP tables rules got into some state which upset Docker, and the reboot cleared this.","Without the strider-worker-ssh image, I've been unable to reproduce.\r\n\r\nSince we don't have push functionality yet, is there anyway you can share the image (or a sanitized version that still reproduces the bug, if that's what you're comfortable with)?","I will see if I can reproduce. I haven't had the issue since I rebooted the system.","I'm seeing this issue on the vagrant local VM after building from master.  Only occurs with port forwarding enabled.","The crash is occurring on the base and custom images for me.","The bug also happens if I run `docker run -p 22 base /usr/sbin/sshd -D` on a fresh docker install on an EC2 instance.\r\n\r\nEdit: forgot to mention that I have exactly the same traceback.","I can't reproduce it on my virtualbox+official binaries install.\r\n","The bug only manifests itself periodically on virtualbox for me.  Once it does occur only a reboot seems to fix it.","Looking into it. Can someone give me a combination of (a) full traceback\r\nand (b) exact revision which generated the traceback?\r\n\r\n\r\nOn Fri, Mar 22, 2013 at 6:47 PM, Shawn Siefkas \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e The bug only manifests itself periodically on virtualbox for me. Once it\r\n\u003e does occur only a reboot seems to fix it.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/97#issuecomment-15329155\u003e\r\n\u003e .\r\n\u003e","So the binaries have a git sha compiled in anywhere ? \r\n\r\nSent from my iPhone\r\n\r\nOn Mar 22, 2013, at 6:52 PM, Solomon Hykes \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Looking into it. Can someone give me a combination of (a) full traceback \r\n\u003e and (b) exact revision which generated the traceback? \r\n\u003e \r\n\u003e \r\n\u003e On Fri, Mar 22, 2013 at 6:47 PM, Shawn Siefkas \u003cnotifications@github.com\u003ewrote: \r\n\u003e \r\n\u003e \u003e The bug only manifests itself periodically on virtualbox for me. Once it \r\n\u003e \u003e does occur only a reboot seems to fix it. \r\n\u003e \u003e \r\n\u003e \u003e — \r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/97#issuecomment-15329155\u003e \r\n\u003e \u003e . \r\n\u003e \u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","Unfortunately not... It's on the todo-list! (if anybody finds the time go\r\nfor it!)\r\n\r\n\r\nOn Fri, Mar 22, 2013 at 7:13 PM, niallo \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e So the binaries have a git sha compiled in anywhere ?\r\n\u003e\r\n\u003e Sent from my iPhone\r\n\u003e\r\n\u003e On Mar 22, 2013, at 6:52 PM, Solomon Hykes \u003cnotifications@github.com\u003e\r\n\u003e wrote:\r\n\u003e\r\n\u003e \u003e Looking into it. Can someone give me a combination of (a) full traceback\r\n\u003e \u003e and (b) exact revision which generated the traceback?\r\n\u003e \u003e\r\n\u003e \u003e\r\n\u003e \u003e On Fri, Mar 22, 2013 at 6:47 PM, Shawn Siefkas \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e \u003e\r\n\u003e \u003e \u003e The bug only manifests itself periodically on virtualbox for me. Once\r\n\u003e it\r\n\u003e \u003e \u003e does occur only a reboot seems to fix it.\r\n\u003e \u003e \u003e\r\n\u003e \u003e \u003e —\r\n\u003e \u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/97#issuecomment-15329155\u003e\r\n\u003e \u003e \u003e .\r\n\u003e \u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/97#issuecomment-15330181\u003e\r\n\u003e .\r\n\u003e","With version 690cae0ef442301a97546f953dfdc8b661f3d9ef\r\n\r\n```\r\n2013/03/23 02:17:09 Listening for RCLI/tcp on 127.0.0.1:4242\r\n2013/03/23 02:17:11 docker run -p 22 toto /usr/sbin/sshd -D\r\npanic: runtime error: invalid memory address or nil pointer dereference\r\n[signal 0xb code=0x1 addr=0x0 pc=0x43040a]\r\n\r\ngoroutine 5 [running]:\r\ngithub.com/dotcloud/docker.(*PortMapper).Map(0x0, 0xc001, 0xf84008bfbc, 0x400000004, 0x16, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/network.go:142 +0xa0\r\n----- stack segment boundary -----\r\ngithub.com/dotcloud/docker.(*NetworkInterface).AllocatePort(0xf8401f2280, 0x16, 0xf8401eb5a0, 0x0, 0x0, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/network.go:286 +0xda\r\ngithub.com/dotcloud/docker.(*Container).allocateNetwork(0xf8401ac000, 0x0, 0x0, 0xf8401a3600)\r\n\t/root/go/src/github.com/dotcloud/docker/container.go:421 +0x121\r\ngithub.com/dotcloud/docker.(*Container).Start(0xf8401ac000, 0xf840189f00, 0xf84018ce98, 0x100000001)\r\n\t/root/go/src/github.com/dotcloud/docker/container.go:315 +0x9a\r\ngithub.com/dotcloud/docker.(*Server).CmdRun(0xf84018a200, 0xf84018bd20, 0xf84018a4a0, 0xf84018bd50, 0xf84018cd40, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/commands.go:988 +0x1130\r\n----- stack segment boundary -----\r\nreflect.Value.call(0x640e48, 0x427a23, 0x130, 0x6a804c, 0x6c6c614300000009, ...)\r\n\t/usr/lib/go/src/pkg/reflect/value.go:521 +0x1329\r\nreflect.Value.CallSlice(0x640e48, 0x427a23, 0x130, 0x7fa52a9afc58, 0x400000004, ...)\r\n\t/usr/lib/go/src/pkg/reflect/value.go:347 +0x85\r\ngithub.com/dotcloud/docker/rcli._func_005(0xf84016ea00, 0xf84018a480, 0x436448, 0xf84018bd20, 0xf84018a440, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/types.go:81 +0x21e\r\ngithub.com/dotcloud/docker/rcli.LocalCall(0xf84018b420, 0xf84018a200, 0xf84018bd20, 0xf84018a440, 0xf84018bd50, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/types.go:50 +0x61e\r\ngithub.com/dotcloud/docker/rcli.call(0xf84018b420, 0xf84018a200, 0xf84018bd20, 0xf84018a440, 0xf84018bd50, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/types.go:30 +0x89\r\ngithub.com/dotcloud/docker/rcli.Serve(0xf84018bc00, 0xf84018cd40, 0xf84018b420, 0xf84018a200, 0xf84018cd40, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/tcp.go:66 +0x2d3\r\ngithub.com/dotcloud/docker/rcli._func_002(0xf84018a290, 0xf84018a210, 0x0, 0x0)\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/tcp.go:45 +0x60\r\ncreated by github.com/dotcloud/docker/rcli.ListenAndServe\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/tcp.go:50 +0x2b7\r\n\r\ngoroutine 1 [chan receive]:\r\nnet.(*pollServer).WaitRead(0xf840189480, 0xf84017f5a0, 0xf8400806c0, 0xb, 0x1, ...)\r\n\t/usr/lib/go/src/pkg/net/fd.go:268 +0x73\r\nnet.(*netFD).accept(0xf84017f5a0, 0x4e6775, 0x0, 0xf84007ef00, 0xf84008f040, ...)\r\n\t/usr/lib/go/src/pkg/net/fd.go:622 +0x20d\r\nnet.(*TCPListener).AcceptTCP(0xf84018ccc8, 0x1, 0x0, 0x0, 0x10, ...)\r\n\t/usr/lib/go/src/pkg/net/tcpsock_posix.go:322 +0x71\r\nnet.(*TCPListener).Accept(0xf84018ccc8, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/usr/lib/go/src/pkg/net/tcpsock_posix.go:332 +0x49\r\ngithub.com/dotcloud/docker/rcli.ListenAndServe(0x6a5c1c, 0x70637400000003, 0x6bacb4, 0x2e3732310000000e, 0xf84018b420, ...)\r\n\t/root/go/src/github.com/dotcloud/docker/rcli/tcp.go:41 +0x23d\r\nmain.daemon(0x6a51cc, 0x6400000001)\r\n\t/root/go/src/github.com/dotcloud/docker/docker/docker.go:42 +0xb9\r\nmain.main()\r\n\t/root/go/src/github.com/dotcloud/docker/docker/docker.go:27 +0xf0\r\n\r\ngoroutine 2 [syscall]:\r\ncreated by runtime.main\r\n\t/build/buildd/golang-1/src/pkg/runtime/proc.c:221\r\n\r\ngoroutine 3 [finalizer wait]:\r\ncreated by runtime.gc\r\n\t/build/buildd/golang-1/src/pkg/runtime/mgc0.c:882\r\n\r\ngoroutine 4 [syscall]:\r\nsyscall.Syscall6()\r\n\t/build/buildd/golang-1/src/pkg/syscall/asm_linux_amd64.s:40 +0x5\r\nsyscall.EpollWait(0xf8000000a3, 0xf8400c1f30, 0xa0000000a, 0xffffffff, 0xc, ...)\r\n\t/usr/lib/go/src/pkg/syscall/zerrors_linux_amd64.go:1781 +0xa1\r\nnet.(*pollster).WaitFD(0xf8400c1f20, 0xf840189480, 0x0, 0x0, 0x0, ...)\r\n\t/usr/lib/go/src/pkg/net/fd_linux.go:146 +0x110\r\nnet.(*pollServer).Run(0xf840189480, 0x0)\r\n\t/usr/lib/go/src/pkg/net/fd.go:236 +0xe4\r\ncreated by net.newPollServer\r\n\t/usr/lib/go/src/pkg/net/newpollserver.go:35 +0x382\r\n```","@shykes this is what i reported yesterday, and you fixed it in commit 301a8afff","Looks like this is all fixed up?","This issue can probably be closed.","+1 be very nice to avoid the manual `iptables -t nat -A OUTPUT -j DOCKER` step.","+1. The fewer manual steps the better. I really love the \u003c2-line demos we've been pushing for","@shin- can we close this?","Just tried with current master, and it doesn't work (but I can't definitely confirm/infirm since docker crashes while setting up networking).\r\n\r\nTo address connections to `localhost`, see #137.","Using the pybuilder example, this works:\r\n```\r\ndocker port 9bd58bb56ac3 5000\r\n49153\r\nwget http://192.168.1.173:49153/ -q -O - \u0026\u0026 echo \"\"\r\nHello world!\r\n```\r\n\r\nHowever, this doesn't work:\r\n```\r\nwget http://127.0.0.1:49153/ -q -O - \u0026\u0026 echo \"\"\r\n```\r\nThe first problem (being unable to connect via a mapped port from a local IP) is fixed.\r\nConnecting via a mapped port using 127.0.0.1 requires something like portfwd and that's probably too much for docker.\r\n\r\nSo this issue can probably be closed.","This has been fixed - the host can now reach its containers using any of its own IPs, with the exception of the loopback interface. That last case should be addressed in its own issue.\n\nClosing.","\u003e This has been fixed - the host can now reach its containers using any of its own IPs\r\n\r\ntrue, and verified. however, connecting to $(hostname) -- as mentioned in the README and documentation -- doesn't work:\r\n\r\n```\r\n$ echo hello world | nc -v 192.168.69.217 $PORT\r\nConnection to 192.168.69.217 49153 port [tcp/*] succeeded!\r\n$ echo hello world | nc -v $(hostname) $PORT\r\nnc: connect to six port 49153 (tcp) failed: Connection refused\r\n$\r\n```\r\n\r\n`hostname` in my case is set to \"six\" (`ping six`, etc. works). i can also run `nc -v six $PORT` from externally.","@srid If the hostname resolves to 127.0.0.1, it won't work without an userland proxy.","Hi all, I just implemented a userland proxy (911925b54a42fffa0fed8bac2a3eeba14bf3ec4b) which emulates DNAT for connections to localhost. This should make all container ports available on localhost.\r\n\r\n","PULL REQUEST NUMBER 100! NICE!\r\n\r\nThanks for reading and correcting :)","I am able to reproduce this fairly consistently (though not always) using the following command:\r\n\r\ndocker -D run -t -i base /bin/bash -c \"exit 1\"\r\n\r\nI've only been able to reproduce while not having a docker daemon running in the background, so I guess the code path for creating and calling a local service instead of a remote one would be the place to start troubleshooting.","Impossible to reproduce. Closing. So many things have been improve regarding this, difficult to know what fixed it :)","discarded. When restarting docker we want to be able to reattach to those containers.","Discarded","Did you start docker in stand alone without the daemon?","\u003e Did you start docker in stand alone without the daemon?\r\n\r\nyes, but isn't that the default behaviour?\r\n\r\nbut out of curiosity i tried running the daemon and that fixes this issue (though the nc port mapping example fails, so i'm looking into that).","Will be fixed by #27.","The standalone mode as been deprecated then removed. Closing.","it seems like if you attach to a container once, you cannot do it again.. I was able to run, stop, start and attach.. after stopping again, starting and trying to attach, I get the same result. See below for the flow:\r\n\r\nezbercih@ubuntu-server:~$ docker run base /bin/sh -c \"while true; do echo hello world; sleep 1; done\"\r\n61014665\r\nezbercih@ubuntu-server:~$ docker logs 61014665\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nezbercih@ubuntu-server:~$ docker stop 61014665\r\n61014665\r\nezbercih@ubuntu-server:~$ docker start 61014665\r\n61014665\r\nezbercih@ubuntu-server:~$ docker attach 61014665\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\nhello world\r\n^Cezbercih@ubuntu-server:~$ docker attach 61014665\r\nhello world\r\nhello world\r\nhello world\r\n^Cezbercih@ubuntu-server:~$ docker stop 61014665\r\n61014665\r\nezbercih@ubuntu-server:~$ docker start 61014665\r\n61014665\r\nezbercih@ubuntu-server:~$ docker attach 61014665\r\n^Cezbercih@ubuntu-server:~$","trying to stop the container results in orphan containers. First attempt to stop hangs (probably shutsdown lxc-start process but doesn't clean up):\r\n\r\nezbercih@ubuntu-server:~$ docker attach 61014665\r\n^Cezbercih@ubuntu-server:~$ docker stop 61014665\r\n\r\n^Cezbercih@ubuntu-server:~$ docker stop 61014665\r\nError: os: process already finished\r\nezbercih@ubuntu-server:~$ docker ps -a\r\nID          IMAGE              COMMAND                CREATED          STATUS             COMMENT\r\n61014665    a1f063269abde34e   /bin/sh -c while tru   11 minutes ago   Up 10 minutes","That one might be related to #109 ","Looks like the problem doesn't occur with 'docker kill'. I can reproduce it with 'docker stop'.","fixed by #318 ","docker server need open about 5 file descriptors for each container,  so if you want to running more containers, you must check ulimit -n, and set it big enough, otherwise there has a lot of trick problems.","Thanks!","would it be possible to have a some sort of ``--fstab`` option that'd result in adding ``lxc.mount.entry`` entries in the container's config file??","actually, there are two options here:\r\n\r\n- copy the given ``fstab`` verbatim and use ``lxc.mount =`` option\r\n- translate the content of the file to corresponding ``lxc.mount.entry``","The key principle to keep in mind is that we want to minimize how much the\r\ncontainer's execution environment depends on the host's.\r\n\r\n\r\nOn Tue, Mar 26, 2013 at 7:40 AM, Mikhail Sobolev\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e actually, there are two options here:\r\n\u003e\r\n\u003e    - copy the given fstab verbatim and use lxc.mount = option\r\n\u003e    - translate the content of the file to corresponding lxc.mount.entry\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/111#issuecomment-15462016\u003e\r\n\u003e .\r\n\u003e","1. Short term.\r\nThe command-line binding proposed by @synack would work great. That would make an easy way to persist data, with minimal \"out of docker\" instrumentation. My personal taste would be to reverse the args, e.g. `dotcloud run base -volume /path/in/container=/path/on/host`, but that's just me.\r\n\r\n2. Mid term.\r\nI don't know what we want in the `config.json` file. FTR, on the current dotCloud platform (which uses the [cloudlets](https://github.com/dotcloud/cloudlets) format, this is split between two parts: `manifest` and `config`. The `manifest` is the conceptual equivalent of a class definition. It says \"to run this, I need one tcp port for SSH, and another for SQL; and also, /var/lib/mysql should be a persistent volume\". The `config` is the instantiated version, so it tells exactly which port was allocated, which volume was binded, etc.\r\nIt looks like we might have port information in the image json file (to mention \"hey, that image exposes a service on port 5432, so by default, `dotcloud run` should automatically add `-p 5432` unless overriden\").\r\nIf that's so, it would make sense to also mention which paths are supposed to be volumes, if only for mere introspection purposes.\r\nThen, if we implement container tagging, it would integrate very neatly to provide persistent data storage. I.E. by default, you get a tmpfs on each volume, but if the container is tagged, then volume `foo` is bound from e.g. `/var/lib/docker/volumes/\u003ccontainertag\u003e/foo`.\r\n\r\n3. Long term.\r\nI believe that storage providers will be an important feature. It's too early to discuss that in detail I guess; but the idea would be to allow docker to interface with storage systems like LVM, btrfs, iSCSI, NFS, glusterfs, ceph... The scheme used by Xen 3 for network and block devices is not perfect, but it's a good source of inspiration (TL,DR: it allows to specify that e.g. `/dev/xvdk` should be `myiscsi:foobar`, and it will offload to a `myiscsi` script the task of locating `foobar` and making it available, whatever that means; so it is fairly extendable without touching the core). Of course docker wouldn't implement all those interfaces, but provide something that makes it easy for everyone to hook up whatever they need in the system.","(Just for the record) I realized one thing: the bound directory should somehow excluded from what is being tracked as \"changes\". I am not sure if a straightforward implementation would work right away.","That will actually work out of the box—because docker tracks changes by checking the AUFS layer, and a bind mount wouldn't show up in the layer.","+1 want",":+1: I want to see if I can get Ceph running in docker so that I can get docker running on Ceph.","Updated the title for clarity.","So, here's the current plan.\r\n\r\n### 1. Creating data volumes\r\n\r\nAt container creation, parts of a container's filesystem can be mounted as separate data volumes. Volumes are defined with the -v flag.\r\n\r\nFor example:\r\n\r\n```bash\r\n$ docker run -v /var/lib/postgres -v /var/log postgres /usr/bin/postgres\r\n```\r\n\r\nIn this example, a new container is created from the 'postgres' image. At the same time, docker creates 2 new data volumes: one will be mapped to the container at /var/lib/postgres, the other at /var/log.\r\n\r\n2 important notes:\r\n\r\n1) Volumes don't have top-level names. At no point does the user provide a name, or is a name given to him. Volumes are identified by the path at which they are mounted inside their container.\r\n\r\n2) The user doesn't choose the source of the volume. Docker only mounts volumes it created itself, in the same way that it only runs containers that it created itself. That is by design.\r\n\r\n\r\n### 2. Sharing data volumes\r\n\r\nInstead of creating its own volumes, a container can share another container's volumes. For example:\r\n\r\n```bash\r\n$ docker run --volumes-from $OTHER_CONTAINER_ID postgres /usr/local/bin/postgres-backup\r\n```\r\n\r\nIn this example, a new container is created from the 'postgres' example. At the same time, docker will *re-use* the 2 data volumes created in the previous example. One volume will be mounted on the /var/lib/postgres of *both* containers, and the other will be mounted on the /var/log of both containers.\r\n\r\n### 3. Under the hood\r\n\r\nDocker stores volumes in /var/lib/docker/volumes. Each volume receives a globally unique ID at creation, and is stored at /var/lib/docker/volumes/ID.\r\n\r\nAt creation, volumes are attached to a single container - the source of truth for this mapping will be the container's configuration.\r\n\r\nMounting a volume consists of calling \"mount --bind\" from the volume's directory to the appropriate sub-directory of the container mountpoint. This may be done by Docker itself, or farmed out to lxc (which supports mount-binding) if possible.\r\n\r\n\r\n### 4. Backups, transfers and other volume operations\r\n\r\nVolumes sometimes need to be backed up, transfered between hosts, synchronized, etc. These operations typically are application-specific or site-specific, eg. rsync vs. S3 upload vs. replication vs...\r\n\r\nRather than attempting to implement all these scenarios directly, Docker will allow for custom implementations using an extension mechanism.\r\n\r\n### 5. Custom volume handlers\r\n\r\nDocker allows for arbitrary code to be executed against a container's volumes, to implement any custom action: backup, transfer, synchronization across hosts, etc.\r\n\r\nHere's an example:\r\n\r\n```bash\r\n$ DB=$(docker run -d -v /var/lib/postgres -v /var/log postgres /usr/bin/postgres)\r\n\r\n$ BACKUP_JOB=$(docker run -d --volumes-from $DB shykes/backuper /usr/local/bin/backup-postgres --s3creds=$S3CREDS)\r\n\r\n$ docker wait $BACKUP_JOB\r\n```\r\n\r\nCongratulations, you just implemented a custom volume handler, using Docker's built-in ability to 1) execute arbitrary code and 2) share volumes between containers.\r\n","One aspect of the spec which is not yet determined: specifying read-only mounts. Any preference on the best way to extend the syntax?","Can you specify --volumes-from more than once?","@glasser I didn't consider it. One obvious problem is that 2 containers might each have a volume mounted on the same path - in which case the 2 volumes would conflict.\r\n\r\nI'm guessing you have a specific use case in mind? :)","Sure, but that should be something that can be statically checked by docker while building the container, right?\r\n\r\nAnd yes :)","Would docker fail in the case of a conflict?\r\n\r\nIt would help if you shared the use case.","(I guess one other possibility could be to specify a container-specific prefix, so eg. volumes from container1 could be mounted at /data/container1/ and volumes from container2 would be mounted at /data/container2/)","Sure, the idea here is (with read-only mounts) that programs would declare their dependencies from our ecosystem of versioned packages. We could keep around a container for each package version, and then to run programs, we join the containers of all the dependencies.\r\n\r\nBut there are much simpler use cases. Imagine that your backup-postgres script was actually, eg, \"copy Mongo to postgres\" (eg, https://github.com/stripe/mosql).  Presumably that task would want to `--volumes-from $POSTGRESCONTAINER --volumes-from $MONGOCONTAINER`?","@shykes How do I expose a specific mountpoint inside of a container?\r\n\r\n**Example**\r\n\r\nI want to containerize Ceph, which is typically configured with one OSD process per drive (drives are formatted with XFS or btrfs). What I'd like to do is boot up N docker containers where N is the number of drives that I have and expose a drive (just the mounted volume, actually) to each of them.","On Mon, Apr 8, 2013 at 1:42 PM, Jonathan Rudenberg \u003cnotifications@github.com\n\u003e wrote:\n\n\u003e @shykes \u003chttps://github.com/shykes\u003e How do I expose a specific mountpoint\n\u003e inside of a container?\n\u003e\n*Example*\n\u003e\n\u003e I want to containerize Ceph, which is typically configured with one OSD\n\u003e process per drive (drives are formatted with XFS or btrfs). What I'd like\n\u003e to do is boot up N docker containers where N is the number of drives that I\n\u003e have and expose a drive (just the mounted volume, actually) to each of them.\n\u003e\nI don't know how Ceph works. Beyond fine-grained control over which volume\nis stored where on the host filesystem, would those containers require any\nsort of runtime privileges? Eg. device access etc.\n\nIf not, I'm going to assume your example can be generalized to \"How can I\nspecify which volume is stored where on the host\".\n\nThere's a 2-part answer to that\n\n- Answer part 1: if specifying where *all* docker volumes are stored on the\nhost is enough - and in a lot of cases it is - then the answer is to\nsymlink /var/lib/docker/volumes to the path of your choice.\n\n- Answer part 2: if really you need fine-grained control (as it seems is\nthe case in this example), you need to configure Docker with a hook. The\nformat and UI of these hooks is not yet defined, and suggestions are\nwelcome :)","Question 1: if I want a specific data volume to reside on a specific filesystem, what should I do?\r\nQuestion 2: what's the lifecycle of a volume? i.e. how does it get deleted?\r\n","Question 3: if, down the road, we want to introduce support for container migration from a docker host to another (or if one is to implement it with the current API), what's the suggested approach?","On Tue, Apr 9, 2013 at 6:37 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Question 1: if I want a specific data volume to reside on a specific\r\n\u003e filesystem, what should I do?\r\n\u003e\r\nSee above my 2-part answer to @titanous. I think it's the same request.\r\n\r\n\r\n\u003e Question 2: what's the lifecycle of a volume? i.e. how does it get deleted?\r\n\u003e\r\nGood question. The thinking so far is to add an option to 'rm' so that\r\n'docker rm $ID --volumes' removes a container's volumes. This would fail if\r\nany running container has the volumes mounted.\r\n\r\nThis means volumes can outlive the volumes they're attached to. To avoid\r\nlittering the ground with orphan volumes, we can preserve enough metadata\r\nto refer to a container's volumes even after the container has been removed\r\n(the storage requirements are basically zero).\r\n\r\nIn general, I prefer erring on the side of \"oh noz, I need to garbage\r\ncollect orphan volumes\" rather than \"oops I just removed the production\r\ndatabase by mistake\".","On Tue, Apr 9, 2013 at 6:49 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Question 3: if, down the road, we want to introduce support for container\r\n\u003e migration from a docker host to another (or if one is to implement it with\r\n\u003e the current API), what's the suggested approach?\r\n\u003e\r\nI would say implement your migration logic in a container, and run it with\r\nshared access to the target's volumes. (See parts 4 and 5 of\r\nhttps://github.com/dotcloud/docker/issues/111#issuecomment-16074795)","I think one of the most common reasons for wanting persistent storage is going to be for databases, where the performance of the database can be quite commonly \"make it or break it\" depending on physical (often isolated) storage and to a lesser degree the chosen filesystem.  Just want to make sure that's being kept in mind, so that it's easy for someone to say \"time to spin up a new database, but I want to dedicate this one hard drive to it for performance and IO contention\" (which is fairly common).\r\n\r\nIf this is implemented with some kind of hook, there probably ought to be a standard library of common hooks for scenarios like this one so that we're not all rolling our own little solutions. :)","Totally agree, this should be a supported scenario. I'm still thinking about the best way to expose hooks... That probably deserves a separate issue.","Your answer to question 1 (exposing a given mountpoint into a container) was \"use hooks\", but won't that lead to something *way* more complicated than the alternate proposal? Also, hooks are by definition tied to an inside API, and much more difficult to maintain than user-facing code.\r\n\r\nRegarding question 2 (container lifecycle), I don't buy it neither. How can docker decide when it is appropriate to remove a persistent volume? Sometimes you want to keep them forever (e.g.: hibernating containers in the dotCloud platform). Sometimes you want them to go away immediately (e.g.: /tmp, or when removing an abusing service to free up disk space). Sometimes you want to keep them for a \"reasonable\" time (e.g.: most other cases), but the definition of \"reasonable\" will change for every different person (hours? days?). Isn't *explicit better than implicit*?\r\n\r\nLast but not least, regarding question 3 (container migration), it is indeed an elegant approach, *but* it completely bars the way to use CRIU and modern container migration techniques (which would require some cooperation from docker anyway).\r\n\r\nWhat was wrong with the alternate proposal, which seemed to address successfully those 3 concerns?","I somehow feel that this whole thread is worth summarizing in a separate page...  Reading through references here and there makes it really difficult to get the whole picture [for anybody who does not have a vision :)]","@sa2ajj your wish is my command :)  https://github.com/dotcloud/docker/blob/master/SPECS/data-volumes.md","On Wednesday, April 10, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e [...] won't that lead to something *way* more complicated than the\r\nalternate proposal?\r\n\u003e What was wrong with the alternate proposal [...] ?\r\n\r\nTo repeat my previous comment: Docker cannot allow arbitrary outside\r\nbind-mounts at container runtime, that would break the repeatability of a\r\nrun, and even more importantly would require out-of-band host configuration\r\nand operation. \"Run this container with the following command, but first\r\nmake sure you create a directory call /mnt/foo/bar, then make sure\r\nblablbla.\" This is exactly what docker is trying to avoid.\r\n\r\nThe command (and soon the API call) for running a container must always be\r\nthe same regardless of how storage (or networking) is implemented under the\r\nhood. Otherwise Docker becomes useless as a component for automating a\r\ndistributed system. That is why I couldn't accept @sa2ajj 's pull request\r\n(sorry!) or your proposal.\r\n\r\nThe ability to customize storage backends is very desirable! It just can't\r\nbe exposed in the runtime API. Which is why it requires hooks.\r\n\r\n can docker decide when it is appropriate to remove a persistent volume?\r\n\u003e\r\n\u003e When the user types \"docker rm --volumes\".\r\n\r\nIsn't *explicit better than implicit*?\r\n\u003e\r\nYes.\r\n\r\n\r\n\u003e  (container migration), it is indeed an elegant approach, *but* it\r\n\u003e completely bars the way to use CRIU and modern container migration\r\n\u003e techniques (which would require some cooperation some docker anyway).\r\n\u003e\r\nNo, it doesn't. The migration container can be instrumented by a system\r\nwhich makes appropriate docker calls, or it can make the calls itself once\r\nwe expose an appropriately powerful introspection api.","The proposal didn't require any out-of-band configuration and didn't break\nrepeatability of a run.\n\nSpecifying \"-v=/var/lib/mysql=/mnt/mysql\" doesn't \"break repeatability\"\nmore than \"-p :3306\".\nBecause the intent is very different between \"-v=/var/lib/mysql\" (resp. \"-p\n3306\") and \"-v=/var/lib/mysql=/mnt/mysql\" (resp. \"-p :3306\"). In one case,\nyou're running a generic container, without much concern for its actual\nstate, context, and side-effects. In the other, you're running a specific\ncontainer, with well-defined expectations about the data it will use, and\nthe way it will be accessible from other hosts. Obviously this can be\nrepeated only in the appropriate context, and (in most cases) only once at\na time.\n\nIf the intent is to provide a 100% repeatable interface, then we should\nalso remove \"-p :X\" since it bears exactly the same issue.","Thanks!","Chooper: commit 726b3233b7e018ea4f1045f1e82638dc800d3ee9 is an improved version that properly handles puppet provisioning. (adding  creation of ~/docker if it doesn't exist and  hostonly ) What do you think?","I just installed this on a new MacBook (10.7.5) using vagrant 1.0.7, and it worked perfectly, with no issues the very first time.\r\n\r\nClosing the issue.","Got an error: 'docker put' is now 'docker import -stdin'","What?\r\nOh crap, it pulled another commit which was in a different pull request in the first place. What should we do then?","I'll merge it now since it's a contrib script - not the end of the world if it's out of date for a couple days. Remember to fix it at some point.\r\n\r\nThanks!","seems to be 32-bit specific (or at least doesn't happen on precise64 with same commands)","Yeah, I don't think there's been much testing with 32-bit.\r\n\r\n\r\nOn Wed, Mar 20, 2013 at 1:49 PM, Andy Smith \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e seems to be 32-bit specific (or at least doesn't happen on precise64 with\r\n\u003e same commands)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/116#issuecomment-15202494\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","Reproduced, fixed locally, pull request pending. Stealing.","I think this issue can be closed, as 32-bit is totally unsupported now.","Reproduced","@chooper damn right you did","All caps issue is being addressed in #116 \r\n\r\nFor the lxc-start/init issue, I'm thinking that either the base image being in 64-bit is breaking or the bind mount for /sbin/init is broken. In any case, the former will definitely become an issue, so I'm building a \"base32\" image.","Docker currently doesn't support i386, for the sake of simplicity and focus. It will eventually, but for now you will need a 64-bit host. I have made this more clear in f7837599283ff89493d4fcfb7d9a046a7f9dc13b","This has changed. ```docker help``` prints the same thing as ```docker``` and ```docker -help``` prints the list of flags for running the daemon.\r\n\r\nThis is correct because ```docker help``` isn't a docker top level command and ```docker -help``` is actually about showing the daemon flags.\r\n\r\n@creack Please take a look at this issue. It can probably be closed.","Fixed by #689 ","Yep. That's correct and needs to be considered. What about commit 726b3233b7e018ea4f1045f1e82638dc800d3ee9","Nice Catch!","Hello ezbercih,\r\n\r\nThank you for the request.\r\n\r\nActually, the go parser considers only options given right after the command.\r\n\r\nIf you do docker attach -e -i -o 30a00b56, cmd,Nargs() will still be one and the options will be parsed. 30a00b56 will be cmd.Arg(0).\r\n\r\nHowever, if you do docker attach 30a00b56 -e -i -o, cmd.Nargs() will be 4 and -e -i -o will be discarded.\r\n\r\nAs we can only attach only one image at the time, it is better to keep if cmd.Nargs() != 1.\r\n\r\nRegards,\r\n","I understand. I should've read things better :) I guess the reason why I was confused was the help message I see when I issue docker help attach:\r\n\r\nUsage: docker attach [OPTIONS]\r\n\r\nAttach to a running container\r\n\r\n  -e=true: Attach to stderr\r\n  -i=false: Attach to stdin\r\n  -o=true: Attach to stdout\r\n\r\nMaybe the help should mention to add ID of the container to attach similar to start:\r\n\r\nUsage: docker start [OPTIONS] NAME\r\n\r\nStart a stopped container\r\n\r\nAlthough, NAME does not make sense either, I guess, since containers are not referred to with names anywhere in docker.","Thanks Don!","Might be similar to #108 ","Thanks for the contribution! Your solution is much more elegant than what we have now.\r\n\r\nUnfortunately I was not able to get it to work with the vagrant-aws provider plugin (it did work great with VirtualBox). I believe that this is actually a bug from within the vagrant-aws plugin, so I've filed an issue there and will be submitting a pull request to to fix the issue later in the day: https://github.com/mitchellh/vagrant-aws/issues/16\r\n\r\nI'm going to keep this issue open until this is resolved but I just wanted to update you on why there's been a delay.","Hi @thoward, thanks again for your contribution.\r\n\r\nAfter today, we actually rsync the path to the repo. This guarantees that the source directory exists and so this is no longer needed. If you can think of a use case where this is still needed, please re-open this PR and I will reconsider.","Thanks!","You can ignore them. It is functional but there is an issue with the TTY control. See #18 for the follow-up","Note: the current handling of pseudo-terminals (which are used when running a container in \"attached\" mode) would be affected by a restart, though. This is due to the fact that the docker daemon is holding the master side of the pseudo-terminal. When the daemon goes away, the process running in the container will get a `SIGHUP` (unless it detached from its controlling terminal, of course).","I had few problems with docker when crashing/shutting it down and there are possible solutions as well.\r\n\r\n# Problem 1\r\nIn current situation docker \"corrupts\" all running containers if shutting docker daemon or host/daemon crashes. Starting containers after that causes containers to become ghosts (actually container starts correctly but is marked as ghost).\r\n## Current workaround\r\nIf you currently want to restore your containers you can do following:\r\n- stop docker daemon\r\n- be sure all container processes are killed\r\n- modify each containers **config.json** and make sure **running** and **ghost** is both set to **false**\r\n\r\n## What it should do?\r\nWhen shutting docker daemon down it should gracefully stop all running containers (at least default behavior)\r\n\r\n# Problem 2\r\nAfter docker shutdown (clean or unclean) *in some situations* there may be dockers old bridge-interface (ie. 127.16.42.0/24) still left which causes restarted docker daemon to take a new ip-subnet (ie. 10.0.3.0/24). However if in the old ip-space there was containers they have their ip-addresses still in restarted docker-daemon but not needed iptables configuration (masquerading). This causes old containers not to have networking from containers to outside internet. (the bridge is still available so containers can ping the host and each others but not outside, also from outside you can connect to container)\r\n## Current workaround\r\n- stop and remove containers in new ip-space\r\n- stop docker daemon\r\n- kill all container-processes\r\n- remove all bridges and flush the ip-tables\r\n- start docker daemon and now you should have working networking with the old ip-space\r\n\r\n## What it should do?\r\nIdentify and kill old docker bridges OR make sure the starting containers belong to right ip-space OR some kind of multi subnet/interface support","This is pretty broad and should be discussed in the mailing list, and/or broken down in smaller, actionable issues.\n\nSince this issue was open we added 1) \"ghost mode\" which allows docker to partially regain control of surviving containers after a restart, and 2) docker -d -r which causes docker to restart stopped containers.\n\nI think the current situation can be improved, but again we should discuss on the list.","Hi,\r\n\r\nI understand how this could be confusing. Basically, `docker -d` (daemonized docker) needs to be run as root because it will handle all sorts of operations that can't be executed by normal users, such as mounting aufs filesystems and such. Once `docker -d` is running, you can use docker commands as a simple client since the only thing it does is send commands to the daemon.\r\n\r\nIf you don't launch the `docker -d` process, the docker command will start an ephemereal daemon process. If you're doing simple operations like listing containers or images, it will probably run fine as a normal users, but commands like `docker run` will obviously still need to be run as root.\r\n\r\nHope that helps clarifying it!","Looking back on this ticket after using docker a lot over the past couple of weeks, my position is that we should get rid of standalone mode entirely. The root/non-root confusion will be reduced as a nice side-effect.","@cespare, :+1:","It looks like we might need to deprecate standalone mode... I summarized the arguments for it in #364. Please weigh in if you have an opinion.","By the way, if CONFIG_USER_NS is turned on, then it is possible for an unprivileged user on the host to have privileges to mount inside the container.\r\n\r\nGiven that, is it possible that docker will support running as non-root in the future? Has this been discussed before?","@pwaller I think you should reenter the ``CONFIG_USER_NS`` idea as a new issue and label it as a feature request. This issue was about documenting the requirements for root vs non-root, and now that the docker daemon *must* be running (per #364) and must be run as root to become a daemon, the documentation becomes simpler.\r\n\r\nRunning the daemon as non-root would be a new feature request and separate from this documentation issue.\r\n\r\nI'll review the docs to make sure we always talk about starting the daemon with sudo and then I'll close this ticket.","I've confirmed that the current docs always show ``docker`` used in a situation where the daemon is already running as root (e.g. the vagrant installations) or demonstrate starting the daemon with sudo (eg the [examples](http://docs.docker.io/en/latest/examples/running_examples/))\r\n\r\nClosing.","Could this have label project/security added?","+1","Oh cool, you beat me to it! Thanks!","@chooper I'll wait for your ok to merge.","Thanks Antony!","Thanks for the contribution @amesserl! I don't have a RackSpace account (yet) so I wasn't able to test the RackSpace integration specifically, but I *was* able to still deploy to VirtualBox and AWS, following some minor changes.\r\n\r\n@shykes This is ready to be merged","No problem, those changes look safe enough to me... did some unintended changes from creack creep in?","I did a merge with upstream so this pull request could be automatically merged and so it pulled a bunch of other stuff in. I'm about to do it again because we're out of date :)","@shykes This is ready to be merged (again)","Here's what I suggest:\r\n\r\nStep 1: docker only supports amd64. It will refuse to start a container on any other architecture.This should be made clear to the user.\r\n\r\nStep 2: docker will eventually support more architectures, including i386. This will include arch-specific images, facilities to look them up etc.\r\n\r\nSo, I will accept anything that makes it easier to support multiple architectures *in the future*. But for now we're sticking to amd64.\r\n","Enforced in f7837599283ff89493d4fcfb7d9a046a7f9dc13b","\u003e Step 2: docker will eventually support more architectures, including i386. This will include arch-specific images, facilities to look them up etc.\r\n\r\n\u003e So, I will accept anything that makes it easier to support multiple architectures in the future. But for now we're sticking to amd64.\r\n\r\nSo getting a i686 build would be something you would merge?","Shouldn't there be an open issue that we can subscribe to and get notified when it gets implemented?","@brunoqc #611","How should we interpret the closure of this issue?  Is the real answer \"wontfix\", or are there seriously plans to support hosting on 32 bit (and other architectures) someday?  If the former, then closing this issue makes sense.  If the latter, then leaving this issue open makes sense.  Saying that docker will eventually support 32 bit hosts, then closing this issue without first doing so, sends mixed signals at best. \r\n\r\nThe reference to bug #611 doesn't make sense here either -- #611 is about 32 bit *containers*, not hosts; not a dup.\r\n\r\nFor the record:  As of today, there still appears to be no supported way to install or build docker on a 32 bit Ubuntu Raring machine.\r\n\r\n(1)  The instructions at http://docs.docker.io/en/latest/installation/ubuntulinux/ cover 64 bit only, and fail on a 32 bit machine with \"E: Unable to locate package lxc-docker\".\r\n\r\n(2)  Following http://docs.docker.io/en/latest/contributing/devenvironment/ to build from source fails, of course, because it depends on an existing installation of docker, which isn't readily available due to (1).  Wash, rinse, repeat.","There is a solution I need to try here:\r\nhttp://mwhiteley.com/linux-containers/2013/08/31/docker-on-i386.html\r\nby @whiteley","What's the 'official' word on this? Is official support for running Docker containers on 32-bit systems coming?","I am also curious about the official word on 32-bit Linux support.  Thanks.","\u003e I am also curious about the official word on 32-bit Linux support.\r\n\r\nme, too","Supporting this in docker is easy but that hard work is around registry support to make sure that when you run `docker pull debian` you get the correct image depending on your arch.  This is what makes the feature request non-trivial.  ","Here's another vote for 32-bit hosts. I have no desire to run a 64-bit operating system, since it chews up much more memory than a 32-bit one (I'm guessing it has to do with pointers taking up 8 bytes instead of 4).\r\n\r\nI am also interested in why @shykes refuses to run containers on anything other than amd64. What are the technical limitations or dangers of 32bit for containers? (it's not a rhetorical question, I have no knowledge about the subject and would like to know why)","I think @crosbymichael's post explains the main reasoning. The actual running of the container is not hard, getting the images to be architecture aware is the plumbing that is not present today.","Good point, @vmarmol. Didn't notice that comment, was falling asleep at the keyboard :)\r\n\r\nCould someone elaborate on that issue, please?\r\n\u003e hard work is around registry support to make sure that when you run docker pull debian you get the correct image depending on your arch\r\n\r\nWhat's that \"registry support\"?\r\nAnd why isn't this as simple as naming the images after their architecture, like debian32, ubuntu-amd64, or something similar? (honest question, I think if it were this simple it would have been done already :) )","+1 to 32 bit support. We're distributing an open source application for humanitarian use in lightweight netbooks. We use LXC because there's no way of running virtual machines in the netbook, and that's why Docker is very interesting to us. If only docker can start supporting 32 bit, we can get rid of all the current manual rpm/deb/lxc packages/snapshots, and simply say docker rules everything!","+1 for 32bits support","+1 to 32 bit support. Trying to setup sample application with database through docker, as application under test to demonstrate open source testing tools. But we are blocked due to this issue, since most of users will have low end machines only. ","+1 for making it possible to connect to localhost:port \r\n\r\nWith my vagrant install connecting to $(hostname) (as in the example) also doesn't work because it also resolves to 127.0.0.1 ","I've looked into this and it won't be possible to use localhost at all without something like portfwd.\r\n\r\nI'll provide a solution for the second problem (the one which causes ports to loop back to the container).\r\n\r\n@jpetazzo You can assign this issue to me.","Instead of trying to list all IPs of the host so that we allow the containers to connect on any of them, we could just pass to docker the interfaces we want it to take into account.\r\n\r\nFor example, I might have 6 interfaces and only care about allowing docker hosts to connect to each other via the IP of one single interface. So I'd pass docker -d some argument like -forward-if=tap0.\r\nDocker would then get the IP of that interface and set up a rule to forward only traffic going to the IP of tap0.\r\n\r\nAlso, if I want to connect to any container, I have to use that IP + port, not localhost, nor any other IP of the host.","Assigned to you, thanks!\r\n\r\nAgreed on first issue (using localhost): it requires some userland proxy.\r\n\r\nAbout second issue: \"we could just pass to docker the interfaces we want it to take into account\" — I think it won't be simpler than enumerating all of them, and some cases might even be tricky (e.g. what if I want to catch traffic directed to one specific secondary address or alias?)\r\n\r\nIMHO, using all addresses would be \"good enough\" at first; and having a way to specify interfaces and/or IP addresses would be a nice bonus.","@jpetazzo In that case, we could specify IPs on which we want docker to make the mapped ports available.\r\nWould this be ok?\r\n\r\nAlso, it's easier to specify the IPs from which we map those ports from to the containers than enumerating all the interfaces and letting traffic through for all of them. It's also better to make things explicit than implicit in this case.\r\n\r\nSpecifying the IPs means we don't need to add code to get the list of interfaces.\r\n\r\nSo the flags would look something like: -map-ip=192.168.1.24 -map-ip=10.4.0.2.\r\n\r\nFor those who don't want to have to pass IPs to docker, we can also allow them to use the interface name. We won't have to obtain the IP or IPs of the interface(s) in that case either.","\u003e  In that case, we could specify IPs on which we want docker to make the mapped ports available.\r\n\u003e Would this be ok?\r\n\r\nYes, I think that would be perfect.\r\n\r\n\u003e we can also allow them to use the interface name. \r\n\u003e We won't have to obtain the IP or IPs of the interface(s) in that case either.\r\n\r\nI don't understand — if people specify an interface name, how are we going to build the iptables rules?\r\nIIRC, we want to setup `DNAT` rules, and those rules have to be in the `PREROUTING` chain, where the output interface (`-o` flag) isn't available, right?\r\n","This issue is done, so it can be closed.","see issues #97 for what happens without this change.","Thanks!","hmm, not a good idea to log these when called from `setup`, otherwise a normal functioning dockerd would log as:\r\n\r\n```\r\n2013/03/22 22:16:57 ERROR: iptables failed (iptables -t nat -D PREROUTING -j DOCKER): iptables: No chain/target/match by that name.\r\n2013/03/22 22:16:57 Listening for RCLI/tcp on 127.0.0.1:4242\r\n2013/03/22 22:17:02 docker run -p 4444 base /bin/nc -k -l -p 4444\r\n2013/03/22 22:17:10 docker port 97111af5 4444\r\n```","@creack I was looking through the code to see what it would take in order to get my desired log output and I had a few questions. Remember I'm still new to Go, so if what I'm suggesting isn't kosher, just let me know.\r\n\r\nin https://github.com/dotcloud/docker/blob/master/registry.go#L216 we are calling imgOrig.WalkHistory and passing in a big inline function. Is there a reason for doing it this way instead of calling imgOrig.History() and then looping over the image list it returns inside of registry.PushImage()?\r\n\r\nSo the code would look similar except it would be inside out from it's current form, but the advantage is that we would know what images we are working on, the total number of images, and we could easily mark the logs with the \"[#/n]\" showing which images we are working on. Another plus is that we can reverse the order we are processing the images, and start with the base and work our way down from there, it will make the logs make more sense since we start with the parents, and work down to the last image we are pushing. \r\n\r\nI'm not sure how this will effect the other features we want to add in the future, progress bar, and pushing images in parallel, but I don't think it will be that much of a hassle, and it might even be easier.\r\n\r\nBefore I made any changes, I wanted to run it by you to make sure I was on the right track.\r\n","Actually, History() is just a wrapper on top of WalkHistory().\r\n\r\nI didn't used it in order to do something 'generator like' (from far in the fog). This way, you don't need to have all the history in memory and you only work with one image at the time.\r\n\r\nNow, we need to check if it stil interesting to do that, it might indeed be easier to take the whole history at once and then play with it.\r\n\r\nEither way, it is linked to #150","pull request #143 fixed this so I'm closing the issue.","Pull request #143 fixed this, so closing issue.","Looks good","Agreed, it would be nice to autologin, and it looks like you commit will do that.. :)","closing, code already merged into master.","If we already have it working, I say lets keep it. ","I start by adding the command 'rmrep' and I'll merge all the 'rm' later.","The changeset you're attaching has this comment in the commands.go file: `// Priority: Container, Image, Repository`\r\n\r\nMy concerns with this are two-fold:\r\n\r\n1. While this is documented in the source-code, there is nothing to indicate it in the UI, which is bound to be confusing for users\r\n2. Isn't this a recipe for disaster? Like - how much can I trust this order to stay consistent in future updates? Can I use it in my docker scripts without fear that tomorrow's update will break the state of my docker? \r\n\r\n\r\nAs a side note, it also seems that I could mistype `rm` while trying for `rmi` or `rmc` and end up with unexpected results (but I guess the same argument could be made for `rmi` versus `rm` before).\r\n\r\nJust my two cents!","Ok for the UI, but the thing is that containers, images and reporisotires have different formats, so if you try to rmc an image or rmi a container, it will just fail :)","Fixed by #385 ","So I've taken a swing at this, assuming the underlying server is an s3 instance, and I can use this: http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingRESTAPImpUpload.html.\r\nIs that assumption correct or am I being foolish here? \r\n\r\nIn any case my first run at this can be found here: https://github.com/byAtlas/docker/tree/149-chunked-push","You're correct, the store is currently backed by S3 *but* I really don't\r\nwant to introduce a dependency on S3 in docker. As long as the solution\r\nworks with standard HTTP servers, then we are good.\r\n\r\n\r\nOn Thu, Mar 28, 2013 at 11:49 AM, byAtlas \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e So I've taken a swing at this, assuming the underlying server is an s3\r\n\u003e instance, and I can use this:\r\n\u003e http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingRESTAPImpUpload.html.\r\n\u003e Is that assumption correct or am I being foolish here?\r\n\u003e\r\n\u003e In any case my first run at this can be found here:\r\n\u003e https://github.com/byAtlas/docker/tree/149-chunked-push\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/149#issuecomment-15607130\u003e\r\n\u003e .\r\n\u003e","OK, sweet. Ignore this for now then. I'll work on it a bit more over the\r\nweekend.\r\nOn Mar 29, 2013 7:54 AM, \"Solomon Hykes\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e You're correct, the store is currently backed by S3 *but* I really don't\r\n\u003e want to introduce a dependency on S3 in docker. As long as the solution\r\n\u003e works with standard HTTP servers, then we are good.\r\n\u003e\r\n\u003e\r\n\u003e On Thu, Mar 28, 2013 at 11:49 AM, byAtlas \u003cnotifications@github.com\u003e\r\n\u003e wrote:\r\n\u003e\r\n\u003e \u003e So I've taken a swing at this, assuming the underlying server is an s3\r\n\u003e \u003e instance, and I can use this:\r\n\u003e \u003e http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingRESTAPImpUpload.html.\r\n\u003e\r\n\u003e \u003e Is that assumption correct or am I being foolish here?\r\n\u003e \u003e\r\n\u003e \u003e In any case my first run at this can be found here:\r\n\u003e \u003e https://github.com/byAtlas/docker/tree/149-chunked-push\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/149#issuecomment-15607130\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/149#issuecomment-15607410\u003e\r\n\u003e .\r\n\u003e","I don't think the image needs to be chunked on the docker side. Go can stream from disk (or from the tar output) just fine without reading everything into memory, so the code should be refactored to do this. The registry server just needs to implement streaming multipart uploads to S3.","Correct, docker should stream a tar directly. This is already supported on the registry side - it uses an HTTP redirect to point docker directly to an S3 upload url.","@byAtlas I just took a quick look at the code, and it looked good, but I noticed one issue. And I'm not surprised, since the push/pull stuff isn't documented very well. \r\n\r\nIt push works like this.\r\n\r\nStep 1: upload the metadata (json) passing in the username/password\r\n\r\nAssuming step 1 works. \r\n\r\nStep 2: do a put request to the registry, with no data. The registry will either reply with a \"we already have it, HTTP 307 redirect to this URL.) The redirected URL is an s3 endpoint.\r\n\r\nStep 3: upload the data to the s3 url that was given to us in step 2.\r\n\r\nRIght now it does one big upload, and we need to break it up into chunks, which your code looks like it does. But the issue is that your step 3, sends the files to the registry server instead of s3. Minor detail, easy to fix, but I wanted to let you know.\r\n\r\nSo to sum up, we have a web app that runs the registry, but we store all of the data in S3. But future registries, ours or others might not use s3 as a backend so we will need to make sure we create the code so that it is standard HTTP solution that works for any backend. \r\n\r\nDoes that makes sense? Hopefully I answered some more questions, but if you have any more, feel free to let me know. \r\n\r\nThank you for taking the time to contribute the code.","@shykes I'm pretty sure that would either require docker to be aware of the S3 multipart API or to specify the `Content-Length` ahead of time, which both preclude just streaming the tar up.","@kencochrane @shykes I feel like a better solution is for the registry server to accept a `Transfer-Encoding: chunked` request (with no specified `Content-Length`) and proxy that through to a S3 multipart upload. This way there is no tie to S3 and streaming will work properly.","@titanous that is our plan B if there is no way to stream to S3 with non-S3-specific code. But if there's any way to avoid that, it would be preferable, if only to remove a bottleneck and keep our bandwidth costs down :)\r\n","@shykes The only way to stream to S3 without using the multipart API is if the `Content-Length` for the request is set.","@titanous I'm guessing we can probably get the Content-Length from out of the Tar operation.","@byAtlas I think that's only possible if we save it out to a tempfile first.\r\n\r\n@shykes It's just a bottleneck factor here, I think. Inbound bandwidth is free if you're on EC2 (and is free to S3 as well).","The current code (not the PR) already sets the content length.\r\n\r\nAccording to http://golang.org/pkg/net/http/httputil/#NewChunkedWriter\r\n\r\nIt says Go will automatically chuck the upload, if there is no content length.. So if we remove the content length would that automatically start doing a chucked upload to S3? Or am I reading that wrong?\r\n\r\n---\r\nNewChunkedWriter is not needed by normal applications. The http package adds chunking automatically if handlers don't set a Content-Length header. Using NewChunkedWriter inside a handler would result in double chunking or chunking with a Content-Length length, both of which are wrong.","@kencochrane Yes, that's correct, but it's not the problem. S3 **requires** the `Content-Length` header to be set.","There is a nice Go package here that does multipart uploads to S3, but I'm not a fan of making docker aware of S3 usage in registries: https://github.com/kr/s3","@titanous you can get the archive size out of tar. --totals.","@titanous OK, thanks.. I have looked at that package, and was trying to see if we can take what he does and use it to make a generic solution, but if S3 does things a little different then we might not be able to.. We would need to do Plan B (the solution you mentioned earlier) ","@kencochrane There's nothing generic about the S3 multipart uploads. It's a bunch of individual HTTP requests uploading fixed-size chunks, then a final request with a manifest that materializes the object from the uploaded chunks.","@byAtlas That doesn't solve the problem, as we'd need the size *before* starting the tar stream. So it'd have to be saved to a tempfile first.","@titanous, @kencochrane There is of course the hacky way, whereby if a response from the server has the s3 stuff, we do it the s3 way, or otherwise do normal http.\r\nIf someone makes a server that responds to everything with x-amz-id-2, and x-amz-request-id, we will, of course, be in trouble, however.","From the looks of all this, we might be forced to stream through the\r\nregistry. Let me confer with the registry-people.\r\n\r\nOn Thursday, March 28, 2013, byAtlas wrote:\r\n\r\n\u003e @titanous \u003chttps://github.com/titanous\u003e, @kencochrane\u003chttps://github.com/kencochrane\u003eThere is of course the hacky way, whereby if a response from the server has\r\n\u003e the s3 stuff, we do it the s3 way, or otherwise do normal http.\r\n\u003e If someone makes a server that responds to everything with x-amz-id-2, and\r\n\u003e x-amz-request-id, we will, of course, be in trouble, however.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/149#issuecomment-15611393\u003e\r\n\u003e .\r\n\u003e","@titanous My bad, clearly I'm past the time of the morning where coherent thought is a thing.","@creack This has been fixed by the registry update. You can probably close this issue. ","I've just thrown up a branch with the pull parallelized: byatlas/docker@23dca00f41f80d37b7111f301550d67097f04abf\r\n\r\nIt's also a lot more verbose, in line with the proposed push output for #140.\r\n\r\nI'm not entirely happy with the use of the struct, but I'll take another look at this tomorrow, just wanted to throw it up so everyone can take a look and tell me how wrong everything is :smile: ","@byAtlas Instead of `for` loops and counters, it could be cleaner to use a pool of worker goroutines and a channel to handle uploading/downloading.","@titanous Good call. I've made that change and have started work on the pushing code.","I'm tentatively submitting this for inclusion in 0.6. What do you think @creack @vieux? We had a pull request but didn't merge it.","There are two things here:\r\n- first: currently you can pull 2 images at the same, `docker pull ubuntu` `\u003cctrl+c\u003e` `docker pull centos` works. Problem is if the 2 repos use the same images, like `samalba/hipache` and `shykes/couchdb` I think we should use the push and pull pools but using images ID, not the repo name.\r\n\r\n- second: we have to change the UI, do you want `docker pull REPO [REPO...]` ?","@vieux what I would like to see is the following. If a repo has 10 images, and I have none of them, instead of downloading them one at a time, download them in parallel. Same with pushing if possible. I normally don't want to pull two repos at the same time, so that isn't that important to me. ","Lets' say you have the ubuntu repo (2 images `8dbd9e392a96` and `b750fe79269d`)\r\n\r\n    $\u003e docker images\r\n    REPOSITORY          TAG                 ID                  CREATED             SIZE\r\n    ubuntu              12.04               8dbd9e392a96        3 months ago        131.5 MB (virtual 131.5 MB)\r\n    ubuntu              12.10               b750fe79269d        4 months ago        24.65 kB (virtual 180.1 MB)\r\n    ubuntu              latest              8dbd9e392a96        3 months ago        131.5 MB (virtual 131.5 MB)\r\n    ubuntu              precise             8dbd9e392a96        3 months ago        131.5 MB (virtual 131.5 MB)\r\n    ubuntu              quantal             b750fe79269d        4 months ago        24.65 kB (virtual 180.1 MB)\r\n\r\nLet's delete `8dbd9e392a96`\r\n\r\n    $\u003e docker rmi ubuntu:12.04 ubuntu:latest ubuntu:precise\r\n    Untagged: 8dbd9e392a96\r\n    Untagged: 8dbd9e392a96\r\n    Untagged: 8dbd9e392a96\r\n    Deleted: 8dbd9e392a96\r\n\r\nIf I do a `docker pull ubuntu` I'll get all the missing images, I don't see what you need","What if you had a repo with 10 images, and I only had 2 of them on my machine. When I do a docker pull, it will download the missing 8 serially (one after the other), it would be nice to download the missing images in parallel (more then one at a time).  This would speed up the download time, assuming I have enough bandwidth.","This issue is about parallel download of images within the scope of a single pull command (what @kencochrane is describing)\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, Jul 24, 2013 at 7:35 AM, Ken Cochrane \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e What if you had a repo with 10 images, and I only had 2 of them on my machine. When I do a docker pull, it will download the missing 8 serially (one after the other), it would be nice to download the missing images in parallel (more then one at a time).  This would speed up the download time, assuming I have enough bandwidth.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/150#issuecomment-21489054","@vieux Are we still waiting on Parallel Push in order to close this issue?","Yes, I'm on it.","tag #1570","Should this be closed now? ","status on this?","+1","Not sure if its linked to this, but having my pushes spend 2 minutes attempting to send layers 1 at a time, only to decide the repo already has them is insanely slow.\r\n\r\nAs part of the paralell processes, is there anything to stop the following sequence?\r\n\r\n```\r\ninitiate_push: send repo the ID of all layers\r\nrepo_response: lists IDs of layers it doesn't have\r\npush: parallel send all missing IDs.\r\n```\r\n\r\nsimilar for pull, although that already has some parallel behaviour",":+1: ","everything that this issue references (pull and push) is closed and merged. This looks ready to close\n","So what docker release would I see this in?","@dweinstein most of them. definitely in 1.0.0","Unfortunately not yet in my brew-installed docker client. Darn. `docker --version` \r\n`Docker version 0.11.1, build fb99f99`","What are you doing to test?\r\nOn Jun 12, 2014 5:24 PM, \"David Weinstein\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Unfortunately not yet in my brew-installed docker client. Darn. docker\r\n\u003e --version\r\n\u003e Docker version 0.11.1, build fb99f99\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\r\n\u003e \u003chttps://github.com/dotcloud/docker/issues/150#issuecomment-45949924\u003e.\r\n\u003e","I was pushing to a private registry. I guess it's possible that it doesn't support it.","Running docker 1.0, both push and pull are definitely still very serial. Looking at the code, I can't see anything which would make those parallel. Am I missing something? When did this land?","Let me re-evaluate, since they merged features may have been since been\r\nreverted.\r\nOn Jun 12, 2014 6:13 PM, \"Jonas Nicklas\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Running docker 1.0, both push and pull are definitely still very serial.\r\n\u003e Looking at the code, I can't see anything which would make those parallel.\r\n\u003e Am I missing something? When did this land?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\r\n\u003e \u003chttps://github.com/dotcloud/docker/issues/150#issuecomment-45954804\u003e.\r\n\u003e","Hey so. It doesn't look like the code to do a parallel push was ever merged, afaik. #1570 isn't merged, and I had a look for anything else from @vieux that referenced parallel and couldn't find anything, unless it was merged from someone else's branch? ","Docker Pull and Push are still really slow, can this please be looked at?","@sammcj As related ticket - What's \"really slow\":\r\n\r\n1. For which image?\r\n2. For what Docker version? \r\n\r\nPlease provide data otherwise this isn't a helpful update. Thanks!","-Docker version 1.1.0, build 79812e3\r\n-All images\r\n-Regardless if it's a local server or off the net we can only get around 3-5MB/s\r\n-If we curl the layers directly we get 132MB/s\r\n\r\nEdit, lets move performance discussion over to #1888 so we're not duplicating efforts","So should this issue be reopened? Is parallel push code missing?","Yes. I agree with you. I just copied to local and compile it.","Indeed :) Now, the \"import\" feature requires the whole URL. in case of base, it would be docker import http://get.docker.io/images/base\r\n\r\nBut as you pointed out, it is much easier to just do docker pull base :) which will pull the image from the registry.","So I'm wrong actually. Would be nice to have the output to `docker images` look something like that maybe?\r\n\r\n    REPOSITORY      TAG     ID          CREATED     PARENT\r\n    \u003cnone\u003e          \u003cnone\u003e  abcd3426    2 hours ago 12ffffff","I believe @shykes worked on this part and changed a lot of things. @shykes ?","Thank you!\r\nHowever, I think we do not depend on sqlite anymore as now we store everything in json on the disk. Maybe we can simply remove it? As well as curl?\r\n\r\n@mzdaniel  or @sa2ajj If someone could double check all the dependencies, it would be nice :)\r\n","@creack, at least ldd shows that it somehow depends, though I do not see any mention in the code:\r\n\r\n\u003cpre\u003e\r\n$ ldd `which docker`\r\n\tlinux-vdso.so.1 =\u003e  (0x00007fffa8ba7000)\r\n\tlibpthread.so.0 =\u003e /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fd0d54f9000)\r\n\tlibc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007fd0d516f000)\r\n\tlibsqlite3.so.0 =\u003e /usr/lib/x86_64-linux-gnu/libsqlite3.so.0 (0x00007fd0d4ec3000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x00007fd0d571f000)\r\n\tlibdl.so.2 =\u003e /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fd0d4cbf000)\r\n\u003c/pre\u003e\r\n\r\nVersion:\r\n\u003cpre\u003e\r\n$ docker version\r\nVersion:0.0.3\r\n\u003c/pre\u003e\r\n\r\nSo it does not seem to be the latest from git (I still need to understand how to build it locally :))","@sa2ajj Since yesterday, we merge the 'graph' branch and the new version is 0.1.0 :)\r\nI'll see with @shykes in order to upgrade the docker-master.tgz\r\n\r\n$ ldd docker\r\n        linux-vdso.so.1 =\u003e  (0x00007fffbdbff000)\r\n        libpthread.so.0 =\u003e /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f9abb87b000)\r\n        libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007f9abb4bc000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00007f9abbaa2000)","while we are at it, it might be nice to know what client OS is making the request (os, kernel, arch, etc).. etc. it would be nice way to track what the most popular clients are, and in the future we might need to give different responses depending on the value? 32bit, vs 64bit being the most obvious. ","+1","Any update on when this might get done, this will make it easier to track metrics on what docker version people are running.  /cc @creack @shykes \r\n\r\nI don't have much time to work on it, but I can take a stab if someone else is busy.","I think this might never happen, we used the alternative: pass the version via URL. Is there issues using this data?","@creack This is for when docker connects to the registry or index. In the index/ registry we have no idea what version of docker is getting used and it would be nice to know that for a few reasons.\r\n\r\n1. We can audit the different versions of docker that is getting used, so we know how many people are using what versions.\r\n2. If we start getting to the point where the docker index/registry needs to know what version of docker is getting used to do something differently it would be nice to have.\r\n3. In future if we want, We can start sending back messages to people letting them know when a new version of docker is available, to help push upgrades.\r\n\r\nIf we can set a User-Agent header with the docker version information, that would be perfect.","@shykes any though on this?","I briefly read the code. It seems to me that it only requires to add some lines like ``req.Header.Set(\"User-Agent\", r.dockerVersion)`` to registry/registry.go. Am I correct on this?\r\n\r\nIs there anyone working on this issue now? If there is no one, I would like to do it as my weekend project.","@monnand I think you are correct, I don't think the change is too complicated, we just need to make sure it is added to all calls to the registry. \r\n\r\nI also don't think anyone is working on it. @shin- or @vieux do you know if anyone is working on this?","@kencochrane Thanks. If no one works on this, I will do it this weekend. ","@monnand If you're on it. It would be great to add a complete user-agent set, not just the docker version. See #650 ","@dhrp OK. Since #650 requests several pieces of information, I may split it into several pull requests.","This looks like it can be closed now.  Thanks @monnand ","Could you include a copy of the daemon's and client's outlut, if any?\r\nThanks!\r\n\r\nOn Sunday, March 24, 2013, David Romulan wrote:\r\n\r\n\u003e I run docker as a daemon under root:\r\n\u003e\r\n\u003e sudo docker -d\r\n\u003e\r\n\u003e Then if I run a container with a tty with any command:\r\n\u003e\r\n\u003e docker run -t base true\r\n\u003e\r\n\u003e then the daemonized docker dies.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/157\u003e\r\n\u003e .\r\n\u003e","I try to run the daemon with -D debugging but then I can't get it to die\r\n(and seems like this is a workaround for my problem).\r\n\r\nSuggestions on getting logs in background daemon mode?\r\n\r\nOn Sun, Mar 24, 2013 at 8:42 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Could you include a copy of the daemon's and client's outlut, if any?\r\n\u003e Thanks!\r\n\u003e\r\n\u003e On Sunday, March 24, 2013, David Romulan wrote:\r\n\u003e\r\n\u003e \u003e I run docker as a daemon under root:\r\n\u003e \u003e\r\n\u003e \u003e sudo docker -d\r\n\u003e \u003e\r\n\u003e \u003e Then if I run a container with a tty with any command:\r\n\u003e \u003e\r\n\u003e \u003e docker run -t base true\r\n\u003e \u003e\r\n\u003e \u003e then the daemonized docker dies.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/157\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/157#issuecomment-15376660\u003e\r\n\u003e .\r\n\u003e","Sorry, I didn't understand what -d does -- when run in the foreground with -d, I can't get it to die.  Only when run in the background with upstart does it die.  I'll try to get logging that way and update this issue.","docker daemon only dies when I start it under upstart directly with \"exec docker -d\" in /etc/init/docker.conf.  If I specify a bash script, it will die in the bash script only if I exec the \"docker -d\" process.  Just running it and keeping the bash script shell prevents the daemon from dying.\r\n","Tried to reproduce this but wasn't able to.\r\n\r\n    # exec ./docker -d \u0026\r\n    2013/03/25 09:00:05 Listening for RCLI/tcp on 127.0.0.1:4242\r\n    # docker run -t base true\r\n    2013/03/25 09:00:18 docker run -t base true\r\n    # docker ps -a\r\n    ID                 IMAGE               COMMAND      CREATED              STATUS        COMMENT\r\n    52da9875e7f9eed7   base:latest         true         About a minute ago   Exit 0        \r\n    [snip]\r\n    # ps faux | grep docker\r\n    root      3075  0.0  0.7 222652  7452 tty1     Sl   09:00   0:00              \\_ ./docker -d\r\n    root      3146  0.0  0.0   9388   928 tty1     S+   09:04   0:00              \\_ grep --color=auto docker\r\n\r\nCan you confirm the bug still occurs with the latest version? (assuming you compile from source). Otherwise, the docker daemon should provide you with some info when it crashes, having this would help a ton!","Can't reproduce either. Closing.","Thanks for the report! Just fixed it in master.","I confirm (kind of):\r\n\r\n  19│func isNotExist(err error) bool {\r\n  20│        switch pe := err.(type) {\r\n  21│        case nil:\r\n  22│                return false\r\n  23│        case *PathError:\r\n  24│                err = pe.Err\r\n  25│        case *LinkError:\r\n  26│                err = pe.Err\r\n  27│        }\r\n  28│        return contains(err.Error(), \"does not exist\")\r\n  29│}","Is this still relevant @creack?","@creack do you still want me to merge this?","no, let's discard it. Will implement a better Rm later on today.","the Makefile should respect an existing `GOPATH` if defined. otherwise, it will violate a Go developer's already set-up development environment. for example, i keep all my Go sources at ~/go/src (with `GOPATH` set to ~/go), but this Makefile will unwittingly overwrite it.","@srid very good point. thank you. Let me think how to address this.","@srid, will this approach work for you?","+1 ... i personally have two preferences,\r\n* use `./.gopath` instead of `./build` just to make it explicit. `./build` generally won't contain source code, but in our case it will.\r\n* pass the `-v` flag to `go get` and `go build` for more verbose output from build, so that we will know what packages are being downloaded, and what docker packages are being built.","@srid, I changed thedir to .gopath and introduced a possibility to perform verbose operations","@sa2ajj so far looks good to me, except this: i have the docker source repo cloned under $GOPATH/src/github.com/dotcloud/docker (in future, once docker goes public, i could use `go get` to directly fetch the repo under the same directory). it looks like the Makefile will delete this directory upon `make clean`.\r\n\r\nwhen `.gopath` is not in use (i.e., $GOPATH is already defined), $DOCKER_DIR can be assumed to exist, and is the same as the directory where the Makefile lives.","@srid, you have a very particular setup that helps to find all corner cases :)\r\n\r\nI took a slightly different approach. Does it work for you?","I think the original concern is quite valid: you do not want to download the same deps again and again. And for some people (or situations) that might be a problem. So if GOPATH is already set, let's re-use whatever is available there (downloaded and built).","So, any outstanding issues? Should I try it out and merge if it works for me?\r\n","I think it's now good to go (more testing from the open source users will tell us if there's any issue:))","#171","It seems to be working right now, but an error is still being printed in the end:\r\n\r\n```\r\ndocker run --help\r\n\r\nUsage: docker run [OPTIONS] IMAGE COMMAND [ARG...]\r\n\r\nRun a command in a new container\r\n\r\n  -d=false: Detached mode: leave the container running in the background\r\n  -e=[]: Set environment variables\r\n  -i=false: Keep stdin open even if not attached\r\n  -m=0: Memory limit (in bytes)\r\n  -p=[]: Map a network port to the container\r\n  -t=false: Allocate a pseudo-tty\r\n  -u=\"\": Username or UID\r\nError: flag: help requested\r\n\r\n```\r\n\r\nedit: It's actually fine:\r\n```\r\ndocker help run\r\n\r\nUsage: docker run [OPTIONS] IMAGE COMMAND [ARG...]\r\n\r\nRun a command in a new container\r\n\r\n  -d=false: Detached mode: leave the container running in the background\r\n  -e=[]: Set environment variables\r\n  -i=false: Keep stdin open even if not attached\r\n  -m=0: Memory limit (in bytes)\r\n  -p=[]: Map a network port to the container\r\n  -t=false: Allocate a pseudo-tty\r\n  -u=\"\": Username or UID\r\n\r\n```\r\n\r\nThis issue can be closed.","Testing right away!","This is awesome. Well done.\r\n\r\nPS. why the hell does this not work in pure Go? Maybe you should open an issue on golang.org?","I am not sure if this change is related, but I got https://gist.github.com/sa2ajj/5243788 with the latest master","Yeah it's related. Pushing a fix in acouple hours, sorry. In the meantime\r\nyou can export NORAW=1.\r\n\r\nOn Tuesday, March 26, 2013, Mikhail Sobolev wrote:\r\n\r\n\u003e I am not sure if this change is related, but I got\r\n\u003e https://gist.github.com/sa2ajj/5243788 with the latest master\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/163#issuecomment-15446064\u003e\r\n\u003e .\r\n\u003e","Should be fixed now! https://github.com/dotcloud/docker/commit/3cce89d8edc9c3151bd982c6b5acfa8c20d5ae71","yes, it works for me.  thank you.","to make it lighter can we remove any of the images? Maybe host the windows install images somewhere else, like s3?\r\n\r\nAlso, are these images needed?\r\n\r\ndocs/theme/docker/static/img/docs-splash-top-3.png\r\ndocs/theme/docker/static/img/docs-splash-top-2.png\r\ndocs/theme/docker/static/img/docs-splash-top-1.png\r\ndocs/theme/docker/static/img/docs-mediawiki-ex.png\r\n\r\nif not, can we remove?","Any particular reason to put documentation in the ``source/``?","@sa2ajj it is under /docs? do you mean /docs/sources? Not sure, using sphinx for docs, so maybe related?","yes, i meant ``docs/sources``.\r\n\r\nI actually appreciate it's sphinx since https://readthedocs.org/ could be used to automatically build and publish the documentation :)\r\n\r\nIt's not really related: sphinx-quickstart *offers* to put sources in a separate directory and, in general, I'd kindly refuse the offer :)","I'm not sure, I didn't create the directory structure, is there a reason why it is bad form to have them in docs/sources? I'm still a newbie when it comes to sphinx\r\n\r\nI believe the goal is to use readthedocs so whatever we can do to make them work best with it, is ideal.","no, it's not bad. it just one more directory level that serves no particular purpose\r\n\r\nas for readthedocs, they just look for a conf.py file: as soon as it's found, they are happy to build a new version (https://read-the-docs.readthedocs.org/en/latest/faq.html#where-do-i-need-to-put-my-docs-for-rtd-to-find-it)","Good catch. The mentioned (splash) images are not used indeed. Let me also re-check if we need all js files. \r\n\r\nThe windows install images are higly compressed and don't take up much space. Together ~400k I believe. If we feel it is better i'll be happy to move them out. \r\n\r\n;-) - mobiele email\r\n\r\nOn 26 mrt. 2013, at 06:38, Ken Cochrane \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e to make it lighter can we remove any of the images? Maybe host the windows install images somewhere else, like s3?\r\n\u003e \r\n\u003e Also, are these images needed?\r\n\u003e \r\n\u003e docs/theme/docker/static/img/docs-splash-top-3.png\r\n\u003e docs/theme/docker/static/img/docs-splash-top-2.png\r\n\u003e docs/theme/docker/static/img/docs-splash-top-1.png\r\n\u003e docs/theme/docker/static/img/docs-mediawiki-ex.png\r\n\u003e \r\n\u003e if not, can we remove?\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","@shykes what do you think, should we keep the images in the repo, or put somewhere else (s3) and link in.. they are about 400k total.","there is a dir for sources because all files thereunder are compiled with sphinx (using the theme dir) it also helps to distnguish and prevents conflicts between theme files and _build files (generated by sphinx on your local machine. \r\n\r\nIt does get me thinking: \r\nI can see if I can remove the docs/sources/documentation dir.. And put the sections straight under sources\r\n\r\n\r\n\r\nOn 26 mrt. 2013, at 07:26, Mikhail Sobolev \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e no, it's not bad. it just one more directory level that serves no particular purpose\r\n\u003e \r\n\u003e as for readthedocs, they just look for a conf.py file: as soon as it's found, they are happy to build a new version (https://read-the-docs.readthedocs.org/en/latest/faq.html#where-do-i-need-to-put-my-docs-for-rtd-to-find-it)\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","Hi!\r\n\r\nCan you provide more details about your setup? I'm guessing you're connecting to your docker machine using ssh. What terminal application are you using? What shell? Did you run other commands before `docker version` (e.g. `docker run`) before this or was it a \"clean\" term?\r\n\r\nThanks!","Okay, nevermind, I was able to reproduce. Looking into it!","Should be fixed: https://github.com/dotcloud/docker/commit/3cce89d8edc9c3151bd982c6b5acfa8c20d5ae71","yep, it works. Thanks!","Thanks John!","Thanks!","I'm guessing this could be due to the `ISIG` flag in `term/termios_linux.go` (now that it's properly interpreted) -- what do you think @creack ?","We are going change a little rcli so the client will go in raw mode only when needed. Right now it does it all the time, that's why.\r\n","+1","Closed by #214 :)","cc @botchagalupe ","You might want to try this kernel:\r\nhttp://get.docker.io/kernels/kernel-3.2.40_grsec_dotcloud-4.x86_64.rpm\r\n\r\n*Warning:* the package is 700MB! I'm sorry, that's what I got when running `make rpm` on our kernel tree.\r\n\r\nThis kernel features:\r\n- grsec (for hardened security)\r\n- AUFS\r\n- `setns` support\r\n\r\nI don't have any RHEL/Fedora/CentOS machine around, so I can't test it, but it's compiled with exactly the same `.config` as our kernels. It is configured to run on bare metal, KVM virtual machines, Xen virtual machines (and therefore supports EC2). It might work on HyperV but I never tested it there.","cc @brianm ","Anyone else interested in Red Hat support?","+1","I'm interested in building a proper AUFS RPM against the existing sources, honestly I think having it released to EPEL or something would be best. Future maintanability and development ecosystem and so on.\r\n\r\nI'll start researching what this effort will take and open a case and link it to this one.","+1\r\n\r\nSent from my iPhone\r\n\r\nOn Mar 27, 2013, at 5:51 PM, Solomon Hykes \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Anyone else interested in Red Hat support?\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","+1\r\n","Ideally a DKMS RPM should be built. I am pretty sure RHEL 6 uses DKMS and it will keep AUFS working across kernel upgrades.","I could be wrong, but it seems that AUFS doesn't support building through\r\nDKMS.\r\nUnless there is a generic way to build any kind of module with DKMS?\r\nI would be quite surprised though; because AUFS hooks itself within some\r\nvery specific places within the VFS layer.\r\n\r\nOn Wed, Mar 27, 2013 at 11:51 PM, Joseph Glanville \u003cnotifications@github.com\r\n\u003e wrote:\r\n\r\n\u003e Ideally a DKMS RPM should be build. I am pretty sure RHEL 6 uses DKMS and\r\n\u003e it will keep AUFS working across kernel upgrades.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/172#issuecomment-15571153\u003e\r\n\u003e .\r\n\u003e","DKMS can build any module. It's the same as doing make, make install in the module source directory. (or doing make modules; make modules_install in the kernel source tree).\r\n\r\nThe only thing that DKMS does for you is automatically rebuild the module against the newly installed kernel so that it has the correct symbols.","It's worth trying, but even when it's built as a module, AUFS patches the\nVFS layer, AFAIR.","Ahh yes you are correct, my mistake. :(\r\n\r\nShame about that, I hope one day AUFS becomes mainline so this doesn't happen sigh.","+1 for RHEL/CentOS","It appears that DKMS will not work for this, as we cannot logically separate the components of AUFS from the Kernel image 100%. It still requires the Kernel image be patched with specific AUFS code.\r\n\r\nThe only realistic way to include this is to patch it directly into the EL6 upstream Kernel and release that code as buildable. Which is what I'm going to pursue right now. Once it's complete I'll be releasing it on my Github, however a longer term goal may be to operate a specific Kernel for Docker anyway. Include all the new fancy cgroup utils and other filesystems. \r\n\r\nThoughts?","If you can point me to the EL6 source tree, I can add it to our kernel build farm (with some luck, our AUFS patch queue will apply neatly; or at least, require only minor work to merge).\r\n\r\nFWIW, I recompiled our production kernels without debugging symbols (so now the RPM is just 50MB instead of 700MB):\r\n\r\nhttp://get.docker.io/kernels/kernel-3.2.40_grsec_dotcloud-4.x86_64.rpm\r\n\r\nIf someone could give it a try, that would be awesome.","Depends, are you using AUFS 3.x? If so the RHEL Kernel won't work, since it's a 2.6.32 Kernel. It'll be missing most of the API/ABI that I'm assuming AUFS 3 requires since it specifically states Kernel 3.0 requirement.\r\n\r\nHowever though, as requested, the current SRPM:\r\nhttp://ftp.redhat.com/pub/redhat/linux/enterprise/6Server/en/os/SRPMS/kernel-2.6.32-358.2.1.el6.src.rpm\r\n\r\nObviously you can unpack the source using rpm, in the case you're on debian or osx (with brew) or something...\r\n\r\nrpm2cpio kernel-blablabla.rpm | cpio -idmv\r\n\r\n--\r\n\r\nAlso, going to give that Kernel a try now on an EL6 machine.","Yea, there's a lot of depsolving and conflicts in this Kernel you have posted...\r\n\r\nWhere is the srpm at? I'll be happy to work the spec out.\r\n\r\nIdeally, this Kernel wouldn't upgrade or replace the existing RHEL Kernel (so it'll remain updated) it should be supplemental to the RHEL Kernel and updated separately.\r\n\r\nErrors here:\r\nhttps://gist.github.com/stevencrothers/5269833/raw/a42f40f6feb2813fb6a78b4e80cfcb08c1cc525e/gistfile1.txt\r\n\r\nI'm going to open a case for this so it can be properly tracked.","For the record, new case is here to track the specific Kernel changes:\r\ndotcloud/docker#253\r\n\r\nThis case should be made dependent on 253, not sure if that's possible on Github.","It seems like targeting Fedora 18/19 (and thus what will likely become EL7) would be easier/better than working on the 2.6 kernels in EL6. ","FYI Ubuntu is discontinuing support for aufs in their 3.9 kernels, so we\r\nmight be forced to extend support to another filesystem sooner rather than\r\nlater. I started playing with btrfs, and will continue to tinker during my\r\nupcoming vacation :)\r\n\r\n\r\nOn Wed, May 1, 2013 at 10:47 PM, Michael Stahnke\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e It seems like targeting Fedora 18/19 (and thus what will likely become\r\n\u003e EL7) would be easier/better than working on the 2.6 kernels in EL6.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/172#issuecomment-17321530\u003e\r\n\u003e .\r\n\u003e","What about overlayfs?\r\n\r\nhttps://lwn.net/Articles/447650/\r\nhttp://lists.opensuse.org/opensuse-kernel/2013-05/msg00054.html\r\nhttp://www.phoronix.com/scan.php?page=news_item\u0026px=MTMyNzA","OverlayFS is attempting (again) acceptance for merge into mainline 3.10, but it still seems unlikely at this point, since Al Viro (the VFS maintainer) doesn't like some chunks of the design (primarily use of xattrs for opaques), which seems to be causing a little friction since Miklos is somewhat attached to the idea for portability (FWIW, I kind of agree with Miklos here).\r\n\r\nThat said, it's already included in the standard kernel patchsets for at least Ubuntu and SuSE, maybe others.  and as @shykes points out, aufs is soon to be dropped for Ubuntu so some decision here will have to be made.","I'm actively working on btrfs support for docker [1].\nIt's not ready yet, but it should offer a pretty solid alternative for\nsystems without aufs.\n\n[1] https://github.com/jpetazzo/docker/compare/master...btrfs","I just hacked support for overlayfs, which is is already on the SUSE and Ubuntu kernels, and probably the only one that will make it to upstream. I can't get the tests to pass because an unmount fails in the test. However I can run the container and docker diff seems to be working.\r\nhttps://github.com/dmacvicar/docker/tree/feature_overlayfs\r\n\r\n//cc @flavio @silviomoioli\r\n","@dmacvicar Did you change FILESYSTEM_MAX_STACK_DEPTH in your kernel to allow overlayfs to stack more than 2 layers?\r\n\r\nedit: just noticed this limit may not apply on opensuse if they don't have that check in their version of overlayfs. On ubuntu FILESYSTEM_MAX_STACK_DEPTH is 2 so mounting a stack a b c d will fail when you go to mount d. ","@kstaken Mmmm... I only tried with 3 layers so you may be right base + 1 + 1 is still in the max range.\r\n\r\nI need to check whether our kernel patches also have that limit.","@kstaken you are completely right\r\n\r\nMay 28 10:21:47 piscola kernel: overlayfs: maximum fs stacking depth exceeded\r\n\r\nI oversaw that. Documentation says \"The lower filesystem can even be another overlayfs\", but did not mention any limits. ARGH.\r\n\r\nI would guess for docker the main usecase would be to have an image and keep the changes of the image separate, and then commit them to another image. Are more layers at the same time useful?\r\nBecause then we could introduce the limit to docker itself, when using overlayfs.","@kstaken I talked to Miklos (overlayfs author) as he work for us, and he confirmed that there is a limit to avoid a kernel stack overflow. He may look into adding arbitrary layers in the future, may be after it is included in the mainline kernel.\r\nThe question is whether docker really needs so many layers?","I'm new to docker but I believe more layers at the same time is core to the way docker is intended to work.\r\n\r\nThe base image works but using a random image from the registry hits the limit.\r\n\r\ndocker run mbkan/lamp ps aux\r\n2013/05/28 17:04:17 error: Error starting container b6a38d3e5dbc: Unable to mount using overlayfs\r\n\r\nin syslog.\r\n\r\nMay 28 17:04:17 precise64 kernel: [111971.681350] overlayfs: maximum fs stacking depth exceeded\r\n\r\nIs it pretty likely overlayfs is going to make it into the mainline kernel?","Fixed by #177 and confirmed fixed on master.","confirmed fixed. closing.","Thanks @creack. Could you add a test to avoid regression?","Thanks, merged.","The docker daemon can be configured to listen on a unix socket with \"docker -d -H unix://...\". Then you can apply the permissions of your choice to the socket.","This will fixed once #192 is merged","#192 has been merged","Suggestions:\r\n- look for `aufs` in `/proc/filesystems`\r\n- if not found, try `modprobe aufs` (after all, we're root)\r\n- if after that, we still don't have `aufs` in `/proc/filesystems`, abort, or at least issue an obnoxious warning","Updated to use `/opt/go` as the `GOPATH` in a provider-independent way. Tested on Virtualbox and AWS.\r\n\r\n@amesserl Do you mind testing this on Rackspace? I don't have an account.","@titanous Yeah, I gave it a whirl and I think it breaks because Rackspace only provisions a root user by default which is what vagrant-rackspace assumes and drops the key under.  It fails when trying to create the Vagrant profiles because it's trying to link it to a nonexistant user ubuntu user.  The path also doesn't work unless I specify the exact path to the binary.  We might need to rework how the Rackspace user is set up.  I'll try and poke around on it this week if someone else doesn't.","@amesserl I found Rackspace credentials, so I can fix it up. Currently `vagrant provision --provider rackspace` is hanging on:\r\n```\r\nWaiting for SSH to become available...\r\n```\r\n\r\nAny ideas?","@amesserl I should note that I can ssh to `root@SERVER_IP` just fine.","Hanging on \"Waiting for SSH to become available\" is usually an authentication issue. Vagrant doesn't seem to differentiate between \"I can't SSH because it won't connect\" and \"I can't SSH because auth failed\"\r\n\r\nThere is already an open issue to fix the assumptions about how users are setup in the puppet provisioner, but I need to get my hands on some Rackspace credentials before I can actually move forward with that.","I did run into this issue here with StrictHostKeyCheck: https://github.com/mitchellh/vagrant-rackspace/pull/5\r\n\r\nI could see it when doing VAGRANT_LOG=debug vagrant up --provider=rackspace","Ah, StrictHostKeyCheck... I ran into that with vagrant-aws as well. I'll have to see if there's a patch for that one already too.\r\n\r\n@amesserl Speaking of Rackspace credentials, I sent an email to you today (at your publicly listed Github email) :-)","@amesserl Turns out my private SSH key path was wrong. Moving on...","@chooper I've updated the patch, now it's working on Virtualbox, AWS, and Rackspace.","Looks good to me!","Looks good, thank you.","Thank you!","This used to work, but it's broken now.\r\n\r\nIt used to work something along these lines:\r\ndocker import -stdin node010 \u003c nodejs.tar","Thanks, I just tried that to see the error message and this is what I got:\r\n\r\n$ sudo ./docker import -stdin node010 \u003c nodejs.tar\r\n2013/03/26 17:20:13 docker import -stdin node010\r\nflag provided but not defined: -stdin\r\n\r\nUsage: docker import [OPTIONS] URL|- [REPOSITORY [TAG]]\r\n\r\nCreate a new filesystem image from the contents of a tarball.\r\n\r\nI'm still looking through the docker source to determine where this functionality resides so that I can provide a patch.","This is still supported, the syntax changed slightly:\r\n\r\n     tar -c . | docker import - broken_test_image\r\n\r\n\r\nOn Tue, Mar 26, 2013 at 5:23 PM, Sean Mountcastle\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Thanks, I just tried that to see the error message and this is what I got:\r\n\u003e\r\n\u003e $ sudo ./docker import -stdin node010 \u003c nodejs.tar\r\n\u003e 2013/03/26 17:20:13 docker import -stdin node010\r\n\u003e flag provided but not defined: -stdin\r\n\u003e\r\n\u003e Usage: docker import [OPTIONS] URL|- [REPOSITORY [TAG]]\r\n\u003e\r\n\u003e Create a new filesystem image from the contents of a tarball.\r\n\u003e\r\n\u003e I'm still looking through the docker source to determine where this\r\n\u003e functionality resides so that I can provide a patch.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/188#issuecomment-15497487\u003e\r\n\u003e .\r\n\u003e","Thanks that works, as does: cat nodejs.tar | sudo ./docker import - node010\r\n\r\nUnfortunately the image is incomplete for running (it basically just the node.js binary download for Linux along with a simple node.js app), so I'll try starting with base and install node.js into that.","This works for me as well. It can be closed.","Here are some random security things, I'll add more later:\r\n\r\n- Every piece of code in docker that executes a subprocess needs to be checked for injection vulnerabilities.\r\n- Are there network attacks that can be performed from inside a container? If so, document or mitigate.\r\n- Check that no environment variables leak into containers.\r\n- All docker code that runs in the container is potential attack surface, audit carefully.\r\n- Document GRSEC patches and AppArmor configs.\r\n","I am +42 in favor of this, but it is not a specific action item or bug report, so it should be discussed on the mailing list. Thanks!","How hard would it be to set up an AMI that has a `vagrant` user so that we have parity across providers? Changing #184 to support multiple home directories sucks (I just tried).","... And by the way, why do we need a custom AMI? Wouldn't be better to use a standard AMI?\r\n(I don't know at all how the Vagrant provisioning mechanism work, but I secretly hope that it could let us provide some user data, which in turn, could be used by cloud-init to do any kind of extra setup?)","@jpetazzo I think we just need it for puppet, but we *could* just shift to using a plain shell script, as the provisioning is quite simple.","@jpetazzo Vagrant uses SSH to provision via Puppet, Chef, shell scripts, or custom providers after the instance boots. It doesn't use cloud-init at all AFAIK.","I think I saw some cloud-init scripts using puppet as well...\r\n\r\nFrom my experience, authoring custom AMIs is fine if you do it \"all the\r\nway\". I.E.:\r\n- support all regions\r\n- support all instance types (boot on EBS, boot on ephemeral, HVM)\r\n- publish updates when distros get updated\r\n\r\nBut of course, a custom AMI is better than nothing!\r\n\r\nOn Tue, Mar 26, 2013 at 5:57 PM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e @jpetazzo \u003chttps://github.com/jpetazzo\u003e I think we just need it for\r\n\u003e puppet, but we *could* just shift to using a plain shell script, as the\r\n\u003e provisioning is quite simple.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/192#issuecomment-15498481\u003e\r\n\u003e .\r\n\u003e","Ubuntu AMI's use cloud-init by default to install SSH keys. Currently this (and needing to install puppet) is the only reason we use a custom AMI, since it's non-trivial to replace/augment the \"ubuntu\" user with a \"vagrant\" user.\r\n\r\nThis was my \"needs to ship today\" fix, but yes, the overall goal would be to use one of the publicly available, standard AMIs","Hmm, yeah, that feels like a lot of work when Vagrant is supposed to solve this by doing provisioning from a vanilla-ish AMI. I'd prefer to pick from:\r\n\r\n- Build custom AMIs with Docker included, don't use Vagrant.\r\n\r\nOR\r\n\r\n- Shift to vanilla Ubuntu AMIs and use shell provisioning with Vagrant.","Couldn't you add a user-data-script to cloud-init that installs puppet and creates a vagrant user? You could also use the cloud-config syntax to have Ubuntu manage those steps for you. It would basically replicate the steps you took to create your custom AMI every time, without needing to maintain the image.\r\n\r\nhttps://help.ubuntu.com/community/CloudInit\r\n\r\nEDIT: relevant cloud-init examples\r\n - Create users: http://bazaar.launchpad.net/~cloud-init-dev/cloud-init/trunk/view/head:/doc/examples/cloud-config-user-groups.txt\r\n - Install puppet: http://bazaar.launchpad.net/~cloud-init-dev/cloud-init/trunk/view/head:/doc/examples/cloud-config-puppet.txt","Looking over another pull request, it seems we've got a branch queued up that will actually install puppet prior to running the puppet provisioner. I'm going to test and merge that pull request and then follow up with this one.","Turns out that pull request was already merged. I've tested using one of the public/standard Ubuntu AMIs successfully. The changes will be appearing here shortly.","user-data-script + cloud-init / cloud-config was exactly what I had in mind.\r\nThat's what I use to do dead simple provisioning of EC2 machines with\r\nDocker.\r\nI.e. just put:\r\n\r\n    #include\r\n    http://get.docker.io/\r\n\r\nin the user data of the instance, and it will boot up with docker.\r\n\r\nAnyway! I think Charles is up to something :-)\r\n\r\nOn Tue, Mar 26, 2013 at 6:48 PM, Charles Hooper \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Turns out that pull request was already merged. I've tested using one of\r\n\u003e the public/standard Ubuntu AMIs successfully. The changes will be appearing\r\n\u003e here shortly.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/192#issuecomment-15499939\u003e\r\n\u003e .\r\n\u003e","OK, we're off the custom AMI.\r\n\r\nWe still have some puppet \"magic\" that causes different home directories because the VirtualBox image we're using needs it but I've opened a separate issue (#201) for that.","Thanks!","While we're at it, we might as well enable high compression whenever docker creates a tarball. Eg. 'docker push' and 'docker export'.","Using higher compression for all operations which create tarballs would be really nice.\r\n\r\nThe return is quite significant over time when it comes to the amount of storage needed on S3 and the network traffic.\r\n\r\nI think only these changes are required to start using high compression for all new images on the registry:\r\nregistry.go:\r\n```\r\n // FIXME: Don't do this :D. Check the S3 requierement and implement chunks of 5MB\r\n // FIXME2: I won't stress it enough, DON'T DO THIS! very high priority\r\n- layerData2, err := Tar(path.Join(graph.Root, img.Id, \"layer\"), Gzip)\r\n- layerData, err := Tar(path.Join(graph.Root, img.Id, \"layer\"), Gzip)\r\n+ layerData2, err := Tar(path.Join(graph.Root, img.Id, \"layer\"), Bzip2)\r\n+ layerData, err := Tar(path.Join(graph.Root, img.Id, \"layer\"), Bzip2)\r\n```","Don't use bzip2: use lzma/xz instead. `xc` is faster than `bzip2` and achieves better compression; and it even has an \"extreme\" mode achieving even tighter compression (but then making it slower).\r\n\r\nSee e.g. http://pokecraft.first-world.info/wiki/Quick_Benchmark:_Gzip_vs_Bzip2_vs_LZMA_vs_XZ_vs_LZ4_vs_LZO\r\n\r\nAlso, I couldn't check in the source, but we should obviously make sure that the layer hash is done on the uncompressed tar.","There is no layer hash right now, image IDs are computed randomly. I want\r\nto bring back content-generated IDs and yes, that requires a tar-aware\r\nchecksum.\r\n\r\nOn Sunday, March 31, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e Don't use bzip2: use lzma/xz instead. xc is faster than bzip2 and\r\n\u003e achieves better compression; and it even has an \"extreme\" mode achieving\r\n\u003e even tighter compression (but then making it slower).\r\n\u003e\r\n\u003e See e.g.\r\n\u003e http://pokecraft.first-world.info/wiki/Quick_Benchmark:_Gzip_vs_Bzip2_vs_LZMA_vs_XZ_vs_LZ4_vs_LZO\r\n\u003e\r\n\u003e Also, I couldn't check in the source, but we should obviously make sure\r\n\u003e that the layer hash is done on the uncompressed tar.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/194#issuecomment-15697513\u003e\r\n\u003e .\r\n\u003e","I've done some tests with the pybuilder image:\r\n```\r\n468 MB pybuilder.tar\r\n221 MB pybuilder.tar.gz - 47% of the original size\r\n208 MB pybuilder.tar.bz2 - 44% of the original size\r\n180 MB pybuilder.tar.xz - 38% of the original size\r\n```\r\nThe xz lzma2 compressed image is 14% smaller than the bzip2 compressed image.\r\n\r\nOther images show a similar decrease in size. Some even go down to 30% of the original size.","Note: we would also have to update docker dependencies and installation instructions to tell people to install `xz`.\r\n\r\nBonus points if docker makes sure that `xz` is installed when starting, to get an informative error message rather than a cabalistic tar error (should that be another issue?)","The extra dependency is definitely a -1. Is it *really* worth the trouble compared to bzip2 -9?","xz isn't required. bsdtar has native support for xz compression and it doesn't need xz from xz-utils, nor anything else.\r\n\r\nI've just verified this by using bsdtar to compress in xz format, ran xz to make sure it's not there and then installed xz-utils to extract the archive. Everything worked.\r\n\r\nSo there's really nothing to warn about, other than about bsdtar's absence.","Awesome.\r\n\r\n\r\nOn Mon, Apr 1, 2013 at 10:26 AM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e xz isn't required. bsdtar has native support for xz compression and it\r\n\u003e doesn't need xz from xz-utils, nor anything else.\r\n\u003e\r\n\u003e I've just verified this by using bsdtar to compress in xz format, ran xz\r\n\u003e to make sure it's not there and then installed xz-utils to extract the\r\n\u003e archive. Everything worked.\r\n\u003e\r\n\u003e So there's really nothing to warn about, other than about bsdtar's absence.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/194#issuecomment-15725699\u003e\r\n\u003e .\r\n\u003e","If we want to drop the bsdtar dependency we can. Just swap in [`archive/tar`](http://tip.golang.org/pkg/archive/tar/) and http://godoc.org/code.google.com/p/lzma instead of shelling out. It may make sense to wait until the registry supports streaming upload to do this, but it's not required.","archive/tar doesn't support actual tarring and untarring on the filesystem.\r\nOnly parsing/encoding of the tar stream itself.\r\n\r\nThere is also auto-detection of compression which is a really useful\r\nfeature.\r\n\r\nOn Monday, April 1, 2013, Jonathan Rudenberg wrote:\r\n\r\n\u003e If we want to drop the bsdtar dependency we can. Just swap in archive/tar\u003chttp://tip.golang.org/pkg/archive/tar/\u003eand\r\n\u003e http://godoc.org/code.google.com/p/lzma instead of shelling out. It may\r\n\u003e make sense to wait until the registry supports streaming upload to do this,\r\n\u003e but it's not required.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/194#issuecomment-15726255\u003e\r\n\u003e .\r\n\u003e","@shykes Yeah, it would require essentially reimplementing the file walking and tar header building that tar/bsdtar does.","The changes mentioned in this issue were made by pull request #308.\r\n\r\nAnother issue was created to add the hashing for layer contents and parent id when creating the image id. The issue is #310.","Just an extra comment: it is normal for 'docker kill' to leave the container directory. By default all containers are stored, so you can inspect their filesystem state, commit them into images, restart them etc.\r\n\r\nBut of course it is *not* normal to see \"stale NFS handle\" errors :)","I can't reproduce.\r\n\r\nMy host is ubuntu12.10 and I used the base as guest.\r\nAnybody can reproduce ?","Is there a way to manually repair the directory so I can delete the directories without rebooting the host?","Not that I know of. Note that there is no known side-effect outside the\r\nscope of that container.\r\n\r\nOn Monday, April 15, 2013, Thomas Hansen wrote:\r\n\r\n\u003e Is there a way to manually repair the directory so I can delete the\r\n\u003e directories without rebooting the host?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/197#issuecomment-16385541\u003e\r\n\u003e .\r\n\u003e","As discussed earlier, this is probably due to the asynchronous nature of aufs unmount.\r\n\r\nI'm downgrading this to minor bug, since:\r\n\r\na) it occurs very rarely (1 known occurrence so far)\r\nb) it has no impact on the behavior of docker or the system,\r\nc) it's very hard to reproduce\r\n","+1 on a fix for this since i just bumped into it:\r\n\r\n\u003ccode\u003e~# docker rm 5cbb64c3279a\r\nError: Error destroying container 5cbb64c3279a: stat /var/lib/docker/containers/5cbb64c3279a76acaac4769e4a6c57c39a7fff6027b51d14ecff08040d252d13/rootfs: stale NFS file handle\r\n\u003c/code\u003e\r\n\r\n\r\n","@simonjohansson Since #816, did you get the error?","ping @simonjohansson ","Hi guys, sorry I didn't see this until now. I have some holiday coming up in the next couple of days, Ill make sure to see if #816 fixed the issue!","Just encountered the same issue:\r\n\r\n```\r\nroot@dscape:~# docker ps -a | grep 'Exit' |  awk '{print $1}' | xargs docker rm\r\nError: Error destroying container 38b561af34e1: stat /var/lib/docker/containers/38b561af34e1bb0b3e92d7b1fe734aeabf223d6a5c36757be8925514e28e8b45/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 112a0c0b9c95: stat /var/lib/docker/containers/112a0c0b9c9546697f20dd7ed21899b789f981eb5195d189b1503ab1893184e4/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container ef13c73b64a9: stat /var/lib/docker/containers/ef13c73b64a991e2b937fbcb1fae412d7b6404dcb67ae105c06ebd5b62926f35/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container e0178615f6d8: stat /var/lib/docker/containers/e0178615f6d8be7ca343c89c398536713542413fa7ac04d172bb268f626a252a/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 3c8659a041c9: stat /var/lib/docker/containers/3c8659a041c9217e35c056e96da0fe5dc9d5eae43f37874ff372190ed8867277/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 99dee8e5a486: stat /var/lib/docker/containers/99dee8e5a486b8eeff3855e6750e1dee90ec4c8af022ed9a43304edda411b507/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container b7ac0d3f3f79: stat /var/lib/docker/containers/b7ac0d3f3f79ae35883d09e796332726322e56bdd715e5484210bf84099cc513/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 7329c9be9795: stat /var/lib/docker/containers/7329c9be97957b187cdb6cbb825ab506e3a8610c01b4055ad5cc64fc58a6e985/rootfs: stale NFS file handle\r\n```\r\n\r\n```\r\nroot@dscape:~# docker version\r\nClient version: 0.4.8\r\nServer version: 0.4.8\r\nGit commit: ??\r\nGo version: go1.1.1\r\n```","I cannot reproduce anymore.\r\n\r\n```\r\nClient version: 0.5.0\r\nServer version: 0.5.0\r\nGit commit: 51f6c4a\r\nGo version: go1.1.1\r\n```\r\n\r\nGG :)","@dscape can you try again with docker 0.5.1?","I keep seeing this issue over and over using docker inside VirtualBox. I usually run docker rm $(docker ps -a |cut -d \" \" -f 1) to remove all containers but many of them fail with stale NFS file handle.\r\n","Just to add, I tried some brutal force removing the directories of such containers. After that,  trying to remove them  via docker rm still prints the same message. \r\n\r\nManaged to remove after restarting docker host.","This seems fixed to me.\r\nUsing:\r\n```\r\n# docker version\r\nClient version: 0.5.3\r\nServer version: 0.5.3\r\nGit commit: 5d25f32\r\nGo version: go1.1.1\r\n```\r\nAlso make sure you have no bash running inside the container path.","Was the asynchronous unmount theory ever proven? I wonder if this is the \"deleted a container's image while the container is running\" bug:\r\n\r\n```\r\n# Pane 1\r\n$ docker run -i -t foo /bin/bash\r\nroot@d6d23b36b613:/#\r\n\r\n# Pane 2\r\n$ docker rmi foo\r\nUntagged: 1cfaa4fe8724\r\nDeleted: 1cfaa4fe8724\r\n$\r\n\r\n# Pane 1\r\nroot@d6d23b36b613:/# exit\r\n$ docker rm `docker ps -l -q`\r\nError: Error destroying container d6d23b36b613: stat /var/lib/docker/containers/d6d23b36b613337b8e8bbc2ee90af11da3c5fab78a07a01a43ba7262359292ca/rootfs: stale NFS file handle\r\n\r\n$\r\n```","@dsissitka i think that is exactly what it is. happened with me.\r\n\r\n```\r\n $ docker version\r\nGo version (client): go1.1.1\r\nGo version (server): go1.1.1\r\nLast stable version: 0.6.3\r\n```\r\n\r\nhow can the container be removed now?","The original issue is resolved in 0.7 because kill does not do an umount anymore.  Containers are unmounted when the daemon is stopped. ","In case anyone has a `/var/lib/docker/volumes` directory full of orphaned volumes, feel free to use the following Python script (make sure to understand what it does before executing it):\r\n\r\n```Python\r\n#!/usr/bin/python\r\n\r\nimport json\r\nimport os\r\nimport shutil\r\nimport subprocess\r\nimport re\r\n\r\ndockerdir = '/var/lib/docker'\r\nvolumesdir = os.path.join(dockerdir, 'volumes')\r\n\r\ncontainers = dict((line, 1) for line in subprocess.check_output('docker ps -a -q -notrunc', shell=True).splitlines())\r\n\r\nvolumes = os.walk(os.path.join(volumesdir, '.')).next()[1]\r\nfor volume in volumes:\r\n    if not re.match('[0-9a-f]{64}', volume):\r\n        print volume + ' is not a valid volume identifier, skipping...'\r\n        continue\r\n    volume_metadata = json.load(open(os.path.join(volumesdir, volume, 'json')))\r\n    container_id = volume_metadata['container']\r\n    if container_id in containers:\r\n        print 'Container ' + container_id[:12] + ' does still exist, not clearing up volume ' + volume\r\n        continue\r\n    print 'Deleting volume ' + volume + ' (container: ' + container_id[:12] + ')'\r\n    volumepath = os.path.join(volumesdir, volume)\r\n    print 'Volumepath: ' + volumepath\r\n    shutil.rmtree(volumepath)\r\n```","thanks for the script! I fixed the indentation and a small bug: \r\n\r\n    container_id = volume_metadata['id'] # (not container anymore)\r\n\r\nhttps://gist.github.com/mindreframer/7787702\r\n","Thanks! No idea why the indentation was messed up in my post, edited + fixed it.\r\n\r\nI used `volume_metadata['container']` because I was still on `0.6.6` when I wrote the script, but anyone using `0.7.0` (or later) should use your changes.","Docs branch was broken.  Lets make sure we can cleanly merge to master and push to a different branch for now. ","Waiting on #192 to be merged before I dig too heavily into the vagrant/puppet magic","Just wanted to let you know I tested choopers branch with standard AMI image and it works nicely.\r\nFor you to be sure I am using the latest: ws.ami = \"ami-ae9806c7\"","The \"standard\" Vagrant images I'm finding still use a \"vagrant\" user, when the rest of the providers' (AWS, Rackspace) images use an \"ubuntu\" user. This currently works, but it'd allow us to clean up some of our puppet magic if all of our images used the same user.","Just a FYI, the reason why I created the custom virtual box image is because in order to overcome a bug in the kernel, we need to install a newer kernel, which requires a restart of the vm, and some other hoops to jump through in order to make sure AUFS, vagrant and the new kernel work correctly. It wasn't possible to do all of this with puppet, and required the user to run a bunch of different vagrant commands in the right order to get it working. To make the setup process easier, we decided it was best to use the custom image. \r\n\r\nHere are some of my notes from a while ago, but these were using an older version of the vagrant and puppet scripts then what we have today, so I don't know if it will work, but including them here for reference.\r\n\r\nvagrant up\r\nvagrant ssh\r\n    sudo reboot\r\n    sudo /etc/init.d/vboxadd setup\r\nvagrant reload\r\n\r\n","There really isn't anything wrong with the image (I ran into these same issues you described when testing some of the more \"official\" images) but there's some messy puppet configuration to make supporting different usernames work reasonably well.\r\n\r\nAfter looking over why we need this in the first place, I think we can continue using the same image provided that the user-specific stuff get moved out. I'm going to rename this issue in order to reflect this new scope.","I can update #184 to solve this issue if you don't have a problem with the approach. (I'll put the `GOPATH` in `/opt/go` or similar).","@titanous Sure, let's try that","@chooper #184 is all set now.","@titanous Thanks! I'm going to see if we can get it tested on Rackspace before merging","While we didn't remove the user-specific config, @titanous's work on puppet makes dealing with the different providers clean and easy enough to work with.","See also #184.","Hi @hblanks, thanks for your contribution! It looks like someone else beat you to the punch in #205 so I'll be closing this one. ","No worries! Thanks for a quick fix.","Thanks!","Hello,\r\n\r\nThank you for the report.\r\n\r\nThe branch 96-dns_issue-fix is totally outdated and unfinished. Even applying the patches merges from master, there is no warranty it will work.\r\n\r\nIf you have issues with your dns, for the moment you can simply change the /etc/resolv.conf on the host.\r\n\r\nI will fix this issue as soon as posisble but anyway, I think I will remove this branch and start over.\r\n\r\nI tried to reproduce the issue with the latest master but haven't been successful.\r\n\r\nDid you happen to have this error outside this branch?\r\n\r\nRegards,","Good point, I'll switch back to master and rerun the test. My thinking was that your patch looked relatively minor and shouldn't have made much difference but happy to be proven otherwise.","Almost the same result using master and with the pre-compiled distribution:\r\n\r\n```bash\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to inject docker in PREROUTING chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to inject docker in PREROUTING chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to create DOCKER chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to create DOCKER chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to create DOCKER chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to create DOCKER chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to create DOCKER chain\r\n2013/03/28 10:05:08 Unable to setup port networking: Failed to create DOCKER chain\r\n2013/03/28 10:05:08 docker run base /bin/bash -c echo \"hi there\"\r\n2013/03/28 10:05:08 docker run base /bin/bash -c echo \"hi there\"\r\nhi there\r\nhi there\r\n```","I think we're reaching the limits of the standalone mode. Docker is not designed to have multiple instances running concurrently... And the lock mechanism today is binding on the socket - which is bypassed in standalone mode.\r\n\r\nWe should either:\r\n\r\n1) make sure standalone mode also uses some sort of host-wide lock\r\nor 2) restrict standalone mode to commands which are safe without a lock","I figured it was probably contention over a network resource of some kind. Given the options though I'm not exactly sure which would best suit the scenario I'm attempting to use it for.\r\n\r\nBasically what I'm attempting to do is use docker to sandbox untrusted user scripts which are short lived and executed server side. This necessitates running many docker instances concurrently. Am I doing it wrong? Is there another way to use a single docker instance to spawn multiple containers simultaneously? Moreover is this the kind of use case the project sees as valuable?","There is no docker usage scenario that cannot be done in daemon mode.\r\nDaemon mode is and will remain the primary mode of using Docker. The\r\nstandalone mode is more of a convenience so you can explore the\r\nfunctionalities out of the box - sorry if that wasn't clear!\r\n\r\nFor your use case, I recommend simply running \"docker -d\" in the background\r\n(ideally this would happen at boot time in your host system). Then run\r\n'docker run -d' as many times as necessary to run multiple containers in\r\nparallel, in detached mode. This will pass the commands to the daemon,\r\nwhich can handle any number of concurrent containers.\r\n\r\nI hope this helps!\r\n\r\n\r\nOn Wed, Mar 27, 2013 at 4:19 PM, Dave Kuhn \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I figured it was probably contention over a network resource of some kind.\r\n\u003e Given the options though I'm not exactly sure which would best suit the\r\n\u003e scenario I'm attempting to use it for.\r\n\u003e\r\n\u003e Basically what I'm attempting to do is use docker to sandbox untrusted\r\n\u003e user scripts which are short lived and executed server side. This\r\n\u003e necessitates running many docker instances concurrently. Am I doing it\r\n\u003e wrong? Is there another way to use a single docker instance to spawn\r\n\u003e multiple containers simultaneously? Moreover is this the kind of use case\r\n\u003e the project sees as valuable?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/206#issuecomment-15559294\u003e\r\n\u003e .\r\n\u003e","Oh fantastic, that appears to have solved my issue.\r\n\r\nYou might want to update the docs as the run command makes no reference to the -d option. Also to my mind the relationship between the docker daemon and the run command isn't exactly clear either. With a daemon started, executing the run command executes via the daemon (with or without the -d option) though the behaviour is different with -d returning the container ID and without the -d printing the process output.","This is one more argument in favor of deprecating standalone mode - see #364 for a summary.\r\n","You are getting that error, because docker currently doesn't support 32bit hosts. see #136 ","Thanks.","might be related to #108 and #109 ","Something like this happened to me, but \"rm\" ultimately worked for me while \"kill\" and \"stop\" didn't. Did it work for you?","gottagetmac: Yes, it appears that rm eventually worked, despite the failure messages:\r\n\r\nsmountcastle@ubuntu:~$ sudo $GOPATH/bin/docker ps\r\n2013/03/27 05:41:22 docker ps\r\nID          IMAGE       COMMAND     CREATED     STATUS      COMMENT","sean: This seems to happen whenever the actual process stops in any way other than \"docker stop\" or \"docker kill\"—you get a zombie container than docker thinks is alive but has no way to kill, since it's already dead.","This is actually a side effect of #257. When docker server crashed or is killed, the containers go ghost.\r\nRefers to #257 for follow-up","Same issue. Neither stop nor kill worked for me (my container runs Meteor) . @danrobinson suggestion worked for me to: `docker rm CONTAINER_ID`.","I have the same though I canneither `stop`, `kill`, `rm` or `rm -f` the container.","possibly related: https://github.com/docker/docker/issues/19166","AHHHHHHHHHHHHHHHHHHHHH","Thanks.","@metalivedev and @kencochrane, I'll leave it up to you what to do with this issue - is it specific enough to know when it can be closed? Or should it be broken down in smaller issues?\r\n","I think it would be helpful if we broke down each topic under usability into it's own issue, and reference this ticket, and then we track each one individually. We will also need to get some help to get those docs made so if we have an issue for each topic, it will be easier to assign to others. ","+1","For reference, there was this: https://github.com/dotcloud/docker/commit/acd51ecea8f5d3c02b00a08176171c59442df8b3\r\n\r\nBut it was overwritten by a later push. I don't know where it should be resurrected.","Maybe a new \"Internals\" section in the docs?\r\n\r\n\r\nOn Mon, Apr 1, 2013 at 3:27 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e For reference, there was this: acd51ec\u003chttps://github.com/dotcloud/docker/commit/acd51ecea8f5d3c02b00a08176171c59442df8b3\u003e\r\n\u003e\r\n\u003e But it was overwritten by a later push. I don't know where it should be\r\n\u003e resurrected.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/211#issuecomment-15741258\u003e\r\n\u003e .\r\n\u003e","The registry API is now documented at https://github.com/dotcloud/docker/blob/v0.3.4/docs/sources/api/registry_api.rst","I'm also in the proces of making them even better, should have a pull request early next week.","Several examples have been added to the docs since this issue was opened. Feel free to suggest more as necessary - the more specific the better.","You can do this with 'ps -a'\r\n\r\nOn Wednesday, March 27, 2013, Daniel Robinson wrote:\r\n\r\n\u003e As far as I can tell, there is no way to list stopped containers. \"docker\r\n\u003e ps\" only lists containers that are running. The only way I can find them is\r\n\u003e to look in /var/lib/docker/containers.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/215\u003e\r\n\u003e .\r\n\u003e","how can I do with http rest api?","according to https://github.com/dotcloud/docker/blob/7a0e5991421d423908504531bee7b5dc46443b3f/api/server/server.go\r\n\r\n```\r\nhttp://.../containers/json?all=true\r\n```\r\n\r\ndoes the trick.\r\n","There are actually 2 distinct changes in here:\r\n\r\nChange 1: use os.Stdin.Fd() instead of 0\r\nChange 2: change signal handling\r\n\r\nCould you make it 2 commits? Thanks","Done :)","Thanks! Testing now.","Thanks! Could you make it a pull request so we can properly credit you? If you don't want to bother, let me know and I'll apply it directly.","Thanks! I'll leave the credit to you :)","going to reopen to make sure the patch doesn't get lost. @shykes close when you are done with the patch.","..is there any way to actually fix this? I mean, does docker create the interface on ubuntu, while it's failing on debian, for some reason? (I mean: can I safely just create the interface \"manually\", or there could be any drawback if docker isn't able to manage the interfaces?)","Yes, you can safely create the bridge manually. There is a pull request (\r\n#221 ) for automatically creating a bridge instead of relying on a\r\npre-existing one.\r\n\r\n\r\nOn Mon, Apr 1, 2013 at 6:15 PM, Samuele Santi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e ..is there any way to actually fix this? I mean, does docker create the\r\n\u003e interface on ubuntu, while it's failing on debian, for some reason? (I\r\n\u003e mean: can I safely just create the interface \"manually\", or there could be\r\n\u003e any drawback if docker isn't able to manage the interfaces?)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/217#issuecomment-15747989\u003e\r\n\u003e .\r\n\u003e","a little note on the command above: the right command is\r\n\r\n```bash\r\nbrctl addbr lxcbr0 \u0026\u0026 ip a a 10.65.41.1/24 brd + dev lxcbr0\r\n```\r\n(i suppose that a \"random\" /24-net is okay?)","I changed the error message to be more explicit, and added basic instructions to create the bridge if it doesn't exist.\n\nClosing.","@metalivedev @kencochrane is there some doc (even basic) explaining the registry and how to use it?","I have something in the docker guide book, maybe we can move it over to the official docs","Currently the docs talk about registries here: http://docs.docker.io/en/latest/use/workingwithrepository/","There definitive docs about the registry and repository in http://docs.docker.io/en/latest/api/registry_index_spec/ so I'll consider this closed for now.\r\nI will open some new bugs related to cleaning up that doc and adding information to the glossary section.","Hey @shawnsi, thanks for starting that! If you make it a branch + pull request, we can review it together and get it ready for merge!","My advice about IP address ranges: you *cannot* use a fixed range. You will *always* find someone using that range. Many shops use 192.168.X.Y, many others (including e.g. EC2) use 10.X.Y.Z, and a good number of enterprise-y shops use 172.16-31 precisely because \"most other people use 192.168 or 10.X, so we should be good with 172.16-31\". IMHO, it shouldn't be too hard to enumerate the network interfaces, and pick an unassigned network range that doesn't conflict. If someone is using all of 10.X, all of 192.168.X, and all of 172.16-31, they can probably setup docker's bridge themselves without complaining :-)","I agree that no single range is going to work in every case.  That being said we should be able to find a way to remove the current dependency on the lxc-net service in Ubuntu (or a look alike lxcbr0 bridge device).  172.16-31, or another default, will likely work for lots of folks.  For those that can't use the default a simple override should be a realistic option.","What about the 198.18.0.0/15 range as a default? It seems like that would be orders of magnitude less frequent than the 3 typical private ranges (10/172/192). Then we can show a clear error message when the conflict *does* occur, and offer a --bridge option for easy customization.","The range 198.18.0.0/15  was suggested by @tobert on irc. I had never heard of it before.","That somehow feels very wrong. If IANA reclaims some of those ranges (on the basis that they aren't commonly used) it could be problematic. In the short run, fixed range (and abort if the range is already in use on the system) would work, and in the long run, automatic allocation (and abort if *all* possible ranges are already taken) would be great.","There's a nice overview of reserved IP ranges on Wikipedia.\r\n\r\nhttp://en.wikipedia.org/wiki/Reserved_IP_addresses\r\n\r\nIt's an abuse of the standard, but all of the popular RFC 1918 ranges are likely to hit conflicts in one environment or another. Probably the safest \"legal\" range would be something high in the 172.16/12.","Suggestion: as the go developers do, you could have a \"help wanted\"-type label for lower priority issues making it clear for which problems outside help is desired.","It should be easy to setup the dev environment. A simple setup script to wget and execute can do the trick.\r\nIt's simpler for the contributors and it makes sure everyone is working under the same environments.","@glorieux, doesn't `go get` satisfy this?","@pwaller ```go get``` already does all the work of fetching the package and installing it but does nothing about resolving the system dependencies like ```lxc wget bsdtar curl golang git```.\r\n\r\nI was thinking of a simple script that would do the dev environment setup, the same way the regular install is done ```curl get.docker.io | sh -x```.\r\n\r\nBTW - I think ```gcc``` is missing from the current ```apt-get``` command on the documentation.","The contribution docs came a long way. I think we can close this in favor of more specific, actionable issues.","I have reservations about just adding a 172.16.0.0/12 address to a machine without asking or warning etc.\r\n\r\nEither way this is an improvement but I would propose that it bail out and make some noise if it detects the system has an address already bound to 172.16.0.0/12.","Good point.  I'm working on some basic network enumeration so we can intelligently handle conflicts.  I'll update the branch once I work out a reasonable solution.","The logic to detect network overlap is incomplete.  Working on a fix.","I wouldn't mind breaking out the iptables wrapper fix. That one could be merged right away.\r\n\r\nThanks!","More discussion in #219","@shawnsi This needs a `go fmt`.","Bridge device creation should new properly detect any conflicts and error out.  \r\n\r\nI'm not sure how best to allow the user to override though.  If I add flags to docker for bridge iface and addr specification then I think I need to pass them from main() to NewRuntime() somehow.  This seems like there will be a lot of redundant parameter passing between the daemon(), NewServer(), and NewRuntime() functions.  \r\n\r\nAnyone have any tips on implementing this cleanly?","Due to the fact that all subnets must be a contiguous range of IP addresses the simplified overlap logic above is valid.  I've added more thorough test cases as well.","Let's try and get this merged today. Commencing review.","Implemented the suggestions from creack and titanous.","@shawnsi I added a check for overlapping route, and actually, we don't have to check the interfaces. If no routes matches, then its ok.","@creack That makes sense and seems a little more straightforward.  Do you want to submit a pull request with your changes that I can merge?","Just an FYI, I'll be going offline in a few hours and will be more or less unavailable through the weekend.","After chatting with @shykes, I simplified (a lot) the codes/feature. Now, we only can specify a bridge name, docker will handle the IPs. If the user wants his own custom network, he needs to create it prior lunching docker.\r\n\r\nSee #337 for follow-up","@dhrp: docs.docker.io now points to docker.readthedocs.org","PR #225 has been merged.\r\n\r\nStill working with dyn to get the redirect working, hopefully will be figured out this morning.","Just update the gh-pages branch now. @shykes We don't need to change the A for that yet. \r\nWe need the update to docs bcause they are way behind. \r\n\r\n;-) - mobiele email\r\n\r\nOn 28 mrt. 2013, at 06:59, Ken Cochrane \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e PR #225 has been merged.\r\n\u003e \r\n\u003e Still working with dyn to get the redirect working, hopefully will be figured out this morning.\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","closed by #225 ","Docker currently overrides `/sbin/init`, but you can try the following hack:\r\n- copy /sbin/init to /sbin/init.real\r\n- start /sbin/init.real\r\nYou will probably hit weird things since the init system will try to setup things that it really shouldn't mess up with (like network interfaces and filesystems) but that would be a good starting point.","Totally agree, this would be very useful and there is nothing in Docker's design preventing it.\r\n\r\nCurrently this will not work because of the following implementation detail: when starting a new container, docker mint-bounds itself as /sbin/init inside the container, hiding the real /sbin/init and in the proces smaking it unavailable for execution.\r\n\r\nOnce docker-as-init has been executed, the binary can be safely unmounted, un-hiding the real /sbin/init and making it available for execution. The problem is that unmounting must be done from *outside* the container, which requires cross-namespace synchronization between docker-as-init and dockerd. This can be implemented over a unix socket for example.\r\n","(I'm not sure if it's totally relevant)\r\n\r\nlxc comes with templates for various distributions, and those [templates](http://lxc.git.sourceforge.net/git/gitweb.cgi?p=lxc/lxc;a=tree;f=templates;h=8e1d7aa0c6efda2fd5ac7679e65c6ded28086aed;hb=HEAD) do heavy hacking of the freshly installed systems to make them runnable in a container (e.g. [Debian template](http://lxc.git.sourceforge.net/git/gitweb.cgi?p=lxc/lxc;a=blob;f=templates/lxc-debian.in;h=7bbc46b94103a3a87df91db9d289b9a240186dfc;hb=HEAD) and [Ubuntu template](http://lxc.git.sourceforge.net/git/gitweb.cgi?p=lxc/lxc;a=blob;f=templates/lxc-ubuntu.in;h=39c5a1c4206b2b074282620e5d459a72cfc88281;hb=HEAD))\r\n\r\nSo if the filesystem is not \"adjusted\", users might run into other kind of problems...","Bringing up an entire system is a use case better served by virtualization. I'm not saying it should be impossible to do with docker, just that it's not the core value prop. Docker seems to be best at process-level isolation, not machine-level. I think encouraging developers to think this way is helpful, and adding complexity/fragility to support full instances seems like a poor tradeoff.\r\n\r\nlxc is mostly the same and the hacks needed in their full-system templates are evidence of that.","@vsekhar, I agree.","I agree also. The fix I propose is the right thing to do anyway - the less\r\nside-effects on the guest filesystem, the better. If further changes are\r\nnecessary and those changes deviate from Docker's core value prop, we might\r\nnot implement them. At this time I'm not aware of any extra changes needed\r\nthough.\r\n\r\n\r\nOn Wed, Mar 27, 2013 at 5:21 PM, Mikhail Sobolev\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @vsekhar \u003chttps://github.com/vsekhar\u003e, I agree.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/223#issuecomment-15561614\u003e\r\n\u003e .\r\n\u003e","Docker overwrites /sbin/init inside the container for three reasons: 1) set the default gateway route, 2) change the user and 3) clean up `container` from the environment. 1) can be solved by setting `lxc.network.ipv4.gateway` in the lxc config file, 2) could be left to the user run command (there are chpst, sudo, sysv init scripts, upstart, systemd can do it as well) and 3) what's the reason for that?","1. `lxc.network.ipv4.gateway` doesn't work with lxc userland tools 0.7, that's why we implemented it; we need to make sure that it works with the tools provided with 12.04.\r\n\r\n2. Setting the user from docker itself allows to run unprivileged processes without relying on something specific in the container (which in some cases is a nice feature)\r\n\r\n3. Not sure about that one!\r\n\r\nI don't know if we are ready to drop the `/sbin/init` override yet, but it might become an option switch.","I feel like we could solve a big part of the problem simply by mounting docker as /sbin/docker-init instead of /sbin/init. Not perfect but should be good enough.\nI know of at least one person who gave up on using docker in favor of a home-made script which did exactly that.\n\nDoes anybody oppose this? Any negative side-effects I'm not thinking of?","Might work, but remember that you need to create /sbin/docker-init then.\nA good candidate for injection (that would almost always be there, and\ncould be created harmlessly if it's not) is /bin/true.","Couldn't we just create /sbin/docker-init? Especially if we're going to\r\nhave logic to create /bin/true if it doesn't exist anyway.\r\n\r\n\r\nOn Tue, May 28, 2013 at 6:15 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Might work, but remember that you need to create /sbin/docker-init then.\r\n\u003e A good candidate for injection (that would almost always be there, and\r\n\u003e could be created harmlessly if it's not) is /bin/true.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/223#issuecomment-18590503\u003e\r\n\u003e .\r\n\u003e","That works too. Initially the point of bind-mounting init and resolv.conf\n(vs. just copying) was to avoid modifying the existing image. Depends if\nthat's still a priority or not.","Should be simple enough to scope the bind-mount with a touch/rm in case it\r\ndoesn't exist, to cover all cases.\r\n\r\n\r\n\r\nOn Tue, May 28, 2013 at 6:31 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e That works too. Initially the point of bind-mounting init and resolv.conf\r\n\u003e (vs. just copying) was to avoid modifying the existing image. Depends if\r\n\u003e that's still a priority or not.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/223#issuecomment-18590992\u003e\r\n\u003e .\r\n\u003e","I'm not terribly well versed in the issues involved here, but had an idea I wanted to share in case it's useful.  What if you check for the existence of /sbin/docker-init first, and if it is there, you use that (so that images prepared specifically with docker in mind can include it and get \"upgraded\" docker functionality, if you will), but if it isn't, you use /sbin/init (so images that aren't necessarily prepared with docker in mind still work properly).\r\n\r\nAgain, I'm not well versed in the issues, or have much opinion either way, but it was a thought I had so I figured I'd share in case I'm thinking of something useful (but might just be more complex than what is wanted).","Hey Tianon, what you're describing is indeed very useful, and you can\r\nalready do it by setting a default command in the container's metadata.\r\nThis way the container author doesn't need to create a specially named file\r\n- you can name it whatever you like and tell docker to run it by default.\r\n\r\nOne thing thing this doesn't allow is telling docker to execute an \"entry\r\npoint\" command every time the container is run, regardless of the command\r\nspecified by the user. That could be an interesting addition.\r\n\r\nIn any case, those 2 topics are different from what we're discussing -\r\nspecifically the ability for the user to type \"docker run CONTAINER\r\n/sbin/init\" without having docker blow up :)\r\n\r\n\r\nOn Tue, May 28, 2013 at 7:59 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I'm not terribly well versed in the issues involved here, but had an idea\r\n\u003e I wanted to share in case it's useful. What if you check for the existence\r\n\u003e of /sbin/docker-init first, and if it is there, you use that (so that\r\n\u003e images prepared specifically with docker in mind can include it and get\r\n\u003e \"upgraded\" docker functionality, if you will), but if it isn't, you use\r\n\u003e /sbin/init (so images that aren't necessarily prepared with docker in mind\r\n\u003e still work properly).\r\n\u003e\r\n\u003e Again, I'm not well versed in the issues, or have much opinion either way,\r\n\u003e but it was a thought I had so I figured I'd share in case I'm thinking of\r\n\u003e something useful (but might just be more complex than what is wanted).\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/223#issuecomment-18593352\u003e\r\n\u003e .\r\n\u003e","Ah, that makes much more sense.  Thanks for clearing that up! :)","Hey guys, there's a pull request pending to make this possible: #898.\n\nIt looks like the base images will need some tweaking to boot properly (booting seems to hang on udev-related things for both ubuntu and centos), but I don't expect it to be too hard.","This has been merged into master, and is scheduled for the 0.6 stable release (target is August 21)","Ok, this should be in the release now. How do I in practice start the full container in Docker?\r\n\r\nI've also posted this on Stackoverflow http://stackoverflow.com/questions/19332662/start-full-container-in-docker","@epeli if you want to start in \"machine mode\" you can 'docker run /sbin/init'","hi, @shykes ,  I start container with :  \r\ndocker run -d ubuntu:12.04   /sbin/init  \r\nThis start a container, but how can I login into this container or attach this container?","You'd have to set the root password and install openssh-server.  You probably want to use a Dockerfile or docker run bash then docker commit to get the image setup the way you want/need it before you run `/sbin/init`.","HI, @tianon , \r\nNow I try following steps:\r\n1).  docker run -i -t ubuntu:12.04 /bin/bash\r\n2). inside container:\r\n\r\ndpkg-divert --local --rename --add /sbin/initctl\r\nln -s /bin/true /sbin/initctl\r\n\r\ninstall openssh-server inside it;\r\n\r\ncd /etc/init\r\nmv ssh.conf ssh.conf.bak\r\n\r\nafter these steps, I can start ssh server with both \" service ssh start\"  or \"/etc/init.d/ssh start\"\r\n\r\n3). commit the image\r\n4). start a container with this new image and '/sbin/init'\r\ndocker run -d xxxxx  /sbin/init\r\n\r\n5). \r\nps auxf\r\n\r\nI can't find ssh server inside container.\r\n\r\n\r\n\r\n","![image](https://f.cloud.github.com/assets/1398364/1564526/67b24ff0-5070-11e3-93fe-4d838f43d04b.png)\r\n","above is the screen snapshot, you can find /sbin/init inside container 8936xxxx","docker version is 0.6.6","`docker run $IMAGE /sbin/init` works perfectly.  Thank you!","Hi, @blalor  Could you give a detail step about how to use /sbin/init  ? thanks!\r\n\r\n\r\n","@chenyf I'm not sure what you're looking for.  I'm using the centos base image so life is apparently easier than dealing with ubuntu.\r\n\r\nDockerfile:\r\n\r\n```\r\nFROM centos\r\nRUN yum install -y openssh-server\r\nRUN yum install -y passwd\r\nRUN echo d0cker | passwd --stdin root\r\n\r\n## https://github.com/dotcloud/docker/issues/1240#issuecomment-21807183\r\nRUN echo \"NETWORKING=yes\" \u003e /etc/sysconfig/network\r\n\r\n## http://gaijin-nippon.blogspot.com/2013/07/audit-on-lxc-host.html\r\nRUN sed -i -e '/pam_loginuid\\.so/ d' /etc/pam.d/sshd\r\n\r\nEXPOSE 22\r\nCMD /sbin/init\r\n```\r\n\r\nRun it: `docker run -d -P $IMAGE`\r\nFind ssh port: `docker port $CONTAINER 22`\r\nConnect: `ssh -p $PORT root@localhost`","you may have a look to our ubuntu based containers\r\n (https://github.com/makinacorpus/vms/tree/master/docker)\r\nYou can have also a look to this entry point for a bunch of bugs: https://github.com/dotcloud/docker/issues/2276","That is of course possible, but I'm not ready to support a stable API at\r\nthat level - we still need the freedom to break it to accomodate Docker's\r\nneeds.\r\n\r\n\r\nOn Wed, Mar 27, 2013 at 5:25 PM, Vivek Sekhar \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Document the Go code so that it can be used directly in other Go programs.\r\n\u003e Specifically, the following components could be independently usable:\r\n\u003e\r\n\u003e    - creating a container in an arbitrary rootfs path (not just the\r\n\u003e    system-wide lxc registry, or any particular AUFS repo)\r\n\u003e    - running a process within a container\r\n\u003e    - creating an AUFS repo and extracting branch paths (to pass to\r\n\u003e    container creation)\r\n\u003e\r\n\u003e I'd like to be able to do in Go something like this easily:\r\n\u003e\r\n\u003e aufs := docker.AUFS.New(my_repo_path, ...)\r\n\u003e my_aufs_path := aufs.Branch(\"branchname\").Path()\r\n\u003e caufs := docker.Container.New(my_config, my_aufs_path, ...)\r\n\u003e cplain := docker.Container.New(my_config, my_plain_path, ...)\r\n\u003e caufs.RunCommand(\"echo\", \"hello\", \"world\")\r\n\u003e cplain.RunCommand(\"echo\", \"hello\", \"world\")\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/224\u003e\r\n\u003e .\r\n\u003e","In the shorter term, I think it makes sense to split the functionality out into smaller, logically distinct internal packages with no stable API, instead of being mostly lumped into one big package.","That's where we started - but as we kept moving components around and\r\nre-arranging them, it complicated things, so we moved a lot of it back into\r\nthe same package. Once the dividing lines solidify, I will definitely\r\nconsider breaking them apart again.\r\n\r\n\r\nOn Wed, Mar 27, 2013 at 6:38 PM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e In the shorter term, I think it makes sense to split the functionality out\r\n\u003e into smaller, logically distinct internal packages with no stable API,\r\n\u003e instead of being mostly lumped into one big package.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/224#issuecomment-15563761\u003e\r\n\u003e .\r\n\u003e","Yeah, I'm not advocating we do that now. It definitely makes sense for things to stabilize a bit before rearranging.","As I think about this more, the major components of docker are actually also independently useful. Eventually docker itself could be architected around these major buckets for modularity/maintainability.\r\n\r\n - Container: executes code inside rootfs and lxc container\r\n   - Input: path to rootfs, command and arguments, capabilities/permissions\r\n   - Output: modified rootfs, execution logs, error codes\r\n - NetworkManager: manages routing between network interfaces on a host\r\n   - Input: a set of network interfaces, Map/Unmap function calls, RPCs, etc.\r\n   - Output: modified iptables on the host\r\n - DirectoryManager: computes directory diffs, merges them, patches on-disk paths (can use AUFS under the hood)\r\n   - Input: source paths, Diff/Patch/Export function calls, RPCs, etc.\r\n   - Output: diffs, directories on disk suitably patched\r\n - HistoryManager: maintains a graph of a directory's history based on patches applied (essentially a simplified file-level git)\r\n   - Input: a StorageDriver instance, Init/Commit/Checkout/Push/Pull function calls, RPCs, etc.\r\n   - Output: checkouts of requested directories on the local filesystem\r\n - StorageDriver: a Go interface for getting/setting blobs from HistoryManager, with predefined implementations for local on-disk repo, S3, Blobstore, etc.\r\n   - Input: credentials and parameters as required (e.g. AWS ID/key, etc.), Get/Set functions\r\n   - Output: blobs written to disk, S3, etc. as specified\r\n\r\nThen docker's runtime just pulls together these functions:\r\n  1. setup routing between eth0 and lxcbr0 using NetworkManager\r\n  1. checkout the desired rootfs using HistoryManager\r\n  1. run the command using Container (pointing to rootfs and lxcbr0 defined above)\r\n  1. commit back changes to rootfs using HistoryManager\r\n\r\nDocker developers can then specialize on each of those components based on their expertise and not bump into each other, since the components don't really have any interactions between them (other than passing a rootfs path around).\r\n\r\nEDIT: add StorageDriver","+1\r\n\r\nI _want_ to start some tests and some integration between tsuru and docker next week, and having an API would be awesome. We already have some troubles using juju from command line instead of using a Go API.\r\n\r\nI don't mind having some unstable API at the moment, mr Jenkins will protect us :-)","@fsouza if you don't mind a private API, you can definitely go ahead and start playing :) Soon there will be a remote API which should make things easier.\r\n\r\n1) I recommend starting in commands.go. The CLI commands are defined in there, so you can follow the calls down to the low-level implementation.\r\n\r\nThat will lead you to docker.Runtime, which ties containers and images together. One of the sub-components of docker.Runtime is docker.Graph, which is the raw collection of images. Separately, docker.TagStore is the collection of repositories and tags referencing certain image IDs in the graph.\r\n\r\n2) Just run 'godoc .' in the root repository, it will show you all available calls. Most of them are pretty self-explanatory.\r\n\r\n\r\n3) A few quick examples (omitting error checking):\r\n\r\n   // Load an image and mount it somewhere\r\n    runtime := docker.NewRuntime(\"/var/lib/docker\")\r\n    img := runtime.LookupImage(\"base:latest\")\r\n    img.Mount(\"/tmp/base/mountpoint\", \"/tmp/base/rw\")\r\n    changes := img.Changes(\"/tmp/base/rw\")\r\n\r\n   // Create a new container\r\n    container := docker.Create(\u0026docker.Config{Image: \"shykes/helloflask:master\", Cmd: \"runapp\", Ports: int[]{5000}}\r\n    container.Start()\r\n    changes := container.Changes()\r\n\r\n\r\nAgain: it's private and will break in the future! :)\r\n\r\n","@vsekhar I will gladly accept suggestions on improving the current architecture, god knows it's not perfect... But first you need to take the time to read the code and understand the current architecture :)","Where do you think I was getting my ideas if not from your code? :) But yes, I will try expressing my ideas more in pull requests and less in issues.","Sorry if I got the wrong impression! In that case it would be helpful to point out what existing components should be changed, even at a high-level. Even if it's not expressed in code, it would help map your suggestions to the current state of affairs.\r\n\r\nJust to be clear, in any case your feedback is definitely appreciated.","In the 1.0 api all core components will be exposed as independent plugins. The ApI will include Go bindings.","thanks, merging","The syntax error turns out to be an issue for Windows users who are using Vagrant. It goes something like:\r\n\r\n1. The Windows git client translates the line endings of the `.profile` template to CRLF\r\n\r\n2. Vagrant shares the `.profile` with the VM and runs puppet\r\n\r\n3. Puppet installs the .profile with the CRLF line endings\r\n\r\nThat might be fixable with a `.gitattributes` rule. https://help.github.com/articles/dealing-with-line-endings","I merged in the change to remove `/usr/local/bin/docker`. The Windows CRLF issue i still open. Ideas on how best to solve it? Do we set the repo's line-ending behavior off of auto? Do we override it for just this one file?","I recommend\r\n\r\ntext eol=lf\r\n\r\nForce to always use lf, since the target scripts run on is always Linux.","@fkautz: There are plenty of changes in /Vagrantfile, and we are now using docker's PPA, deprecating the need to build it on the fly. Could you verify what is the status of this issue?","You shouldn't have to clean up. Thanks for catching this!\r\n\r\nOn Wednesday, March 27, 2013, Dave Kuhn wrote:\r\n\r\n\u003e After running the docker daemon for about 15 minutes under load I abruptly\r\n\u003e ran out of file descriptors. Given that my ulimit is 10000 and I wasn't\r\n\u003e handling anywhere near that level of concurrent requests I thought it was\r\n\u003e strange.\r\n\u003e\r\n\u003e Running sudo lsof | grep ' root ' | awk '{print $NF}' | sort shows that a\r\n\u003e huge number of container log files still remain. Is this a bug or should I\r\n\u003e be doing something to clean up after each run?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/228\u003e\r\n\u003e .\r\n\u003e","Okay cheers, glad to know I'm not missing something here. If I get a chance I'll delve into the code and see if I can track down the culprit. Any pointers on where to start looking would be appreciated.","@kuhnza Likely a missing `Close()` for one or more of these: https://github.com/dotcloud/docker/blob/master/container.go#L39-L45","This is linked to #125, I found the bug and will submit a pull request in a couple of minutes.\r\n\r\nThe ptys stay open forever.","Actually, make it a couple of hours, I still need to do a lot of tests","I'm adding this to the shortlist.","Fantastic work guys, thanks for getting this closed so quickly. Looking forward to taking it for a test drive.","Thanks","+1",":+1: ","Cc @unclejack , for reference in your future dockerrun patches","This seems to have been merged. Closing","This is probably caused by the IP address allocator. It puts all the\r\navailable addresses in a pool when docker starts. I thought that it might\r\nbe noticeable with a /8 but I'm surprised that a /16 would cause problems.\r\n\r\nCan you please try with different subnet sizes and report the memory usage\r\nof the docker daemon?\r\nOn Mar 28, 2013 4:07 AM, \"Tamás Gulácsi\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e If the lxcbr0 interface is configured to 10.65.26.1, for example (\r\n\u003e 10.65.0.0/16).\r\n\u003e If it is 192.168.13.13, then its ok.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/231\u003e\r\n\u003e .\r\n\u003e","Yeah that allocator should be lazy... If any of you feel like looking at\r\nit, assign to yourself. Otherwise I will do it.\r\n\r\nOn Thursday, March 28, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e This is probably caused by the IP address allocator. It puts all the\r\n\u003e available addresses in a pool when docker starts. I thought that it might\r\n\u003e be noticeable with a /8 but I'm surprised that a /16 would cause problems.\r\n\u003e\r\n\u003e Can you please try with different subnet sizes and report the memory usage\r\n\u003e of the docker daemon?\r\n\u003e On Mar 28, 2013 4:07 AM, \"Tamás Gulácsi\" \u003cnotifications@github.com\u003cjavascript:_e({}, 'cvml', 'notifications@github.com');\u003e\u003e\r\n\u003e wrote:\r\n\u003e\r\n\u003e \u003e If the lxcbr0 interface is configured to 10.65.26.1, for example (\r\n\u003e \u003e 10.65.0.0/16).\r\n\u003e \u003e If it is 192.168.13.13, then its ok.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/231\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/231#issuecomment-15598820\u003e\r\n\u003e .\r\n\u003e","I'll have a pull request ready soon (within the day)","See also #211 and #218. These are basically the same request. ","Is this still the case? Is it precise and actionable enough to remain open?","I think they are better, what do you think @metalivedev ?","I think http://docs.docker.io/en/latest/use/workingwithrepository/ solves this. Still room for improvements and examples, but there is an example of search, commit and push.","+1, we need this.\r\n\r\nThe command you tried does not work, but it should!\r\n\r\n    cat test.txt | docker run -i -d base cat\r\n\r\nThis should remain attached until stdin is fully sent, and then detach.\r\n\r\nI know @progrium asked for this too.\r\n","Here's a temporary workaround:\r\n\r\n     cat test.txt | docker run -i -d base cat\r\n     LAST=$(docker ps -a -q | head -n 1)\r\n\r\nThis will not work if you run another container in parallel...\r\n","Also worth noting here that if Docker supported optional aliases/names for\r\ncontainers, you wouldn't have to get the ID because you'd run \"cat test.txt\r\n| docker run -n mycontainer -i -d base cat\" and already have a reference to\r\nthat container.\r\n\r\n\r\nOn Thu, Mar 28, 2013 at 11:23 AM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Here's a temporary workaround:\r\n\u003e\r\n\u003e  cat test.txt | docker run -i -d base cat\r\n\u003e  LAST=$(docker ps -a -q | head -n 1)\r\n\u003e\r\n\u003e This will not work if you run another container in parallel...\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/234#issuecomment-15605594\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","```\r\ncat test.txt | docker run -i -d base cat\r\n```\r\nThis doesn't work for me, it never stops running.","Fixed :)","@shykes what is the command to get the stdout of `cat`?\r\n\r\n    cat test.txt | docker run -i -a stdin base cat\r\n\r\nReturns the container ID. And: \r\n\r\n    cat test.txt | docker run -i -a stdout base cat\r\n\r\nNever returns. Running 0.5.0","@MatthewMueller `cat test.txt | docker run -i  base cat` ?","@MatthewMueller Doing '-a stdout' means that only stdout will be attach. '-i' Only allocates stdin but does not attach it. Meaning that cat never get the input and the input never closes therefore it never returns.","Changed the Fatal as requested.  The caller doesn't currently handle the error returned from iptables() very well.  Shall we change that up at all before merging?","Good point. That might be on purpose because certain iptables commands might be expected to fail (eg. delete something that doesn't exist).\r\n\r\nI am open to suggestions on the clean way to handle this!","Something like this combines the previous error messages with the error returned from iptables().","I think we can leave the errors on rule cleanup unhandled.","gofmt -w","Squash and LGTM. :+1:","Squashed.","@shykes I think we can definitely merge this now!","Testing now, thanks.","Hmm. Weird. It shows changes to files I did not change. These changes should all be trivial. I merged master into my local branch. ","Ah. Now my pull is up to date. ","@dhrp If you `git rebase master` and then `git push -f origin docs` it should get rid of all the extraneous merge commits.","A copy of this should be created as [`CONTRIBUTING.md`](https://github.com/blog/1184-contributing-guidelines) so that it shows up as a message when opening pull requests and issues.","Group hug for @titanous ... Helpful advice everywhere I turn :)\r\n",":heart_eyes: :flushed:","Thanks @johncosta! I think unit tests are already mentioned elsewhere on the doc, could you double-check?","@shykes It looks like the README still has portions of text that are duplicated within the `Contribution guidelines` documentation.  This includes the mention of unit tests. To reduce duplication, I'd like to suggest we remove it from the README[0] and correct the link to the contribution guide `http://docs.docker.io/en/latest/contributing/contributing/` [1]\r\n\r\n[0]: https://github.com/dotcloud/docker/blob/master/README.md lines 209-226\r\n[1]: https://github.com/dotcloud/docker/blob/master/README.md line 195\r\n","@johncosta I agree. Want to do it?","Fixed in master closing.","This is already supported :)\r\n\r\n    $ docker  run -e FOO=BAR busybox env\r\n    HOME=/\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\r\n    FOO=BAR\r\n\r\n","Ah, I missed that!","@jbarbier Can you squash these commits?","@titanous DONE :) -\u003e https://github.com/dotcloud/docker/pull/244\r\ntx","@jbarbier Thanks! FYI: you can `git push -f` and the pull request will update!","That should work already, thanks to the `uts` namespace.\r\n\r\nCan you please describe what you were trying to do, what you were expecting, and what happened?\r\n\r\nThank you!","@kim0 would this be a good solution for you?\r\n\r\n    docker run -h MY_HOSTNAME /bin/sh -c 'my hostname is $(hostname)'\r\n\r\n","Yes absolutely, I didn't look hard enough. Thanks folks\r\n\r\n\r\nOn Fri, Mar 29, 2013 at 3:13 AM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @kim0 \u003chttps://github.com/kim0\u003e would this be a good solution for you?\r\n\u003e\r\n\u003e docker run -h MY_HOSTNAME /bin/sh -c 'my hostname is $(hostname)'\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/243#issuecomment-15624414\u003e\r\n\u003e .\r\n\u003e","Perhaps this should be tied to container naming.\r\n\r\n\r\nOn Thu, Mar 28, 2013 at 6:29 PM, kim0 \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Yes absolutely, I didn't look hard enough. Thanks folks\r\n\u003e\r\n\u003e\r\n\u003e On Fri, Mar 29, 2013 at 3:13 AM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e\r\n\u003e \u003e @kim0 \u003chttps://github.com/kim0\u003e would this be a good solution for you?\r\n\u003e \u003e\r\n\u003e \u003e docker run -h MY_HOSTNAME /bin/sh -c 'my hostname is $(hostname)'\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/243#issuecomment-15624414\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/243#issuecomment-15624809\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","See #299 ","It would be rad if you could then refer to containers by hostname instead\r\nof ID. :D\r\n\r\n\r\nOn Mon, Apr 1, 2013 at 2:43 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e See #299 \u003chttps://github.com/dotcloud/docker/issues/299\u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/243#issuecomment-15739222\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","@progrium, maybe you could open another issue and describe the scenario you envision?\r\n\r\nMy personal _feeling_ is that referring to the container by the host name might be ambigous in certain scenarios...","That would really be up to you to make it ambiguous. You can always fall\r\nback to ID. Anywhere you use ID, you should be able to use hostname. Or\r\nsome other alias. But since we have custom hostnames, we might as well use\r\nthat for naming?\r\n\r\n\r\nOn Mon, Apr 1, 2013 at 2:52 PM, Mikhail Sobolev \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @progrium \u003chttps://github.com/progrium\u003e, maybe you could open another\r\n\u003e issue and describe the scenario you envision?\r\n\u003e\r\n\u003e My personal *feeling* is that referring to the container by the host name\r\n\u003e might be ambigous in certain scenarios...\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/243#issuecomment-15739655\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","is there a reason this strips out anything with subdomains?\r\n\r\n    kr@utils:~/dockerfiles/graphite$ docker run -h 'utils.mysite.com' -i -t ubuntu /bin/bash\r\n    root@utils:/# echo $(hostname)\r\n    utils\r\n","It sets the host and domain names:\r\n\r\n```\r\n$ docker run -h foo.bar.baz -i -t ubuntu bash\r\nroot@foo:/# hostname\r\nfoo\r\nroot@foo:/# hostname -d\r\nbar.baz\r\nroot@foo:/# hostname -f\r\nfoo.bar.baz\r\nroot@foo:/#\r\n```","Awesome thanks a bunch, learning new things I am sure that was a pretty obvious fail on my part. ;)","Correct on all counts :)\r\n\r\nWhat we're shooting for is a system comparable to the go language. eg. you can host a package anywhere, and as a convenience there's a central curated namespace with guidelines for quality, auditing, safety etc.","This is a subcomponent of #21.","I changed the title to clarify the difference with #350.\r\n\r\nThis issue is about adding the peer-to-peer push/pull feature to Docker. With this feature, 2 docker hosts can exchange images directly as if they were exchanging images with the registry.","Thinking a little more of specifics here.\r\n\r\n* Do we want to support pushing to *and* pulling from another daemon?\r\n* Should the docker always accept image pushes (and pulls), or does it need to be run in promiscuous mode?\r\n* What about daemon - daemon authentication and authorization?\r\n* What's the command for pushing to another daemon? `docker push -d other.docker.com myimage`?\r\n* Is the transfer going to use the exact same mechanism as the regular registry push/pull? (HTTP, etc.)\r\n* #21 is tied into this issue. For example, it would include a route for `POST`ing an image to another daemon. Or maybe that's superseded by whatever API the registry uses.\r\n","On Mon, Apr 8, 2013 at 8:21 PM, Caleb Spare \u003cnotifications@github.com\u003ewrote:\n\n\u003e\n\u003e    - Do we want to support pushing to *and* pulling from another daemon?\n\u003e\n\u003e Yes, I think so. If I had to choose one, I would choose push to start.\n\n\u003e\n\u003e    - Should the docker always accept image pushes (and pulls), or does it\n\u003e    need to be run in promiscuous mode?\n\u003e\n\u003e I think it's fine to start that way. We can make it a conditional switch,\neg. 'docker -d --no-push-pull'\n\n\u003e\n\u003e    - What about daemon - daemon authentication and authorization?\n\u003e\n\u003e I think we can worry about that later.\n\n\u003e\n\u003e    - What's the command for pushing to another daemon? docker push -d\n\u003e    other.docker.com myimage?\n\u003e\n\u003e This seems reasonable. @samalba @kencochrane and @shin- who are\nimplementing the registry might have an opinion here.\n\n\u003e\n\u003e    - Is the transfer going to use the exact same mechanism as the regular\n\u003e    registry push/pull? (HTTP, etc.)\n\u003e\n\u003e Yes, that is the goal.\n\n\u003e\n\u003e    - #21 \u003chttps://github.com/dotcloud/docker/issues/21\u003e is tied into this\n\u003e    issue. For example, it would include a route for POSTing an image to\n\u003e    another daemon. Or maybe that's superseded by whatever API the registry\n\u003e    uses.\n\u003e\n\u003e Absolutely. I started working on #21, how about I share the base with you\nand we work on parallel on the 2 different parts of the API?","@shykes That sounds great. Just push the #21 code to a branch?","This will be significantly easier using the 1.0 api.\n\nThis would be a great plugin, if somebody is interested in working on this, please say so here. I will hook you up with early API docs and tips for getting started.","This sounds interesting. Is there any hard deadline for this feature? If not, I can take it and work on it by the end of this month (or may be September. I have some other work to do these recent weeks.)\r\n\r\n@shykes It would be great if I could access more detailed plan of 1.0 APIs.","@tobstarr, if you feel like using that go registry implementation of yours to allow docker to receive a push... I think that would be a killer feature! I will be happy to help you get it merged.","I am still interested in this. If somebody wants to give it a try, let me know :)","+1 for me","I would really like to get this built. Is the basic idea to overlay the registry API on top of the remote API? It looks like the `/images/:id/json` endpoint is more-or-less compatible, and everything else doesn't collide.\r\n\r\nIt would be really neat if the registry API was a subset of the remote API. Alternatively, I guess we could have a separate port / URL namespace that was the registry. Or even a different API entirely?","+1 - I would love to see it work the same way the registry works so you didn't have to care if you were talking to a registry or to a remote docker daemon.\r\n\r\nI'm not sure how much work this would be, but if they're the same then the push / pull functionality of the registry could essentially become a lightweight authentication that sits in front of a docker daemon.","A working implementation over SSH here: https://github.com/docker/docker/pull/9304","Can anyone please tell me if we are going to get this feature in near future in any release?\r\nI would love to see this feature","+1 Would love to see that too!","+1. ","+1 on this. Currently we use `docker save | ssh -C docker load` to transfer images, but that transfers *everything*, including the pieces we already have. Would be much easier if I could only transfer the bits that mattered.","*USER POLL*\n\n*The best way to get notified when there are changes in this discussion is by clicking the Subscribe button in the top right.*\n\nThe people listed below have appreciated your meaningfull discussion with a random +1:\n\n@xiaods\n@hustcat\n@leonardschneider\n@v00rh33s","https://github.com/Dataman-Cloud/p2pull","Solved by 0b9a3c86a26b4b7eb463a6c73cb030bc851fdd64 and 1632566ecb133fb0853aec6715c5c06a4a9e41da","+1 :)\n\nI think we should continue these use case discussions in the mailing list, to keep the number of open issues small and manageable.","I am interesting on this topic @shykes ","@synack had a good debianization in a branch (better than the one in deb/ subdir)\r\n\r\n#161 was implemented to support his effort","That'd be a Debian package as in compatible with Debian (stable?), or a Debian package for Ubuntu? :sweat_smile: ","Since the package includes an upstart configuration file (and the quick start also suggests to create on), I'd say it's Ubuntu specific.","@mdaniel could you clarify if this issue is for generic .deb creation, or\r\nspecifically for inclusion in the Debian distro? Thanks.\r\n\r\nOn Saturday, March 30, 2013, Mikhail Sobolev wrote:\r\n\r\n\u003e Since the package includes an upstart configuration file (and the quick\r\n\u003e start also suggests to create on), I'd say it's Ubuntu specific.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/251#issuecomment-15684958\u003e\r\n\u003e .\r\n\u003e","Sorry meant @mzdaniel\r\n\r\nOn Saturday, March 30, 2013, Solomon Hykes wrote:\r\n\r\n\u003e @mdaniel could you clarify if this issue is for generic .deb creation, or\r\n\u003e specifically for inclusion in the Debian distro? Thanks.\r\n\u003e\r\n\u003e On Saturday, March 30, 2013, Mikhail Sobolev wrote:\r\n\u003e\r\n\u003e\u003e Since the package includes an upstart configuration file (and the quick\r\n\u003e\u003e start also suggests to create on), I'd say it's Ubuntu specific.\r\n\u003e\u003e\r\n\u003e\u003e —\r\n\u003e\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/251#issuecomment-15684958\u003e\r\n\u003e\u003e .\r\n\u003e\u003e\r\n\u003e","@shykes, gh issues have an edit feature :)\r\n\r\nthe keyword in the question was \"compatible\", how I took it: if the package is installed, can it be used right away on a Debian system.  The answer is: no, you'd have to enable daemon start somehow.","@shykes: We are talking about Debian. We are currently looking for landing docker in the Unstable distro.","@oz: That'd be a Debian package compatible with Debian Wheezy (currently Testing distro)\r\n","@sa2ajj: Thank you so much, Mikhail, for implementing the Makefile!  It is  super useful for all developers and neatly done.","Changed title to clarify that issue #251 is for Debian, and issue #30 is for Ubuntu.","cc @paultag @mzdaniel what is missing to make this an official Debian package? Let us know if there's any way we can help.","Issue #396 has been solved in branch 396-disabling_memory_limit-feature. Thank you Guillaume!","As explained in issue #396, Wheesy Debian stock kernel does support limiting memory, only that needs a couple of kernel boot parameters as by default they are disabled. The parameter settings for properly enable kernel suport are:\r\n\r\ncgroup_enable=memory swapaccount=1\r\n\r\nDebian users can fully enjoy docker passing all its tests with standard Wheesy kernel adding the following parameters into their /boot/grub/grub.cfg:\r\n\r\nlinux /boot/vmlinuz-3.2.0-4-amd64 [other parameters] cgroup_enable=memory swapaccount=1\r\n\r\nThis implies that with good documentation, Debian Wheesy with no special packages fully support Docker\r\n","Debian package has been uploaded to https://mentors.debian.net/package/lxc-docker","The debian lxc-docker package had been uploaded to http://mentors.debian.net/package/lxc-docker using what it is on docker mainline /packaging/debian . There are a few loose ends at this point, including the need to rewrite /packaging/debian/Makefile logic into  /packaging/debian/rules, aligned with debian go packaging guidelines. If you are interested in helping out we will have this package faster and all debian and downstream distros will benefit :) \r\n","On 06/07/2013 12:11 PM, Yaroslav Halchenko wrote:\n\u003e\u003e\u003e\u003e ...\u003c\n\u003e\n\u003e\u003e All fair questions! We are following the practice we use for\n\u003e\u003e publishing PPA packages, which after installing building\n\u003e\u003e dependencies (git debhelper build-essential autotools-dev devscripts\n\u003e\u003e golang), boils down to:\n\u003e\n\u003e\u003e git clone git://github.com/dotcloud/docker; cd\n\u003e\u003e docker/packaging/debian; make debian\n\u003e\n\u003e\u003e That will take care of generating all packaging files. For the PPA,\n\u003e\u003e that's enough. Launchpad builders will take it from there. As you\n\u003e\u003e point out, this is not quite the process debian uses. We have\n\u003e\u003e already access rights and the next step is creating the proper repo.\n\u003e\u003e Upstream is meant to have /packaging/debian as we highly prefer to\n\u003e\u003e keep the root level clean and organized ( having /debian will\n\u003e\u003e suggest we could have /ubuntu\n\u003e\u003e /redhat /arch. It's much cleaner to have /packaging for packaging stuff :)\n\u003e\n\u003e I hear you!  I do...\n\u003e\n\u003e but there are few \"problems\" with such an approach which would\n\u003e keep such package at least \"non-conventional\" in Debian land:\n\u003e\n\u003e - ideally Debian source package should not contain \"generated\"\n\u003e    files but rather sources ... including the content of debian/ directory.\n\u003e\n\u003e    the reason is simple -- maintenance of debian/ content.\n\u003e\n\u003e    if someone introduces fixes and uploads via\n\u003e    non-maintainer uploads, most probably those changes would be under\n\u003e    debian/ and if debian/ itself is \"derived\" from some other location --\n\u003e    it might get messy quickly\n\u003e\n\u003e - people who 'debcheckout' (via Vcs- header fields in debian/control)\n\u003e    expect getting some repository (possibly a branch) where debian/\n\u003e    directory is already there so they could quickly tune it up and build\n\u003e    package right away, e.g. via\n\u003e\n\u003e    dpkg-buildpackage\n\u003e\n\u003e    which is the standard way to build a debian package out of extracted\n\u003e    sources (the actual standard is to e.g. call debian/rules binary\n\u003e    -- to generate binary packages)\n\u003e\n\u003e with original debian packaging residing somewhere under packaging/ --\n\u003e things would get...  non-standard to say the least.  It should not\n\u003e preclude upload to Debian proper, since Debian policy doesn't mandate\n\u003e original VCS structure, but the fact would be that contribution by\n\u003e debian community could be hindered...\n\u003e\n\u003e FWIW -- just to share alternative ways -- it is common to go with\n\u003e branches, i.e. I keep debian branch which adds  debian/ directory with\n\u003e packaging on top of \"master\"/releases content.  That has pros and cons too\n\u003e\n\u003e - pros: anyone could debcheckout (branch could be specified in vcs-git)\n\u003e    and adjust packaging, build package right away\n\u003e\n\u003e    it becomes clearer what was the released into Debian-land state of\n\u003e    things (by last merge from master)\n\u003e\n\u003e - cons:  if releases come from release branches (and not from a single\n\u003e    branch like master, or \"releases\") then merging into 'debian' branch\n\u003e    could be tricky and requires some trickery (I usually create\n\u003e    \"releases\" branch which \"merge theirs\"  releases to be packaged)...\n\u003e\n\u003e alternative resolution here could also be to have 'debian' branch as an\n\u003e overlay -- containing just debian/ directory, and then use\n\u003e git-buildpackage with overlay option (and specify that in\n\u003e debian/gbp.conf).  That one would happily overlay it on top of any\n\u003e given branch/tarball and everyone would be happy... cons -- working with\n\u003e such detached branch might be trickier too\n\u003e\n\u003e just my .1c whatever they are worth\n\nThank you Yaroslav for sharing! I am curious to explore these \nalternatives. Could you point us to a few projects to see these in action?","\u003e \u003e\u003eAll fair questions! We are following the practice we use for\n\u003e \u003e\u003epublishing PPA packages, which after installing building\n\u003e \u003e\u003edependencies (git debhelper build-essential autotools-dev devscripts\n\u003e \u003e\u003egolang), boils down to:\n\n\u003e \u003e\u003egit clone git://github.com/dotcloud/docker; cd\n\u003e \u003e\u003edocker/packaging/debian; make debian\n\n\u003e \u003e\u003eThat will take care of generating all packaging files. For the PPA,\n\u003e \u003e\u003ethat's enough. Launchpad builders will take it from there. As you\n\u003e \u003e\u003epoint out, this is not quite the process debian uses. We have\n\u003e \u003e\u003ealready access rights and the next step is creating the proper repo.\n\u003e \u003e\u003eUpstream is meant to have /packaging/debian as we highly prefer to\n\u003e \u003e\u003ekeep the root level clean and organized ( having /debian will\n\u003e \u003e\u003esuggest we could have /ubuntu\n\u003e \u003e\u003e/redhat /arch. It's much cleaner to have /packaging for packaging stuff :)\n\n\u003e \u003eI hear you!  I do...\n\n\u003e \u003ebut there are few \"problems\" with such an approach which would\n\u003e \u003ekeep such package at least \"non-conventional\" in Debian land:\n\n\u003e \u003e- ideally Debian source package should not contain \"generated\"\n\u003e \u003e   files but rather sources ... including the content of debian/ directory.\n\n\u003e \u003e   the reason is simple -- maintenance of debian/ content.\n\n\u003e \u003e   if someone introduces fixes and uploads via\n\u003e \u003e   non-maintainer uploads, most probably those changes would be under\n\u003e \u003e   debian/ and if debian/ itself is \"derived\" from some other location --\n\u003e \u003e   it might get messy quickly\n\n\u003e \u003e- people who 'debcheckout' (via Vcs- header fields in debian/control)\n\u003e \u003e   expect getting some repository (possibly a branch) where debian/\n\u003e \u003e   directory is already there so they could quickly tune it up and build\n\u003e \u003e   package right away, e.g. via\n\n\u003e \u003e   dpkg-buildpackage\n\n\u003e \u003e   which is the standard way to build a debian package out of extracted\n\u003e \u003e   sources (the actual standard is to e.g. call debian/rules binary\n\u003e \u003e   -- to generate binary packages)\n\n\u003e \u003ewith original debian packaging residing somewhere under packaging/ --\n\u003e \u003ethings would get...  non-standard to say the least.  It should not\n\u003e \u003epreclude upload to Debian proper, since Debian policy doesn't mandate\n\u003e \u003eoriginal VCS structure, but the fact would be that contribution by\n\u003e \u003edebian community could be hindered...\n\n\u003e \u003eFWIW -- just to share alternative ways -- it is common to go with\n\u003e \u003ebranches, i.e. I keep debian branch which adds  debian/ directory with\n\u003e \u003epackaging on top of \"master\"/releases content.  That has pros and cons too\n\n\u003e \u003e- pros: anyone could debcheckout (branch could be specified in vcs-git)\n\u003e \u003e   and adjust packaging, build package right away\n\n\u003e \u003e   it becomes clearer what was the released into Debian-land state of\n\u003e \u003e   things (by last merge from master)\n\n\u003e \u003e- cons:  if releases come from release branches (and not from a single\n\u003e \u003e   branch like master, or \"releases\") then merging into 'debian' branch\n\u003e \u003e   could be tricky and requires some trickery (I usually create\n\u003e \u003e   \"releases\" branch which \"merge theirs\"  releases to be packaged)...\n\n\u003e \u003ealternative resolution here could also be to have 'debian' branch as an\n\u003e \u003eoverlay -- containing just debian/ directory, and then use\n\u003e \u003egit-buildpackage with overlay option (and specify that in\n\u003e \u003edebian/gbp.conf).  That one would happily overlay it on top of any\n\u003e \u003egiven branch/tarball and everyone would be happy... cons -- working with\n\u003e \u003esuch detached branch might be trickier too\n\n\u003e \u003ejust my .1c whatever they are worth\n\n\u003e Thank you Yaroslav for sharing! I am curious to explore these\n\u003e alternatives. Could you point us to a few projects to see these in\n\u003e action?\n\nbtw - 1 more point why eventually you would need to branch anyways.\nE.g. if some version in Debian stable would need to be fixed -- so you\nwould need to get back to that point and branch off \n\n1. debian (or alike) branch with merges of the main code branch\n\n a. where all releases come from 'master' branch so merging into\n  debian branch becomes easy -- examples are numerous, but let me point\n  to our own project:\n\n  https://github.com/PyMVPA/PyMVPA/tree/dist/debian/proper/sid\n\n  so here we named branch not simply \"debian\" but rather\n  \"dist/debian/proper/sid\", since we might also need to upload bug fix\n  package releases to debian stable, and then it would become\n  \"dist/debian/proper/wheezy\".\n\n  'proper' was there because we thought we might need a special branch\n  for neurodebian repository backports (http://neuro.debian.net/) but\n  that never got to be the case (we ship patches for backporting within\n  the same dist/debian/proper/sid   under debian/patches)\n\n b. if releases come from \"release branches\", so merging into \"debian\"\n branch becomes tricky, I created 'releases' branch for  sklearn\n\n http://github.com/yarikoptic/scikit-learn\n\n for merges into \"releases\" branch I use following git alias\n\n    # To overcome absence of \"ours\" strategy in git merge \n    mtheirs = !sh -c 'git merge -s ours --no-commit $1 \u0026\u0026 git read-tree -m -u \"$1\"' -\n\n so I do smth like\n\n git checkout releases\n git mtheirs RELEASE-TAG\n git checkout debian\n git merge releases \n\n note that you can always got from a. to more complicated b.\n\n2. debian branch carries only debian/ directory\n\n well -- there is a lot of \"debian packaging\" projects which use this strategy,\n and usually they are still under SVN... here might be an example on how it would look\n\n http://anonscm.debian.org/gitweb/?p=pkg-exppsy/python-traits4.git\n\n but probably it is not the convenient one for your case.\n\n-- \nYaroslav O. Halchenko, Ph.D.\nhttp://neuro.debian.net http://www.pymvpa.org http://www.fail2ban.org\nSenior Research Associate,     Psychological and Brain Sciences Dept.\nDartmouth College, 419 Moore Hall, Hinman Box 6207, Hanover, NH 03755\nPhone: +1 (603) 646-9834                       Fax: +1 (603) 646-1419\nWWW:   http://www.linkedin.com/in/yarik","Just a quick note, the correct way to add the kernel params \"cgroup_enable=memory swapaccount=1\" would be to edit the /etc/default/grub:\r\n\r\nGRUB_CMDLINE_LINUX=\"cgroup_enable=memory swapaccount=1\"\r\n\r\nThis way it get's added to all the kernels when the grub.cfg file is regenerated. It's not a good practice to edit grub.cfg file directly seeing as it's a generated file.","Thank you for the note @denibertovic. I am not convinced this is a good idea. Modifying system files is a big deal and we might be even breaking packaging guidelines in doing so. FWIW, our documentation already addresses the issue:  http://docs.docker.io/en/latest/installation/kernel. ","@mzdaniel I was merely referring to the comment in this pull request that suggested modifying the grub.cfg file directly. I did not mean to imply that this should be done in the packaging.\r\n\r\nThanks for the link to the docs as i was not aware that the correct way to modify kernel parameters was already outlined there.","Thank you for sharing all this wealth of information, Yaroslav. I've got \nto admit I was a little confused about so many different ways to go \nabout packaging, until you mention git-buildpackage and I saw you are \nusing it on https://github.com/PyMVPA/PyMVPA . Thank you so much for \npointing that out!\nThe other side of packaging docker has been understanding how to do \nproper packaging of go libraries. Michael Stapelberg has done an amazing \njob in this area and together we currently reviewing the first docker \nlibrary dependency for an unstable release:\nhttp://mentors.debian.net/package/golang-mux-dev\nhttp://anonscm.debian.org/gitweb/?p=collab-maint/golang-mux-dev.git;a=summary\nSo, it looks that now we are on firm track to release docker in a no \ndistant moment.\n\n\nOn 06/17/2013 11:45 AM, Yaroslav Halchenko wrote:\n\n\u003e\u003e\u003e FWIW -- just to share alternative ways -- it is common to go with\n\u003e\u003e\u003e branches, i.e. I keep debian branch which adds  debian/ directory with\n\u003e\u003e\u003e packaging on top of \"master\"/releases content.  That has pros and cons too\n\u003e\n\u003e\u003e\u003e - pros: anyone could debcheckout (branch could be specified in vcs-git)\n\u003e\u003e\u003e    and adjust packaging, build package right away\n\u003e\n\u003e\u003e\u003e    it becomes clearer what was the released into Debian-land state of\n\u003e\u003e\u003e    things (by last merge from master)\n\u003e\n\u003e\u003e\u003e - cons:  if releases come from release branches (and not from a single\n\u003e\u003e\u003e    branch like master, or \"releases\") then merging into 'debian' branch\n\u003e\u003e\u003e    could be tricky and requires some trickery (I usually create\n\u003e\u003e\u003e    \"releases\" branch which \"merge theirs\"  releases to be packaged)...\n\u003e\n\u003e\u003e\u003e alternative resolution here could also be to have 'debian' branch as an\n\u003e\u003e\u003e overlay -- containing just debian/ directory, and then use\n\u003e\u003e\u003e git-buildpackage with overlay option (and specify that in\n\u003e\u003e\u003e debian/gbp.conf).  That one would happily overlay it on top of any\n\u003e\u003e\u003e given branch/tarball and everyone would be happy... cons -- working with\n\u003e\u003e\u003e such detached branch might be trickier too\n\u003e\n\u003e\u003e\u003e just my .1c whatever they are worth\n\u003e\n\u003e\u003e Thank you Yaroslav for sharing! I am curious to explore these\n\u003e\u003e alternatives. Could you point us to a few projects to see these in\n\u003e\u003e action?\n\u003e\n\u003e btw - 1 more point why eventually you would need to branch anyways.\n\u003e E.g. if some version in Debian stable would need to be fixed -- so you\n\u003e would need to get back to that point and branch off\n\u003e\n\u003e 1. debian (or alike) branch with merges of the main code branch\n\u003e\n\u003e   a. where all releases come from 'master' branch so merging into\n\u003e    debian branch becomes easy -- examples are numerous, but let me point\n\u003e    to our own project:\n\u003e\n\u003e    https://github.com/PyMVPA/PyMVPA/tree/dist/debian/proper/sid\n\u003e\n\u003e    so here we named branch not simply \"debian\" but rather\n\u003e    \"dist/debian/proper/sid\", since we might also need to upload bug fix\n\u003e    package releases to debian stable, and then it would become\n\u003e    \"dist/debian/proper/wheezy\".\n\u003e\n\u003e    'proper' was there because we thought we might need a special branch\n\u003e    for neurodebian repository backports (http://neuro.debian.net/) but\n\u003e    that never got to be the case (we ship patches for backporting within\n\u003e    the same dist/debian/proper/sid   under debian/patches)\n\u003e\n\u003e   b. if releases come from \"release branches\", so merging into \"debian\"\n\u003e   branch becomes tricky, I created 'releases' branch for  sklearn\n\u003e\n\u003e   http://github.com/yarikoptic/scikit-learn\n\u003e\n\u003e   for merges into \"releases\" branch I use following git alias\n\u003e\n\u003e      # To overcome absence of \"ours\" strategy in git merge\n\u003e      mtheirs = !sh -c 'git merge -s ours --no-commit $1\u0026\u0026  git read-tree -m -u \"$1\"' -\n\u003e\n\u003e   so I do smth like\n\u003e\n\u003e   git checkout releases\n\u003e   git mtheirs RELEASE-TAG\n\u003e   git checkout debian\n\u003e   git merge releases\n\u003e\n\u003e   note that you can always got from a. to more complicated b.\n\u003e\n\u003e 2. debian branch carries only debian/ directory\n\u003e\n\u003e   well -- there is a lot of \"debian packaging\" projects which use this strategy,\n\u003e   and usually they are still under SVN... here might be an example on how it would look\n\u003e\n\u003e   http://anonscm.debian.org/gitweb/?p=pkg-exppsy/python-traits4.git\n\u003e\n\u003e   but probably it is not the convenient one for your case.\n\u003e","\nOn Tue, 09 Jul 2013, Daniel Mizyrycki wrote:\n\n\u003e Thank you for sharing all this wealth of information, Yaroslav. I've\n\u003e got to admit I was a little confused about so many different ways to\n\u003e go about packaging, until you mention git-buildpackage and I saw you\n\u003e are using it on https://github.com/PyMVPA/PyMVPA .\n\nSorry for being confusing -- but that is the realm of things in Debian: Debian\npolicy clearly specifies only the state of binary and source packages, but\ninternal \"housekeeping\" is up for the developers/teams to decide.  And having\nthousands of people working on Debian, and coming from different fields,\nuse-cases and work patterns, different people/teams have different approaches\non how to organize their package maintenance. Tools such as git-build-package\nhelp to standardize flows while allowing for so demanded flexibility (e.g. I\nuse overlay setups for some projects but not the others etc)\n\n\u003e  Thank you so much\n\u003e for pointing that out!\n\u003e The other side of packaging docker has been understanding how to do\n\u003e proper packaging of go libraries. Michael Stapelberg has done an\n\u003e amazing job in this area and together we currently reviewing the\n\u003e first docker library dependency for an unstable release:\n\u003e http://mentors.debian.net/package/golang-mux-dev\n\u003e http://anonscm.debian.org/gitweb/?p=collab-maint/golang-mux-dev.git;a=summary\n\u003e So, it looks that now we are on firm track to release docker in a no\n\u003e distant moment.\n\nThat all sounds great, thank you Daniel for the follow up!  I am glad I\ncould have been of help, and yes -- I do use git-buildpackage quite\nextensively.  While we are at it I might recommend also some\ngeneric customizations I use\n\n$\u003e cat ~/.gbp.conf \n[git-buildpackage]\nsign-tags = True\n# use this for more svn-buildpackage like bahaviour:\nexport-dir = ../build-area/\ntarball-dir = ../tarballs/\n\nso -- git-buildpackage always builds for me in a clean checkout under export-dir.\nand signing the tags is also quite neat\n\nCheers!\n\n-- \nYaroslav O. Halchenko, Ph.D.\nhttp://neuro.debian.net http://www.pymvpa.org http://www.fail2ban.org\nSenior Research Associate,     Psychological and Brain Sciences Dept.\nDartmouth College, 419 Moore Hall, Hinman Box 6207, Hanover, NH 03755\nPhone: +1 (603) 646-9834                       Fax: +1 (603) 646-1419\nWWW:   http://www.linkedin.com/in/yarik","More progress towards debian lxc-docker package:\r\n\r\nPromoted to debian new queue:\r\nhttp://ftp-master.debian.org/new/golang-pty-dev_0.0~git20130701-1.html\r\nhttp://ftp-master.debian.org/new/golang-mux-dev_0.0~git20130701-1.html\r\n\r\nIn current review by our debian sponsors:\r\nhttp://anonscm.debian.org/gitweb/?p=collab-maint/golang-context-dev.git\r\nhttp://anonscm.debian.org/gitweb/?p=collab-maint/lxc-docker.git\r\n","Great news Daniel! Don't forget to move the debian stuff to github.com/dotcloud/docker-debian so we can refactor upstream.\r\n​\r\nThanks \r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sat, Jul 27, 2013 at 9:02 PM, Daniel Mizyrycki\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e More progress towards debian lxc-docker package:\r\n\u003e Promoted to debian new queue:\r\n\u003e http://ftp-master.debian.org/new/golang-pty-dev_0.0~git20130701-1.html\r\n\u003e http://ftp-master.debian.org/new/golang-mux-dev_0.0~git20130701-1.html\r\n\u003e In current review by our debian sponsors:\r\n\u003e http://anonscm.debian.org/gitweb/?p=collab-maint/golang-context-dev.git\r\n\u003e http://anonscm.debian.org/gitweb/?p=collab-maint/lxc-docker.git\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/251#issuecomment-21676854","Most pieces are in place now. github.com/dotcloud/docker-debian has been created, and golang-mux-dev and golang-pty-dev are now official part of the Debian repository on sid.\r\nHere is a rough list of commands to build lxc-docker package assuming a sid system with the dependencies listed in debian/control plus git-buildpackage.\r\n\r\ngit clone https://github.com/dotcloud/docker-debian.git -b draft-master\r\n( cd docker-debian; git-buildpackage --git-arch=all --git-pristine-tar-commit --git-ignore-branch )\r\n\r\n","As update: the last dependency, golang-context-dev is now in the Debian repo. http://packages.debian.org/search?keywords=golang-context-dev\r\nThe Docker Debian package has been updated to 0.5.3 on both http://anonscm.debian.org/gitweb/?p=collab-maint/lxc-docker.git and https://github.com/dotcloud/docker-debian\r\n\r\nThe last piece of the puzzle is to add the ability to compile docker go code in the Debian builders without needing root. This might require changes in the Debian golang package.\r\n","@mzdaniel in case it's related to having write access to GOROOT (/usr/lib/go) for the go test / go install, Gentoo has a similar issue and I'm solving it with a temporary copy of GOROOT and then changing the GOROOT environment variable to the temporary copy during compile so we can make sure our docker binary is completely static, in case a similar approach might work here (currently being discussed on [#1847](https://github.com/dotcloud/docker/pull/1847#discussion_r6353768)).\r\n\r\nIf it's not really related, my apologies.","What's the status of this issue now? git-buildpackage from https://github.com/dotcloud/docker-debian.git (master branch) failed for me with the error \"fatal: Not a valid object name upstream/0.5.3+ds1\" - is anonscm now the canonical place to build this deb from?","If there's a mirror on non-Debian services, there should be code to keep it\r\nin sync with the Debian services.\r\n\r\nBe aware there's a DFSG repack, so please use uscan to download the tarball\r\n\r\n\r\nOn Fri, Nov 1, 2013 at 11:38 AM, Tim Pierce \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e What's the status of this issue now? git-buildpackage from\r\n\u003e https://github.com/dotcloud/docker-debian.git (master branch) failed for\r\n\u003e me with the error \"fatal: Not a valid object name upstream/0.5.3+ds1\" - is\r\n\u003e anonscm now the canonical place to build this deb from?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/251#issuecomment-27574518\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\n:wq","ping @mzdaniel Don't we have a deb package now?","This is unnecessary if you can name containers. Because you can use\r\nconvention of name instead of hook. Naming containers helps with a number\r\nof other issues too. This would be a cleaner/simpler solution than hooks\r\n(as much as I like them).\r\n\r\n\r\nOn Thu, Mar 28, 2013 at 10:29 PM, Pavel Nuzhdin \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Container id should be accessible inside hook ofcourse.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/252\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","It's only necessary if you are *required* to name containers. Which I'm not\r\nsure we want.\r\n\r\nOn Thursday, March 28, 2013, Jeff Lindsay wrote:\r\n\r\n\u003e This is unnecessary if you can name containers. Because you can use\r\n\u003e convention of name instead of hook. Naming containers helps with a number\r\n\u003e of other issues too. This would be a cleaner/simpler solution than hooks\r\n\u003e (as much as I like them).\r\n\u003e\r\n\u003e\r\n\u003e On Thu, Mar 28, 2013 at 10:29 PM, Pavel Nuzhdin \u003cnotifications@github.com\u003cjavascript:_e({}, 'cvml', 'notifications@github.com');\u003e\u003ewrote:\r\n\u003e\r\n\u003e\r\n\u003e \u003e Container id should be accessible inside hook ofcourse.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/252\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e\r\n\u003e\r\n\u003e --\r\n\u003e Jeff Lindsay\r\n\u003e http://progrium.com\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/252#issuecomment-15629594\u003e\r\n\u003e .\r\n\u003e","Nope, I can run image multiple times anonymously and doesn't want to name containers","But it's easier to randomly generate a throwaway name than to script a hook\r\nhandler just to get an ID, right? Unless I'm mistaken what the experience\r\nwould be like for having a hook.\r\n\r\n\r\nOn Thu, Mar 28, 2013 at 10:53 PM, Pavel Nuzhdin \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Nope, I can run image multiple times anonymously and doesn't want to name\r\n\u003e it\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/252#issuecomment-15629773\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","ambiguously","At the very least if you were to provide a script for the hook and this was\r\npart of some automation or script, you'd have to have 2 scripts for the\r\nautomation, or at least 2 entry points for a single script. It's the\r\ndifference between callbacks (node.js) and green threads (Go): callback\r\ncomplexity vs inline simplicity.\r\n\r\nNames would be optional, just like a hook would be optional. I'm saying,\r\nuse optional names when you'd need a hook. We went through this exact issue\r\nwith localtunnel (getting a tunnel name via hook vs just providing a name\r\n-- the latter solved the problem of the former and was much easier to use\r\nand implement, but was also desired regardless)\r\n\r\n\r\nOn Thu, Mar 28, 2013 at 11:06 PM, Pavel Nuzhdin \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e ambiguously\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/252#issuecomment-15629980\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","The 1.0 api will allow a post-hook for any command","Sorry, I built this package with `make rpm` in the kernel source tree. What is the appropriate way to build a kernel RPM package then?","No, technically that is a correct way to build an RPM. However that's the problem, it's \"just\" an RPM. It doesn't account for package managers, dependencies or file collisions.\r\n\r\nOverall, this needs to be scripted in a .spec file properly like the EL6 Kernel, that way we can garuntee that it'll build and remain consistent to the EL6 \"way of life\".\r\n\r\nI'm more than happy to write the required spec file, where is the Kernel source? \r\n\r\nWhen I'm done you can just fork it out of my GH, or I can commit it to a repo of your choosing or email it. It doesn't really matter to me.\r\n\r\nAlso, if you're happy with the condition of the package(s) that I build, I'm more than happy to officially maintain some EL6 packaging for you. I have quite a bit of experience maintaining EL5/6 clones and doing continuous integration with them using Koji. Though, admittedly, it's not too difficult once you build the first SRPM, it becomes more or less an SOP you follow.","Sending kernel-build and kernel-version issues to @jpetazzo for coordination.","I maintain our kernels with a quilt patch queue, and some extra semi-manual operations (can't automate everything, especially the occasional conflict resolution between grsec and aufs).\r\n\r\nThe process involves:\r\n- retrieving matching versions of upstream, grsec, aufs, and setns patches\r\n- running a few quilt commands to turn those into quilt patches\r\n- resolving conflicts (sometimes everything applies correctly, sometimes you have to fix up things)\r\n- configure kernel (start with distro's config, and apply relevant changes for GRSEC and AUFS)\r\n- build.\r\n\r\nDo you want an export of the quilt patch queue used against 3.2.40?\r\nOr a full tarball of the patched source tree?\r\nOr should I start the process over with the latest EL6 kernel (which might not work at all if it's 2.6.32)?\r\n","Let's start out with a full tarball, let me get that rolled up properly into both an SRPM and RPM -- then we can talk about automating the build from quilt. \r\n\r\nLet's start with baby steps, I'm willing to get this all packaged up nice and neat, but I don't want to overwhelm either :clock1: ","Quick summary of our IRC conversation: I handed to you the tarball of our 3.2.40 kernel :-)","Yup, got some progress done on it yesterday. A lot of it is hardcoded still to that specific version, I'm starting the scripting portion of the spec tonight sometime after dinner. \r\n\r\nOnce it's all scripted, then I just have to split up the packages properly into the following:\r\nkernel, debug, headers, firmware, devel \r\n\r\nThen in order to keep this RPM truely compatible I need to tackle getting these built from your sources:\r\nkmod-bnx2.x86_64 : bnx2 kernel module(s)\r\nkmod-bnx2-firmware.x86_64 : bnx2 kernel module firmware\r\nkmod-bnx2fc.x86_64 : bnx2fc kernel module(s)\r\nkmod-bnx2i.x86_64 : bnx2i kernel module(s)\r\nkmod-bnx2x.x86_64 : bnx2x kernel module(s)\r\nkmod-bnx2x-firmware.x86_64 : bnx2x kernel module firmware\r\nkmod-cnic.x86_64 : cnic kernel module(s)\r\nkmod-hpwdt.x86_64 : hpwdt kernel module(s)\r\nkmod-igb.x86_64 : igb kernel module(s)\r\nkmod-ixgbe.x86_64 : ixgbe kernel module(s)\r\nkmod-mlx4_core.x86_64 : mlx4_core kernel module(s)\r\nkmod-mlx4_en.x86_64 : mlx4_en kernel module(s)\r\nkmod-mlx4_ib.x86_64 : mlx4_ib kernel module(s)\r\nkmod-pch_gbe.x86_64 : pch_gbe kernel module(s)\r\nkmod-snd-hda.x86_64 : snd-hda kernel module(s)\r\nkmod-snd_core.x86_64 : snd_core kernel module(s)\r\nkmod-snd_hda.x86_64 : snd_hda kernel module(s)\r\nkmod-tg3.x86_64 : tg3 kernel module(s)\r\n\r\nOnce that's done we'll more or less have a perfect EL6 compatible Kernel.\r\n\r\nI'll then make a docker-kernel-compat RPM which will optionally supersede the exsiting kernel* rpm's with the docker-kernel* rpms. \r\n\r\nAnywho, pizza is here. Progress has been made!","I would like to see the aufs2 patches applied to actual EL6 kernel sources.  While we could package up the 3.2.40 kernel that @jpetazzo has provided it kind of defeats the point of leveraging RHEL, and probably CentOS or SL, in the first place.  Granted in either solution the kernel will not be supported by Red Hat.\r\n\r\nUltimately, I don't think there will be a viable solution for docker on RHEL or clones until EL7 is available.\r\n\r\nJust my 2 cents.","@shawnsi, do you know what's the status of btrfs on EL6 kernels?\r\nSince we're working on ntrfs support (see #443) it *might* be a viable alternative.\r\n[RHEL6 docs](https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/ch-btrfs.html) say that it's \"not a production quality\" but that it is in \"tech preview stage\", but I don't know if that means \"mostly usable, at least until EL7 is out\" or \"mostly broken and will eat your data for breakfast\".","Here is a Red Hat provided definition of Technology Preview...\r\n\r\n\u003e Technology Preview features are currently unsupported, may not be functionally complete, and are not \u003e suitable for deployment in production. However, these features are provided to the customer as a\r\n\u003e courtesy and the primary goal is for the feature to gain wider exposure with the goal of full support in \r\n\u003e the future.\"\r\n\r\nIn practice I interpret this as at least as stable as Fedora and, as stated, no support provided.  I don't use btrfs in RHEL though so I can't speak to stability otherwise.","Just noticing that we have another issue already tracking this - #172; so I'm closing this one as it is a duplicate.","To slightly elaborate on the question, the answer would serve two purposes:\r\n\r\n1. better describe what it does for the prospective users\r\n1. describe what is expected to be implemented (so it could be used as a reference point for contributors)","+1","+1","cc @metalivedev @kencochrane anybody want to take this on?","@shykes I don't know everything that is done off the top of my head, I would need to do some digging to figure it out. If someone could give me the high level overview, I can write it up and make it easier to read.","ping @creack \r\n\r\nI think you have some good slides for this issue. ","ping @SvenDowideit ","@SvenDowideit @crosbymichael @kencochrane @shykes I can write this up, but I need an SME who knows the content to work with me. Can you suggest someone?","me","I think it depends how deep you want to go, i think I have a rough draft somewhere on how libcontainer works and what has to happen to create a container. i'll try to find it","Okay, Michael and I are working on this and I should have something written by next week.","@fredlf not sure if this is covered by this issue, but some things I was thinking about the other day that might need some explanation;\r\n\r\n- Where are images, volumes and containers stored\r\n- Some general description of the docker directories and their purpose\r\n- How do I uninstall / perform a fresh install?","@thaJeztah Aw, crud. I let this slip off my radar. I have a nice write up from @crosbymichael that I need put in. Sorry about that. I'll get it done and we'll see if it addresses your concerns.","@fredlf no worries, I'll manage :). Just came by this issue and thought of some thing that (I think) weren't covered in the manual","@fredlf Did this ever happen?","@cpuguy83 No, sorry, I never finished it. It's on my backlog. We finally hired some help, so maybe I'll be able to move forward on some of these side-project sorts of things.","we came over some unclear phrasing about volumes in context with the `run`-command (or rather the `RUN`-directive) in [a discussion](https://github.com/samos123/docker-drupal/issues/10), to quote myself:\r\n\r\n\u003e actually, referring to [this documentation](https://docs.docker.com/reference/builder/#volume) the behaviour you describe (the empty `…/all/modules`-folder in your `Dockerfile`), which i can reproduce,  would rather be a bug:\r\n\r\n\u003e\u003e The docker run command initializes the newly created volume with any data that exists at the specified location within the base image. (...) This Dockerfile results in an image that causes docker run, to create a new mount point at /myvol and copy the greating file into the newly created volume.\r\n\r\n\u003e As the `run`-command wasn't invoked at the time of the build, there wouldn't be any volume intialized. and when this will happen, the content at the mount-point of the image will be copied into the volume. or am i getting something very wrong here?\r\n\r\nas a response to [this case](https://gist.github.com/cerisier/b14c0f79d0a6ba2332dc).\r\n\r\nso, i'd have these questions to be clarified:\r\n1. does a `RUN`-directive in a `Dockerfile` do the same as a `docker run`?\r\n2. if so, why would it be useful that it initializes volumes in the same way?\r\n\r\nor is it a bug we stumbled over here?","@funkyfuture \r\n1) Yes, `docker run` and `RUN` in a Dockerfile are equivelent.\r\n2) It's not useful and there have been a few attempts to resolve this, none of which have been particularly acceptable.","@cpuguy83 thanks, can you hint me to an issue or PR regarding 2) to follow?","Thanks - I didn't know about this race detector. Is there a way go add it to the test suite?\r\n","Just run the testsuite with go test -race\r\n\r\n\r\nOn Fri, Mar 29, 2013 at 9:50 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Thanks - I didn't know about this race detector. Is there a way go add it\r\n\u003e to the test suite?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/255#issuecomment-15660040\u003e\r\n\u003e .\r\n\u003e","(on go tip)","On Fri, Mar 29, 2013 at 10:06 PM, Jonathan Rudenberg\n\u003cnotifications@github.com\u003e wrote:\n\u003e (on go tip)\nAh, right. Also, it will be in Go1.1","Thanks Robert. I added a FIXME to add a timeout to your test, to avoid blocking the whole test suite when it fails. I merged anyway, but if you have time to add that it would be great.\r\n\r\nYou can do this by:\r\n\r\n 1) creating a timeout channel with time.After(3 * time.Second)\r\n 2) creating a success channel to signal test completion\r\n 3) select on both channels\r\n\r\nThanks again.\r\n","This is probably related to Issue #109.","The issue occurs only in stand alone mode.\r\n\r\nWhen doing 'start', as docker will not wait for the process to finish and leave, the process is nerver marked as 'stopped'.\r\n\r\nWe need a better check of the status of containers when docker starts. Will do that now :)\r\n\r\nIt might also be nice to add a 'wait' option to docker start? or to be aware that we are in standalone mode.\r\n@shykes  any thoughts?","I fixed the issue by adding a better check of the running state in runtime.restore().\r\nI still need to add unit tests and I'll push","Thanks!","Why is the README duplicated?","Hi titanous. It's great having you onboard!  This pull request is meant to reflect how the original PPA was created on launch date and cleanup some of the rush at that time. Originally, the README was a symlink to master. If we keep the symlink, this pull won't make much sense. In the future, we should reference the *master* commit id to make the context crystal clear.","I'm not an expert in Ubuntu packaging. @mzdaniel, are you saying the packaging/ubuntu does not define how to build an ubuntu package from the current revision, but rather describes which revision is currently published as a PPA? If that's the case, what happens when I build the package from a current checkout? Will it also use the code from that old revision? Or will it combine an old README with a new revision of the code?\r\n","All I'm saying is that we took some shortcuts to meet launch release. One of them was not having a proper structure to support packaging. Each distro is going to have their particular ways to do things, so we are creating the packaging subdirectory to accommodate them and putting the original Ubuntu files on their place to build over them. This pull request is just an intermediate step to achieve a cleaner foundation for release 0.2.0 and preserve the original content.","As discussed with @mzdaniel, I have 2 requests:\r\n\r\n1) remove duplicate README\r\n2) add a reference doc for how to build \u0026 release a package\r\n\r\nThen we should be good to go.\r\n\r\nThanks!","The goal is to have a streamlined packaging process for 0.2.0, which I would like to release early next week.","@shykes, done. Clarified pull request title and an extra changeset with your requests. I propose to fix ubuntu packaging on the branch 30-packaging-ubuntu","Done for now. Debian is in itself a social network and fundamentally a volunteer organization. Paul Tagliamonte has gratefully volunteer to sponsor the first release of the docker package. I will keep updating the maintainer document with what I learn through the process of becoming a Debian maintainer.","Thanks Daniel! Will review for merge as soon as I'm back on a keyboard.\r\n\r\nThanks Paul for your support!\r\n\r\nOn Thursday, April 11, 2013, Daniel Mizyrycki wrote:\r\n\r\n\u003e Done for now. Debian is in itself a social network and fundamentally a\r\n\u003e volunteer organization. Paul Tagliamonte has gratefully volunteer to\r\n\u003e sponsor the first release of the docker package. I will keep updating the\r\n\u003e maintainer document with what I learn through the process of becoming a\r\n\u003e Debian maintainer.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/259#issuecomment-16274611\u003e\r\n\u003e .\r\n\u003e","Just found some regressions, needs more test..","Everything should be working just fine now :)","So far I think this should be split in the following pull requests:\r\n\r\n* Various formatting and code style changes: fmt.Errorf(), debug messages, removed unused variables, missing error checking, harmonize use of defer(), etc.\r\n\r\n* Improve tests\r\n\r\n* Remove -i -e -o flags from CmdAttach\r\n\r\n* Refactor CmdRun to call CmdAttach\r\n\r\n* Refactor container.Wait() to no longer require mutexes\r\n\r\n* Actually fix pty leak ( #228)\r\n\r\n* Actually fix stop+attach stdin in tty mode (#125)\r\n\r\n* Actually fix stop+attach stdout (#108)\r\n","Maybe stop could take an optional argument, the seconds to wait.\r\nWhat do you think ?","Any comments on this pull request? @shykes ",":+1: ",":+1: ","In the line: \"Save your containers state to a container image\" it might be better to say \"your containers filesystem\" than \"your containers state\" since state could be understood to include the running processes memory as well.","Thanks",":+1:","Discarded commit. It introduces regressions. We need more unit tests :)\r\n\r\n@cespare your changes breaks the ./docker login command. My guess is that the strings.NewBuffer was not useless.\r\n\r\nI'll take a look later on, but feel free to check and fix :)\r\n\r\nAnd sorry about this, but can you do a new pull request?","Sure, I'll take a look.\r\n\r\nNot sure exactly what you did to this PR :\\ I'll open a new one.","By the way, isn't semantics of a Close() strange? I would expect Close() to close a writer irrevocably, and not just reset everything.","@robryk I agree, it seems like subsequent writes should fail with an error after it's been closed.","I'll submit a similar list-removal for runtime.containers soon. Do you prefer slightly unrelated commits on the same part of code in one or many pull requests? Oh, and the Close() change is done.","@robryk Put it in a separate pull request. Also, please squash the two commits you made earlier into their logical parent commits.","Squashing done.","I agree the semantics of Close are not intuitive. Also, they are different\r\nfor Container.stdout/stderr (broadcastwriter behavior) and  Container.stdin\r\n(io.Pipe behavior).\r\n\r\n@creack has a branch cleaning up this part, if you keep digging watch out\r\nfor conflicts.\r\n\r\nThanks guys!\r\n\r\nOn Saturday, March 30, 2013, robryk wrote:\r\n\r\n\u003e Squashing done.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/271#issuecomment-15675981\u003e\r\n\u003e .\r\n\u003e","@robryk thanks! Much better with locks now :) And with maps too!.\r\n\r\nHowever, on the Close thingy, it introduces a regressions: the broadcaster is local to the container and not to the process. And when a process dies, the broadcaster is closed. So when we restart the process, the addWriter will fail.\r\nMaybe we could simply rename the .Close() into .Reset() or something? Or we could make the broadcaster local to a process. @shykes any thoughts?\r\n","I prefer keeping broadcaster local to the container. That way we have the option to either disconnect listeners at process death, at container destruction, or a combination of the 2. If we make it local to the process, we lose that flexibility.","Quick ping. @robryk would you like to finish this, or should we take it over as-is?\r\n\r\nThanks","I think it's done now.","Does it make sense to prioritize reusing addresses over allocating new ones?","\u003e Does it make sense to prioritize reusing addresses over allocating new ones?\r\n\r\nAbsolutely, yes.","Actually, no. It is better to allocate new addressed before using new ones.\r\nThis drastically decreases the frequency at which an IP is reused. In\r\ntheory this should not matter, but in a large distributed system it greatly\r\nreduces the probability and gravity of sending traffic to the wrong\r\ncontainer.\r\n\r\nThis friendly tip brought to you courtesy of the dotCloud ops team /cc\r\n@samalba @jpetazzo @kencochrane @chooper @shin-\r\n\r\n\r\nOn Sat, Mar 30, 2013 at 4:07 PM, Dominik Honnef \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Does it make sense to prioritize reusing addresses over allocating new\r\n\u003e ones?\r\n\u003e\r\n\u003e Absolutely, yes.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/272#issuecomment-15683545\u003e\r\n\u003e .\r\n\u003e","@shykes Cool, I wasn't sure if that was the case. :pencil:","If you allocate new addresses, however, you will slowly fill up the list of released IPs. In the case of an /8 network (see original issue), you will face continuously growing memory consumption for every VM you ran.\r\n\r\nI do acknowledge the problem of reusing IPs, but not reusing them at all but yet storing them (which this PR does), is not acceptable either. \r\n\r\nOptions I can think of (not ops-approved, however) are starting to use old IPs once the list reaches a certain size, using them at random, or implementing a compact way of storing reusable IPs.","Here's what I have in mind:\r\n\r\n- Generator goes over address space mathematically (no storage consumption)\r\n- When generator reaches end of available space, it wraps back to beginning\r\n- All *allocated* IPs are stored in a map. Generator checks the map before\r\nallocating. If the IP is in the map, the generator skips it\r\n\r\nThis way you only store as many IPs as you have allocated, regardless of\r\ntotal available address space.\r\n\r\nAnd we have to implement this map anyway for the \"real port\" feature.\r\n\r\n\r\n\r\n\r\nOn Sat, Mar 30, 2013 at 4:46 PM, Dominik Honnef \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e If you allocate new addresses, however, you will slowly fill up the list\r\n\u003e of released IPs. In the case of an /8 network (see original issue), you\r\n\u003e will face continuously growing memory consumption for every VM you ran.\r\n\u003e\r\n\u003e I do acknowledge the problem of reusing IPs, but not reusing them at all\r\n\u003e but yet storing them (which this PR does), is not acceptable either.\r\n\u003e\r\n\u003e Options I can think of (not ops-approved, however) are starting to use old\r\n\u003e IPs once the list reaches a certain size, using them at random, or\r\n\u003e implementing a compact way of storing reusable IPs.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/272#issuecomment-15683970\u003e\r\n\u003e .\r\n\u003e","That sounds reasonable. \r\n\r\nSince you're referring to a \"real port feature\" that I'm not aware of I'll hold off implementing this since I don't know what kind of information you want in the map, or where the map is supposed to be managed.","See issue #273 for details. I'm thinking a simple map[int]struct{} would be\r\nsufficient - we would use it as a set of currently allocated ports.\r\n\r\n\r\nOn Sat, Mar 30, 2013 at 4:59 PM, Dominik Honnef \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e That sounds reasonable.\r\n\u003e\r\n\u003e Since you're referring to a \"real port feature\" that I'm not aware of I'll\r\n\u003e hold off implementing this since I don't know what kind of information you\r\n\u003e want in the map, or where the map is supposed to be managed.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/272#issuecomment-15684110\u003e\r\n\u003e .\r\n\u003e","The same goroutine which allocates IPs should probably also own access to\r\nthe map to avoid conflicts. Probably via 2 channels: one to allocate IPs,\r\none to release them, and a select on the 2.\r\n\r\n\r\nOn Sat, Mar 30, 2013 at 5:04 PM, Solomon Hykes\r\n\u003csolomon.hykes@dotcloud.com\u003ewrote:\r\n\r\n\u003e See issue #273 for details. I'm thinking a simple map[int]struct{} would\r\n\u003e be sufficient - we would use it as a set of currently allocated ports.\r\n\u003e\r\n\u003e\r\n\u003e On Sat, Mar 30, 2013 at 4:59 PM, Dominik Honnef \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e\u003e That sounds reasonable.\r\n\u003e\u003e\r\n\u003e\u003e Since you're referring to a \"real port feature\" that I'm not aware of\r\n\u003e\u003e I'll hold off implementing this since I don't know what kind of information\r\n\u003e\u003e you want in the map, or where the map is supposed to be managed.\r\n\u003e\u003e\r\n\u003e\u003e —\r\n\u003e\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/272#issuecomment-15684110\u003e\r\n\u003e\u003e .\r\n\u003e\u003e\r\n\u003e\r\n\u003e","This should work as you intended. ","There should be some tests that cover the allocation strategy.","Done. I'm still not entirely sure about #273, but I'm sure someone else can make changes to the IP allocator as needed, based on this.","Thanks @dominikh. Reviewing.","Fwiw, you might want to consider renaming the populate method. I don't think it's quite fitting anymore, considering what it's doing now.","@dominikh Please squash your commits before @shykes merges.","@titanous Will do once he approves of the changes. \r\n\r\nI suppose I'll just force push the feature branch and GitHub will do the right thing?","@dominikh Yep, the pull request will update when you force-push.","I agree, populate is no longer adequate. I guess Allocate() would work\r\nbetter?\r\n\r\n\r\nOn Sun, Mar 31, 2013 at 12:08 PM, Dominik Honnef\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Fwiw, you might want to consider renaming the populate method. I don't\r\n\u003e think it's quite fitting anymore, considering what it's doing now.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/272#issuecomment-15696221\u003e\r\n\u003e .\r\n\u003e","@dominikh sorry I need to go afk for a few more hours, but so far this looks like really good work. Thanks again.","I was thinking of something like `Start()` maybe, but then there'd be the lack of a `Stop()`. Possibly `Run()`","Or rather unexported versions of those. `newIPAllocator` should probably still be the only one calling it.","Agreed\r\n\r\nOn Sunday, March 31, 2013, Dominik Honnef wrote:\r\n\r\n\u003e Or rather unexported versions of those. newIPAllocator should probably\r\n\u003e still be the only one calling it.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/272#issuecomment-15697293\u003e\r\n\u003e .\r\n\u003e","Looks good! Let me know when you're ready for me to merge.","Are you sure that we want to close this issue? It looks like #272 only addresses IP allocation and doesn't touch port allocation, or was I misled?","I just implemented it in 2aad4a34785a1b0d02d910a14dbb9b0d6d3edc17  :)\r\n\r\n\r\nOn Fri, Apr 5, 2013 at 2:38 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Are you sure that we want to close this issue? It looks like #272\u003chttps://github.com/dotcloud/docker/issues/272\u003eonly addresses IP allocation and doesn't touch port allocation, or was I\r\n\u003e misled?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/273#issuecomment-15982239\u003e\r\n\u003e .\r\n\u003e","\"Toutes mes confuses\" :-)\r\nOkay, great! Re-closing, then. Sorry!","Guys, this option belongs in CmdKill, not CmdStop.\r\n\r\nI recommend the following:\r\n\r\n1) Refactor container.Kill to accept an optional signal (instead of always sending SIGKILL/9).\r\n\r\n2) Refactor container.Stop to call Kill(15) then Kill(9) instead of the current exec(\"lxc-kill\", \"-n\", \"15\") and Kill().\r\n\r\n3) Expose this option in CmdKill (default should remain SIGKILL). Bonus points if you expose it unix-style: 'docker kill -15 $ID'\r\n\r\n","@shykes I have implemented what you have asked here. https://github.com/mahendra/docker/compare/signal\r\ncould you have a look? If it looks good, I will send a pull request. Still trying to figure out how to compile and test docker.","Have created a pull request for this #2416 ","solved by #234 + #329","Seems still reproduced in docker 1.5.0. How I can debug that? @styleex","Is there a use case for overriding the identity of the user (as known to the registry)?","Fixed by 4ef2d5c1e6e65b1e214071388618fc9fa4345be9","I don't know exactly what you have in mind, but in the line of image building, I happened to always repeat the same sequence of commands:\r\n\r\n    CID=$(docker run oldimage \u003csomecommand\u003e)\r\n    ... wait for completion ...\r\n    docker commit $CID newimage\r\n\r\nI wonder if this could be replaced with one single command, e.g.:\r\n\r\n    docker run -wait -commit newimage oldimage \u003csomecommand\u003e\r\n\r\nNote that `-wait` could probably be implicit when `-commit` is specified, since it doesn't make sense to commit a container just after the process has been started. ","That's basically docker build.\r\n\r\nOn Sunday, March 31, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e I don't know exactly what you have in mind, but in the line of image\r\n\u003e building, I happened to always repeat the same sequence of commands:\r\n\u003e\r\n\u003e CID=$(docker run oldimage \u003csomecommand\u003e)\r\n\u003e ... wait for completion ...\r\n\u003e docker commit $CID newimage\r\n\u003e\r\n\u003e I wonder if this could be replaced with one single command, e.g.:\r\n\u003e\r\n\u003e docker run -wait -commit newimage oldimage \u003csomecommand\u003e\r\n\u003e\r\n\u003e Note that -wait could probably be implicit when -commit is specified,\r\n\u003e since it doesn't make sense to commit a container just after the process\r\n\u003e has been started.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/278#issuecomment-15697046\u003e\r\n\u003e .\r\n\u003e","Okay, cool.","I've debated making it extra options to Run the way you describe... But\r\nthat build pattern is so fundamental that I think it deserves a top-level\r\ncommand. Also, I want to avoid the \"git effect\": 10,000 magical hidden\r\nflags that turn each command into a swiss army knife. :)\r\n\r\n\r\n\r\nOn Sunday, March 31, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e Okay, cool.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/278#issuecomment-15697545\u003e\r\n\u003e .\r\n\u003e","Since the image -\u003e run -\u003e container -\u003e image -\u003e repeat workflow is the base of build, it would be nice to be able to merge layers above a desired image into a single image.\r\n\r\nFor example, I've gone through a few steps and some large files were changed a few times, then they were completely removed by whiteout files; I'd like to merge all these changes into one image up until a specified image id.\r\nLet's say the base image has an id of 1 and we've got image with id 5 and we want to create a new image which merges everything starting with 2, but we don't want to merge the base, so that's still kept out of our layer.\r\nWe should be able to do something like: docker flatten name_of_new_image 1...5 and get a history like this: 1 new_image_id.\r\n\r\nHistory should be preserved when doing this.\r\n\r\nI believe this would be an useful feature to use together with build. It would certainly make things easier.","Closed by #472 ","Wouldn't it be better to pull it once, export it and then import it whenever it's needed?\r\n","@shykes  Seems resolved now, can we close this ?","Question: Mount binding /proc... will that be smart and only show what's available in the container's namespace?\r\n\r\nSecond, I'm worried about mount binding /dev blindly, as we promise isolation and giving access to certain resources (like /dev/mem) does exactly the opposite of that, unless namespaces do some magic when it's accessed from within an LXC container.","A few searches on the 'net did not reveal any cases where /dev/mem could safely be used if the user has root access. If a user absolutely needs /dev/mem or other dangerous resources, these resources should probably be provided disabled by default with an enable flag on the container's start.","I meant bind-mounting *empty* /proc /dev etc. Not the actual host's.\r\n\r\nThe reason for bind-mount vs just mkdir is to avoid side effects:\r\na) If the image didn't have it, we don't add it in the next commit.\r\nb)  If it did exist, we don't remove it.\r\nc) If it didn't but was created during the run, we won't remove it either.\r\n\r\nOn Sunday, March 31, 2013, Frederick F. Kautz IV wrote:\r\n\r\n\u003e A few searches on the 'net did not reveal any cases where /dev/mem could\r\n\u003e safely be used if the user has root access. If a user absolutely needs\r\n\u003e /dev/mem or other dangerous resources, these resources should probably be\r\n\u003e provided disabled by default with an enable flag on the container's start.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/280#issuecomment-15693797\u003e\r\n\u003e .\r\n\u003e","Unfortunately, this is wishful thinking, since any kind of mount (even bind mount) requires the mount point to exist:\r\n\r\n    # mkdir testmount\r\n    # cd testmount\r\n    # mkdir a\r\n    # mount -o bind a b\r\n    mount: mount point b does not exist\r\n\r\nAlso, if we move to that direction, we should also make sure that a few essential libraries do exist as well in the image, since they are mandatory to execute the \"inner docker\" (which is currently bind-mounted on `/sbin/init`).\r\n\r\nIMHO, there are two saner things to do:\r\n\r\n1. Make sure that those essential files and directories exist. If they don't, refuse to start the container (unless some `-force` flag is given).\r\n\r\n2. Use an intermediary AUFS layer, containing those files and directories. The layer would be mounted between the image and the read-write layer of the container, thus ensuring that those files and directories are present, but also making sure that we don't touch the image itself.\r\n\r\nIf you want an exhaustive list of the files and directories required to run a bare container, have a look at the contrib script used to create the busybox image; with the notable exception of the `/bin` directory, almost everything else was added because it was needed (i.e. the container would start without it).","This is now possible with the dockerinit layer.","Actually, this is not only possible but *currently implemented* with the dockerinit layer. :)","Thanks very much. This is absolutely needed as currently doing a docker pull doesnt give any information as to what is happening. Running a strace on the bsdtar process also doesnt give much information as the reads seem very slow (not sure if its my network, but will try from a different network at home).\r\n","I'm getting this as well. @chooper?","Failed for me too. I also tried AMI: ami-4e75ee27 (which is actually found) but returns:\r\n\r\nnotice: /Stage[main]/Docker/Exec[build-docker]/returns: exec gcc: exec: \"gcc\": executable file not found in $PATH\r\nerr: /Stage[main]/Docker/Exec[build-docker]/returns: change from notrun to 0 failed: /usr/local/go/bin/go get -v ./... \u0026\u0026 /usr/local/go/bin/go install ./docker returned 2 instead of one of [0] at /tmp/vagrant-puppet/modules-0/docker/manifests/init.pp:89\r\nnotice: /Stage[main]/Docker/Service[dockerd]: Dependency Exec[build-docker] has failures: true\r\nwarning: /Stage[main]/Docker/Service[dockerd]: Skipping because of failed dependencies\r\nnotice: Finished catalog run in 168.04 seconds\r\nThe following SSH command responded with a non-zero exit status.\r\nVagrant assumes that this means the command failed!\r\n\r\nThe standard Ubuntu AMI also failed.","@mzdaniel would you mind picking this up? I don't know if it's still relevant.\r\n","@shykes: not at all.\r\n@astraw, @titanous, @troyronda: Do you mind trying mainline /Vagrantfile. Would be nice to put this issue to rest.  ","This is fixed - I don't get the error as of current git master. I did need to do this:\r\n\r\n    diff --git a/Vagrantfile b/Vagrantfile\r\n    index 3d56826..6fd9714 100644\r\n    --- a/Vagrantfile\r\n    +++ b/Vagrantfile\r\n    @@ -49,6 +49,7 @@ Vagrant::VERSION \u003e= \"1.1.0\" and Vagrant.configure(\"2\") do |config|\r\n         aws.access_key_id = ENV[\"AWS_ACCESS_KEY_ID\"]\r\n         aws.secret_access_key = ENV[\"AWS_SECRET_ACCESS_KEY\"]\r\n         aws.keypair_name = ENV[\"AWS_KEYPAIR_NAME\"]\r\n    +    aws.security_groups = ENV['AWS_SECURITY_GROUPS']\r\n         override.ssh.private_key_path = ENV[\"AWS_SSH_PRIVKEY\"]\r\n         override.ssh.username = \"ubuntu\"\r\n         aws.region = AWS_REGION\r\n\r\nBut I guess that's because my default security group is different than other peoples for whatever reason. (Mine blocks all incoming connections from the outside world, so I have to use another security group that allows SSH.)","sorry, this isn't ready yet. I'll create a new pull request later.","@creack I'm going to assign to you reviews for registry client.","Thanks!","Oops - this should fix it. Thanks for the heads up!","Yep, that looks right, please squash the commits.","Oh, and add `Fixes #257` to the commit message, which will close the issue when it gets merged.","#289 ","+1, especially for reflowing the text.","FYI: you can just `git push -f` to your feature branch after rebasing and the pull request will update automatically.","LGTM. :+1: ","Actually, the check should use lxc-info. You can't be sure an other process took the same pid as a crashed lxc container.","And if a container was still running, we need to restart a monitor() on it","Agree with @creack, the check should use lxc-info. @shin- let me know when you're ready for me to re-check.","@shykes I just created #318 , based off @creack 's previous work on this. Closing this.","@unclejack would you like to contribute the recipe for your CentOS base, so we can make it official?","Yes, it's not a problem. We just need to get it working and then I can write it down as a script.","Here's a build script contributed by @unclejack:\r\n\r\n```bash\r\n#!/bin/bash\r\n\r\nMIRROR_URL=\"http://centos.netnitco.net/6.4/os/x86_64/\"\r\nMIRROR_URL_UPDATES=\"http://centos.netnitco.net/6.4/updates/x86_64/\"\r\n\r\nyum install -y febootstrap xz\r\n\r\nfebootstrap -i bash -i coreutils -i tar -i bzip2 -i gzip -i vim-minimal -i wget -i patch -i diffutils -i iproute -i yum centos centos64  $MIRROR_URL -u $MIRROR_URL_UPDATES\r\ntouch centos64/etc/resolv.conf\r\ntouch centos64/sbin/init\r\n\r\ntar --numeric-owner -Jcpf centos-64.tar.xz -C centos64 .\r\n```\r\n\r\nWe'll need someone from the registry team to build it and publish it as base:centos-6.4","@unclejack should we wait for #194 before uploading?","@shykes #194 is done, I just have to send the pull request.","Thank you so much unclejack. Your little script is awesome!","@mzdaniel You're welcome.","@unclejack let us know when you've played with creack/centos and think it's good to go. We'll promote it to base:centos","@shykes I'll prepare a set of tests for it so it can be validated.","@shykes I've used the CentOS image a bit more and I haven't encountered problems.\r\n\r\nIt could be moved to the official repo.","@unclejack just to confirm, you're talking about image id 539c0211cd76cdeaedbecf9f023ef774612e331137ce7ebe4ae1b61088e7edbe ?","@shykes Yes, that's the image I was talking about.","This image can now be pulled by running:\r\n```\r\ndocker pull centos\r\n```",":+1: \r\n\r\nNote that we can use tags to expose multiple versions. 'docker run centos' will automatically use the 'latest' tag, but you can also 'docker run centos:6.4'","Thanks for the recipe @unclejack !","@shykes You're welcome!","*Disclaimer: I’m fairly new to Linux.*\r\nHow do I change the root password on this CentOS image? I tried running\r\n\r\n    docker run -i -t centos /bin/bash\r\n    bash-4.1# passwd\r\n    bash: passwd: command not found\r\n\r\nBut it doesn’t have the `passwd` command. Is there a default root password set?","@gasi You have to install the passwd package with ```yum install passwd```. This isn't included in the image as it's not normally required.","Thanks @unclejack!\r\n\r\n\r\nOn Fri, May 31, 2013 at 3:31 PM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @gasi \u003chttps://github.com/gasi\u003e You have to install the passwd package\r\n\u003e with yum install passwd. This isn't included in the image as it's not\r\n\u003e normally required.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/290#issuecomment-18775156\u003e\r\n\u003e .\r\n\u003e","@unclejack @shykes Confirmed that works. Thanks :+1: ","@unclejack, which version of febootstrap is that script designed for? (It uses a number of options not present in modern builds as documented at http://libguestfs.org/febootstrap.8.html)","@charles-dyfis-net You need to use CentOS 6.x to build the image.","In order to do that, we need a smart client.\r\nRight now, the client is 99% dummy and just forward the user input to the server","I'm folding this into the \"remote API\" requirement. Obviously the api will need to be versioned. And once it's available we will no longer need the current \"rcli\" hack.","This seems to be fixed for me. This is what I'm getting with the current master:\r\n```\r\ndocker run \r\n\r\nUsage: docker run [OPTIONS] IMAGE COMMAND [ARG...]\r\n\r\nRun a command in a new container\r\n\r\n  -a=map[]: Attach to stdin, stdout or stderr.\r\n  -c=0: CPU shares (relative weight)\r\n  -d=false: Detached mode: leave the container running in the background\r\n  -dns=[]: Set custom dns servers\r\n  -e=[]: Set environment variables\r\n  -h=\"\": Container host name\r\n  -i=false: Keep stdin open even if not attached\r\n  -m=0: Memory limit (in bytes)\r\n  -p=[]: Expose a container's port to the host (use 'docker port' to see the actual mapping)\r\n  -t=false: Allocate a pseudo-tty\r\n  -u=\"\": Username or UID\r\n  -v=map[]: Attach a data volume\r\n  -volumes-from=\"\": Mount volumes from the specified container\r\n```","It's now used like this:\r\n```\r\ndocker help run\r\n```","You might also run\r\n\r\n``docker run --help``\r\n\r\nthough the output is a bit unexpected","The help flags have been removed from all commands and the list of flags is provided when running a docker top level command without arguments.\r\n","both `docker help run` and `docker run --help` display a correct usage.\r\nI think we can close this.","Look at the help. It's now 'docker import -'\r\n\r\nOn Monday, April 1, 2013, Jérôme Petazzoni wrote:\r\n\r\n\u003e I tried to re-run a command which used to work, and doesn't anymore (since\r\n\u003e the syntax was upgraded). I'm not bitching about the syntax change, but the\r\n\u003e error message that I got:\r\n\u003e\r\n\u003e #docker import -stdin=true centos \u003c centos-6.4-31.03.2013.tar.bz2\r\n\u003e\r\n\u003e flag provided but not defined: -stdin\r\n\u003e\r\n\u003e Usage: docker import [OPTIONS] URL|- [REPOSITORY [TAG]]\r\n\u003e\r\n\u003e Create a new filesystem image from the contents of a tarball\r\n\u003e\r\n\u003e 2013/04/01 18:09:45 Couldn't send EOF: shutdown tcp 127.0.0.1:45630: transport endpoint is not connected\r\n\u003e 2013/04/01 18:09:45 sendfile tcp 127.0.0.1:4242: broken pipe\r\n\u003e\r\n\u003e The last two lines are really confusing.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/294\u003e\r\n\u003e .\r\n\u003e","Look at what I wrote. I'm perfectly fine with the change, but the two last\r\nlines look pretty bogus :-)\r\n\r\n```\r\n2013/04/01 18:09:45 Couldn't send EOF: shutdown tcp 127.0.0.1:45630:\r\ntransport endpoint is not connected\r\n2013/04/01 18:09:45 sendfile tcp 127.0.0.1:4242: broken pipe\r\n```\r\n\r\nOn Mon, Apr 1, 2013 at 11:14 AM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Look at the help. It's now 'docker import -'\r\n\u003e\r\n\u003e On Monday, April 1, 2013, Jérôme Petazzoni wrote:\r\n\u003e\r\n\u003e \u003e I tried to re-run a command which used to work, and doesn't anymore\r\n\u003e (since\r\n\u003e \u003e the syntax was upgraded). I'm not bitching about the syntax change, but\r\n\u003e the\r\n\u003e \u003e error message that I got:\r\n\u003e \u003e\r\n\u003e \u003e #docker import -stdin=true centos \u003c centos-6.4-31.03.2013.tar.bz2\r\n\u003e \u003e\r\n\u003e \u003e flag provided but not defined: -stdin\r\n\u003e \u003e\r\n\u003e \u003e Usage: docker import [OPTIONS] URL|- [REPOSITORY [TAG]]\r\n\u003e \u003e\r\n\u003e \u003e Create a new filesystem image from the contents of a tarball\r\n\u003e \u003e\r\n\u003e \u003e 2013/04/01 18:09:45 Couldn't send EOF: shutdown tcp 127.0.0.1:45630:\r\n\u003e transport endpoint is not connected\r\n\u003e \u003e 2013/04/01 18:09:45 sendfile tcp 127.0.0.1:4242: broken pipe\r\n\u003e \u003e\r\n\u003e \u003e The last two lines are really confusing.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/294\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/294#issuecomment-15728263\u003e\r\n\u003e .\r\n\u003e","Looks like we can close this:\r\n\r\n```\r\n$ id=`docker run -d base echo foo`\r\n$ docker export $id \u003e foo.tgz \r\n$ docker import -stdin=true foo \u003c foo.tgz \r\nflag provided but not defined: -stdin\r\n\r\nUsage: docker import URL|- [REPOSITORY [TAG]]\r\n\r\nCreate a new filesystem image from the contents of a tarball\r\n\r\n$\r\n```","Wrong branch, sorry about this -_-. Discard.","Nice, I was half way through writing the same patch!","I think we should all of the important details to the version, so that users can report all of the needed details with bugs trivially.\r\n\r\n**Examples**\r\n\r\nBuilt from git master using go tip:\r\n\r\n```\r\ndocker git:c9a1314 Mon Apr 1 17:30:01 2013 -0500 (devel +354db178ad99) darwin/amd64\r\n```\r\n\r\nBuilt with a version specified:\r\n\r\n```\r\ndocker v0.1.3 (git:c9a1314) (go1.0.3) linux/amd64","I'm not familiar with go tip and can't seem to find much about it.  Can you point me in the right direction?","\"go tip\" refers to the latest commit of the Go mercurial repo. It will become Go 1.1 in a few weeks, and has hundreds if not thousands improvements over Go 1.0.3. It's pretty stable, so there are some like me who use it daily.\r\n\r\nhttp://golang.org/doc/install/source has details on how to install.","@titanous simply passing the git revision seems more than enough. Attaching any other git metadata would be redundant.","@shykes Sure, I don't have strong feelings about that. I've updated my example.","I'll wait for this to support differentiating \"dirty\" commits, either with \"$rev+CHANGES\", or \"\". From past experience I want to avoid the possibility of a binary advertising a git commit which it does not in fact implement.","I've implement the \"$rev+CHANGES\" approach.\r\n\r\nClean\r\n\u003cpre\u003e\r\nVersion:0.1.0\r\nGit Commit:5471f5b\r\n\u003c/pre\u003e\r\n\r\nDirty\r\n\u003cpre\u003e\r\nVersion:0.1.0\r\nGit Commit:5471f5b+CHANGES\r\n\u003c/pre\u003e","Are we comfortable assuming the git cli exists if someone is building from source?","Wouldn't it be better to have something like what go does?\r\n\r\ntip:\r\n$\u003e go version\r\ngo version devel +163d528e7436 Tue Mar 26 20:25:43 2013 +0400 linux/amd64\r\n\r\n\"+163d528e7436\" is the actual hg revision.\r\n\r\nrelease:\r\n$\u003e go1.0.3 version\r\ngo version go1.0.3\r\n","Thanks!","I felt like being nice so added a test instead of asking you to write one :) Next time I will ask though!\r\n\r\nThanks for the contribution.\r\n","You don't need find. Just ``gofmt -l -w .``.\r\n\r\nAlso, I'd recomend using ``-s``: ``gofmt -s -l -w .``","@fsouza +1 on both of those changes.\r\n\r\nWant to open a new PR? :)","Sure, please take a look at #305.","hmm, are you using the binaries or a build from the sources? I just tried with the master branch and it works fine.","Binaries via curl http://get.docker.io | sudo -s","Here are the steps to build a container which exhibits the problem. FWIW I am on Ubuntu 12.04 LTS in EC2:\r\n\r\n`docker run -t -i base /bin/bash`\r\n\r\nThen enter commands:\r\n\r\n```\r\napt-get update\r\napt-get install -y wget curl build-essential libssl-dev python-dev vim-tiny sudo\r\nuseradd -d /home/testrun -m testrun\r\n```\r\n\r\nFinally, in the same session, try:\r\n\r\n`su - testrun`\r\n\r\nOn my system this hangs forever.","The wrong shell is set. useradd will use /bin/sh. It would always hang for me as well if I added the user with useradd.\r\n\r\nThe right command to make the new user use bash is:\r\n```\r\nuseradd -d /home/testrun -m -s /bin/bash testrun\r\n```\r\n\r\nThe issue can probably be closed after @niallo confirms it's working.","Fixes it for me. Thanks!","Indeed, it is not working like this. You need to start the daemon first.\r\n\r\nI am updating the doc right away.","Actually, it is already documented, at the bottom of the page.\r\n\r\nCould you please confirm that it works once the daemon is started? (sudo docker -d \u0026)","Yes, running `docker -d` fixes the problem. I'd missed that part of the docs. \r\n\r\nGiven the docker daemon should be running at all times, and is included in some of the installation methods, I wonder if this is something that should be mentioned in the [Ubuntu install instructions](http://docs.docker.io/en/latest/installation/ubuntulinux/)?\r\n\r\n","I just noticed this was fixed. Thanks Ken!","This is linked to #148.\r\nSince we truncated the Id, the rmi does not work anymore as it does perform a lookup. Once #148 will be done, rmi will work once more :)","Thanks for catching that. I forgot to add support for short IDs in image removal.\r\n\r\nIn the meantime here's a workaround:\r\n\r\n```bash\r\ndocker rmi $(docker inspect b1343935b9e5 | sed -E -n 's/^ *\"id\": \"(.*)\",.*$/\\1/p')\r\n```","@shykes : Thanks for providing the workaround, it worked.","Pushing this one to the shortlist. @creack can you take a look? Nobody can login on master.","Login works in tag v0.1.0","Login also works in tag v0.1.1","The problem is present in 1fc9405537a1c528a59356ec36189a61db146701","Also present in 6ccd473127c334ee6dcd1694a1fddcf6cdc1fd32","The problem was introduced in: ff26493fd5ac1205e5f9d23b976e759730a3229c.","looking into it too","For the record, the bug was not present with go1.1\r\nIt has something to do with the way go handles the content-length in net/http","@creack Perhaps testing should be performed both with go1.0 and go1.1.","Agreed. Anybody want to create a go1.1 version of shykes/dockerbuilder? :)\r\n\r\n\r\nOn Tue, Apr 2, 2013 at 10:52 AM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @creack \u003chttps://github.com/creack\u003e Perhaps testing should be performed\r\n\u003e both with go1.0 and go1.1.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/307#issuecomment-15791262\u003e\r\n\u003e .\r\n\u003e","@shykes I can take care of it if you tell me what's needed for it.","This makes the changes needed for #194.","Hmm... I made the branch on top of ``hostname-parameter`` (#299), hence more changes than anticipated","Hey, cool! Could you show an example of usage?\r\n\r\nThanks.","@sa2ajj you can rebase your changes on top of master and force push if you want to remove the other changes from this pull request. (Unless this change requires the change in `hostname-parameter`?)\r\n\r\n    $ git rebase --onto master hostname-parameter persistent-storage","@cespare, thank you.  I was considering doing that.\r\n\r\n(The changes are independent :))","Though the first commit is not that necessary, I'd still like to have it :)\r\n\r\n@shykes, as for an example, what would be the best place for it?  docs/sources/commandline/cli.rst?","A good start would be 1 or 2 simple examples here in the comments.","@sa2ajj Thank you for working on this and for updating the patch!\r\n\r\nIt can already be used like this:\r\ndocker run -volume /mnt=/storage/data1234 [other options for run]\r\n/mnt is the mountpoint in LXC\r\n/storage/data1234 is the path to the data on the host\r\n\r\nIt looks like it's only possible to have read only mounts now. Perhaps something like -volume /mnt=/storage/data1234,rw and -volume /mnt=/storage/data1234,ro could be used to specify whether the volume should be RW or RO. I think it's best to not provide a default so that the user has to decide and always specify it.","Good catch!\r\n\r\nWhat about ``-volume=rw:/container/dir=/host/dir`` and ``-volume=ro:/container/dir=/host/dir``?","I think both options are OK, but @shykes should probably tell you which one he prefers.","It's working properly, I've tested it.","Hi guys, sorry but I cannot accept this pull request in its current form. Docker cannot allow arbitrary outside bind-mounts at container runtime, that would break the repeatability of a run, and even more importantly would require out-of-band host configuration and operation. \"Run this container with the following command, but first make sure you create a directory call /mnt/foo/bar, then make sure blablbla.\" This is exactly what docker is trying to avoid.\r\n\r\nData volumes are necessary but they need to be created and managed by Docker throughout their entire lifecycle.\r\n\r\n'docker run --volume=/var/lib/postgres --volume=/var/log'  should create 2 data volumes, map them 1-to-1 to the newly created container, and mount-bind them in the right place at start.\r\n\r\n","Word!\r\n\r\n\r\nOn Wed, Apr 3, 2013 at 12:29 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Hi guys, sorry but I cannot accept this pull request in its current form.\r\n\u003e Docker cannot allow arbitrary outside bind-mounts at container runtime,\r\n\u003e that would break the repeatability of a run, and even more importantly\r\n\u003e would require out-of-band host configuration and operation. \"Run this\r\n\u003e container with the following command, but first make sure you create a\r\n\u003e directory call /mnt/foo/bar, then make sure blablbla.\" This is exactly what\r\n\u003e docker is trying to avoid.\r\n\u003e\r\n\u003e Data volumes are necessary but they need to be created and managed by\r\n\u003e Docker throughout their entire lifecycle.\r\n\u003e\r\n\u003e 'docker run --volume=/var/lib/postgres --volume=/var/log' should create 2\r\n\u003e data volumes, map them 1-to-1 to the newly created container, and\r\n\u003e mount-bind them in the right place at start.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/309#issuecomment-15859037\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","@shykes I definitely have use cases for docker that require mounting specific disks or directories outside of docker's control inside of a container. By default docker needs to provision data volumes. However, I think that we should make sure that the auto-provisioning isn't required.","@shykes Can you describe the exact workflow you'd like to have, including the exact commands and desired behavior, please?\r\n\r\nAlso, this would be useful for things you don't care about, like mapping the container's /tmp to a folder in /tmp. So there are some use cases for ephemeral storage.","@titanous that is a valid requirement and we'll need a way for the operator to hook volume allocation. But it should not affect the external facing API and UI. Eg. the user doesn't need to know *how* volumes were allocated.\r\n\r\nSame comment applies for advanced network allocation.","@shykes Yes, something as simple as calling a script that returns the mountpoint given the container metadata is perfect here.","In the case of host-wide storage strategy (eg. \"all containers on this host should store data on this EBS volume\"), it gets even simpler - just symlink /var/lib/docker/volumes to the right place before starting docker (similar to \"bring-your-own-bridge\" for networking)\r\n","There are multiple workflows and use-cases for volumes.\r\n\r\n1. AUFS is great, but it's not perfect. In some cases, it won't behave as expected. Examples: inode numbers can change across mounts; all `mmap()` semantics are not perfectly emulated; and there might be some others that we're not aware of. Also, some people might complain about AUFS' overhead (even if in my experiments it wasn't noticeable).\r\n2. You want to persist data across multiple invocations of `docker run`. I guess that you can always commit a stopped container into a new image, but when you have a significant amount of data, it is not convenient. (This one might be addressed by a command allowing the restart a stopped container.)\r\n3. You want to share some data between containers for a very short period of time. Example: when upgrading a web app, you want to move static assets from the old container to the new container with minimal downtime. \r\n4. You want to share some data between containers on a permanent basis. Example: you want to run a wiki web frontend in a container, and have the wiki files accessible from another container where you will run a sphinx doc builder. In other words, this can be seen as \"composition\" of containers (that's how the dotCloud internal wiki works, by the way :-))\r\n5. You want some data to reside on a shared storage, allowing you to easily move a container from a place to another. One possibility is to have /var/lib/docker on the shared storage, but then we have to make sure that all access to that directory is protected against concurrent access. \r\n6. You want to edit e.g. the configuration of your database (or upgrade it) and make an image out of it, without including the data (because it's confidential, or too big).\r\n\r\nSome additional remarks.\r\n\r\n1. \"Persistence\" means that volumes have to be identified *somehow*. Either the user makes up an identifier, or docker does it and informs the user.\r\n2. I assume that it SHOULD NOT be necessary to supply command-line flags to start a container. E.g., if I have to provide `-v foo=bar`, it's wrong.\r\n3. However, I equally assume that a container MAY require extra (optional) flags to be usable in a production setup. E.g., if I start a MySQL container without `-p 3306`, it will probably be much less useful than intended, but it will start alright, and be usable in some specific scenarios.\r\n4. I also assume that we ultimately want to put some information in the image metadata, to inform the user that \"this image is probably more useful if you expose port 3306 and make /var/lib/mysql a volume\".\r\n\r\nWith all those things in mind, my proposal would be:\r\n- volumes (just like ports) are optional; i.e. you don't have to specify them to start the image, and likewise, you can specify them even if it wasn't intended in the first place; i.e. nothing prevents you from starting a MySQL image with /usr/local being a volume, if you fancy that;\r\n- volumes (just like ports, if that's the plan) can be \"hinted\" in the image metadata;\r\n- volumes are identified in the container by their absolute path;\r\n- volumes are identified in the docker host by a path, which can be relative or absolute (more on that later);\r\n- a \"volume binding\" can be specified on the command-line when starting a container, and combines the two previous items, as well as a read-only/read-write flag\r\n\r\nMore about \"relative or absolute\" host paths: this is more of an implementation detail, but I would suggest the following rules.\r\n1. If the path is empty, assume that it will be `/var/lib/docker/volumes/\u003ccontainerid\u003e/\u003cpathincontainer\u003e`.\r\n2. If the path starts with `/`, assume that it's an absolute path on the host. The path should exist.\r\n3. If the path doesn't start with `/`, prepend the path with `/var/lib/docker/volumes/` and use that.\r\n4. If the path contains `:`, abort.\r\n\r\nThose rules allow to implement the following:\r\n1. `-v=/var/lib/mysql` means that the mysql data directory will be mapped to a new \"anonymous\" volume.\r\n2. `-v=/var/lib/mysql=/mnt/mysql` means that `/mnt/mysql` (on the docker host) will appear inside the container.\r\n3. `-v=/var/lib/mysql=webdb` means that `/var/lib/docker/volumes/webdb` will be used.\r\n4. `-v=/var/lib/mysql=iscsi:iqn.2001-04.com.example:diskarrays-sn-webdb0` will be denied for now, but leaves the door open for future extensions.\r\n\r\nLast but not least:\r\n- if the directory doesn't exist in the container, I don't know if we should create it or abort;\r\n- if the directory doesn't exist in the docker host, I think we should create it;\r\n- if the directory in the docker host is empty, data from the image should be copied.\r\nThe last rule lets you auto-populate the volume with whatever was in the image. In other words, you can author a MySQL image, and later turn /var/lib/mysql into a volume without bothering about initializing its content. If you want an empty volume, just create a dummy file in it (since the copy will happen only on an empty volume).\r\n\r\nComments?","Thanks @jpetazzo, that's a lot of text, I'll need a little time to review ;)","@jpetazzo That was very detailed and it addresses my concerns.\r\n\r\n1 Would it be ok to use the format rw:/var/lib/mysql=webdb for making a volume RW or RO? If not, what should it be?\r\nRO volumes would also be useful for \"file writer - file reader\" use cases like the one you've mentioned.\r\n\r\n2 Data storage pool management must also exist for named volume allocation. It should be possible to have a default storage area to allocate volumes on. This could be something like: -v=rw:pool2:/var/lib/mysql=webdb and -v=rw:pool2:/var/lib/mysql for anonymous volumes.\r\n\r\nMaybe we have \"slow \u0026 cheap storage\" for free accounts and \"fast \u0026 expensive storage\" for paid accounts.\r\n\r\n3 How would quotas be handled in this case? Would it be possible to use some hooks to set this up?\r\n4 How would the various hooks work and where would they be added?\r\n5 How would the volume export and import hooks work?\r\n6 Anonymous volumes allocated automatically will have the same properties as the named ones, but they'll have a random name.\r\n\r\nThe direct mapping of directories from the host is an important feature, especially during development.","\r\n\u003e    Would it be ok to use the format rw:/var/lib/mysql=webdb for making a\r\n\u003e    volume RW or RO?\r\n\r\nYes, that's a good idea.\r\n\r\n\r\n\u003e    Data storage pool management must also exist for named volume\r\n\u003e    allocation. It should be possible to have a default storage area to\r\n\u003e    allocate volumes on. This could be something like:\r\n\u003e    -v=rw:pool2:/var/lib/mysql=webdb and -v=rw:pool2:/var/lib/mysql for\r\n\u003e    anonymous volumes.\r\n\r\nI was thinking that it could be addressed by the \"future extension\" scope. I.E., `-v=rw:/var/lib/mysql=pool2:webdb` (and an anonymous volume could be `-v=rw:/var/lib/mysql=pool2:`)\r\nWould that work?\r\n\r\n\u003e Maybe we have \"slow \u0026 cheap storage\" for free accounts and \"fast \u0026\r\n\u003e expensive storage\" for paid accounts.\r\n\u003e\r\n\u003e    1. How would quotas be handled in this case? Would it be possible to\r\n\u003e    use some hooks to set this up?\r\n\u003e    2. How would the various hooks work and where would they be added?\r\n\u003e    3. How would the volume export and import hooks work?\r\n\r\nRegarding those 3 questions: I honestly don't know. I deliberately left those issues out, because my message was already very long :-)\r\nI think that the problem is split between two parts.\r\n- First, define which options we want to allow, and how to expose them in the CLI and the future API.\r\nExample: `-v=rw:/var/lib/mysql=pool2:webdb,size=1G,iops=100,arbitraryparameter=foo`\r\n- Then, define how we interface with the \"storage plug-ins\".\r\nExample: the above volume definition might execute `/var/lib/docker/plugins/pool2`, providing him all the parameters on the command-line / environment, and docker would expect it to return one single line containing the local path, ready to be bound to the container.\r\nThose are just ideas though.\r\n\r\n\u003e    1. Anonymous volumes allocated automatically will have the same\r\n\u003e    properties as the named ones, but they'll have a random name.\r\n\r\nIndeed.","@jpetazzo @unclejack do you guys want to hash out a proposal together, and then I will review it once? Maybe better than 2 moving targets.","(the last update changes the name of entry_re to entryRegExp)","Hey @sa2ajj, I moved #111 to the top of the list, since obviously it's an important feature for a lot of people. I tried to start off of your pull request, but it ends up being much simpler starting over. Sorry about that.\r\n\r\nI'm going to close this PR for clarity, to discuss the feature itself please refer to #111.\r\n\r\nThanks!","Not just the hash - it should be specific to hash+parentID","Does the parent matter if the state of the image is known? If two images are in every way identical but have different parents, should their hash be different? Aren't they guaranteed interchangeable for any purpose, including generating downstream images?\r\n\r\nAlong these lines, Git separates out trees from commits. Identical trees have identical hashes, regardless of ancestry. Commits are the ones that handle ancestry.","On Mon, Apr 1, 2013 at 6:51 PM, Vivek Sekhar \u003cnotifications@github.com\u003ewrote:\n\n\u003e Does the parent matter if the state of the image is known? If two images\n\u003e are in every way identical but have different parents, should their hash be\n\u003e different?\n\u003e\nYes, for the same reason that applying the same diff in 2 different repos\nwill yield 2 different git commit IDs.\n\nAn image must be uniquely identified by its ID. The filesystem layer is\njust one part of the image.\n\n\u003e Along these lines, Git separates out trees from commits. Identical trees\n\u003e have identical hashes, regardless of ancestry. Commits are the ones that\n\u003e handle ancestry.\n\u003e\nConversely, an image's *layer* can be compared to other layers by a hash.\nIdentical layers will have identical hashes, regardless of ancestry. But\njust like a tree hash does not identify a commit, a layer hash does not\nidentify an image.","Are you talking about hashing the contents of the image? There are two reasons I can think of on why this is probably not the best approach.\r\n\r\n1. Hashing is expensive. If you're hashing a bunch of small files with git, the cost is acceptable. If you're hashing entire filesystems, the computational cost of performing the hash may be prohibitively expensive.\r\n\r\n2. The chances of the filesystem being exactly the same is pretty low if you take into account timestamps of modified files. Any algorithm you use would need to ignore timestamps to make the tree match by content.\r\n\r\nIn the interest of conversation though, here's my thoughts on how this could be implemented:\r\n\r\nGit solves this by storing a file by setting the address as the hash of its contents with no filesystem metadata, and having a tree object provide the filesystem information such as timestamps and permissions. If we took the git approach, the trade off is we would have additional upfront computation to push or pull the overlay to create the overlay.\r\n\r\nIf this approach is taken, I think the best time to perform this extra work is at the push and pull step. Perhaps push and pull directly to and from a git repo. Convert an overlay to a representative git repo, and back.","Note: hashing is actually very cheap; I/O is the real deal. If you hash a layer on-the-fly, as it is being sent, computing the hash is quasi free (this local laptop can compute SHA1 at 100s of MB/s). Computing the hash of the whole image would be more expensive, of course, because it would involve re-reading data which is not needed during the push operation.","I'm closing this since it's a general design discussion and not a specific improvement or bug. Feel free to continue the thread on the mailing list :)","Thanks for making this for me. Been so flat out over the last few days.\r\nThe make file / source instructions don't look too onerous so I'll have to take a peek \u0026 see if I can get a rudimentary eBuild cobbled together and up into my Layman Repository.","My own simple first attempt:\r\n\r\n```ebuild\r\nEAPI=4\r\n\r\nDESCRIPTION=\"Docker complements LXC with a high-level API which operates at the process level. It runs unix processes with strong guarantees of isolation and repeatability across servers.\"\r\nHOMEPAGE=\"http://www.docker.io/\"\r\nSRC_URI=\"https://github.com/dotcloud/${PN}/archive/v${PV}.tar.gz -\u003e ${P}.tar.gz\"\r\n\r\nLICENSE=\"Apache-2.0\"\r\nSLOT=\"0\"\r\nKEYWORDS=\"~amd64\"\r\nIUSE=\"\"\r\n\r\nDEPEND=\"\r\n\tdev-lang/go\r\n\"\r\nRDEPEND=\"\r\n\tapp-emulation/lxc\r\n\tapp-arch/libarchive\r\n\tnet-misc/curl\r\n\"\r\n\r\nsrc_install() {\r\n\tdobin bin/docker\r\n}\r\n```","I guess it would also be helpful to mention that I called this \"app-emulation/docker\" and put that in docker-0.1.1.ebuild (to grab from the most recent \"release\" tag to avoid the annoyance of a live ebuild).","I'm also thinking that dobin might be better as dosbin, since docker does have to be run as root.  I'd definitely love some outside opinions.","I've also added the following to the end of the ebuild (referencing issue #219), since this is probably the first issue Gentoo users will run into (even before a misconfigured kernel for LXC):\r\n```ebuild\r\npkg_postinst() {\r\n\tewarn \"Docker currently assumes a network bridge named lxcbr0 exists and is usable\"\r\n\tewarn \"see also https://github.com/dotcloud/docker/issues/219\"\r\n}\r\n```\r\n\r\nThe best temporary solution I can see for the ebuild to do would be to create something similar to the lxcbr0 from Ubuntu (and if named differently, which is probably a good idea, perform the tiny patch necessary to network.go -- something like dockerbr0 would be more obvious).  The real solution, of course, is the actual resolution of #219, especially since reliably creating said bridge at install-time would pose somewhat of a challenge (from what I know).","As a side note, since the final resolution to the bridge issue will either be #221 or will be similar to it, we will need to add `net-misc/bridge-utils` (for `/sbin/brctl`) to RDEPEND.  I think RDEPEND also ought to include `sys-apps/iproute2` (for `/bin/ip`).","Sorry for waxing slightly spammy in comment volume here; I am very excited about getting this to work, and do enjoy practice making ebuilds since I have so few legitimate opportunities to do so.  Here is an updated ebuild that can be either docker-0.1.1 or docker-9999 (yes, finally a proper live ebuild):\r\n```ebuild\r\nEAPI=4\r\n\r\nDESCRIPTION=\"Docker complements LXC with a high-level API which operates at the process level. It runs unix processes with strong guarantees of isolation and repeatability across servers.\"\r\nHOMEPAGE=\"http://www.docker.io/\"\r\n\r\nif [[ ${PV} == *9999 ]]; then\r\n\tEGIT_REPO_URI=\"git://github.com/dotcloud/docker.git\"\r\n\tinherit git-2\r\n\tSRC_URI=\"\"\r\n\tKEYWORDS=\"\"\r\nelse\r\n\tSRC_URI=\"https://github.com/dotcloud/${PN}/archive/v${PV}.tar.gz -\u003e ${P}.tar.gz\"\r\n\tKEYWORDS=\"~amd64\"\r\nfi\r\n\r\nLICENSE=\"Apache-2.0\"\r\nSLOT=\"0\"\r\nIUSE=\"\"\r\n\r\nDEPEND=\"\r\n\tdev-lang/go\r\n\"\r\nRDEPEND=\"\r\n\tapp-arch/libarchive\r\n\tapp-emulation/lxc\r\n\tnet-misc/bridge-utils\r\n\tnet-misc/curl\r\n\tsys-apps/iproute2\r\n\"\r\n\r\nsrc_install() {\r\n\tdobin bin/docker\r\n\tdodoc README.md\r\n\t[[ ${PV} == *9999 ]] \u0026\u0026 dodoc CONTRIBUTING.md\r\n}\r\n\r\npkg_postinst() {\r\n\tewarn \"Docker currently assumes a network bridge named lxcbr0 exists and is usable.\"\r\n\tewarn \"See https://github.com/dotcloud/docker/issues/219 for more details.\"\r\n}\r\n```\r\nI have also included here the runtime dependencies of `net-misc/bridge-utils` and `sys-apps/iproute2`, mostly so that I don't forget to add them later when the bridge issue is finally resolved nicely.","We just barely got a v0.1.2 tag, but since it now uses git directly in the Makefile (to include GIT_COMMIT in the build for nice versioning information), I've updated the ebuild to just always use the git-2 eclass instead of only doing so for live ebuilds:\r\n```ebuild\r\nEAPI=4\r\n\r\nDESCRIPTION=\"Docker complements LXC with a high-level API which operates at the process level. It runs unix processes with strong guarantees of isolation and repeatability across servers.\"\r\nHOMEPAGE=\"http://www.docker.io/\"\r\nSRC_URI=\"\"\r\n\r\nEGIT_REPO_URI=\"git://github.com/dotcloud/docker.git\"\r\nif [[ ${PV} == *9999 ]]; then\r\n\tKEYWORDS=\"\"\r\nelse\r\n\tEGIT_COMMIT=\"v${PV}\"\r\n\tKEYWORDS=\"~amd64\"\r\nfi\r\n\r\ninherit git-2\r\n\r\nLICENSE=\"Apache-2.0\"\r\nSLOT=\"0\"\r\nIUSE=\"\"\r\n\r\nDEPEND=\"\r\n\tdev-lang/go\r\n\"\r\nRDEPEND=\"\r\n\tapp-arch/libarchive\r\n\tapp-emulation/lxc\r\n\tnet-misc/bridge-utils\r\n\tnet-misc/curl\r\n\tsys-apps/iproute2\r\n\"\r\n\r\nsrc_install() {\r\n\tdobin bin/docker\r\n\tdodoc README.md\r\n\t[[ ${PV} == *9999 ]] \u0026\u0026 dodoc CONTRIBUTING.md\r\n}\r\n\r\npkg_postinst() {\r\n\tewarn \"Docker currently assumes a network bridge named lxcbr0 exists and is usable.\"\r\n\tewarn \"See https://github.com/dotcloud/docker/issues/219 for more details.\"\r\n}\r\n```\r\nShould still be saved as either `app-emulation/docker/docker-0.1.2.ebuild` or `app-emulation/docker/docker-9999.ebuild`.","I've created a public gentoo-overlay repo for me to do further development on this in so that it will be publicly accessible and simpler for others to see, use, and contribute to.\r\n\r\nhttps://github.com/tianon/gentoo-overlay/tree/master/app-emulation/docker","I finally created lxcbr0 manually to test further, and now we run into a \"no such device\" error in docker.go on line 40.  This is one issue with just bubbling errors up and logging them at the top level. :)\r\n\r\nFull output:\r\n```\r\n$ sudo docker run -i -t busybox /bin/echo hi\r\n2013/04/03 22:57:16 docker run -i -t busybox /bin/echo hi\r\n2013/04/03 22:57:16 no such device\r\n```\r\n\r\nAnd again with debugging enabled, in case that helps:\r\n```\r\n$ sudo docker -D run -i -t busybox /bin/echo hi\r\n[debug] runtime.go:228 Loaded container 000681152368dacad8351b0872a120dd3fe3795f769b15b3bdf5e5fb6d644611\r\n[debug] runtime.go:228 Loaded container 0a9d888ebaf63c8e2e113dd168d725aba90e9cdcf5464cfd6d304af81561bb8c\r\n[debug] runtime.go:228 Loaded container 0e0284b89613110251a73a3bfcf77c957c557d77eed0eb4e70ee641ce5839ae2\r\n[debug] runtime.go:228 Loaded container 4a88d53f08f444a82ae288c94c0b1e5edc94d01154d6baadf5cb23c996ab43ea\r\n[debug] runtime.go:228 Loaded container 7ccaea4b9ea365719d3a46b2ee8bf060d687846d95fa50c82508fee1c51d8ed7\r\n[debug] runtime.go:228 Loaded container 94aa0f18895b32c371eb53fb224b0d9141289d2b585a91d001e74770644731ff\r\n[debug] runtime.go:228 Loaded container 9c0e938500c490c6c0833cf1566c518ac1b3fe2c2fb5cb3c303844a9d0ec0293\r\n[debug] runtime.go:228 Loaded container a0189933ee35cd3e6c4a9e77b96e277a6fe1eaf88e4d7b47d935f4c4b76061b2\r\n[debug] runtime.go:228 Loaded container a82ee39acb546157408039ee5a8cfa4a7794eeb7a7d5eb8341f2bd2ca9417d8c\r\n[debug] runtime.go:228 Loaded container ae55d007d67b8206888f7149cdc07e639a4d8a1886f80251818a88e29ddd6867\r\n[debug] runtime.go:228 Loaded container aee5a3ca5df8f847f4d8225ec1f4dba7bae15e25c45d7e352066528e60dd3ee1\r\n[debug] runtime.go:228 Loaded container bc56765217f1600f5bad4b8560a94277ae2dbdb4fcb37ba5c3b1867590f04045\r\n[debug] runtime.go:228 Loaded container e0a245fab6891d2b528eb4b36cf2b05f40b30256a82fa20816f633942d49b187\r\n[debug] runtime.go:228 Loaded container e44ecacce56ab96028a933fb740ca700fe8465e40a9d16a8aaf51f68819b0738\r\n[debug] runtime.go:228 Loaded container f2d38dc45945665892c6f5cf93aa5e8359f72fc66008e189f361e78b67498463\r\n2013/04/03 22:57:37 docker run -i -t busybox /bin/echo hi\r\n[debug] commands.go:917 Starting\r\n\r\n[debug] container.go:271 [start] attach stdin\r\n\r\n[debug] container.go:291 [start] attach stdout\r\n\r\n[debug] container.go:308 [start] attach stderr\r\n\r\n[debug] container.go:328 Waiting for job 1/3\r\n\r\n2013/04/03 22:57:37 no such device\r\n```","I should also mention that I am proficient in Go and happy to debug this with some help, but I just don't know enough about LXC or Docker at this point to go much further on my own.","Hi Tianon, this \"no such device\" is because you don't have the aufs module\r\nloaded in your kernel. See issue #183.\r\n\r\n\r\nOn Wed, Apr 3, 2013 at 10:00 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I should also mention that I am proficient in Go and happy to debug this\r\n\u003e with some help, but I just don't know enough about LXC or Docker at this\r\n\u003e point to go much further on my own.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15879995\u003e\r\n\u003e .\r\n\u003e","Ah brilliant, thanks.  Sorry, I should've thought to search the issues here.  I'll play around with that and see about adding a check for that in the ebuild, too (I know it can be done, just haven't done it myself before).","No worries. You hit 2 completely unrelated errors in a row, and they\r\nhappened to both say \"no such device\". I can't blame you for being confused\r\n:)\r\n\r\n\r\nOn Wed, Apr 3, 2013 at 10:04 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Ah brilliant, thanks. Sorry, I should've thought to search the issues\r\n\u003e here. I'll play around with that and see about adding a check for that in\r\n\u003e the ebuild, too (I know it can be done, just haven't done it myself before).\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15880057\u003e\r\n\u003e .\r\n\u003e","Indeed, very fun. :)\r\n\r\nAdding aufs to the ebuild turns out to be much easier than I was thinking.  I thought it was a built-in kernel FS, but it's in a separate package, so I just need to add sys-fs/aufs3 to RDEPEND.\r\n\r\nThe nasty part is that the aufs ebuild requires patching the kernel, so maybe Gentoo won't be one of the first \"supported\" distros outside of Ubuntu - we'll just make sure that for the experienced Gentoo user, it'll at least be possible. :)\r\n\r\nIt's really a choice between the aufs3 ebuild with a patch to the kernel, or using the aufs-sources directly, which are basically gentoo-sources, but including the aufs code.  We'll see what I run into next after getting aufs installed and working.","Now we've made progress.  Kernel recompiled and rebooted, aufs successfully loaded.\r\n\r\nAfter running `sudo docker run -i -t busybox /bin/echo hi`, I get:\r\n```\r\n2013/04/03 23:42:20 docker run -i -t busybox /bin/echo hi\r\n```\r\nThen it hangs for a short while (which I'm assuming is some initial setup, since the hang here didn't happen on subsequent runs), then I got:\r\n```\r\nhi\r\n```\r\nSo docker actually created and ran my container!\r\n\r\nThen we hang until I press a key of some kind and we get:\r\n```\r\n2013/04/03 23:43:33 io: read/write on closed pipe\r\n```\r\nObviously this is because the process is dead, but for some reason our attachment didn't know it.  Maybe I've misunderstood either -i or -t?","Nice!\r\n\r\nDid you run the first \"docker run\" on an virgin docker install? If so, the\r\ndelay was probably docker auto-downloading the busybox image from the\r\nregistry :)\r\n\r\n\r\nOn Wed, Apr 3, 2013 at 10:50 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Now we've made progress. Kernel recompiled and rebooted, aufs successfully\r\n\u003e loaded.\r\n\u003e\r\n\u003e After running sudo docker run -i -t busybox /bin/echo hi, I get:\r\n\u003e\r\n\u003e 2013/04/03 23:42:20 docker run -i -t busybox /bin/echo hi\r\n\u003e\r\n\u003e Then it hangs for a short while (which I'm assuming is some initial setup,\r\n\u003e since the hang here didn't happen on subsequent runs), then I got:\r\n\u003e\r\n\u003e hi\r\n\u003e\r\n\u003e So docker actually created and ran my container!\r\n\u003e\r\n\u003e Then we hang until I press a key of some kind and we get:\r\n\u003e\r\n\u003e 2013/04/03 23:43:33 io: read/write on closed pipe\r\n\u003e\r\n\u003e Obviously this is because the process is dead, but for some reason our\r\n\u003e attachment didn't know it. Maybe I've misunderstood either -i or -t?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15881034\u003e\r\n\u003e .\r\n\u003e","On Wed, Apr 3, 2013 at 10:50 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\n\n\n\u003e Then we hang until I press a key of some kind and we get:2013/04/03\n\u003e 23:43:33 io: read/write on closed pipe\n\u003e\n\u003e Obviously this is because the process is dead, but for some reason our\n\u003e attachment didn't know it. Maybe I've misunderstood either -i or -t?\n\u003e\n\nThis is a bug which was introduced in the last 24 hours... We are currently\nfixing it. The correct behavior would be for docker to return on its own.","I'm not sure what the delay was, since I had already pulled the busybox image, but it's certainly cool to be this far.  I'm currently waiting for the ubuntu base image to download so I can play with that, too. :)\r\n\r\nSo overall, Gentoo appears to be just fine as a platform, once we get the bridge figured out more nicely and now that we've got the dependencies nailed down correctly. :+1:","Next step: publish a standard guest Gentoo image, so we non-gentoo users\r\ncan experiment with it inside docker? :) 'docker run -i -t gentoo bash'\r\nwould be pretty cool.\r\n\r\n\r\nOn Wed, Apr 3, 2013 at 10:58 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I'm not sure what the delay was, since I had already pulled the busybox\r\n\u003e image, but it's certainly cool to be this far. I'm currently waiting for\r\n\u003e the ubuntu base image to download so I can play with that, too. :)\r\n\u003e\r\n\u003e So overall, Gentoo appears to be just fine as a platform, once we get the\r\n\u003e bridge figured out more nicely and now that we've got the dependencies\r\n\u003e nailed down correctly. [image: :+1:]\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15881195\u003e\r\n\u003e .\r\n\u003e","More output from the base image:\r\n```\r\nsudo docker run -i -t base /bin/bash\r\nPassword: \r\n2013/04/04 00:01:24 docker run -i -t base /bin/bash\r\nbash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\nbash: no job control in this shell\r\ngroups: cannot find name for group ID 11\r\nroot@64b98c5e6e37:/#\r\n```\r\n\r\nWith an active, working bash terminal inside the image. :)\r\n\r\nHaving a Gentoo image would indeed be very nice.  Not entirely sure how to go about creating such a thing, but I might look into it later (probably looking at that nice script that generates the busybox image to help me figure out what I'm doing).","You can create a new image from a tarball with 'docker import'.\r\n\r\nFor example, if \"rootfs\" containers a full root filesystem: 'tar -C\r\n./rootfs -c . | docker import tianon/gentoo' then 'docker run -i -t\r\ntianon/gentoo bash'.\r\n\r\n\r\nOn Wed, Apr 3, 2013 at 11:04 PM, Tianon Gravi \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e More output from the base image:\r\n\u003e\r\n\u003e sudo docker run -i -t base /bin/bash\r\n\u003e Password:\r\n\u003e 2013/04/04 00:01:24 docker run -i -t base /bin/bash\r\n\u003e bash: cannot set terminal process group (-1): Inappropriate ioctl for device\r\n\u003e bash: no job control in this shell\r\n\u003e groups: cannot find name for group ID 11\r\n\u003e root@64b98c5e6e37:/#\r\n\u003e\r\n\u003e With an active, working bash terminal inside the image. :)\r\n\u003e\r\n\u003e Having a Gentoo image would indeed be very nice. Not entirely sure how to\r\n\u003e go about creating such a thing, but I might look into it later (probably\r\n\u003e looking at that nice script that generates the busybox image to help me\r\n\u003e figure out what I'm doing).\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15881298\u003e\r\n\u003e .\r\n\u003e","Hmm, that base image doesn't have internet, so I'm pretty much positive my lxcbr0 is not setup correctly, which is odd since I followed the same steps in the pull request that's trying to normalize all that.\r\n\r\nHere's what I did:\r\n```\r\nsudo brctl addbr lxcbr0\r\nsudo ip addr add 172.16.0.1/24 dev lxcbr0\r\nsudo ip link set lxcbr0 up\r\nsudo iptables -t nat -A POSTROUTING -s 172.16.0.1/24 '!' -d 172.16.0.1/24 -j MASQUERADE\r\n```\r\n\r\nLearning about how docker import works, we might be able to use a stage3 directly.  That would be magical and mind-blowing.  I'm definitely going to have to play with that more.","Fyi, those steps were specifically from https://github.com/dotcloud/docker/pull/221/files#L3R457 (the CreateIface function).  If they aren't right or aren't sufficient, then that pull request definitely needs more loving. :)","Just to double-check, can you confirm ip routing to the outside is broken,\r\nand not just dns?\r\n\r\nOn Wednesday, April 3, 2013, Tianon Gravi wrote:\r\n\r\n\u003e Fyi, those steps were specifically from\r\n\u003e https://github.com/dotcloud/docker/pull/221/files#L3R457 (the CreateIface\r\n\u003e function). If they aren't right or aren't sufficient, then that pull\r\n\u003e request definitely needs more loving. :)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15881552\u003e\r\n\u003e .\r\n\u003e","I always verify connectivity with a ping to 8.8.8.8 before I ever try google.com. :P","I assumed so - but had to ask! :)\r\n\r\nOn Wednesday, April 3, 2013, Tianon Gravi wrote:\r\n\r\n\u003e I always verify connectivity with a ping to 8.8.8.8 before I ever try\r\n\u003e google.com. :P\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/313#issuecomment-15881805\u003e\r\n\u003e .\r\n\u003e","Understand completely. :)\r\n\r\nAlso, `ifconfig lxcbr0` host-side gives me `172.16.0.1` (as it should), and `ifconfig eth0` base-side gives me `172.16.0.2` (which is expected), and `ping -c 1 172.16.0.1` base-side succeeds nicely, as does `ping -c 1 172.16.0.2` host-side.","To further muddy the waters of this conversational thread, here's some output from my initial attempt at pushing the Gentoo stage3 into a docker image:\r\n```\r\n2013/04/04 00:34:57 docker run -i -t tianon/gentoo bash\r\nlxc-start: No such file or directory - failed to mount 'devpts' on '/usr/lib/lxc/rootfs//dev/pts'\r\nlxc-start: failed to setup the mount entries for '4a7a675d27bde40380f6c7e475301b46f55e2393e0df2b9b31c3999c1e8dda45'\r\nlxc-start: failed to setup the container\r\nlxc-start: invalid sequence number 1. expected 2\r\nlxc-start: failed to spawn '4a7a675d27bde40380f6c7e475301b46f55e2393e0df2b9b31c3999c1e8dda45'\r\n```\r\n\r\nAnd for completeness, the full steps performed to create said image:\r\n```bash\r\nwget -c 'http://distfiles.gentoo.org/releases/amd64/autobuilds/current-stage3/default/20130321/stage3-amd64-20130321.tar.bz2'\r\nmkdir rootfs\r\n# basically following the Gentoo Handbook from here to get our initial chroot environment setup (which should be sufficient for a docker image, too, in theory)\r\n(cd rootfs \u0026\u0026 sudo tar xvjpf ../stage3-amd64-20130321.tar.bz2)\r\nsudo vim rootfs/etc/portage/make.conf # just to verify CFLAGS/CXXFLAGS and add GENTOO_MIRRORS and SYNC as per the handbook -- not strictly necessary just to get a working chroot environment\r\nsudo vim rootfs/etc/resolv.conf # to add nameservers -- also not strictly necessary for a \"working\" chroot environment\r\nsudo tar -C rootfs -c . | sudo docker import - tianon/gentoo\r\n```\r\n\r\nI suppose I really ought to go look at that example script and make sure I'm not missing something important that makes a docker image different from the stage3 I've created.","Could it be the fact that the stage3 dev is not empty, and thus wouldn't like being mounted on top of without force?  Any other directories that might have similar issues?  Are dev, proc, and sys mounted by docker/lxc directly?","I really like the idea of placeholders for use cases with a request for help fleshing them out.\r\n\r\nI don't think we need a new \"future\" section for that. We can simply use the existing \"examples section\". See for example https://github.com/dotcloud/docker/blob/master/docs/sources/examples/python_web_app.rst","So something like ``../examples/future.rst`` where the above mentioned script would offer a choice of checking what's cooking (about to cook) or to proceed to basic commands?\r\n\r\n(I believe python_web_app page describes a scenario that _is_ currently supported)","I think it's better to mix supported and unsupported use cases in one place, and mention the current status for each. In fact most of the use cases *are* already supported, just poorly documented. For example, the use case in your pull request definitely is supported already :) Just not with this particular command.\r\n\r\nSo over time there would be a single, easily accessible list of use cases, and we would all flesh it out together.\r\n\r\nDoes this makes sense?","i'll re-think the proposal and submit a new pr.","+1 (am I doing this right?)\r\n\r\nFor various reasons, I pull images from S3, be nice to pull image diffs, too.","Wouldn't `docker export` be an answer to that? Or am I misunderstanding the request?","docker uses a composed filesystem layered from the various images that form the history. Each image is only a small set of files. A container is built from an image and all it's parents forming a complete filesystem. docker export doesn't export images and there for doesn't export the metadata, history, or seperation of images. docker export exports entire containers, ie all the layers are collapsed to one. If I fetch from a git bundle multiple times, the identity of the imported objects remains the same and the size of my on disk storage remains the same. If I docker import a tarball from docker export I get multiple new images that are each very large because they have the base layers included in each one of them.\r\n\r\nEven better than just exporting the individual layers in a common tarball would be to support the git format of COMMITID..COMMITID. For docker it would be IMAGEID..IMAGEID. That way that I can export a few thin layers where I know or assume that the recipient already has the other parent layers. This keeps the exported tarball size down in addition to the keeping the docker image storage size down after import.","+1\r\n\r\nThis would really seem to help with building images on one system and deploying them elsewhere. Currently I can do it by committing containers but the resulting tarballs are fairly large compared to the actual changes to the filesystem from a previous known image. Being able to redistribute images without going through a registry seems like a great step.","+1\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Tue, Jul 9, 2013 at 7:35 AM, Michael Merickel \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e +1\r\n\u003e This would really seem to help with building images on one system and deploying them elsewhere. Currently I can do it by committing containers but the resulting tarballs are fairly large compared to the actual changes to the filesystem from a previous known image. Being able to redistribute images without going through a registry seems like a great step.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/316#issuecomment-20678170",":+1: ","Scheduling tentatively for 0.8","My favorite approach for that would be to allow push/pull to a plain\ndirectory (in other words, using the local filesystem* as registry).\n\n*local filesystem = local mountpoint, so it could be NFS, CephFS,\nGlusterFS, or anything like that.\n\nIn any case, once you can push/pull to the local FS, it makes shipping\nimages a trivial task.","+1 for @jpetazzo 's idea","+1\r\n\r\nThis would open up many doors for Docker—given that many people can't publicly disclose their containers, and yet don't get around to setting up their own private registry with all the maintenance that entails.","Docker 0.7 now has `save` and `load` that allow you to do offline image transfers via tar along with all the history and metadata.","@shykes @creack I think this is ready to be merged. Will squash as soon as you validate it!","Could you describe how you might use it, with an emphasis on use cases that\r\nare not possible without it?\r\n\r\nThanks!\r\n\r\n\r\nOn Tue, Apr 2, 2013 at 11:16 AM, Carter Charbonneau \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e It would be great to have support for ZFSonLinux volumes instead of\r\n\u003e filesystem images.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/319\u003e\r\n\u003e .\r\n\u003e","Well there should be a good speed gain and volumes (as block devices or just using ZFS as the FS in guest (lxc)) should be easier to manage than FS images on ZFS. \r\nSee http://zfsonlinux.org/example-zvol.html for details on ZFS volume block device.\r\nSee http://zfsonlinux.org/example-zpl.html for normal ZFS (ZFS on ZVOL).","To be clear, this would only be useful for existing ZFSonLinux users.","I did a proof-of-concept implementation of docker using BTRFS, and I'm I started to look how to map this on ZFS. Don't expect fast progress here (I'm doing this on my spare time), but I'm definitely looking at it.","This will be possible as a plugin with the upcoming plugin API.","+1 also very much interested in ZoL support","This is actually expected. As golang does not as a 'final' function (as opposed with init()), we can't remove the image.\r\n\r\nThe tests needs a new environment each time, so in order to avoid the UT image to be redownloaded each time, it is done once in the init() and tests just copy it each time.\r\n\r\nIf you have ideas how to solve this, I take :)","Maybe combine this with #279 and always create a dummy runtime in a known\r\nlocation, eg. /var/lib/docker-ut ? The 'docker pull docker-ut' would take\r\nplace in there and could be used as a cache in between test runs.\r\n\r\n\r\nOn Thu, Apr 11, 2013 at 12:14 PM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e This is actually expected. As golang does not as a 'final' function (as\r\n\u003e opposed with init()), we can't remove the image.\r\n\u003e\r\n\u003e The tests needs a new environment each time, so in order to avoid the UT\r\n\u003e image to be redownloaded each time, it is done once in the init() and tests\r\n\u003e just copy it each time.\r\n\u003e\r\n\u003e If you have ideas how to solve this, I take :)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/324#issuecomment-16255177\u003e\r\n\u003e .\r\n\u003e","There is currently discussion to run tests in a docker container or within a qemu vm. If this happens, we can close out this bug.","Is this fixed by z_final_test?","IMHO it shouldn't be handled by a dummy last test, but by the special\nruntime that we use in the tests.\nIt is very common (at least for me :-)) to only run a small subset of the\ntests while developing (just because running all the tests takes a while).","I agree it's not ideal. But the fact is it's probably the best the Golang test suite itself can do (we got the trick straight from bradfitz). We can't handle it in the test runtime because some state is shared between tests, and there is no \"end of tests\" hook.\r\n\r\n    \r\n       \r\n\r\n      +1 to the test container itself handling it, but I'd say that's outside the scope of this issue.\r\n\r\n    \r\n\r\n    —\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sat, Aug 24, 2013 at 12:47 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e IMHO it shouldn't be handled by a dummy last test, but by the special\r\n\u003e runtime that we use in the tests.\r\n\u003e It is very common (at least for me :-)) to only run a small subset of the\r\n\u003e tests while developing (just because running all the tests takes a while).\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/324#issuecomment-23215230","Could we potentially use gocheck? It's supposed to be compatible with\r\ngotest and supports setup/teardown for both tests and suites.","The tests have been cleaned up to not leave anything behind in /tmp, *and* we now run all test suites in a container of its own.\r\n","Same issue as #197 I think.","Agreed.","This patch needs a `gofmt`.","Alright, I removed the underscores from the structures fields.","Is this or #327 the reason why git log -1 doesn't work in docker, nor git push origin master?","As you changed the commands, the commands_test.go should be updated.\r\n\r\nThe tests fail.","See PR https://github.com/lopter/docker/pull/1","I can reproduce the problem. This might have something to do with #326.","This happens when I run this with a tty:\r\n```\r\ndocker run -i -t base less /root/.bashrc\r\n```\r\n\r\nIt doesn't happen when a tty isn't used:\r\n```\r\ndocker run -i  base less /root/.bashrc\r\n```","Is this or #326 the reason why git log -1 doesn't work in docker, nor git push origin master?","Could you try again with latest master? Binary builds have been updated so you can try that.","```git log -1```\r\ndoes not work and the case above \r\n```docker run -i -t base less /root/.bashrc``` results in a container that can't be used again till it is stopped and started","@wsoula I've just tried it and I'm not encountering this problem any more with the latest master.\r\n\r\nI think your docker isn't the latest one.\r\nJust for reference, this is what my docker is saying:\r\n```\r\ndocker version\r\nVersion:0.1.3\r\nGit Commit:0767916\r\n```","@unclejack Here are my commands\r\n   07:20:06 ~/git/docker\u003e make clean all\r\n   bin/docker is created.\r\n   07:20:18 ~/git/docker\u003e docker version\r\n   Version:0.1.1\r\n   07:20:21 ~/git/docker\u003e git remote -v\r\n   origin\tgit@github.com:dotcloud/docker.git (fetch)\r\n   origin\tgit@github.com:dotcloud/docker.git (push)\r\n   07:20:28 ~/git/docker\u003e git pull origin master\r\n   From github.com:dotcloud/docker\r\n    * branch            master     -\u003e FETCH_HEAD\r\n   Already up-to-date.\r\n   07:20:33 ~/git/docker\u003e make clean all\r\n   bin/docker is created.\r\n   07:20:40 ~/git/docker\u003e bin\r\n   bin/  bind  \r\n   07:20:40 ~/git/docker\u003e bin\r\n   bin/  bind  \r\n   07:20:40 ~/git/docker\u003e bin/docker version\r\n   Version:0.1.1\r\n\r\nWhat have I done wrong?","@wsoula Your docker is too old and it looks like docker isn't actually being rebuilt.","@unclejack How can I rebuild it?","@wsoula \r\n```\r\nwhich docker\r\n/you/will/get/a/path/to/the/docker/you/are/really/executing\r\n\r\nmake clean all\r\ncp bin/docker /you/will/get/a/path/to/the/docker/you/are/really/executing\r\ndocker version\r\n```","@unclejack I've symlinked my bin/docker binary to my bin folder in my path so i wouldn't have to copy it:\r\n    07:37:19 ~/git/docker\u003e which docker\r\n    /usr/local/bin/docker\r\n    07:37:48 ~/git/docker\u003e ls -l /usr/local/bin/docker\r\n    lrwxrwxrwx 1 root root 41 Apr  4 09:14 /usr/local/bin/docker -\u003e /home/william.soula/git/docker/bin/docker\r\n    07:37:56 ~/git/docker\u003e pwd\r\n    /home/william.soula/git/docker","@wsoula It looks like that's not working properly.\r\n\r\nAlso, what's your $GOPATH?\r\n```\r\necho $GOPATH\r\n```\r\n\r\nMaybe you can drop by on IRC so I can try to help you.","@unclejack My $GOPATH is empty, what should it be?  I'll see if I can get on irc.","The devs were helpful enough to try and help me in irc and my problem was not stopping the daemon so when docker ran it was always running the old version because the daemon never stopped.  Once I figured that out I could do a make in the root and get the correct version and have the following work correctly\r\n```git log -1``` \r\n```git push origin master```\r\n```docker run -i -t base less /root/.bashrc``` ","Ok, please close the issue if the problem is solved.","@unclejack I don't have permissions to close it, I didn't open this one","@wsoula Sorry, I mixed up the issues.","Pull request #329 has fixed the problem for all cases in which it would show up for me - running bash and executing \"exit\" and running one off commands.","+1\r\n\r\nI'm looking forward to seeing this pull request merged as this error shows up in a few places already.","This fixes the loopback problem for me from another container, however I still see the problem from within the host.\r\n\r\nEg.\r\n\r\n```bash\r\n$ ID=$(docker run -d  -p 5000 base nc -l -p 5000)\r\n\r\n$ PORT=$(docker port $ID 5000)\r\n49155\r\n\r\n$ curl www.google.com:$PORT\r\ncurl: (52) Empty reply from server\r\n\r\n$ docker logs $ID\r\nGET / HTTP/1.1\r\nUser-Agent: curl/7.27.0\r\nHost: www.google.com:49155\r\nAccept: */*\r\n\r\n$\r\n```\r\n\r\nDoes anybody else see this too? If so can we fix it with this PR, or does it require a separate fix?","@shykes Let me check it out, please.","@shykes This fixes it. You can build and try again.\r\n```\r\ncurl www.google.com:$PORT\r\ndoesn't work\r\n\r\ncurl 10.0.3.1:$PORT\r\ncurl: (52) Empty reply from server\r\n```\r\n\r\nIt looks like something else happened when I was testing before and thought the same change isn't necessary for this part as well.","It worked this time! I added extra cleanup to keep reverse compatibility with older versions. Otherwise it crashed when trying to clean up iptables rules :)\r\n\r\nThanks!","Thanks!","@shykes How would you like this to work? Could you provide an example of how this should work, please?\r\n\r\nIt looks like AUFS has some limit with 39-41 layers. We should really have image flattening in order to allow commit-\u003erun-\u003ecommit to be used after deployment as well.","Ping. \r\n\r\nMy dockerfiles grow as I find neat stuff like this https://gist.github.com/jpetazzo/6127116\r\n\r\nand IIRC, each RUN line makes a new level of AUFS, no? \r\n\r\nI'm basically ignorant about many things, happy to admit it - if a \"docker flatten\" isn't coming down the pipe soon, does anyone have a reference for how to do it by hand? Or a reason it can't be? \r\n\r\n(I guess I could workaround by moving all of the RUN lines into a single shell script, so it's not vital; but I can't do that with someone else's image. Hmm. Is there a way to \"decompile\" an image, recreating the Dockerfile used for it (assuming it was done entirely by a Dockerfile, of course). ","I encountered this recently too when building images. Will something like http://aufs.sourceforge.net/aufs2/shwh/README.txt help here ?","I made a small tool to flatten images: https://gist.github.com/vieux/6156567\r\n\r\nYou have to use full ids, to flatten dhrp/sshd : sudo python flatten.py 2bbfe079a94259b229ae66962d9d06b97fcdce7a5449775ef738bb619ff8ce73","+1\r\n\r\ni see the need too.\r\nif possible i would like a command that allows both, flatten all and squashing some selected layers.\r\n\r\nif a container is flattened we should think about what happends when it is pushed. the registry / index could remove unneeded / duplicated layers, if enough inormation is sent during the push.\r\nlike \"replaces Xxxxxxxxx, yyyyyyy, zzzzzzz\"\r\n\r\n","FWIW, the \"aubrsync\" (in aufs-tools package) might be useful for that,\nsince it aims at synchronizing and merging AUFS branches.","From my answer in a different thread:\r\n\r\nCurrently the only way to \"squash\" the image is to create a container from it, export that container into a raw tarball, and re-import that as an image. Unfortunately that will cause all image metadata to be lost, including its history but also ports, env, default command, maintainer info etc. So it's really not great.\r\n\r\nThere are 2 things we can do to improve the situation:\r\n\r\n1) A short-term solution is to implement a \"lossless export\" function, which would allow exporting an image to a tarball with all its metadata preserved, so that it can be re-imported on the other side without loss. This would preserve everything except history, because an image config does not currently carry all of its history. We could try to plan this for 0.7 which is scheduled for mid-September. That is, if our 0.7 release manager @vieux decides we have time to fit it in the release :)\r\n\r\n2) A 2nd step would be to add support for history as well. This is a little more work because we need to start storing an image's full history in each image, instead of spreading it out across all the aufs layers. This is planned for 0.8.\r\n","Hey guys, here's an idea we are prototyping. Let's say an image consists of 4 layers\r\n\r\nL1\u003c-L2\u003c-L3\u003c-L4\r\n\r\nWhen we start a container off L4, we make changes in L5. Once the changes are complete, we commit back to get a new image\r\n\r\nL1\u003c-L2\u003c-L3\u003c-L4\u003c-L5\r\n\r\nAt this point, we do a post-commit merge step where we start a new container, L4A from L3. We copy L5 \u0026 L4 into L4A and create a new image like this\r\n\r\nL1\u003c-L2\u003c-L3-\u003c-L4A\r\n\r\nThis way, we preserve the impermutable nature of the image but can compress layers when necessary to create new images \r\n\r\n","@shykes @ykumar6  i did some experiments on exporting the image and trying to preserve metadata last night here https://github.com/dqminh/docker-flatten . Would love to know if the approach is reasonable.\r\n\r\nWhat it does is that it will try to compress all image's layers into a tarfile, generate a dockerfile with as much metadata as possible, and create a new image from that.","Question: do we really want to flatten existing images, or to reduce the number of layers created by a Dockerfile?\r\n\r\nIf we want to flatten existing images, it could be the job of an external tool, which would download layers, merge them, upload a new image.\r\n\r\nIf we want to reduce the number of layers, we could have some syntactic sugar in Dockerfiles, meaning \"don't commit between those steps because I want to reduce the number of layers *or* the first steps are creating lots of intermediary files that I clean up later and don't want to includee in my layers\".","@jpetazzo Removing commits done between two steps of a Dockerfile would be useful, but we might still want to be able to flatten images. There are some use cases which require \"-privileged\" to be provided during a run and that's not possible with a Dockerfile, so you have to script a Dockerfile run, some `docker run -privileged` steps and then commit.\r\nWe might also want to craft custom images which have one layer and one single parent layer (a common image such as ubuntu, centos, etc).","@jpetazzo I would say both, as they address separate issues.\r\n\r\nFlattening existing images allows you to work around the AUFS branch limit (you can only stack so many images), in the case where you're building on someone else's image, and someone else builds on yours, and your stack ends up hitting the limit pretty quick.\r\n\r\nThe syntactic sugar in the Dockerfile would allow building docker images that necessitate large toolchains to build and produce a comparatively small result (which I would argue is the more pressing of the two issues). Without it, a 2GB toolchain building a 10MB image will result in a 2058MB image.","I second the syntactic sugar - but I'd flip-flop it, in that I do a bunch of stuff (package building), and I really only want to commit the last step.\r\n\r\nMaybe simply having an explicit \"COMMIT imagename\" in the dockerfile? And an implicit one right at the end? (I actually think commit at the end is sufficient - I'm not sure what use I'd have for an intermediate image, where I wouldn't just do it with a seperate dockerfile...)\r\n\r\nI'll admit the AUFS limit was floating around in the back of my brain, but being able to flatten an arbitrary dockerfile is perfectly adequate for me there. (Doing so *AND* keeping history would be even nicer). ","I am somewhat fond of @bortels idea. I can see use cases where you would want the intermediate steps when building the dockerfile (incase something fails, like apt-get due to networking). You would want to be able to resume at that step. However it would be nice to say \"When this is done\" or \"When you get to point A\" squash the previous layers.","An idea and script by Maciej Pasternacki:\r\nhttp://3ofcoins.net/2013/09/22/flat-docker-images/\r\n\r\nDocker looks really exciting, but the limit of 42 layers could cause some issues if a docker needs to be updated over a few years. Flattening every now and then doesn't sound so bad though.","When I started using Docker I soon wished for a \"graft\" command for image maintenance. Something like this:\r\n\r\n    $ docker graft d093370af24f 715eaaea0588\r\n    67deb2aef0e0\r\n\r\n    $ docker graft d093370af24f none\r\n    e4e168807d31\r\n\r\n    $ docker graft -t repo:8080/ubuntu12 d093370af24f 715eaaea0588\r\n    67deb2aef0e0\r\n\r\nIn other words it would basically change the parent of an image, or make it into a parent-less base image, and then return the new ID (possibly tagging/naming it). Would it be really slow because it'd have to bring both images into existence and compare them?\r\n\r\n\r\nI like the \"COMMIT\" idea too. Or better, a \"make a flattened image\" flag when building, since this is really is more of a build option.\r\n\r\n\r\n(Confession: I love Docker but the concept of the Dockerfile never clicked with me. Why add extra syntax just to run some shell commands? Why commit intermediate steps? So I've been making containers 100% with shell scripts. It's nice because it forces me to create build/setup scripts for my code, which is useful outside of Docker).","Re \"why commit intermediate steps\": I find it very convenient when I have\r\nlonger Dockerfiles; when I modify one line, it only re-executes from that\r\nline, thanks to the caching system; that saves me time+bandwidth+disk\r\nspace, since the first steps are usually those big \"apt-get install\" etc.;\r\nof course, I could do the apt-get install and other big steps in a separate\r\nDockerfile, then commit that, then start another Dockerfile \"FROM\" the\r\nprevious image; but the Dockerfile caching system makes the whole thing way\r\neasier. At least, to me :-)\r\n\r\n\r\n\r\nOn Wed, Sep 25, 2013 at 5:25 PM, a7rk6s \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e When I started using Docker I soon wished for a \"graft\" command for image\r\n\u003e maintenance. Something like this:\r\n\u003e\r\n\u003e $ docker graft d093370af24f 715eaaea0588\r\n\u003e 67deb2aef0e0\r\n\u003e\r\n\u003e $ docker graft d093370af24f none\r\n\u003e e4e168807d31\r\n\u003e\r\n\u003e $ docker graft -t repo:8080/ubuntu12 d093370af24f 715eaaea0588\r\n\u003e 67deb2aef0e0\r\n\u003e\r\n\u003e In other words it would basically change the parent of an image, or make\r\n\u003e it into a parent-less base image, and then return the new ID (possibly\r\n\u003e tagging/naming it). Would it be really slow because it'd have to bring both\r\n\u003e images into existence and compare them?\r\n\u003e\r\n\u003e I like the \"COMMIT\" idea too. Or better, a \"make a flattened image\" flag\r\n\u003e when building, since this is really is more of a build option.\r\n\u003e\r\n\u003e (Confession: I love Docker but the concept of the Dockerfile never clicked\r\n\u003e with me. Why add extra syntax just to run some shell commands? Why commit\r\n\u003e intermediate steps? So I've been making containers 100% with shell scripts.\r\n\u003e It's nice because it forces me to create build/setup scripts for my code,\r\n\u003e which is useful outside of Docker).\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/332#issuecomment-25135724\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\n@jpetazzo \u003chttps://twitter.com/jpetazzo\u003e\r\nLatest blog post: http://blog.docker.io/2013/09/docker-joyent-openvpn-bliss/","On Wed, Sep 25, 2013 at 5:25 PM, a7rk6s \u003cnotifications@github.com\u003e wrote:\n\n\u003e When I started using Docker I soon wished for a \"graft\" command for image\n\u003e maintenance. Something like this:\n\u003e\n\u003e $ docker graft d093370af24f 715eaaea0588\n\u003e 67deb2aef0e0\n\u003e\n\u003e $ docker graft d093370af24f none\n\u003e e4e168807d31\n\u003e\n\u003e $ docker graft -t repo:8080/ubuntu12 d093370af24f 715eaaea0588\n\u003e 67deb2aef0e0\n\u003e\n\u003e In other words it would basically change the parent of an image, or make\n\u003e it into a parent-less base image, and then return the new ID (possibly\n\u003e tagging/naming it). Would it be really slow because it'd have to bring both\n\u003e images into existence and compare them?\n\u003e\n\u003e I like the \"COMMIT\" idea too. Or better, a \"make a flattened image\" flag\n\u003e when building, since this is really is more of a build option.\n\u003e\nThis problem will go ahead on its own once each image carries its full\nhistory (currently history is encoded in the chain of aufs layers, which\navoids duplication of data, but means you can't get rid of one without\ngetting rid of the other, hence the problem we're discussing).\n\nOnce that's in place, whether you commit at each build step or only at the\nend will be entirely up to you (the person running the build). Depending on\nthe granularity you want. More granularity = more opportunities to re-use\npast build steps and save bandwidth and disk space on upgrades. Less\ngranularity = you can remove build dependencies from the final image,\nexport to a single tarball without losing context, etc. I doubt we'll add\nany syntax to the Dockerfile to control that.\n\n\n\u003e (Confession: I love Docker but the concept of the Dockerfile never clicked\n\u003e with me. Why add extra syntax just to run some shell commands? Why commit\n\u003e intermediate steps? So I've been making containers 100% with shell scripts.\n\u003e It's nice because it forces me to create build/setup scripts for my code,\n\u003e which is useful outside of Docker).\n\u003e\nThat's a common misunderstanding. Dockerfiles are not a replacement for\nshell scripts. They provide *context* for running shell scripts (or any\nother kind of script) from a know starting point (hence the FROM keyword)\nand a known source code repository (hence the ADD keyword).","s/the problem will go ahead/the problem will go away/\n\n\nOn Wed, Sep 25, 2013 at 5:36 PM, Solomon Hykes\n\u003csolomon.hykes@dotcloud.com\u003ewrote:\n\n\u003e On Wed, Sep 25, 2013 at 5:25 PM, a7rk6s \u003cnotifications@github.com\u003e wrote:\n\u003e\n\u003e\u003e When I started using Docker I soon wished for a \"graft\" command for image\n\u003e\u003e maintenance. Something like this:\n\u003e\u003e\n\u003e\u003e $ docker graft d093370af24f 715eaaea0588\n\u003e\u003e 67deb2aef0e0\n\u003e\u003e\n\u003e\u003e $ docker graft d093370af24f none\n\u003e\u003e e4e168807d31\n\u003e\u003e\n\u003e\u003e $ docker graft -t repo:8080/ubuntu12 d093370af24f 715eaaea0588\n\u003e\u003e 67deb2aef0e0\n\u003e\u003e\n\u003e\u003e In other words it would basically change the parent of an image, or make\n\u003e\u003e it into a parent-less base image, and then return the new ID (possibly\n\u003e\u003e tagging/naming it). Would it be really slow because it'd have to bring both\n\u003e\u003e images into existence and compare them?\n\u003e\u003e\n\u003e\u003e I like the \"COMMIT\" idea too. Or better, a \"make a flattened image\" flag\n\u003e\u003e when building, since this is really is more of a build option.\n\u003e\u003e\n\u003e This problem will go ahead on its own once each image carries its full\n\u003e history (currently history is encoded in the chain of aufs layers, which\n\u003e avoids duplication of data, but means you can't get rid of one without\n\u003e getting rid of the other, hence the problem we're discussing).\n\u003e\n\u003e Once that's in place, whether you commit at each build step or only at the\n\u003e end will be entirely up to you (the person running the build). Depending on\n\u003e the granularity you want. More granularity = more opportunities to re-use\n\u003e past build steps and save bandwidth and disk space on upgrades. Less\n\u003e granularity = you can remove build dependencies from the final image,\n\u003e export to a single tarball without losing context, etc. I doubt we'll add\n\u003e any syntax to the Dockerfile to control that.\n\u003e\n\u003e\n\u003e\u003e (Confession: I love Docker but the concept of the Dockerfile never\n\u003e\u003e clicked with me. Why add extra syntax just to run some shell commands? Why\n\u003e\u003e commit intermediate steps? So I've been making containers 100% with shell\n\u003e\u003e scripts. It's nice because it forces me to create build/setup scripts for\n\u003e\u003e my code, which is useful outside of Docker).\n\u003e\u003e\n\u003e That's a common misunderstanding. Dockerfiles are not a replacement for\n\u003e shell scripts. They provide *context* for running shell scripts (or any\n\u003e other kind of script) from a know starting point (hence the FROM keyword)\n\u003e and a known source code repository (hence the ADD keyword).\n\u003e\n\u003e","\u003e They provide *context*\r\n\r\nMakes sense. Though, the Dockerfiles I've seen in the wild have been all over the place (as are the ones I've created, since I'm still trying to find the best way to lay things out so it's easy to develop / maintain / repurpose chunks to make different images).\r\n\r\n\u003e once each image carries its full history \r\n\r\nOut of curiosity, will it be possible to do, e.g., \"apt-get clean\" *after* the image has been built, and end up with less disk space used?","I am assuming this didn't make it into .7 as previously mentioned.  Any plans for the next release?","Am I understanding this correctly?  An image can only have a maximum of ~40 RUN/ADD statements in its entire lifetime.. including inheritance?","The limit is now 127 layers. That's the hardcoded maximum layers in an aufs mount.\r\n\r\n\r\n\r\n\r\nWe are working an lifting this by separating commit history from logical history.\r\n\r\nOn Sat, Dec 28, 2013 at 4:23 AM, Luke Chavers \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Am I understanding this correctly?  An image can only have a maximum of ~40 RUN/ADD statements in its entire lifetime.. including inheritance?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/332#issuecomment-31295648","Ah... great.  Any limit in that regard would be reaallly bad, I think, as it completely eliminates the ability to put anything that updates inside of Docker.  i.e. A website deployment..","You can easily update your website any number of times without increasing the number of layers. Just re-run \"docker build\" for each version of the website. Build caching will make sure it's fast and doesn't waste disk space.\r\n\r\nOn Sat, Dec 28, 2013 at 9:06 PM, Luke Chavers \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Ah... great.  Any limit in that regard would be reaallly bad I think as it completely eliminates the ability to put anything that updates inside of Docker without losing the benefits of Docker.  i.e. A website deployment..\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/332#issuecomment-31311588","See #3116 for another potential user interface suggestion for solving this same problem.","I'm fine with Dockerfile build committing each RUN/ADD command into another layer, it makes really fast to develop the Dockerfile. But after the build command completes without error I'd really much like that it would flatten all steps so that the end result would be one image which is added on top of the FROM image, instead of having to ship and push all images in between.","@garo, I think it should be optional as to how much you quash the image. That way people could choose to inherit from base-images or not. Choosing which image ID you'd like to compress down to would be of benefit\r\n\r\ne.g.  Given the following tree:\r\n\r\n```\r\n└─ad18ff9f83df Virtual Size: 484.7 MB Tags: myimage:latest\r\n    └─f45f88e50248 Virtual Size: 552.7 MB\r\n        └─3e5747d65960 Virtual Size: 552.8 MB\r\n            └─8c381ae7a086 Virtual Size: 563.6 MB\r\n                └─13d909f018b8 Virtual Size: 563.6 MB Tags: ubuntu:12.04```\r\n\r\n```docker squash [IMAGE] [FROM] [TO]```\r\n\r\n```docker squash myimage:latest 13d909f018b8 ad18ff9f83df```\r\n\r\nThe above example would result in there only being two images at the end, the base image `13d909f018b8` and `ad18ff9f83df` (myimage:latest).\r\n\r\nJust an idea. I've not even looked into the way AUFS works, so this is purely an idea from an end-user perspective.\r\n\r\nEDIT: Fixing tree formatting","@garo @davidrobertwhite Given the syntax that I recommended in #3116, you can easily perform this explicitly by asking for only one COMMIT at the end of the `Dockerfile`. Without any `COMMIT` rules, it will use the current solution (one layer per RUN), and if you provide multiple `COMMIT` rules then you will be explicitly saying \"I want these pieces as separate layers\".\r\n\r\nThe benefits of this approach is that it's more forward compatible in some ways. For instance, it's possible that Docker might allow for (assuming it doesn't already) parallelized downloading of layers from the index. If you make everything into one giant layer, then you've effectively reduced the usefulness of such a feature. It's better for those kinds of things to be explicitly requested rather than implicitly. Even in the case without parallel downloads from the index, it's nice to have a few smaller layers than one giant one. That way, if a download fails, you don't have to re-download everything again.\r\n\r\nFurthermore, providing this also allows for people to say \"This layer updates the system\", \"This layer is where I installed Java\", \"This is where I installed the services for this machine\" by putting a separate `COMMIT` rule at each point in the `Dockerfile` process. The suggestion that makes development more difficult is a bit NIL, because there could be a flag to --commit-all or something similar. This could effectively allow someone to ignore the `COMMIT` rules. Manually ignoring vs manually requesting in this case is better, because the Dockerfile should represent what it is doing by default unless explicitly requested not to.\r\n\r\nTLDR: It's important to have some way of specifically asking for AUFS to commit at specific points, because the number of changes that one RUN command can make is very arbitrary, and squashing everything can cause problems as easily as not allowing a user to squash anything.","What about the case where you aren't using a dockerfile but instead have multiple commits on an image that update the same files. So you have multiple layers of edits of the same file and you need to compact them into a single layer and don't want to keep a history of all of the prior changes/layers?\r\n\r\n\u003e On Jan 23, 2014, at 4:24 PM, \"Brandon R. Stoner\" \u003cnotifications@github.com\u003e wrote:\r\n\u003e \r\n\u003e @garo @davidrobertwhite Given the syntax that I recommended in #3116, you can easily perform this explicitly by asking for only one COMMIT at the end of the Dockerfile. Without any COMMIT rules, it will use the current solution (one layer per RUN), and if you provide multiple COMMIT rules then you will be explicitly saying \"I want these pieces as separate layers\".\r\n\u003e \r\n\u003e The benefits of this approach is that it's more forward compatible in some ways. For instance, it's possible that Docker might allow for (assuming it doesn't already) parallelized downloading of layers from the index. If you make everything into one giant layer, then you've effectively reduced the usefulness of such a feature. It's better for those kinds of things to be explicitly requested rather than implicitly. Even in the case without parallel downloads from the index, it's nice to have a few smaller layers than one giant one. That way, if a download fails, you don't have to re-download everything again.\r\n\u003e \r\n\u003e Furthermore, providing this also allows for people to say \"This layer updates the system\", \"This layer is where I installed Java\", \"This is where I installed the services for this machine\" by putting a separate COMMIT rule at each point in the Dockerfile process. The suggestion that makes development more difficult is a bit NIL, because there could be a flag to --commit-all or something similar. This could effectively allow someone to ignore the COMMIT rules. Manually ignoring vs manually requesting in this case is better, because the Dockerfile should represent what it is doing by default unless explicitly requested not to.\r\n\u003e \r\n\u003e TLDR: It's important to have some way of specifically asking for AUFS to commit at specific points, because the number of changes that one RUN command can make is very arbitrary, and squashing everything can cause problems as easily as not allowing a user to squash anything.\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","I've been playing around with Redis within Docker and I've hit a couple of gotcha's where I'm not quite sure if there's something that I should be doing differently.  Any feedback or insight would be welcome!\r\n\r\n`docker pull johncosta/redis`\r\n`$ docker run -p 6379 -i -t johncosta/redis /bin/bash`  \r\n\r\n### tldr; \r\n- processes intended for start at startup are not running at container start\r\n- connections to the externally mapped port don't seem to connect correctly\r\n\r\n### the detail\r\n```\r\nvagrant@vagrant-ubuntu-12:/opt/go/src/github.com/dotcloud/docker$ docker version\r\nVersion:0.1.2\r\nGit Commit:\r\n```\r\n\r\n1) Restarting the docker container doesn't seem to start processes which should be running at startup.\r\n\r\nWithin my docker container I run the following to make sure that its set to run at startup: \r\n```\r\nroot@0be92ce8581e:/# update-rc.d redis-server defaults\r\nSystem start/stop links for /etc/init.d/redis-server already exist.\r\n```\r\n\r\nOnce the redis-server is started, I can see that its up and running:\r\n```\r\nroot@0be92ce8581e:/# /etc/init.d/redis-server startStarting redis-server: \r\nredis-server.\r\nroot@0be92ce8581e:/# ps faux\r\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\r\nroot         1  0.0  0.5  18068  1976 ?        S    16:23   0:00 /bin/bash\r\nredis       16  0.0  0.4  36624  1652 ?        Ssl  16:33   0:00 /usr/bin/redis-\r\nroot        19  0.0  0.3  15524  1108 ?        R    16:33   0:00 ps faux\r\n```\r\n\r\nNow I'll restart the container, reattach, and ps.. sadly no redis server running (I have to manually start it): \r\n```\r\n$ docker restart 0be92ce8581e\r\n0be92ce8581e\r\n\r\n$ docker attach 0be92ce8581e\r\n\r\nroot@0be92ce8581e:/# ps faux\r\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\r\nroot         1  0.0  0.5  18068  1904 ?        S    16:37   0:00 /bin/bash\r\nroot         7  0.0  0.3  15524  1104 ?        R    16:38   0:00 ps faux\r\n```\r\n\r\n2) It doesn't seem like I can connect to the externally mapped port. \r\n\r\nRelevant docker inspect information, trimmed for brevity\r\n```\r\n\"Config\": {        \r\n        \"Ports\": [\r\n            6379\r\n        ],\r\n\r\n\"NetworkSettings\": {\r\n        \"IpAddress\": \"10.0.3.12\",\r\n        \"IpPrefixLen\": 24,\r\n        \"Gateway\": \"10.0.3.1\",\r\n        \"PortMapping\": {\r\n            \"6379\": \"49156\"\r\n        }\r\n    },\r\n```\r\n\r\nNow I'll run telnet to make sure I can connect and interact locally:\r\n\r\n```\r\nroot@0be92ce8581e:/# telnet 127.0.0.1 6379\r\nTrying 127.0.0.1...\r\nConnected to 127.0.0.1.\r\nEscape character is '^]'.\r\n+OK\r\n$7\r\nawesome\r\n+OK\r\n+1365180468.638062 \"monitor\"\r\n+OK\r\n+1365180477.548031 \"set\" \"docker\" \"awesome\"\r\n$7\r\nawesome\r\n+1365180482.959256 \"get\" \"docker\"\r\n```\r\n\r\nNow try externally... \r\n```\r\nvagrant@vagrant-ubuntu-12:/opt/go/src/github.com/dotcloud/docker$ telnet 10.0.3.12 49156\r\nTrying 10.0.3.12...\r\ntelnet: Unable to connect to remote host: Connection refused\r\n```\r\n\r\n### Updates: \r\n\r\n- Included how I launch the container (originally)\r\n","It looks like the root of both issues was in how I was calling docker. Using the following seems to work much better as I'm able to connect to the the process externally using the method previously described in my comments.\r\n\r\n`docker run -d -p 6379 -i -t johncosta/redis /usr/bin/redis-server`\r\n\r\n```\r\nvagrant@vagrant-ubuntu-12:/opt/go/src/github.com/dotcloud/docker$ docker ps\r\nID             IMAGE                    COMMAND                CREATED         STATUS         COMMENT\r\nc0f7e48cafcf   johncosta/redis:latest   /usr/bin/redis-serve   4 minutes ago   Up 4 minutes   \r\nvagrant@vagrant-ubuntu-12:/opt/go/src/github.com/dotcloud/docker$ docker inspect c0f7e48cafcf\r\n{    \r\n\u003ctrimmed for brevity\u003e\r\n    \"NetworkSettings\": {\r\n        \"IpAddress\": \"10.0.3.30\",\r\n        \"IpPrefixLen\": 24,\r\n        \"Gateway\": \"10.0.3.1\",\r\n        \"PortMapping\": {\r\n            \"6379\": \"49174\"\r\n        }\r\n}\r\nvagrant@vagrant-ubuntu-12:/opt/go/src/github.com/dotcloud/docker$ telnet 10.0.3.30 49174\r\nTrying 10.0.3.30...\r\nConnected to 10.0.3.30.\r\nEscape character is '^]'.\r\nmonitor\r\n+OK\r\n+1365194060.897490 \"monitor\"\r\nset docker awesome\r\n+OK\r\n+1365194071.640199 \"set\" \"docker\" \"awesome\"\r\nget docker\r\n$7\r\nawesome\r\n+1365194073.519484 \"get\" \"docker\"\r\n```\r\n","Hey John,\n\nYup, that's correct. Docker is much more process-oriented than the usual lxc tools, so it will not \"boot\" containers by default - you need to tell it what to run.\n\nOne small comment: there is a convenience command to look up the public ports of a container without having to dig into the output of 'inspect':\n\n```bash\n$ docker port c0f7e48cafcf 6379\n49174\n\n$\n```\n\nThanks for the details! Are you still stuck on something?","Thanks for pointing out the port command! Not currently stuck. Now that I'm up and running I'd like to run some more thorough tests.","Once docker persistence is available (https://github.com/dotcloud/docker/issues/111) it will be interesting to extend  this usecase to include [Redis persistence features](http://redis.io/topics/persistence).","It looks like might want to close this? @johncosta @shykes ?","Yes, good catch. We used issues quite liberally in the early days, now that\r\nwe have passed the #1000 mark we should move things to the mailing list.\r\n\r\n\r\nOn Tue, Jun 25, 2013 at 5:35 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e It looks like might want to close this? @johncosta\u003chttps://github.com/johncosta\u003e\r\n\u003e @shykes \u003chttps://github.com/shykes\u003e ?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/333#issuecomment-20019138\u003e\r\n\u003e .\r\n\u003e","@natea did you found a solution to your problem ?","+1","+1","+1","I'll make a PR out of my gist, adding the bash completion to the contrib dir.","@felixbuenemann any update? If you don't have time I could help with this.","Oh sorry, forgot about it. I'll do it right now.","@dplarson Done, thanks for reminding me.","For ZSH, there is a good snippet for completion here: https://github.com/felixr/docker-zsh-completion","There is also this one integrated with oh-my-zsh: https://github.com/AeonAxan/oh-my-zsh/tree/master/plugins/docker","I've just submitted a pull request for a tidier version of the bash completion script I had written for myself","Big thanks to @shawnsi for his work on #221!","What version of go are you using? Are you in a different branch of the docker repository?\r\n\r\nEven when the constant is not defined (i.e. when doing go build manually) it should be working. You do nothing wrong :)","I ran go version and it said \"go version go1\"\r\nI am in the master branch of the docker repo\r\nAfter running apt-get update and then apt-get upgrade go \"go version\" reports \"go version go1\"  I then realized that to upgrade just go you do apt-get install go and I did that and it said it was up to date\r\n","This should fix it:\r\n```\r\nmake clean all\r\n```","I just witnessed the issue. Make doesn't see that the sub-repositories have been updated. The unclejack's workaround should work fine.\r\n","I like how you call him THE unclejack :)\r\n\r\nOn Friday, April 5, 2013, Guillaume J. Charmes wrote:\r\n\r\n\u003e I just witnessed the issue. Make doesn't see that the sub-repositories\r\n\u003e have been updated. The unclejack's workaround should work fine.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/338#issuecomment-15985569\u003e\r\n\u003e .\r\n\u003e","unclejack's workaround works for me, thanks!  Don't know if you want to leave this issue open or not, though.","@wsoula Perhaps you should leave it open until it's fixed in the code so running make clean is no longer needed.","edited: actually even though the devenvironment page says to use go it appears possible to still do a make, which has been working for me, will wait for another build to confirm","@wsoula is it fixed ?","I got busy and didn't test right away like I wanted to.  I just did a pull and then tried \"make\" and \"make clean all\" but they both got the same error:\r\n./docker.go:73: undefined: docker.ParseCommands\r\n./docker.go:125: too many arguments in call to docker.NewServer\r\n./docker.go:130: undefined: docker.ListenAndServe\r\n","This looks like an issue with your environment and how it's set up. I've used to have issues and had to do some extra work to fix it, but it seems it's always building properly now.\r\nGo has been updated and that might have also fixed some issues.","@wsoula are you using Go \u003e 1.1?","possibly not, `go version` reports go1.  I did another pull and this is the current error when doing make or make clean all [1].  I tried it on my mac where `go version` reports go1.1 darwin/amd64 and make works fine\r\n\r\n[1]\r\n```\r\nmake\r\n# github.com/dotcloud/docker/term\r\n/usr/lib/go/src/pkg/github.com/dotcloud/docker/term/term.go:113: undefined: getTermios\r\n/usr/lib/go/src/pkg/github.com/dotcloud/docker/term/term.go:120: undefined: setTermios\r\n# github.com/dotcloud/docker/utils\r\n../.gopath/src/github.com/dotcloud/docker/utils/utils.go:669: undefined: strings.TrimPrefix\r\nmake: *** [/home/william.soula/git/docker/bin/docker] Error 2```","@creack It looks like this is being caused by Go 1.0.0. Perhaps you can close this issue?","@wsoula @unclejack it is indeed related to go 1.0.0","Thanks Beau for your feedback. Your diagnosis is correct.\r\n\r\nActually I think it might make sense to explicitly ignore non-standard\r\nfilesystem extensions... This might make docker unsuitable for some use\r\ncases, but I suspect not for many... Since a lot of times filesystem flags\r\nare used for protection in a multi-tenant system, which becomes less of a\r\nproblem since Docker takes care of multi-tenancy.\r\n\r\nWhat do you think?\r\n\r\n\r\nOn Fri, Apr 5, 2013 at 2:27 PM, Beau Breon \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Hello,\r\n\u003e\r\n\u003e I just started working with docker but have been immediately hit with the\r\n\u003e following:\r\n\u003e\r\n\u003e $ sudo docker run -i -t base /bin/bash\r\n\u003e 2013/04/05 14:32:09 docker run -i -t base /bin/bash\r\n\u003e Image base not found, trying to pull it from registry.\r\n\u003e Pulling repository base\r\n\u003e Pulling tag base:ubuntu-12.10\r\n\u003e Pulling 27cf784147099545 metadata\r\n\u003e Pulling 27cf784147099545 fs layer\r\n\u003e 94863360/94863360 (100%)\r\n\u003e 2013/04/05 14:33:10 exit status 1: ./usr/bin/: Failed to set file flags\r\n\u003e ./usr/lib/x86_64-linux-gnu/gconv/: Failed to set file flags\r\n\u003e ./usr/lib/python3.2/__pycache__/: Failed to set file flags\r\n\u003e ./usr/share/consolefonts/: Failed to set file flags\r\n\u003e ./usr/share/man/man8/: Failed to set file flags\r\n\u003e ./usr/share/man/man1/: Failed to set file flags\r\n\u003e ./usr/share/perl/5.14.2/unicore/lib/Blk/: Failed to set file flags\r\n\u003e ./usr/share/i18n/locales/: Failed to set file flags\r\n\u003e ./usr/share/i18n/charmaps/: Failed to set file flags\r\n\u003e ./var/lib/dpkg/info/: Failed to set file flags\r\n\u003e ./var/cache/apt/archives/: Failed to set file flags\r\n\u003e bsdtar: Error exit delayed from previous errors.\r\n\u003e\r\n\u003e Goggling seems to show that this is likely an upstream known issue (\r\n\u003e http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=699499) from bsdtar\r\n\u003e caused when a tar package tries to restore file metadata like flags in use\r\n\u003e by one file system and not another. In this case I would guess that the\r\n\u003e base image was created on Ext2/3/4 and I am trying to extract it to BtrFS...\r\n\u003e\r\n\u003e I understand that restoring the flags in use are likely critical to the\r\n\u003e function and/or security of the container so striping them out of the\r\n\u003e archive or ignoring the errors (or requesting upstream to do either)\r\n\u003e probably aren't good solutions. So if that's true has anyone started any\r\n\u003e BtrFS based images that may be usable by those running with BtrFS? It sure\r\n\u003e would be nice if we could browse and/or query this image repository so I\r\n\u003e could potentially answer this question myself.\r\n\u003e\r\n\u003e Thanks for your efforts so far in creating this exciting piece of software!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/339\u003e\r\n\u003e .\r\n\u003e","I would say that if you are considering ignoring such errors that it would probably be advisable to have that available as a flag (or at least disable-able via a flag) so that future production environments can be more assured that the image has been extracted *exactly* as intended.  Additionally some documentation on how to start a new image from scratch would be helpful so that others can create images with a different file system.\r\n\r\nAnother approach might be to use a loopback mount for the image when it's file system differs from the host file system.  It would sacrifice some speed but maintains the consistency of the image.\r\n\r\nThis issue might pop up again with other file systems like XFS, ZFS, F2FS, etc...","Another place where this is likely to come up and is very crucial to container security would be SELinux flags. I really think it's better to keep the flags intact, especially when you just released a new Centos image.","That is definitely something to take into account.\r\n\r\nOn the other hand, my concern is portability across docker hosts - a\r\ncrucial feature of Docker. Following this path essentially creates\r\n\"flavors\" of docker hosts which will be mutually incompatible. Docker will\r\nneed a new facility to uniquely identify different versions of different\r\nfilesystems (what happens when ZFS introduces a new flag?) - or if it\r\ndoesn't, then a 3d-party tool will be needed to *really* use docker, which\r\nis even worse.\r\n\r\n\r\nSo, before anything: how crucial to security are these flags exactly? Could\r\nyou walk me through such a scenario? I don't know enough about how CentOS\r\ndoes this out of the box.\r\n\r\n\r\n\r\n\r\n\r\n\r\nOn Fri, Apr 5, 2013 at 2:57 PM, Beau Breon \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Another place where this is likely to come up and is very crucial to\r\n\u003e container security would be SELinux flags. I really think it's better to\r\n\u003e keep the flags intact, especially when you just released a new Centos image.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/339#issuecomment-15983033\u003e\r\n\u003e .\r\n\u003e","It would be interesting to figure out which flags caused the problem, because most (all?) recent filesystems use POSIX extended attributes, which are supported in identical ways on btrfs, ext4, and others. FWIW, extended attributes have been around for 10+ years :-)\r\n\r\nI quickly checked on local btrfs and ext4 filesystems, and could set immutable and user xattr on both. I don't have fancy distributed filesystems here (like ceph, glusterfs, or ocfs2) but posix attributes are advertised as being supported on them as well.","Well, the affected files are listed in the opening comment, it should just be a matter of looking at what flag or flags all of those files in the image have in common.  While nearly all linux filesystems may have the same flags, they are probably implemented differently on different file systems, perhpase bsdtar's approach to restoring the flag state is just too naive (like a simple dd or something to that effect?)","I'll see if I can investigate that this week. I wonder if it could be\nsomething silly like restoring the +i flag before other flags! Thanks for\nproviding the image anyway.","Just curious if there was a way then to get docker and bsdtar to work on a Btrfs filesystem? (Could libarchive be built in a way to make it work?) Any hope this might be fixed? I'd love to play with docker, but this is kind of a buzz kill. Docker looks pretty fun though - nice job. ","I haven't tried it yet, but I suspect that if you build your image from scratch on a btrfs file system then it the tar of the image shouldn't include any file flags that btrfs is incompatible with. This was my second idea.  The first idea which I used was simply to use lvm to create a new ext4 partition and mount it as /var/lib/docker.  This worked perfectly fine as one might expect...\r\n\r\nI had to search google pretty long and hard to find the process to create new images for docker, it might be good to add to the documentation at docker.io...  The following are the commands I used to create a Debian `wheezy` container at the repo path `rnd42/wheezy` a while after I applied my fix...\r\n\r\n     $ sudo apt-get install debootstrap\r\n     $ debootstrap wheezy ./wheezy\r\n     $ bsdtar -C ./wheezy -c . | docker import - rnd42/wheezy\r\n\r\nI haven't uploaded that image, but it was built on ext4 anyways so it probably wouldn't work any better for you.  I'd be interested to hear if performing the above on a btrfs file system works out ok, but I suspect it would.\r\n\r\n*(comment deleted and readded because for some reason it didn't pickup the markdown formatting from my email and was rather hard to read.)*","Wonder if we will be able to distribute btrfs-host created images to machines running docker on ext4?\r\n\r\nI hit this today -- btrfs on my workstation. I use LXC + btrfs integration for other projects.","```\r\n ~/mnt/precise  tar -C ./precise -c . | docker import - fujin/precise\r\n737b654b2eec\r\n```\r\n\r\nSeems to have worked.\r\n\r\nI'm pushing it up to the registry now.","I tried pulling your image (twice to be safe) but it failed, I then unmounted my ext4 /var/lib/docker volume and restarted the daemon so that the /var/lib/docker file structure would be rebuilt under btrfs and tried again but still got the same message:\r\n\r\n    $ docker pull fujin/precise\r\n    Pulling repository fujin/precise from https://index.docker.io/v1\r\n    Resolving tag \"fujin/precise:latest\" from [registry-1.docker.io]\r\n    Pulling 737b654b2eec0d06e9ebedc5fdf34f3f02fc99c28c96bb71684096d4b05e4805 metadata\r\n    Pulling 737b654b2eec0d06e9ebedc5fdf34f3f02fc99c28c96bb71684096d4b05e4805 fs layer\r\n    Downloading 157286400/? (n/a)\r\n    Error: exit status 1: ./var/cache/apt/archives/e2fsprogs_1.42-1ubuntu2_amd64.deb: Truncated tar archive\r\n    bsdtar: Error exit delayed from previous errors.\r\n\r\nWere you able to run commands through docker with this image, or just import and upload it?","That looks busted. Maybe the upload broke?\r\n\r\nI should clean the debs out of it. Let me give it a test run, sorry.","@rnd42 I cleaned out the debs, committed and re-pushed fujin/precise from my workstation.\r\n\r\nHere is the output\r\n\r\n```\r\n ~/dev/bento   master  docker push fujin/precise               \r\nProcessing checksums\r\nSending image list\r\nPushing repository fujin/precise to registry-1.docker.io (1 tags)\r\nPushing image fujin/precise:latest\r\nPushing 737b654b2eec0d06e9ebedc5fdf34f3f02fc99c28c96bb71684096d4b05e4805 metadata\r\nImage 737b654b2eec0d06e9ebedc5fdf34f3f02fc99c28c96bb71684096d4b05e4805 already uploaded ; skipping\r\nRegistering tag fujin/precise:latest\r\nPushing image fujin/precise:latest\r\nPushing b104af8f57116fd95f174a7e49b05edcaa3ed5231c6cb35f3bda2414778cd831 metadata\r\nPushing b104af8f57116fd95f174a7e49b05edcaa3ed5231c6cb35f3bda2414778cd831 fs layer\r\n92160/92160 (100%)\r\nRegistering tag fujin/precise:latest\r\n```\r\n\r\nCan you try again?","can I import this into another name or pull it somehow to test it myself?","Not that I'm aware of, but it's relatively easy to stop the daemon, sudo mv /var/lib/docker /var/lib/docker.bak \u0026\u0026 sudo mkdir /var/lib/docker then restart the daemon...  When done testing just stop the daemon, sudo rm -rf /var/lib/docker \u0026\u0026 mv /var/lib/docker.bak /bar/lib/docker and restart the daemon.","nuked my /var/lib/docker, trying to pull now..","Yep.. it's busted..\r\n\r\n```\r\n ~  docker pull fujin/precise\r\nPulling repository fujin/precise from https://index.docker.io/v1\r\nResolving tag \"fujin/precise:latest\" from [registry-1.docker.io]\r\nPulling b104af8f57116fd95f174a7e49b05edcaa3ed5231c6cb35f3bda2414778cd831 metadata\r\nPulling b104af8f57116fd95f174a7e49b05edcaa3ed5231c6cb35f3bda2414778cd831 fs layer\r\nDownloading 92160/? (n/a)\r\nPulling 737b654b2eec0d06e9ebedc5fdf34f3f02fc99c28c96bb71684096d4b05e4805 metadata\r\nPulling 737b654b2eec0d06e9ebedc5fdf34f3f02fc99c28c96bb71684096d4b05e4805 fs layer\r\nDownloading 157286400/? (n/a)\r\nError: exit status 1: ./var/cache/apt/archives/e2fsprogs_1.42-1ubuntu2_amd64.deb: Truncated tar archive\r\nbsdtar: Error exit delayed from previous errors.\r\n```\r\n\r\nHow do I get this thing removed?","Hi Fujin,\r\n\r\nI can remove it easily from the Registry. I just need to figure out which id is corrupted. Actually the Registry includes a system to prevent corrupted image (during transfer) to be available to download. In your case, it looks like there were no problems during the transfer but during layer generation locally.\r\n\r\nAn easier way for you is to update the tag \"latest\" to point to the previous layer. I'll ping you on IRC.","Updated latest tag to point at a good layer. @rnd42 maybe give it a shot.\r\n\r\nTested nuking my local installation and pulling from the Registry. Works: https://gist.github.com/fujin/54f0a193515c2147dcf0","@jpetazzo found out that when using gnu tar instead of bsd tar, it works just fine.\r\nThe issue is that gnu tar can't automatically determine the compression.\r\n@samalba Would it be possible for the registry to send the compression so we could use the regular 'tar' command?","@creack I don't think an extra header makes sense for that.\r\n\r\nRight now the Registry does not interpret the layer data, it passes back what submitted from Docker. It's a good thing to keep, it keeps the Registry independent from Docker's image format.\r\n\r\nWhat about adding those info to the layer's json? To handle old versions, if the format is not in the json, Docker could fallback on the default one. And problem solved.","Note: IMHO it should be fairly trivial to auto-detect the format before\nhanding the stream to tar...","For those of you still having fighting with that one, this is what worked for me:\r\n\r\n    dd if=/dev/zero of=/srv/docker.img seek=20M count=1 # sparse of maximum 10gb of space\r\n    mkfs.ext4 -j /srv/docker.img\r\n    mkdir -p /mnt/docker\r\n    mount -o loop /srv/docker.img /mnt/docker\r\n    rm -Rf /var/lib/docker                             # you should probably stop docker before doing that\r\n    ln -s /mnt/docker/ /var/lib/docker\r\n","@tobstarr take a look at #885 ","Fixes #14","Nice!\n\nOn Friday, April 5, 2013, Guillaume J. Charmes wrote:\n\n\u003e Put back the posix raw mode and add an escape sequence.\n\u003e\n\u003e ctrl-c and all signals are forwarded to the container. In order to detach,\n\u003e the escape sequence is ctrl-p + ctrl-q\n\u003e\n\u003e It would be nice to merge #326\u003chttps://github.com/dotcloud/docker/issues/326\u003eprior this to avoid unexpected output from commands.\n\u003e ------------------------------\n\u003e You can merge this Pull Request by running\n\u003e\n\u003e   git pull https://github.com/dotcloud/docker disable_signals-create_escape_sequence\n\u003e\n\u003e Or view, comment on, or merge it at:\n\u003e\n\u003e   https://github.com/dotcloud/docker/pull/341\n\u003e Commit Summary\n\u003e\n\u003e    - Disable signal catching and enable real posix raw mode\n\u003e    - Implement an escape sequence in order to be able to detach from a\n\u003e    container\n\u003e    - Look for the escape sequence only in tty mode\n\u003e\n\u003e File Changes\n\u003e\n\u003e    - *M* container.go\u003chttps://github.com/dotcloud/docker/pull/341/files#diff-0\u003e(6)\n\u003e    - *M* docker/docker.go\u003chttps://github.com/dotcloud/docker/pull/341/files#diff-1\u003e(10)\n\u003e    - *M* term/termios_linux.go\u003chttps://github.com/dotcloud/docker/pull/341/files#diff-2\u003e(3)\n\u003e    - *M* utils.go\u003chttps://github.com/dotcloud/docker/pull/341/files#diff-3\u003e(50)\n\u003e\n\u003e Patch Links:\n\u003e\n\u003e    - https://github.com/dotcloud/docker/pull/341.patch\n\u003e    - https://github.com/dotcloud/docker/pull/341.diff\n\u003e\n\u003e","thanks @vsekhar  and @titanous for the feedback :)","Tests pass, signal handling seems to work, Ctrl-C is now passed to the process as expected...\r\n\r\nBut I can't get the escape sequence to work. Ctrl-p Ctrl-q doesn't work for me.\r\n","Ok, worked for me this time! Pushing.","This has been merged into master. This pull request is for merging into another branch, so it is not auto-closing. Please only target master in your pull requests.\r\n\r\nThanks! Great work.","Fixed by #710 ","I'm closing this issue as Go 1.0.3 is already being used to build the official binaries..","It looks like this issue still needs some changes before docker is really built with Go 1.0.3.\r\n\r\nI've tested the changes to the docker build script and I will send a pull request.","Pull request #498 has been merged. Docker is being built with Go 1.0.3.","Thanks Ken! Any help on the docs is very very appreciated!","After reading #148, I think I just don't understand the difference between repositories, tags, and images. Closing this out.","It doesn't export image information, it only exports the data. It's symmetric with what you put into docker when you import an image - just a tarball with the image contents.\r\n\r\nExporting an image would be nice, I've found myself committing some changes to export and then remembered I have to export a container.","This will be fixed in the 1.0 architecture. Image and container format will be unified, and history \u0026 config will be embedded in the container itself and therefore be preserved by export.","+1 \r\nJudging by the other Github issues that reference this one, this would also include for metadata such as RUN, EXPOSE and ENV statements declared in Dockerfiles to also be retained when exported and imported?","@cespare can you solve your issues with `docker load` and `docker save` ?","I have been trying `load/save` but I have got a `No space exception`.\r\n\r\nBoth vm are identical clone with sufficient space (and I am following the command help guide from `master`).\r\n\r\n```\r\n# save an image on the first vm\r\ndocker save pra/imagename \u003e /media/sf_shared/repository.tar\r\n# then on another vm\r\ndocker load \u003c repository.tar \r\n2013/12/06 17:49:39 Error: exit status 2: tar: ./20386a30cccdb45d40455a8e5ab0ef9aea7a11da5c65f8cbcd7d8d741058523a/layer.tar: Wrote only 8192 of 10240 bytes\r\ntar: ./20386a30cccdb45d40455a8e5ab0ef9aea7a11da5c65f8cbcd7d8d741058523a/json: Cannot write: No space left on device\r\ntar: ./20386a30cccdb45d40455a8e5ab0ef9aea7a11da5c65f8cbcd7d8d741058523a/VERSION: Cannot write: No space left on device\r\n´´´\r\n","I've also been hitting the \"No space left on device\" error with docker 0.7.2. However I'm only hitting this when using the ```devicemapper``` storage driver. If use ```vfs``` or ```aufs``` the image can be imported just fine.\r\n\r\n```\r\ndocker import - HAVA-latest \u003c/HANA-latest.tar\r\n...\r\ntar: ./usr/share/icons/hicolor/22x22/apps/yast-ldap-server.png: Cannot create symlink to `../../../../YaST2/theme/SLE/icons/22x22/apps/yast-ldap-server.png': No space left on device\r\ntar: ./etc/alternatives/jce_1.6.0_ibm_local_policy: Cannot create symlink to `/usr/lib64/jvm-private/java-1_6_0-ibm/jce/vanilla/local_policy.jar': No space left on device\r\ntar: ./etc/alternatives/jce_1.6.0_ibm_us_export_policy: Cannot create symlink to `/usr/lib64/jvm-private/java-1_6_0-ibm/jce/vanilla/US_export_policy.jar': No space left on device\r\ntar: Exiting with failure status due to previous errors\r\n```\r\n\r\nPlenty of space on my HDD:\r\n```\r\nFilesystem      Size  Used Avail Use% Mounted on\r\n/dev/sda6       458G   36G  399G   9% /\r\nudev            3.9G  4.0K  3.9G   1% /dev\r\ntmpfs           1.6G  300K  1.6G   1% /run\r\nnone            5.0M     0  5.0M   0% /run/lock\r\nnone            3.9G     0  3.9G   0% /run/shm\r\n/dev/sda1        90M   77M  8.4M  91% /boot\r\ncgroup          3.9G     0  3.9G   0% /sys/fs/cgroup\r\n```","I'm closing this issue since `docker save` and `docker load` allow the save and loading of images. Please feel free to comment.\r\n\r\n@PierreR @bodenr If you're still having problems, you might want to open a separate issue for this.\r\n","Is it possible to save an image to tar archive, and load it under different repository/tag?\r\n\r\n","@hvishwanath `docker save` and `docker load`","@cpuguy83 docker save and docker load will load the image with same ID/repository/tag info with what it was saved with. Is there a way to load an image with a different repository name and tag?\r\n\r\nThough `docker import` allows specifying different repo/tag names, importing an image saved with `docker save` causes issues while trying to run the image. Am I missing something here..?",":+1:","This was actually written down in #247.\r\n\r\nDocker should be modified so that it can use multiple repositories. In that case, it could perform ```pull```, ```push``` and ```login``` with multiple repositories.\r\n\r\nImport doesn't really need to be changed. Import will import the image to the local repository and it can be pushed like a normal image to any of the repositories.\r\n\r\nAs for adding repository functionality to docker itself, the layers and their metadata files will have to be stored as tarballs as well. This takes into account the situation where we have one single docker machine acting as repository and as image build server - this is really needed for development and testing. So the --norun flag can be used if we only want a docker instance to run as a repository. If this flag is used, we won't be extracting the layers at all. \r\n\r\nIf we want docker to run as a repository, we can pass it --repository (or something like that) so that it also keeps the layers and metadata as tarballs and so that it also provides the repository services.\r\n\r\nThe image listing API needs a bit more input.","@unclejack well, #247 is more about the docker daemon gaining the ability to trade images (or at least that's how I intended it when I wrote the ticket). Since I filed that, I was told on IRC that the Docker hackers decided that having a standalone repo server was a good idea in the long term, so they decided to open up the server implementation at some point as well.\r\n\r\nAccording to @shykes we want both p2p image transfers between daemons and centralized repo servers.","@cespare I'm aware of that, I was saying I'd like docker to have centralized repo server capabilities.","First, I want to confirm that there are 2 different features here:\r\n\r\n1) Add p2p push/pull to docker (see #247). I'm going to change the title of #247 to clarify.\r\n\r\n2) Open-source the registry so anyone can self-host their own images (This issue #350).The model we're following is roughly Golang's package hosting system. Totally decentralized + a top-level namespace for convenience.","My initial plan was to merge the registry into Docker, but I was convinced otherwise.\r\n\r\nOne reason is that docker and the registry, even though they speak the same protocol, are very different in the backend. The registry for example doesn't need to unpack the filesystem layers from the tarballs. And of course it doesn't need to run containers. Conversely, Docker is only concerned with local storage of its images, whereas Docker may integrate with S3 and other storage backends for scale and reliability.\r\n\r\nIn short: let's keep the registry separate from docker so they can each solve their respective problem in the simplest possible way. Worst case, we realize it was a bad idea and we merge them - and merging is always easier than splitting.\r\n","@shykes What about the docker push having to compress the layers? Doesn't that mean it would also need to store them compressed or would they be compressed every single time? That seems very inefficient.\r\n\r\nA push takes a while right now, one of the reasons is the fact that tar has to wait for some chunks to get uploaded when the channel is full.","Yes, Docker will always tar+compress layers at each push. This is because it untars them as soon as they are imported/pulled. Keep in mind Docker's job is to mount layers into containers. It cannot do that without unpacking them.\r\n\r\nThe reason push is slow currently has nothing to do with compression: it is caused by working around S3's inability to support regular chunked HTTP uploads. The workaround involves generating the tar locally, then sending it as a whole. This obviously doubles the total transfer time.","Renamed this issue from \"Self-hosted Docker Repositories\" to \"Self-hosted Docker Registry\". I think that's more accurate. I'm not 100% clear on the terminology here (the word 'repository' seems to be used in a slightly strange way by docker).","@shykes What's the plan here btw -- are you guys going to open up the Flask/S3 version and extend that, or are you going to write a Go implementation? Has it been started? I'm wondering how I could contribute to this.","Bump on that last question.\r\n\r\nI was thinking of writing an independent Go registry implementation, if the open-sourced one is the Flask app.","Yes, confirming that we will open-source the registry as soon as possible (currently 3 full-time engineers working on an initial release). Also confirming that it will be a Python app, not Go.\r\n\r\n@cepare any chance I can interest you in implementing #247 instead? :) This could be used for a reference Go implementation of the registry protocol. And would be super useful for advanced deployment workflows across multiple servers.\r\n\r\nLet me know and we could work on it together.","@shykes sure, it should be much the same thing either way. #247 seems strictly harder because I need to find my way around more existing code, but I'll give it a shot.\r\n\r\nDon't assign it to me just yet -- I'll have to see whether I have adequate time to actually dive in. I'll  update that issue if I start making any serious progress.","Hey everyone,\r\n\r\nI just wanted to let you all know that we've made lots of progress on the new implementation of the registry, and support for it inside docker. In other words, you can expect to see a code release of the new registry *very* soon. \r\n\r\nHowever, what we need right now to make sure this lives up to your expectations is help testing it. We've set up a [staging index](http://indexstaging-docker.dotcloud.com/) where you can create a user account and search for user-created and official repositories. If you checkout the **[registry-update](https://github.com/dotcloud/docker/tree/registry-update)** branch you can build and install a version of docker that will create users, login, push and pull using the new staging registry.\r\n\r\nAs a disclaimer here's a list of things that are missing but should appear as we approach release date:\r\n* `docker search` command to find repositories in the index.\r\n* support for `user/repo:tag` format in the `docker pull` command (use `docker pull -t TAG user/repo` instead)\r\n* progress bar for downloads/uploads\r\n* checksum system overhaul coming up that should enforce more constraints to verify images have not been corrupted or tampered with during pushes and pulls alike.\r\n\r\nTL;DR Please checkout the  **[registry-update](https://github.com/dotcloud/docker/tree/registry-update)** branch, report any bugs you find and tell us what you think! Thanks :)","It is important to note that any data that is uploaded to the index staging server won't be kept, it is only for testing, so please don't put anything important on there that you haven't already pushed to the prod registry server.\r\n\r\nSince this is a staging server, it is getting updated all of the time, so expect minor errors and periodic down times. ","+1","Released in 0.5.0","You should probably remove the relevant `// FIXME` as part of the change.","OK, I'm done :)","Lol. Thanks. Appreciate the help.","Hey @byAtlas, thanks for the contribution. It seems to work well, and definitely speeds up downloads :)\r\n\r\nI found one problem: the progress bars write over each other. Not sure what's the simplest way to solve that: maybe add an optional \"position\" parameter to ProgressReader, which would add N newlines before writing? This is how pv(1) does it for multiple streams (see pv -c -N).\r\n","Ping :)","Sorry for the radio silence, I just got a new job so that's been keeping me busy.\r\n\r\nAnyway,  I took a swing at this, wrapping a io.Writer both using newlines and console escape codes. Due the the whole async thing, this can cause the cursor to jump around like crazy, and overwrite random lines. \r\nNot particularly useful.\r\n\r\nMaybe we just ignore percentage counters and go 'downloading layer %d of %d'?","So, there is now a new HTTP api, and is streams progress using json. So now we can use the json stream to interleave updates about multiple downloads. This will need a small change to the api (specifically, using \"progress_FOO\" and \"progress_BAR\" as json keys instead of just \"progress\").\r\n\r\n@byAtlas, if you're still motivated to do this, let me know and I will keep this open for you to update it. If you don't have the time, or will get around to it later, let's close it for now and re-open it when it makes sense.\r\n\r\nThanks for the contribution and sorry we couldn't take it in as is.\r\n\r\n","I'll close it for now. I might come up with something in a bit, but we'll see.\r\n\r\nAnd no worries, maybe next time.","a related discussion on IRC: https://botbot.me/freenode/docker/msg/2612873/","@creack This can probably be closed.\r\n\r\nSetting the host name via -h is now possible and it's also working. I've just tested it. ","Great idea.  Do we know why it was closed?",":+1:","+1 This is really super important!","Agree. The culprit is rcli, our overly simple tcp protocol. A proper remote\r\nAPI will fix this.\r\n\r\n(For the same reason the client can't differentiate stdout from stderr on\r\nattach)\r\n\r\nOn Thursday, April 11, 2013, Jochen Breuer wrote:\r\n\r\n\u003e +1 This is really super important!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/354#issuecomment-16223703\u003e\r\n\u003e .\r\n\u003e","Does this also affect regular status code from commands run in a container? (it seems like it).\r\n\r\nFor example:\r\n\r\n```\r\n$ docker run base /bin/sh -c 'exit 1'\r\n2013/04/13 11:49:43 docker run base /bin/sh -c exit 1\r\n$ echo $?\r\n0\r\n```\r\n\r\nI can understand that technically, the docker process exited correctly, so it should return `0`, but is there some other way to get the exit code of the command itself?","Probably in this case, some existing practices (like ``chroot``) could be employed here?\r\n\r\n(A quote from Linux' ``chroot`` info page)\r\n\r\n```\r\n     chroot OPTION NEWROOT [COMMAND [ARGS]...]\r\n\r\n...\r\n\r\n   Exit status:\r\n\r\n     125 if `chroot' itself fails\r\n     126 if COMMAND is found but cannot be invoked\r\n     127 if COMMAND cannot be found\r\n     the exit status of COMMAND otherwise\r\n```","Catching a return value inside the container would be great, but I think that wouldn't be so easy. What value would be used? There could be a whole series of commands executed inside of the container. Which one would be chosen for docker to return? Don't know how this could be implemented in a useful way.","Actually, by design Docker only allows you to execute one command per\r\ncontainer - and it already stores its exit status. You can find it with\r\n\"docker inspect ID\", or with \"docker wait ID\".\r\n\r\n\r\n\r\nOn Sat, Apr 13, 2013 at 1:44 PM, Jochen Breuer \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Catching a return value inside the container would be great, but I think\r\n\u003e that wouldn't be so easy. What value would be used? There could be a whole\r\n\u003e series of commands executed inside of the container. Which one would be\r\n\u003e chosen for docker to return? Don't know how this could be implemented in a\r\n\u003e useful way.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/354#issuecomment-16340511\u003e\r\n\u003e .\r\n\u003e","@shykes I still feel propagating the return code would be a very useful and more unix-y option to add to docker run, mostly when running one-off commands.\r\n\r\nCurrently if I'm not mistaken the return code is lost when using the -rm flag?","+1, propagating the return code of the command run would be insanely helpful, and it makes sense to do so.","@sylvinus @Cidan we already fixed this master (at least I think so):\r\n\r\n```\r\n$\u003e docker run busybox /bin/sh -c 'exit 17'\r\n$\u003e echo $?\r\n17\r\n```\r\n\r\nThis isn't working for you ?","Ah great, works indeed :) I think it was fixed in 0.6.7 then.","So the only problem is now when you pass an invalid endpoint path into docker run it returns a 0 which I use to tell me there was an issue with the docker run command.","I'm still experiencing some weird return values using ENTRYPOINT (or CMD).  I have a bash script that calls some other bash scripts.  At the end of it I do an `exit 1` for testing and about half the time the return value of `docker run` is 0.  If i do: `docker ps -a` it says the return value was 1 for each of the runs.  This only seems to happen if I run multiple commands in the bash script.  A simple bash script that only calls `exit 1` works fine.  \r\n\r\nI'm having trouble isolating the exact conditions that make this happen.  Is there an easy way to easily get the return value without parsing yaml? \r\n\r\nUpdate: The answer is something like this `docker inspect -format='{{.State.ExitCode}}' \u003cid\u003e`.  I still don't know why run gives random return values.\r\n\r\n```\r\nClient version: 0.7.6\r\nGo version (client): go1.2\r\nGit commit (client): bc3b2ec\r\nServer version: 0.7.6\r\nGit commit (server): bc3b2ec\r\nGo version (server): go1.2\r\n```","@bkreider there were a bunch of exit code bugs fixed recently (ie, since 0.7.6 was released).  Can you update to 0.8.0 and see if it resolves the inconsistencies?\r\n\r\nAlso, you might enjoy `docker wait \u003cid\u003e`, which just waits for the container to finish and then prints the exit code on stdout.","@tianon Thanks!  I had just installed the latest yesterday.  The 0.8.0 version seems to fix it.  That's much easier than wrapping in a bash script like this:\r\n```\r\ndocker run --name $name \u003cid\u003e \u0026\u003e /dev/null\r\nret=$(docker inspect -format='{{.State.ExitCode}}' $name)\r\ndocker rm $name\r\nexit $ret\r\n```","All non-zero exit codes are mapped to 255 for me in 0.8.1, is this correct behavior?\r\nThis differs with example provided by @vieux :\r\n\r\n```\r\n$ docker run busybox /bin/sh -c 'exit 17'\r\n$ echo $?\r\n255\r\n$ docker run busybox /bin/sh -c 'exit 132'\r\n$ echo $?\r\n255\r\n$ docker run busybox /bin/sh -c 'exit 0'\r\n$ echo $?\r\n0\r\n$ docker --version\r\nDocker version 0.8.1, build a1598d1\r\n```\r\n\r\nEDIT:\r\nNevermind. After upgrading to 0.9.0 exit code as expected.\r\n","It's possible that the actual locale -- ``en_US.UTF-8`` -- is available on one machine and is not on the other...","How do I know whether this is the case, and how do I fix it?\r\n\r\nAlso, why is the docker export/import dependent on locale? That seems...wrong.","for example, you can run ``locale -a`` to see what locales are currently available.\r\n\r\nas for the second question, it might depend because you have some filenames which use characters outside of ascii page (0-127)...","IMHO, it wouldn't be unreasonable to refuse to create images containing files having names outside of the ASCII-7 charset (unless some force/override flag is set).","Huh, I wonder what I did to create such files. This is basically the image `base` plus a few ubuntu packages installed  plus the Go toolchain.","@sa2ajj `locale -a` shows identical output on machine A (where the `pull` works) and machine B (where it doesn't).\r\n\r\n```\r\nC\r\nC.UTF-8\r\nen_US.utf8\r\nPOSIX\r\n```","After discussing on with @cespare with IRC, it seems the problem appeared only when Docker was run inside Runit. Runit passed a value of LANG which caused bsdtar to misbehave.\r\n\r\nQuestion: is there something Docker can do to prevent this, or at least help debug it? Should Docker force a certain value of LANG when calling bsdtar?","Oh yeah, forgot to update this issue.\r\n\r\nThe issue was that runit runs the command with a sort of blank slate environment that didn't have `$LANG` set, even though the shell where I was running the docker commands did have it set to `en_US.UTF-8`.\r\n\r\nMy fix was to do something like this in the runit run script:\r\n\r\n```\r\nexec env LANG=\"en_US.UTF-8\" docker -d 2\u003e\u00261\r\n```\r\n\r\nClosing this ticket as my original question was answered.","I get this issue with a fresh \"precise64\" vagrant VM -- no runit, and setting LANG in the daemon's environment doesn't fix it. Full reproduction steps:\r\n\r\n    $ vagrant box add precise64 http://files.vagrantup.com/precise64.box\r\n    $ mkdir dockerbox\r\n    $ cd dockerbox\r\n    $ vagrant init\r\n    $ vi Vagrantfile # change config.vm.box to \"precise64\"\r\n    $ vagrant up\r\n    $ vagrant ssh\r\n \r\n    vagrant@precise64:~$ sudo apt-get update\r\n    vagrant@precise64:~$ sudo apt-get install lxc wget bsdtar curl linux-image-extra-3.2.0-23-virtual\r\n    vagrant@precise64:~$ wget http://get.docker.io/builds/$(uname -s)/$(uname -m)/docker-master.tgz\r\n    vagrant@precise64:~$ tar -xf docker-master.tgz\r\n    vagrant@precise64:~$ cd docker-master/\r\n    vagrant@precise64:~/docker-master$ sudo ./docker -d \u0026\r\n    vagrant@precise64:~/docker-master$ ./docker pull shykes/pybuilder","We investigated this with @mzdaniel and found out the following:\r\n- by default, bsdtar will try to create archives using the pax format\r\n- the pax format will use a special kind of header to encode file names\r\n- this pax header stores the file name as an UTF-8 string (instead of a raw binary string)\r\n- the point of this pax header is to allow portability across systems using different encoding formats for special characters\r\n- if bsdtar cannot convert to UTF-8 (when packing) or from UTF-8 (when unpacking) it will disregard the UTF-8 name contained in the pax header, and use the raw name (and it will work fine), but it will display a warning (and docker will consider that things failed)\r\n- gnutar doesn't exhibit the problem, since it doesn't use that pax header (and will therefore always store the file name in binary form)\r\n- it is possible to instruct bsdtar to use gnutar format, which removes the warnings\r\n- the only downside seems to be portability issues with systems using different *internal* encodings (note the subtlety: even if you use filesystems with non-UTF encodings, you will be fine, because the OS will translate on the fly; you will be in trouble only if your system doesn't use UTF-8 internally—tested with a vfat mount using latin-1 charset). Since we support only Linux, this doesn't seem to be a realistic issue.\r\n\r\nBottom line:\r\n- either we ignore the warnings and we're fine,\r\n- or we create archives with `--format=gnutar` (which is equivalent to \"ignore the warnings\")\r\n\r\nAdditional notes: we also found out that virtually *all* real-world base images will exhibit the problem, because most distros will store root CA certs with their full names; i.e. on Ubuntu and Debian, `/usr/share/ca-certificates/mozilla` (among others) contains files named like `T?B?TAK_UEKAE_K?k_Sertifika_Hizmet_Sa?lay?c?s?_-_S?r?m_3.crt` or `NetLock_Arany_=Class_Gold=_F?tan?s?tv?ny.crt`. (With `?` being some non-ASCII7 character, obviously!)\r\n","@jpetazzo Thanks for the detailed investigation!","Does anyone have a workaround for this for ``docker pull``?","OK, I think I solved the problem. with @ojii's help we duplicated the problem on a couple of servers (his and mine) and then with some trial and error, I found out that if you change your init script to this. it will pull correctly.\r\n\r\nWe should make sure that the get.docker.io and the debian packages include the fix.\r\n\r\nWe also need to confirm that the path in docker is correct below, it seems to sometimes live in /usr/local/bin or /usr/bin \r\n\r\n``/etc/init/docker.conf``\r\n```\r\ndescription     \"Run docker\"\r\n\r\nstart on runlevel [2345]\r\nstop on starting rc RUNLEVEL=[016]\r\nrespawn\r\n\r\nscript\r\n    test -f /etc/default/locale \u0026\u0026 . /etc/default/locale || true\r\n    LANG=$LANG LC_ALL=$LANG /usr/local/bin/docker -d\r\nend script\r\n```\r\n\r\n/cc @jpetazzo @mzdaniel ","FYI I still have this issue on my dev VM.\r\n\r\nI have to launch the deamon like this `sudo -E LANG=en_US.utf-8 LC_ALL=en_US.utf-8 docker -d` to fix the problem","Is there a way to reproduce this? I would like to add a fix directly into docker (by hardcoding env variables passed to bsdtar), instead of depending on the init script. I would like to test the result.","See #777","+1, indeed","#777 has been merged in master, closing tentatively.","Thanks!","Hey @sa2ajj, I have addressed this concern in https://github.com/dotcloud/docker/blob/master/CONTRIBUTING.md#how-are-decisions-made\r\n\r\nSpecifically, docker follows a full open-design process, which means that dotCloud projects get no special treatment by the project, and dotCloud employees follow the same process as everybody else to use and contribute to docker.\r\n\r\nSo, although our experience operating dotCloud obviously informs design decisions for Docker, it is only one of many sources of inspiration and ideas. Your ideas and needs are considered on equal footing with the ideas and needs of the dotCloud ops team.\r\n\r\nI hope this helps!","It would be great to combine this with doc generation. Instead of manually editing dozens of real-world examples, if we could somehow generate both a) the tests and b) the docs from the same authoritative description, this would guarantee that examples are always up to date.\r\n\r\n/cc @mzdaniel","We now have coverage over which parts of the CLI are tested and which are not. http://buildbot.docker.io/builders/coverage/builds/6/steps/shell/logs/stdio shows that some of the CLI is tested as Shykes suggests.","I have successfully packaged docker for openSUSE. The package can be found inside of [this](http://download.opensuse.org/repositories/home:/flavio_castelli:/docker/openSUSE_12.3) repository.\r\n\r\n[This](http://software.opensuse.org/ymp/home:flavio_castelli:docker/openSUSE_12.3/docker.ymp?base=openSUSE%3A12.3\u0026query=docker) is the link to SUSE's \"1 click install\".\r\n\r\nI've also created a [SUSE Studio](http://susestudio.com) appliance which can be used to play with docker. You can find it [there](http://susestudio.com/a/CZ0T0D/docker), on SUSE Gallery.\r\n\r\n","I have a question about docker: how can I import a lxc container?\r\n\r\nI created an openSUSE-based lxc container and I invoked:\r\n```docker import http://localhost:8080/suse-12.3-lxc-guest-lxc.x86_64-1.0.0.tbz openSUSE_12.3 1.0.0```\r\n\r\nNow `docker images` gives the following output:\r\n```\r\nREPOSITORY          TAG                 ID                  CREATED             PARENT\r\nopenSUSE_12.3       1.0.0               4ec3eb6b5724        16 minutes ago   \r\n```\r\n\r\nTrying to use the container produces the following error:\r\n````\r\ndocker run openSUSE_12.3 echo Hello world\r\nImage openSUSE_12.3 not found, trying to pull it from registry.\r\nPulling repository openSUSE_12.3\r\nError: HTTP code: 404\r\n```\r\n\r\nI've not looked into docker's sources to figure out what to do, maybe you can save me some time ;)\r\n\r\n\r\n","Hey Flavio, when you specify \"run OpenSUSE_12.3\", Docker translates this to\r\n\"run OpenSUSE_12.3:latest\". Eg. if you don't specify a tag, it looks for\r\nthe \"latest\" tag by default. Since you don't have a tag called \"latest\", it\r\ndoesn't find it.\r\n\r\nI'm looking for a way to make this less confusing.\r\n\r\nIn the meantine, you can solve your problem by either:\r\n\r\na) Specifying the 1.0.0 tag with \"run OpenSUSE_12.3:1.0.0\"\r\n\r\nOR\r\n\r\nb) Create a default latest tag which points to 1.0.0 with \"docker tag\r\nOpenSUSE_12.3:1.0.0 OpenSUSE_12.3\"\r\n\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 9:17 AM, Flavio Castelli\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I have a question about docker: how can I import a lxc container?\r\n\u003e\r\n\u003e I created an openSUSE-based lxc container and I invoked:\r\n\u003e docker import\r\n\u003e http://localhost:8080/suse-12.3-lxc-guest-lxc.x86_64-1.0.0.tbzopenSUSE_12.3 1.0.0\r\n\u003e\r\n\u003e Now docker images gives the following output:\r\n\u003e\r\n\u003e REPOSITORY          TAG                 ID                  CREATED             PARENT\r\n\u003e openSUSE_12.3       1.0.0               4ec3eb6b5724        16 minutes ago\r\n\u003e\r\n\u003e Trying to use the container produces the following error:\r\n\u003e\r\n\u003e docker run openSUSE_12.3 echo Hello world\r\n\u003e Image openSUSE_12.3 not found, trying to pull it from registry.\r\n\u003e Pulling repository openSUSE_12.3\r\n\u003e Error: HTTP code: 404\r\n\u003e\r\n\u003e I've not looked into docker's sources to figure out what to do, maybe you\r\n\u003e can save me some time ;)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/359#issuecomment-16184705\u003e\r\n\u003e .\r\n\u003e","Thanks for the hint, it really helped me.\r\n\r\nI've also uploaded an openSUSE 12.3 container. It can be grabbed doing: `docker pull flavio/openSUSE_12.3`","You can find a detailed report of what I have achieved inside of [this](http://flavio.castelli.name/2013/04/12/docker-and-opensuse/) blog post. Feedback is welcome :)","We can consider this issue solved. Feel free to close it.","Thanks again @flavio!","This would mean storing redundant information, and writing extra code to deal with conflicts between redundant copies. For example, what happens when image A says \"my history is B, C, D\", but image B says \"my history is X, Y, Z\". Now we have to write code to deal with that situation.\r\n\r\nIn the end it's more work for everyone - just because you don't want to implement a simple cache ;)","My 2c: we already have to write code to deal with the following\r\ninconsistencies:\r\n- referencing non-existent images\r\n- invalid layer (wrong format or truncated)\r\n- invalid json (parse error or missing fields)\r\nSo dealing with ancestry isn't that bad, especially as it lifts\r\nrequirements from the registry (i.e. it can now be a static file server if\r\nyou just want a simple local registry).\r\n\r\nOn Mon, Apr 8, 2013 at 4:33 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e This would mean storing redundant information, and writing extra code to\r\n\u003e deal with conflicts between redundant copies. For example, what happens\r\n\u003e when image A says \"my history is B, C, D\", but image B says \"my history is\r\n\u003e X, Y, Z\". Now we have to write code to deal with that situation.\r\n\u003e\r\n\u003e In the end it's more work for everyone - just because you don't want to\r\n\u003e implement a simple cache ;)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/360#issuecomment-16085700\u003e\r\n\u003e .\r\n\u003e","\u003e In the end it's more work for everyone - just because you don't want to implement a simple cache ;)\r\n\r\nWell actually the ancestry will be created on the images push to avoid maintaining the index (since images are immutable, it works perfectly with the design). It does not change anything for the Registry. It would just be more consistent for everyone since images are immutable.","\u003e what happens when image A says \"my history is B, C, D\", but image B says \"my history is X, Y, Z\"\r\n\r\nIn this case, the graph is broken and the image is not usable. Docker knows the graph since it creates the images.","Closing the issue, feel free to continue on the list.","same problem here, running Ubuntu 12.10","Same issue here\r\n\r\n    root@memcompute2:/home/memsql/carl# cat /etc/issue\r\n    Ubuntu 11.04 \\n \\l\r\n\r\n    root@memcompute2:/home/memsql/carl# netstat -nr\r\n    Kernel IP routing table\r\n    Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface\r\n    10.8.0.2        0.0.0.0         255.255.255.255 UH        0 0          0 tun0\r\n    192.168.1.0     0.0.0.0         255.255.255.0   U         0 0          0 eth0\r\n    10.8.0.0        10.8.0.2        255.255.255.0   UG        0 0          0 tun0\r\n    169.254.0.0     0.0.0.0         255.255.0.0     U         0 0          0 eth0\r\n    0.0.0.0         192.168.1.1     0.0.0.0         UG        0 0          0 eth0\r\n","Same problem for me. The interesting thing is that it only happens when a VPN connection is active. \r\nI'm running on Debian Wheezy on my version of docker is:\r\n\r\n(master)~/git/docker$ docker version\r\n2013/05/07 21:16:58 docker version\r\nVersion: 0.3.0\r\nGit Commit: 7b1ec9f\r\nKernel: 3.2.0-4-amd64\r\nWARNING: No memory limit support\r\nWARNING: No swap limit support\r\n\r\nThe main difference I see is that when I'm using the VPN a tun0 interface is created. The new route created by the VPN creates a problem. I can see:\r\n\r\n```\r\n[debug] network.go:129 172.16.42.1/24: Unexpected ip route output: invalid CIDR address: A.B.C.D (A.B.C.D via 192.168.0.254 dev eth0  src 192.168.0.17 )\r\n```\r\nwhere A.B.C.D is the vpn\r\n\r\nAnd this error is the same with 10.0.42.1/24 and 192.168.42.1/24\r\n\r\n*NOTE*: If I start docker before the VPN it works.\r\n\r\nHope this help\r\nGuillaume","I'm having the same problem with Ubuntu 12.04, docker 0.3.2-1 (from ppa) and no special network settings.\r\n\r\n```\r\nansible@raven:~$ route -n\r\nKernel IP routing table\r\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\r\n0.0.0.0         133.9.52.2      0.0.0.0         UG    100    0        0 eth0\r\n10.0.3.0        0.0.0.0         255.255.255.0   U     0      0        0 lxcbr0\r\n133.9.52.2      0.0.0.0         255.255.255.255 UH    0      0        0 eth0\r\n```\r\n\r\n```\r\nansible@raven:~$ ifconfig\r\neth0      Link encap:Ethernet  HWaddr 52:54:00:b3:4e:a6  \r\n          inet addr:133.9.226.97  Bcast:0.0.0.0  Mask:255.255.255.255\r\n          inet6 addr: 2a01:4f8:150:7242:3::2/80 Scope:Global\r\n          inet6 addr: fe80::5054:ff:feb3:4ea6/64 Scope:Link\r\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n          RX packets:40832 errors:0 dropped:0 overruns:0 frame:0\r\n          TX packets:21507 errors:0 dropped:0 overruns:0 carrier:0\r\n          collisions:0 txqueuelen:1000 \r\n          RX bytes:159258823 (159.2 MB)  TX bytes:4816877 (4.8 MB)\r\n\r\nlo        Link encap:Local Loopback  \r\n          inet addr:127.0.0.1  Mask:255.0.0.0\r\n          inet6 addr: ::1/128 Scope:Host\r\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\r\n          RX packets:10671 errors:0 dropped:0 overruns:0 frame:0\r\n          TX packets:10671 errors:0 dropped:0 overruns:0 carrier:0\r\n          collisions:0 txqueuelen:0 \r\n          RX bytes:816106 (816.1 KB)  TX bytes:816106 (816.1 KB)\r\n\r\nlxcbr0    Link encap:Ethernet  HWaddr ce:42:f3:21:d4:ed  \r\n          inet addr:10.0.3.1  Bcast:10.0.3.255  Mask:255.255.255.0\r\n          inet6 addr: fe80::cc42:f3ff:fe21:d4ed/64 Scope:Link\r\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\r\n          TX packets:6 errors:0 dropped:0 overruns:0 carrier:0\r\n          collisions:0 txqueuelen:0 \r\n          RX bytes:0 (0.0 B)  TX bytes:468 (468.0 B)\r\n```\r\n\r\nThe docker debug output looks like this:\r\n\r\n```\r\nansible@raven:~$ sudo docker -d -D\r\n[debug] network.go:100 Routes:\r\n\r\ndefault via 133.9.52.2 dev eth0  metric 100 \r\n10.0.3.0/24 dev lxcbr0  proto kernel  scope link  src 10.0.3.1 \r\n133.9.52.2 dev eth0  proto kernel  scope link  src 133.9.226.97 \r\n\r\n[debug] network.go:129 172.16.42.1/24: Unexpected ip route output: invalid CIDR address: 133.9.52.2 (133.9.52.2 dev eth0  proto kernel  scope link  src 133.9.226.97 )\r\n[debug] network.go:100 Routes:\r\n\r\ndefault via 133.9.52.2 dev eth0  metric 100 \r\n10.0.3.0/24 dev lxcbr0  proto kernel  scope link  src 10.0.3.1 \r\n133.9.52.2 dev eth0  proto kernel  scope link  src 133.9.226.97 \r\n\r\n[debug] network.go:129 10.0.42.1/24: Unexpected ip route output: invalid CIDR address: 133.9.52.2 (133.9.52.2 dev eth0  proto kernel  scope link  src 133.9.226.97 )\r\n[debug] network.go:100 Routes:\r\n\r\ndefault via 133.9.52.2 dev eth0  metric 100 \r\n10.0.3.0/24 dev lxcbr0  proto kernel  scope link  src 10.0.3.1 \r\n133.9.52.2 dev eth0  proto kernel  scope link  src 133.9.226.97 \r\n\r\n[debug] network.go:129 192.168.42.1/24: Unexpected ip route output: invalid CIDR address: 133.9.52.2 (133.9.52.2 dev eth0  proto kernel  scope link  src 133.9.226.97 )\r\n2013/05/14 18:33:59 Could not find a free IP address range for interface 'docker0'. Please configure its address manually and run 'docker -b docker0\r\n```\r\n\r\n`133.9.52.2` isn't a valid CIDR address since it's missing the prefix, but the route outputs are without a prefix. So why do you check for a CIDR address?","Actually, there are 2 issues here.\r\n\r\nThe original issue is that, with your VPN, you are sitting on 3 different networks that use all 3 of the RFC1918 IP spaces.  You can only go so deep here.  There is a FIXME in the code to look wider for a /24 that will work.\r\n\r\nI hit the second issue.  What is happening is that you are on a /32 subnet and the 'ip routes' command leaves off the '/32'.  This code should also check if this can be parsed as an IP.  If so, assume that it is a /32 subnet.  The code in question is here: https://github.com/jbeda/docker/blob/master/network.go#L96.","This can be fixed using the -b option of docker daemon. You need to manually create a bridge for docker and then start the daemon with `docker -d -b mybridge0`","I faced the same issue and used this tutorial below to create a bridge\r\nwww.nsnam.org/wiki/index.php/HOWTO_Use_Linux_Containers_to_set_up_virtual_networks","Could you reopen the issue?\r\n\r\nI'm getting this error because of this line in my \"ip route\" command:\r\n```\r\ndefault via 192.168.0.254 dev eth0\r\n127.0.0.1 dev lo  scope link\r\n192.168.0.0/24 dev eth0  proto kernel  scope link  src 192.168.0.120\r\n```\r\n\r\nEven though the CIDR isn't valid, it should ignore it I think!\r\nOr maybe append /8 to it ?\r\n\r\nAnd maybe add /32 to static ip addresses ?","Got the same message while trying to set up docker while connected to a PPPoWLAN network. To expand on the fix proposed by @creack I created a bridge like this in Ubuntu (following [the help wiki](https://help.ubuntu.com/community/NetworkConnectionBridge)):\r\n\r\n    sudo brctl addbr docker0 # create your bridge\r\n    sudo brctl addif docker0 eth0 # mask an existing interface using the bridge\r\n    sudo ip link set dev docker0 up # bring it up - not really sure if this is necessary or is it done automatically\r\n    sudo ifconfig docker0 10.0.0.4 # give it an IP\r\n\r\nYou should now be able to start docker.\r\n\r\n     sudo docker -d -b docker0\r\n","@kermit666  I follow your commands listed below and then my server's DNS service stops working... Is there anything wrong?","@doomdagger hm... I don't know. If you tried the usual method of just rebooting and it doesn't help, you can try reversing the steps by deleting the bridge (`brctl delbr docker0`) and then rebooting. If it doesn't help, you should probably try some of the official help channels (http://askubuntu.com/ or http://serverfault.com/) or just googling around a bit.","FATA[0000] Get http:///var/run/docker.sock/v1.18/containers/json: dial unix /var/run/docker.sock: no such file or directory. Are you trying to connect to a TLS-enabled daemon without TLS? \r\n\r\nI also face this problem, only when using the Astrill VPN client.. \r\n\r\nFATA[0000] Shutting down daemon due to errors: Could not find a free IP address range for interface 'docker0'. Please configure its address manually and run 'docker -b docker0' \r\n\r\nWhen Astrill VPN client is disabled, without problem.. \r\n\r\n\"Daemon has completed initialization\"",":+1: Same issue here happening when OpenVPN client is running on same machine. Unable to run Docker and OpenVPN client at the same time. ","upstart log here\r\n```\r\nWaiting for /var/run/docker.sock\r\nINFO[0000] +job serveapi(unix:///var/run/docker.sock)\r\nINFO[0000] Listening for HTTP on unix (/var/run/docker.sock)\r\nINFO[0000] +job init_networkdriver()\r\nCould not find a free IP address range for interface 'docker0'. Please configure its address manually and run 'docker -b docker0'\r\nINFO[0000] -job init_networkdriver() = ERR (1)\r\nFATA[0000] Shutting down daemon due to errors: Could not find a free IP address range for interface 'docker0'. Please configure its address manually and run 'docker -b docker0'\r\n```\r\n\r\nkernel version here\r\n```\r\n➜  upstart  uname -r\r\n3.13.0-32-generic\r\n```\r\n\r\nerror here\r\n```\r\nFATA[0000] Get http:///var/run/docker.sock/v1.18/version: dial unix /var/run/docker.sock: no such file or directory. Are you trying to connect to a TLS-enabled daemon without TLS?\r\n```\r\n\r\nos version here\r\n```\r\nVERSION=\"14.04.2 LTS, Trusty Tahr\"\r\nID=ubuntu\r\nID_LIKE=debian\r\nPRETTY_NAME=\"Ubuntu 14.04.2 LTS\"\r\nVERSION_ID=\"14.04\"\r\n```","had the same issue, turns out our dhcp was giving out static routes for 10.0.0.0/8, 192.168.0.0/24, 172.16.0.0/16.  If you are having issues run the docker dameon in the terminal with -d -D and grok the debug output.","Looks much nicer thanks.",":+1: for not keeping it","\u003e Any arguments in favor of keeping it?\r\n\r\nno; +1 for deprecating it. simple is better than complex.","+1 for axing standalone.\r\n\r\nThis pretty much clears up the root confusion I mentioned in #132.",":+1: for removal.","+1\r\n\r\nRemoving it would help get rid of all those weird errors and would also remove the need for asking \"are you running it in standalone mode?\".","Note: at some point, we probably want to make docker able to re-attach (at least partly) to containers after being restarted (due to a crash or upgrade). At this point, re-introducing standalone mode will be fairly straightforward and much less confusing (see #131).","+1\r\n\r\nI can confirm this isn't working. I've just tried to import an image via stdin and it's not working.","I'm betting on a regression with optional raw mode.\r\n\r\ncc @kalessin @creack\r\n\r\nOn Tuesday, April 9, 2013, unclejack wrote:\r\n\r\n\u003e +1\r\n\u003e\r\n\u003e I can confirm this isn't working. I've just tried to import an image via\r\n\u003e stdin and it's not working.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/365#issuecomment-16108410\u003e\r\n\u003e .\r\n\u003e","Need more testing","Test used to crash the server (also crash in master):\r\n#!/bin/bash\r\nID=$(./docker run -d base /bin/bash -c 'while true; do echo hello; sleep 1; done')\r\necho $ID\r\n ./docker stop $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker start $ID\u0026\r\n ./docker stop $ID\u0026\r\n ./docker start $ID\u0026\r\n wait","Sweet. Thanks @johncosta, looking forward to the next tutorial :)","One infrequently advertised feature of go's flag package is the ease of parsing of the -h output.  This can come useful in auto-generating bash completion files, for example.\r\n\r\nAlso, the syntax without equals sign is sometimes subtly incorrect.  For more details, search _You must use the -flag=false_ in http://golang.org/pkg/flag/.\r\n","@masiulaniec Could you point me to how to generate bash completion files from the -h output? I found [something similar for zsh](https://gist.github.com/icholy/5314423#comment-811104), but if there was an easy way to do it for bash too, then I would decide to keep the ='s. The benefit would far outweigh the visual clutter of the \"=\" signs.\r\n\r\nAlso, I'd love any tips for including the docker `Commands:` into autocomplete as well.","Sorry, I only use old-fashioned file-based tab completion, I only mentioned bash completion as a popular example.\r\n\r\nOTOH, I am intrigued by a possibility of commands to satisfy interfaces by including certain flags in -h output, akin to how types in Go satisfy interfaces by implementing certain methods.  I do not yet have a specific use case, but the idea seems powerful.","Hello -- I have decided to keep the `=` notation because:\r\n\r\n1. This is the format used by the golang `flags` package, so the docker CLI help output will always include the `=` characters. All Go packages that use the `flags` module will have the same `help` formatting.\r\n2. The presence of the `=` can help other parsers use the output of `help` commands (as indicated above for zsh).\r\n\r\nI apologize for taking so long to make this decision, and I am grateful to @ebastos for taking the time to update the documentation and make the pull request.","Hi,\r\n\r\nWould you be ok with:\r\n\r\n-l : show only the latest created container, include non-running ones.\r\n-last n : show last n created containers, include non-running ones. (no default)\r\n\r\nCheers\r\n\r\n\r\n","why not using the same flag for both?\r\n\r\n-l : show last\r\n-l n : show n lasts","With the current flag system,\r\nif you set a default value\r\nyou can't know if it was -l or nothing\r\n\r\nthat's why I used 2 flags","+1\r\nI'm looking forward to this.","@unclejack: nice!   It will help a lot If you could do a quick test (everything should run in the first try). What os are you using?","@mzdaniel I'm using Kubuntu 12.10 amd64. I'll set up vagrant and try it out.","Thanks!","First contribution in #373: 'make hack' will setup a new buildbot VM and add a post-commit hook which will automatically trigger tests.\r\n\r\n--\u003e Volunteers needed for testing!","We now have the 'make hack' environment. Perhaps this can be closed?","This is just a placeholder, still work in progress.","We're missing the ability to remove volumes. What do you think of \"docker rm -v CONTAINER\" to optionally remove a container's volumes at the same time as the container?","Rebased master to ease the merge if approved","Thanks for the feedback, I hope the new version looks better.","looks good to me.","This raises a thought: at some point should we have a \"graceful shutdown\" that doesn't just `os.Exit` right away?","\u003e This raises a thought: at some point should we have a \"graceful shutdown\" that doesn't just `os.Exit` right away?\r\n\r\nYou are right. I think that's something which needs to be addressed with a dedicated issue. ","Created #379.","Hey @flavio, I look forward to merging this!\r\n\r\nI think the pidfile should only created when running docker in daemon mode ('docker -d'). When running it in client mode we probably don't want it.\r\n\r\nLook for daemon() in docker/docker.go","\u003e I think the pidfile should only created when running docker in daemon mode ('docker -d'). When running it in client mode we probably don't want it.\r\n\r\nThe pidfile was already being created only when running in daemon mode, but you are right: I think it's better to move this code inside of the `daemon()` function.","thanks @flavio! nice job :)","Few things we need to check.\r\n\r\n1. Does SIGINT work in interactive mode? If not, we should send SIGINT to the child process.\r\n2. SIGTERM should be passed into the child process, allowing it to die naturally and ending the docker session. The application can catch SIGTERM and properly handle or ignore it. This makes it necessary to support SIGKILL.\r\n3. If we send SIGKILL, what happens to the child processes? Are they shut down? Are they reaped automatically? If not, will they turn into zombies keeping the container alive?\r\n\r\nSo, how should we support this? One option is to support the same semantics as kill.\r\n\r\nE.g.\r\ndocker kill (defaults SIGTERM)\r\ndocker kill -9 (sends signal 9 SIGKILL)","@titanous \r\n\r\nWhat does it mean to \"finish what it is doing\"?   Stop containers, builds?  ","Don't stop containers; but do wait for or stop builds, uploads, downloads, and any other stateful tasks.","The expected behavior is for Docker to leave a consistent state on disk so that ongoing operations can be either automatically resumed, or re-started later by the user without side-effects.\r\n\r\nTo my knowledge this is already the case - for example ongoing downloads are stopped and users can pull the same image later without causing an error, that sort of thing.\r\n\r\nIf Docker's behavior deviates from this, I suggest opening a specific bug report, eg. \"`docker pull` can't be restarted after docker daemon is restarted.\".\r\n","Everybody does that sort of orchestration differently. I don't believe this\r\nshould be in the scope of Docker. What you want is not that hard to build\r\naround Docker.\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 11:12 AM, cheddar \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I manage an open-source distributed data store Druid (\r\n\u003e http://www.github.com/metamx/druid) and am looking for a solution that\r\n\u003e can simplify and reduce startup friction for the project.\r\n\u003e\r\n\u003e My company currently uses a deployment framework based around \"standard\"\r\n\u003e tarballs, which appear to be very similar to the \"standard containers\" that\r\n\u003e docker is peddling. I like that abstraction a lot and is part of why I\r\n\u003e think docker might be a good fit for what I'm doing.\r\n\u003e\r\n\u003e The other thing that I'd really like in order to truly reduce friction for\r\n\u003e my users would be a cli that allows them to control and make adjustments to\r\n\u003e what is deployed on running on the cluster as they see fit.\r\n\u003e\r\n\u003e Namely, I'm thinking that my project can build and maintain standard\r\n\u003e containers for the actual software. I'd like to give my users the ability\r\n\u003e to just install docker on their boxes and then go to some \"master\" node and\r\n\u003e issue commands like\r\n\u003e\r\n\u003e docker deploy nodes[0-9] container:druid-1.0.0 config:my_config-1.0.0\r\n\u003e\r\n\u003e And have it deploy the pre-built container along with some config that\r\n\u003e they have defined to nodes 0 through 9.\r\n\u003e\r\n\u003e Then, I'd like to be able to do something like\r\n\u003e\r\n\u003e docker start druid-1.0.0\r\n\u003e\r\n\u003e And have it start all of the druid-1.0.0 containers that have been\r\n\u003e deployed.\r\n\u003e\r\n\u003e docker start node0 druid-1.0.0\r\n\u003e\r\n\u003e could just start the druid-1.0.0 container on node0\r\n\u003e\r\n\u003e I could have a \"stop\" command that essentially stops containers and takes\r\n\u003e the same arguments that \"start\" does.\r\n\u003e\r\n\u003e If you gave me one more command:\r\n\u003e\r\n\u003e docker update druid-1.0.0 container:druid-2.0.0\r\n\u003e\r\n\u003e That would essentially replace the druid-1.0.0 container on the box with\r\n\u003e the druid-2.0.0 container. I could then use start, stop and update to\r\n\u003e implement rolling restart/update scripts for a real deployment. Or, at a\r\n\u003e minimum, my users would have a manually runnable cli that lets them make\r\n\u003e adjustments to the cluster.\r\n\u003e\r\n\u003e I'm not sure how easy or hard this is with docker, but as an external\r\n\u003e person (who basically knows nothing ;)) I think it would be immensely\r\n\u003e beneficial to have this sort of high-level cluster management capability.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/380\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","+1 for @progrium solution. It should not be a docker responsibility.","This would be an interesting project which could use the docker API. However, the closest docker will get to doing something like this is to expose all that is required to implement this via an external tool.\r\n\r\nDocker has to be improved so that return codes are returned properly for all operations and so that a third party tool may be able to monitor the containers properly.\r\n\r\ndocker-cluster would be an interesting project and it could live in its own repository as a separate external tool.\r\n\r\n@shykes Could you take a look at this issue, please? It can probably be closed.","@shykes want to weigh in before this is closed?","ping @shykes","The code from PR #1397 can be used as a starting point. That might be useful for someone who's looking into cluster management.\r\n\r\nI'm closing this issue. If you think it should remain open, please feel free to re-open it or ask me to re-open it.","This patch needs a `gofmt`.","i really prefer running `docker ps | head -n 5` instead of having to remember that ps takes a similar argument. many of us already know the \"| head -n 5\" trick, so it makes more sense to re-use that. \r\n\r\neven better, implement a `--json` option for most docker commands so that the output can be processed more flexibly using [jsontool](https://github.com/trentm/json), eg:\r\n\r\n```\r\n$ docker inspect 63dda77e28a8 --json | json NetworkSettings.PortMapping.6379\r\n49161\r\n$\r\n```","@srid: see #371, some people want this, it does not mean you have to use it, you can keep using | head.\r\n\r\nRegarding the json, it might be a good idea, would you mind openning a separate issue for this? :)","(just for the record, my implementation of #111 would have taken care of that, but since it's now moving in a different direction, I'd like to see how to achieve that :))\r\n\r\nif it seems viable I could implement either a separate command for ``docker`` or add an option to ``docker export``","Hey Mikhail,\r\n\r\nYou're right, I think docker can be an awesome build tool.\r\n\r\n- To get stuff into the container, for now I would recommend passing it via\r\nstdin. The long-term solution is to add a 'docker insert' command (which\r\nwill use tar+stdin behind the scenes).\r\n\r\n- To get build stuff after the tool is finished, it depends what you want\r\nto get. First of all, you can the container itself as a build artifact (and\r\ncommit it as an image). This is perfect if you're building a webapp or\r\ndatabase for example - the underlying system and configuration *are* part\r\nof the build. Another option is to get the diff created during the build.\r\nThere is no command for that but it would be trivial to implement ('docker\r\nexport ---rw' maybe?). Another option is to filter the output of export\r\nwith what you want - eg. \"docker export | tar\r\n--options-to-filter-which-I-dont-know\"\r\n\r\nLastly, I don't think data volumes are a good option for this - because the\r\ncontents of volumes cannot be versioned, so you lose the ability to track\r\nwhich artifact was built by what, when, etc.\r\n\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 1:21 PM, Mikhail Sobolev\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e (just for the record, my implementation of #111\u003chttps://github.com/dotcloud/docker/issues/111\u003ewould have taken care of that, but since it's now moving in a different\r\n\u003e direction, I'd like to see how to achieve that :))\r\n\u003e\r\n\u003e if it seems viable I could implement either a separate command for dockeror add an option to docker\r\n\u003e export\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/382#issuecomment-16199434\u003e\r\n\u003e .\r\n\u003e","Some means of copying files from containers would be nice to have: docker copy container_id guest_path host_path. This would keep the files in the containers to be able to keep track of their versions and would also offer easier access to the container data.","Well, at least, for now I'm looking at building Debian packages (I'm long time Debian based distributions user).  A Debian source package consists of two or more files (``.dsc`` + orig.tar.gz + possible Debian specific changes), hence feeding it to stdin `as is` is not exactly possible -\u003e a tar of the files would be required -\u003e untar on the container side would be required -\u003e hassle :)\r\n\r\nThe result of the Debian package build is two or more files as well (``.changes`` + built binaries + possibly re-built source package (see above)), so it's a bit hasslish as well.\r\n\r\nAs for ``docker export | tar \u003cwith-those-options\u003e``, this command would create a tar of the _whole_ container filesystem where only a small part is needed...  A bit of resource waste, I'd say...\r\n\r\n@unclejack, probably some sort of ``scp`` syntax could be used:\r\n```bash\r\ndocker copy \u003chost-path\u003e \u003ccontainer_id\u003e:\u003cguest_path\u003e\r\n```\r\n \u0026\u0026\r\n```bash\r\ndocker copy \u003ccontainer_id\u003e:\u003cguest_path\u003e \u003chost-path\u003e\r\n```","That seems very reasonable - and symmetrical to \"insert\". What should we\r\ncall it?\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 2:08 PM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Some means of copying files from containers would be nice to have: docker\r\n\u003e copy container_id guest_path host_path. This would keep the files in the\r\n\u003e containers to be able to keep track of their versions and would also offer\r\n\u003e easier access to the container data.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/382#issuecomment-16202353\u003e\r\n\u003e .\r\n\u003e","I like the idea of the scp syntax!\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 2:15 PM, Mikhail Sobolev\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Well, at least, for now I'm looking at building Debian packages (I'm long\r\n\u003e time Debian based distributions user). A Debian source package consists of\r\n\u003e two or more files (.dsc + orig.tar.gz + possible Debian specific\r\n\u003e changes), hence feeding it to stdin as is is not exactly possible -\u003e a\r\n\u003e tar of the files would be required -\u003e untar on the container side would be\r\n\u003e required -\u003e hassle :)\r\n\u003e\r\n\u003e The result of the Debian package build is two or more files as well (\r\n\u003e .changes + built binaries + possibly re-built source package (see\r\n\u003e above)), so it's a bit hasslish as well.\r\n\u003e\r\n\u003e As for docker export | tar \u003cwith-those-options\u003e, this command would\r\n\u003e create a tar of the *whole* container filesystem where only a small part\r\n\u003e is needed... A bit of resource waste, I'd say...\r\n\u003e\r\n\u003e @unclejack \u003chttps://github.com/unclejack\u003e, probably some sort of scpsyntax could be used:\r\n\u003e\r\n\u003e docker copy \u003chost-path\u003e \u003ccontainer_id\u003e:\u003cguest_path\u003e\r\n\u003e\r\n\u003e \u0026\u0026\r\n\u003e\r\n\u003e docker copy \u003ccontainer_id\u003e:\u003cguest_path\u003e \u003chost-path\u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/382#issuecomment-16202700\u003e\r\n\u003e .\r\n\u003e","BTW, as for version of builder containers, at least, in my mind, those containers are throw away ones: build the package, deliver results, keep it for a while and delete it.","+1 for scp syntax\r\n\r\n@sa2ajj These containers are indeed ephemeral, but we need to think of other situations as well.\r\n\r\nI wonder whether it would make sense to allow the insertion of data only into new containers or not.\r\nThis would look like this:\r\n```docker copy \u003chost-path\u003e \u003cimage_id\u003e:\u003cguest_path\u003e```\r\n\r\nThis would be more consistent with the entire concept of build steps, but I can imagine there might be some valid uses cases which might require putting data into an existing container.","And one more thing I just realised: the only way to create a container is to perform ``docker run``, so I can't really copy anything anywhere :)\r\n\r\nAnd copying stuff to the image kinda contradicts the idea: that image would be a _pristine_ environment.. So I do not really want to clutter it...","@sa2ajj That's what I was saying. docker copy host_path container:path could:\r\na) copy to an existing container,\r\nb) copy only to a new container based on the given image\r\nOR\r\nc) both, depending on the passed ID (existing container -\u003e copy to the container, image -\u003e create new container based on image)\r\n","To answer both of you: inserting a file would be a special case of run. Eg.\r\nit would create a new container and run \"tar\" inside it with the file as\r\nstandard input. Just like other containers, running another command in the\r\nsame container will not be possible. You will have to commit the result,\r\nthen run the next command from the resulting image.\r\n\r\nThis might be a problem with the scp syntax: it wouldn't be very\r\nsymmetrical.\r\n\r\n\r\n```\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 2:29 PM, Mikhail Sobolev\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e And one more thing I just realised: the only way to create container is to\r\n\u003e perform docker run, so I can't really copy anything anywhere :)\r\n\u003e\r\n\u003e And copying stuff to the image kinda contradicts the idea: that image\r\n\u003e would be a *pristine* environment.. So I do not really want to clutter\r\n\u003e it...\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/382#issuecomment-16203506\u003e\r\n\u003e .\r\n\u003e","@unclejack it would be answer b).\r\n\r\n\r\nOn Wed, Apr 10, 2013 at 2:34 PM, Solomon Hykes\r\n\u003csolomon.hykes@dotcloud.com\u003ewrote:\r\n\r\n\u003e To answer both of you: inserting a file would be a special case of run.\r\n\u003e Eg. it would create a new container and run \"tar\" inside it with the file\r\n\u003e as standard input. Just like other containers, running another command in\r\n\u003e the same container will not be possible. You will have to commit the\r\n\u003e result, then run the next command from the resulting image.\r\n\u003e\r\n\u003e This might be a problem with the scp syntax: it wouldn't be very\r\n\u003e symmetrical.\r\n\u003e\r\n\u003e\r\n\u003e ```\r\n\u003e\r\n\u003e\r\n\u003e On Wed, Apr 10, 2013 at 2:29 PM, Mikhail Sobolev \u003cnotifications@github.com\r\n\u003e \u003e wrote:\r\n\u003e\r\n\u003e\u003e And one more thing I just realised: the only way to create container is\r\n\u003e\u003e to perform docker run, so I can't really copy anything anywhere :)\r\n\u003e\u003e\r\n\u003e\u003e And copying stuff to the image kinda contradicts the idea: that image\r\n\u003e\u003e would be a *pristine* environment.. So I do not really want to clutter\r\n\u003e\u003e it...\r\n\u003e\u003e\r\n\u003e\u003e —\r\n\u003e\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/382#issuecomment-16203506\u003e\r\n\u003e\u003e .\r\n\u003e\u003e\r\n\u003e\r\n\u003e","+1 on \"docker copy\" (or \"docker cp\") with a scp-like syntax for containers,\ni.e.:\n\n    docker cp container_id:/path/to/file /local/path\n    docker cp /local/path container_id:/path/to/file\n\nI have mixed feelings about doing the same with images.\nObviously the following could be useful:\n\n    docker cp image_id:/path/to/file /local/path\n\n(As a shortcut to cp /var/lib/docker/....../path/to/file /local/path.)\n\nHowever, copying a file *to* an image wouldn't make sense. Or rather, it\nshould be decomposed in basic steps: create container, copy file in\ncontainer, commit container to new image.","Is this now solved with #111? I did not find any documentation on how to \"inject\" a host path into a container. I think that the solution for #111 just allows for sharing paths between containers, not host and container.","Yup #111 doesn't really provide a clean way of copying files into a container from the host, although I suppose you could if you wanted to by having a persistent data volume on start, then inspecting to get the volume id, then finding it in /var/lib/docker/volumes and copying it in straight from the host. I still believe having a direct cp function would be ideal, especially in cases where a persistent data volume is otherwise not needed","Hmm, my guess would be this is due to a bug within Go.\r\n\r\nkill perform a os.Process.Kill() which simply send a SIGKILL to the process. This operation returns without problem. However, for some reason, memcached is still up and running (still can connect to it and he will answer requests).\r\n\r\nthe commands hangs because it does a container.Wait() which wait that the container actually dies. As memcached does not, docker kill hangs forever.\r\n\r\nWhen interrupting the kill and try again, os.Process.Kill() returns an error stating that the process is already dead, which is false. os.Command.Wait never unblocked and the process is still up and running.\r\n\r\nNice tuto btw, really interesting! Good job!","Note that I changed Graph.Delete() already, it no longer requires garbage collection. See 5d3c0767dab1679686933a9b4cf4ddde19bc0faf\r\n","Since this is executed inside the container, it would be even better to try \"ip\" first and keep \"route\" as a fallback. This would increase the population of images which could run in docker without modification :)\r\n","I don't know any distribution that has route and not ip.","Fine - I need to merge this for #399 anyway :)\r\n\r\nThanks","I am actually enjoying the current low-fuss experience with 'docker commit', but I guess I could always restore it by writing a wrapper script.","I was actually talking about the git commit, not the docker commit. You are welcome to 'docker commit' with any message you feel is useful :)","The standalone mode as been removed.","Thank you @creack. Issue solved.","@creack let me know when you've reviewed comments and think it's ready for merge.","Done and ready for merge :)","Fixes #96 \r\n","thanks!","Would be cool to add a test to for this one. How could we go about it? Is there a reliable way to reproduce the situation where you can't kill the process directly?","Maybe you could use this PR to also remove the [OPTIONS] when there are no need?","This issue relates with packaging issue #251","This should probably be reported to the Debian project so they can fix it.","@creack: It works. Thank you!","@unclejack: I did more research on this to present it to Debian, and it turns out that although the stock kernel doesn't support limiting memory, it does support setting kernel boot parameters to enable it. The parameter settings are:\r\n\r\ncgroup_enable=memory swapaccount=1\r\n\r\nIn summary for this issue, Debian users can fully enjoy docker passing all its tests with standard Wheesy kernel adding the following parameters into their /boot/grub/grub.cfg:\r\n\r\nlinux   /boot/vmlinuz-3.2.0-4-amd64 [other parameters] cgroup_enable=memory swapaccount=1\r\n\r\nThis implies that with good documentation, Debian Wheesy with no special packages fully support Docker","Crossposting this issue to the Debian docker package, issue #251 ","just for information to anyone coming here, the standard way in debian to add these options if you want them to persist when the kernel package is updated or the initrd is regenerated, is to add them to GRUB_CMDLINE_LINUX_DEFAULT in /etc/default/grub","for any other poor non-bearded noobs like me wondering how to do this...\r\nhttp://askubuntu.com/a/19487/62915\r\n\r\n1. add `cgroup_enable=memory swapaccount=1` to whatever is currently in the `GRUB_CMDLINE_LINUX_DEFAULT` var in `/etc/default/grub`\r\n2. `sudo update-grub` to make it ready to use\r\n3. restart the instance, should be working","Docs for installing an openstack controller: http://docs.openstack.org/folsom/basic-install/content/basic-install_controller.html\r\n","First pre-requisite: an Ubuntu 12.04 image. Doing that in #399.","I chatted with @shykes briefly about this in IRC. It will basically take a few steps, with the end result being to wind up with this:\r\n\r\n![](http://docs.openstack.org/folsom/basic-install/content/figures/Quantum-PhysNet-Diagram.png)\r\n\r\n**[controller node needs:](http://docs.openstack.org/folsom/basic-install/content/basic-install_controller.html)**\r\n* keystone\r\n* glance\r\n* nova\r\n* cinder\r\n* quantum\r\n* dashboard\r\n* mysql\r\n* rabbitmq\r\n\r\n**[network node needs:](http://docs.openstack.org/folsom/basic-install/content/basic-install_network.html)**\r\n* open-vswitch\r\n* quantum\r\n* virtio/virtual networking\r\n\r\n**[compute node needs:](http://docs.openstack.org/folsom/basic-install/content/basic-install_compute.html)**\r\n* hypervisor\r\n* nova\r\n* quantum\r\n\r\nAll three nodes need some hand-tweaked configuration as well.","I think this is a discussion for the mailing list. I know there's at least one implementation of this in the wild. Feel free to share your experience!","Ack. This is addressed in #717.","Solved in c2c72bcfd796a43b9be33705ec695455c9823489 ","OK, I feel pretty stupid now. It turns out the problem was that I was running\r\n\r\n    HTTP_PROXY=http://x.x.x.x:x/ sudo ./docker run -i -t base /bin/bash\r\n\r\ninstead of\r\n\r\n    sudo HTTP_PROXY=http://x.x.x.x:x/ ./docker run -i -t base /bin/bash\r\n\r\nHowever that hasn't completely fixed the problem, now I get this error message:\r\n\r\n    2013/04/12 16:46:11 use of closed network connection:\r\n\r\nI'm not sure if this is related to the fact that I'm using an HTTP proxy, does anyone have an idea what's going on?","This message occurs when the server close the socket, so it might be the proxy that does not support some of the http requests performed by docker in order to import the base image.\r\nSee #364, try not to use the stand alone mode.\r\nYou could try to start docker in server mode with sudo HTTP_PROXY=http://xx:x/ ./docker -d \u0026\r\nthen you can simple run ./docker run -i -t base /bin/bash without sudo nor proxy.\r\n\r\nIf it still doesn't work, you can try to strart docker server with -d and -D in order to enable the debug mode and see what's going on.","The problem persisted even after using docker in server mode, but then I tried compiling from source (so that I could add additional debug statements to figure out what the problem was) and it worked without any issues.\r\n\r\nSo it was either an intermittent issue with the proxy server, or maybe the binary was out of date. Either way, thanks for the help!","I just tried pulling another image with the binary running as the server, and it failed again. Pulling the same image with the compiled version running as the server succeeded, so we can rule out it being an intermittent proxy issue.\r\n\r\nI'm guessing this probably means the binary is out of date?","the binaries are updated often, but not all the time. The current binaries are maybe 36h old, which makes it way outdated ;) Docker grows fast :)","I am also behind a firewall and I've been trying to get Docker 0.4.0 to work using a proxy. I've followed the commands listed above and I get a certificate error. Here is what I see on the command line:\r\n\r\n```\r\n# sudo HTTP_PROXY=http://172.18.56.12:3128/ ./docker -d \u0026\r\n```\r\n```\r\n2013/06/04 14:53:00 WARNING: Your kernel does not support cgroup swap limit.\r\n2013/06/04 14:53:00 Listening for HTTP on 127.0.0.1:4243\r\n```\r\nThen I ran:\r\n```\r\n# docker pull base\r\n```\r\n```\r\n2013/06/04 14:57:01 POST /v1.1/images/create?tag=\u0026registry=\u0026fromImage=base\r\nPulling repository base from https://index.docker.io/v1\r\n2013/06/04 14:57:01 Get https://index.docker.io/v1/repositories/base/images: certificate is valid for *.docker.io, docker.io, not 172.18.56.12\r\n```\r\n\r\n","@creack @samalba @vieux  any update on this?","It was fixed by #810 , @benkirkley can you confirm ?","@vieux Confirmed that this is working on my end now. I can use the HTTP_PROXY to reach the repositories.\r\n\r\nMany thanks!","cc @destructuring ","I'm going to work on this.","Playing with it as well. @destructuring do you have something up somewhere that I could play with?","Hi @destructuring if you need help with this, I'd be glad to help. Getting it work with multi-vm and provisioners working. I'll start playing with it.","Since there are a lot of concurrent efforts to do this, I created a placeholder pull request to coordinate. Please check out \"contributing\" notes in #440.","Notes of today's brainstorming session:\r\nhttps://gist.github.com/jpetazzo/5423572\r\n\r\n\r\n\r\nOn Fri, Apr 19, 2013 at 5:35 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Since there are a lot of concurrent efforts to do this, I created a\r\n\u003e placeholder pull request to coordinate. Please check out \"contributing\"\r\n\u003e notes in #440 \u003chttps://github.com/dotcloud/docker/issues/440\u003e.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/404#issuecomment-16695986\u003e\r\n\u003e .\r\n\u003e","Hey guys,\r\n\r\nSince I was also one of those [trying to make this happen](https://github.com/fgrehm/vagrant-lxc/issues/41) I got some [thoughts](https://gist.github.com/fgrehm/5424514) to share. Please keep in mind that I wrote those notes after 2 or 3 days playing with Docker and it was a while ago, so there's a huge potential that be some stuff might not make sense for advanced docker users out there ;-)\r\n\r\nI'm also behind the \"[pure lxc](https://github.com/fgrehm/vagrant-lxc)\" provider for vagrant so I might be able to contribute with the Docker provider implementation itself in case you guys need an extra pair of hands ;) I actually don't think a Docker provider would be a \"competitor\" to the pure lxc driver since my goal is to have it as a replacement to VirtualBox for Linux users, what you guys have done here with Docker is actually something a lot bigger.","Thanks Fabio! I'm preparing detailed answers to the questions in your notes.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, Apr 19, 2013 at 7:51 PM, Fabio Rehm \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Hey guys,\r\n\u003e Since I was also one of those [trying to make this happen](https://github.com/fgrehm/vagrant-lxc/issues/41) I got some [thoughts](https://gist.github.com/fgrehm/5424514) to share. Please keep in mind that I wrote those notes after 2 or 3 days playing with Docker and it was a while ago, so there's a huge potential that be some stuff might not make sense for advanced docker users out there ;-)\r\n\u003e I'm also behind the \"[pure lxc](https://github.com/fgrehm/vagrant-lxc)\" provider for vagrant so I might be able to contribute with the Docker provider implementation itself in case you guys need an extra pair of hands ;) I actually don't think a Docker provider would be a \"competitor\" to the pure lxc driver since my goal is to have it as a replacement to VirtualBox for Linux users, what you guys have done here with Docker is actually something a lot bigger.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/404#issuecomment-16697703","(pasting my notes as a comment here as asked by @shykes on the gist)\r\n\r\n---\r\n\r\nTo kick off the provider would be nice to have the big picture of out how Vagrant features / commands map to docker \"stuff\". These are thoughts about how the integration might look like under the hood:\r\n\r\n-------\r\n\r\n\r\n### `vagrant up`\r\n\r\n* how can we tell docker to \"just start\" a container? \"docker start base\" would start the base image right?\r\n* would probably need to commit the base \"box\" image and interact with that\r\n* would it make sense to have a \"commandless\" `docker run -d \u003cimage\u003e`?\r\n* on \"pure lxc\" it basically means a \"lxc-create\" if the container has not been created yet and a \"lxc-start -d\"\r\n* how can we get the container IP from the command line to SSH into it?\r\n\r\n-------\r\n\r\n### shared folders\r\n\r\n* I saw some github issue action a while ago that there was some thinking around something related to that (something like data volumes?)\r\n* on \"pure lxc\" I just pass in '-s lxc.mount.entry=...' to `lxc-start`\r\n\r\n-------\r\n\r\n### vagrant box\r\n\r\n* does it map directly to docker images? what are the contents of an image?\r\n* all boxes will need to have an ssh server running so that people can use provisioners and other plugins that depend on it. does the base image come with it? I can't remember now\r\n* on \"vanilla lxc\" we have\r\n    * a metadata.json with optional template params for lxc-create (this file is required by vagrant and just needs to have a \"provider\" key, the rest is up to us)\r\n    * the rootfs tarball\r\n    * the lxc template script which gets symlinked to the right folder so that \"lxc-create\" finds it\r\n    * the current lxc template script is the same that comes with ubuntu 12.10 without the download / debootstrap part (i handle that when packaging the box)\r\n\r\n-------\r\n\r\n### `vagrant halt`\r\n\r\n* maps to \"docker stop\" + \"docker wait\"?\r\n\r\n-------\r\n\r\n### `vagrant destroy`\r\n\r\n* maps to \"docker rm\" ?\r\n\r\n-------\r\n\r\n### port forwarding\r\n\r\n* could use docker's built in port forwarding + a custom \"vagrant port\" command to lookup the public ports NATed\r\n* it won't work for localhost redirects, we could use \"redir\" as it is currently implemented on vagrant-lxc alread","On Thu, Apr 25, 2013 at 3:37 PM, Fabio Rehm \u003cnotifications@github.com\u003ewrote:\n\n\u003e (pasting my notes as a comment here as asked by @shykes\u003chttps://github.com/shykes\u003eon the gist)\n\u003e\n\nThanks Fabio!\n\n\n\u003e  ------------------------------\n\u003e\n\u003e To kick off the provider would be nice to have the big picture of out how\n\u003e Vagrant features / commands map to docker \"stuff\". These are thoughts about\n\u003e how the integration might look like under the hood:\n\u003e ------------------------------\n\u003e vagrant up\n\u003e\n\u003e    - how can we tell docker to \"just start\" a container? \"docker start\n\u003e    base\" would start the base image right?\n\u003e\n\u003e \"docker start base\" would be incorrect - you can only start/stop a\ncontainer, which you need to create with \"docker run\".\n\n\u003e\n\u003e    - would probably need to commit the base \"box\" image and interact with\n\u003e    that\n\u003e\n\u003e\n\n\u003e    - would it make sense to have a \"commandless\" docker run -d \u003cimage\u003e?\n\u003e\n\u003e\nYes, you could do \"docker run -d $IMAGE sshd\", followed by multiple ssh\ncalls as needed.\n\n\u003e\n\u003e    - on \"pure lxc\" it basically means a \"lxc-create\" if the container has\n\u003e    not been created yet and a \"lxc-start -d\"\n\u003e    - how can we get the container IP from the command line to SSH into it?\n\u003e\n\u003e ```bash\nBOX=$(docker run -d -p 22 $IMAGE sshd)\nssh localhost $(docker port $BOX 22)\n```\n\nYou can replace localhost with any public IP of the host.\n\n\n\u003e\n\u003e\n\u003e ------------------------------\n\u003e shared folders\n\u003e\n\u003e    - I saw some github issue action a while ago that there was some\n\u003e    thinking around something related to that (something like data volumes?)\n\u003e\n\u003e Yes, that would probably be done with data volumes. Of course if docker is\nitself running a virtualbox machine, you will need 2 layers of sharing :)\n\n\u003e\n\u003e    - on \"pure lxc\" I just pass in '-s lxc.mount.entry=...' to lxc-start\n\u003e\n\u003e Yes, data volumes are basically a wrapper around that.\n\n\n\u003e\n\u003e\n\u003e ------------------------------\n\u003e vagrant box\n\u003e\n\u003e    - does it map directly to docker images? what are the contents of an\n\u003e    image?\n\u003e\n\u003e I don't think it maps directly. Taking the EC2 and Rackspace providers as\nexamples: the developer needs to add a provider-specific configuration\noption with the name of a docker image.\n\n\u003e\n\u003e    - all boxes will need to have an ssh server running so that people can\n\u003e    use provisioners and other plugins that depend on it. does the base image\n\u003e    come with it? I can't remember now\n\u003e\n\u003e It doesn't, but we could provide special vagrant images with all the\nrequirements pre-installed: sshd, puppet, chef etc.\n\n\u003e\n\u003e    - on \"vanilla lxc\" we have\n\u003e       - a metadata.json with optional template params for lxc-create\n\u003e       (this file is required by vagrant and just needs to have a \"provider\" key,\n\u003e       the rest is up to us)\n\u003e       - the rootfs tarball\n\u003e       - the lxc template script which gets symlinked to the right folder\n\u003e       so that \"lxc-create\" finds it\n\u003e       - the current lxc template script is the same that comes with\n\u003e       ubuntu 12.10 without the download / debootstrap part (i handle that when\n\u003e       packaging the box)\n\u003e\n\u003e vagrant halt\n\u003e\n\u003e    - maps to \"docker stop\" + \"docker wait\"?\n\u003e\n\u003e Yeah something like that.\n\n\n\u003e\n\u003e\n\u003e ------------------------------\n\u003e vagrant destroy\n\u003e\n\u003e    - maps to \"docker rm\" ?\n\u003e\n\u003e Yes.\n\n\n\u003e\n\u003e\n\u003e ------------------------------\n\u003e port forwarding\n\u003e\n\u003e    - could use docker's built in port forwarding + a custom \"vagrant\n\u003e    port\" command to lookup the public ports NATed\n\u003e\n\u003e How do you do that in the vanilla lxc provider? How does regular Vagrant\nhandle port forwarding? Maybe we could align with that?\n\n\u003e\n\u003e    - it won't work for localhost redirects, we could use \"redir\" as it is\n\u003e    currently implemented on vagrant-lxc alread\n\u003e\n\u003e Localhost redirects work on docker now :)","@shykes just saw your reply today. re port forwarding on vagrant / vagrant-lxc, vagrant uses VBox port forwarding and vagrant-lxc only supports localhost redirects with `redir` atm\r\nBTW, it seems that there is enough information to put up a high level overview of what should happen under the hood for each vagrant feature / command right? have you guys done this already?","Would be an awesome feature!","is there a preview somewhere for this feature so we can test?","Check out destructuring/vagrant-shell, just merged a docker demo into the\r\nmaster branch.\r\n\r\n\r\nOn Fri, Jun 21, 2013 at 6:59 AM, Deni Bertovic \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e is there a preview somewhere for this feature so we can test?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/404#issuecomment-19817282\u003e\r\n\u003e .\r\n\u003e","Is this still being worked on? \r\n\r\nFrom what I gather, vagrant-shell looks like a way to let any set of shell scripts implement the vagrant provisioning interface. It does not have specifics to allow Vagrant to use Docker's LXCs as the containers.\r\n\r\nhttps://github.com/philspitler/vagrant-docker is interesting but I note no work done in the last couple of months.\r\n\r\nMartin.\r\n\r\n","Looks at the demos in branch feature/destructuring/demos in vagrant-shell for a docker script/demo\r\n\r\nSent from my mind\r\n\r\nOn Jul 14, 2013, at 10:49 AM, Martin Cleaver \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Is this still being worked on?\r\n\u003e \r\n\u003e From what I gather, vagrant-shell looks like a way to let any set of shell scripts implement the vagrant provisioning interface. It does not have specifics to allow Vagrant to use Docker's LXCs as the containers.\r\n\u003e \r\n\u003e https://github.com/philspitler/vagrant-docker is interesting but I note no work done in the last couple of months.\r\n\u003e \r\n\u003e Martin.\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","I would still like to see a dedicated provider. I know there is interest in one, but to my knowledge nobody is actively working on it. Consider this an invitation.\r\n\r\nI'm closing this issue, please direct future discussions to the mailing list.","@mrjcleaver I actually forked the repo for vagrant-docker from @destructuring because I was interested in the prospect of a Docker provider for Vagrant.  I noticed the documentation seem to have been copied from the AWS EC2 Provider, so I only contributed that documentation pull request.\r\n\r\nThat said, I am still very interested in the possibilities with this. While I don't have a ton of time to dedicate to a project of this magnitude at the moment, I would love to know if anyone starts working on this and will help in any way I can.","I'm actually planning to spike on a docker _provisioner_ for vagrant / packer when I have the time ;)","Do you mean something like this?\r\nhttp://www.packer.io/intro/getting-started/vagrant.html\r\n\r\nOr am I misunderstanding something (this is totally possible as it's pretty late here)?","Actually [this](http://www.packer.io/intro/getting-started/provision.html) and [this](http://docs.vagrantup.com/v2/provisioning/index.html)","@philspitler and to be clear, this issue is about [this](http://docs.vagrantup.com/v2/providers/index.html) :)","@fgrehm Got it, thanks @fgrehm ","Well, I glad this is coming together... but I'm clear as to what :) \r\n\r\nMaybe someone could spell it out for me? Are there two separate (maybe both valid?) goals here?\r\n\r\nThanks \u0026 please excuse my ignorance!\r\n\r\nMartin","Hey there! What's the status on this? Thanks a lot!","AFAIK there is no one actively working on Docker as a Vagrant provider apart from @destructuring's work on [vagrant-shell](https://github.com/destructuring/vagrant-shell) but I've personally started playing with Docker as a _provisioner_, so instead on using vagrant to control docker containers, I'm using docker to provision Vagrant VMs with multiple containers. If you are interested on that you can check out the [Vocker](https://github.com/fgrehm/vocker) and [Ventriloquist](https://github.com/fgrehm/ventriloquist) projects\r\n\r\nOn a side note, a future version of Vagrant (hopefuly the next one :) [will also support](https://groups.google.com/forum/#!searchin/vagrant-up/docker/vagrant-up/tyexPfzYjIQ/HWjVr0HeaEUJ) Docker as a first class provisioner and I'll be submiting a PR to Vagrant's core with Vocker's code after some more testing with the latest [release](https://github.com/fgrehm/vocker/blob/master/CHANGELOG.md#032-october-12-2013).\r\n\r\nI've been keeping an eye on things related to this and as far as I can tell that's it about Vagrant + Docker :)","Nice! Thanks for your reply. I've seen Ventriloquist lately, but didn't have a look at it yet. What I'd like to see is a functionality for Vagrant which would use a single VM for multiple projects. Those projects would run as separate docker containers inside this VM. In other words; every project would have a Vagrantfile which would provision a VM with a configured base box and  then use Docker to actually set up the project using a docker/lxc container. Keep up the nice work! :)","Vocker looks interesting. Would it also run a Dockerfile from inside a project's directory?","Not yet [but it is planned](https://github.com/fgrehm/vocker/issues/3) :)","Ok folks, apart from docker _provisioners_ (ventriloquist / vocker), I've just open sourced an experimental _provider_ too: https://github.com/fgrehm/docker-provider.\r\n\r\nIt has [quite a few](https://github.com/fgrehm/docker-provider#limitations) limitations which I'm pretty sure will be around unless things changes on Docker itself and TBH I think that supporting things like changing volumes / bind mounts and exposed ports _after_ the container has been created is out of scope for docker.\r\n\r\nAnyways, I hope someone finds it useful :P","This was merged","I just tried the installation process on Arch: works great.\r\nAlso I pushed an archlinux image to the docker registry: jbgi/arch-base\r\n","@shawnsi: Nice work, Shawn! Thank you for doing it. We have created an structure  to host all packaging metadata and documentation under /packaging. Would you like to add /packaging/arch with your work?","@shykes: Shawn made a great job packaging the project under the name dotcloud-docker. The Debian and Ubuntu packaging is following lxc-docker . What name convention official docker packages should follow?","I think lxc-docker is better. It makes it more obvious that docker is an\r\nextension of lxc, and that it's useful even if you're not a dotcloud\r\ncustomer.\r\n\r\n@shawnsi ok with you? Thanks for the work!\r\n\r\nRegarding the base image, could you share steps to reproducing your image?\r\nThat way we can promote it as a top-level image -\u003e 'docker pull arch' :)\r\n\r\n\r\nOn Sun, Apr 14, 2013 at 12:33 PM, Daniel Mizyrycki \u003cnotifications@github.com\r\n\u003e wrote:\r\n\r\n\u003e @shykes \u003chttps://github.com/shykes\u003e: Shawn made a great job packaging the\r\n\u003e project under the name dotcloud-docker. The Debian and Ubuntu packaging is\r\n\u003e following lxc-docker . What name convention official docker packages should\r\n\u003e follow?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/406#issuecomment-16357740\u003e\r\n\u003e .\r\n\u003e","The only reason I used dotcloud-docker is that docker was already used by another project.  lxc-docker is fine with me as well and I'll update my packages to reflect this.","@mzdaniel: I'll update the documentation to include the packaging information as well.  Should have that ready sometime tomorrow.","@shawnsi: Neat! I am looking forward to give it a try.\r\nHave you seen how we are packaging in Ubuntu? Basically, we spawn a VM with vagrant which does all the work, including submission to the docker PPA. I found in http://www.vagrantbox.es there is an Arch box http://vagrant.pouss.in/archlinux_2012-07-02.box we can use for doing something similar for Arch. What do you think?","Daniel, note that to submit the 0.2.0 ubuntu package yesterday (following\r\nyour excellent packager manual) I used the shykes/dockerbuilder container\r\nrunning on Linode, but did not use vagrant.\r\n\r\n\r\nOn Wed, Apr 24, 2013 at 4:53 PM, Daniel Mizyrycki\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @shawnsi \u003chttps://github.com/shawnsi\u003e: Neat! I am looking forward to give\r\n\u003e it a try.\r\n\u003e Have you seen how we are packaging in Ubuntu? Basically, we spawn a VM\r\n\u003e with vagrant which does all the work, including submission to the docker\r\n\u003e PPA. I found in http://www.vagrantbox.es there is an Arch box\r\n\u003e http://vagrant.pouss.in/archlinux_2012-07-02.box we can use for doing\r\n\u003e something similar for Arch. What do you think?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/406#issuecomment-16979900\u003e\r\n\u003e .\r\n\u003e","I managed to reproduce the issue on 2ee3db6cd28b20adb03c3b5114b48030a2ab065e, I need to update the test script to handle the old docker/dockerd scheme in order to go further","Attaching screenshots from virtualbox console output. Unfortunately the output is incomplete.\r\n\r\nSteps to reproduce:\r\n\r\n1. Run docker in daemon mode\r\n\r\n2.\r\n\r\n```bash\r\nfor i in $(seq 100); do docker run base echo hello world; done\r\n```\r\n\r\nThe command causing the crash will print the intended output (\"hello world\"), then crash before returning.\r\n\r\n\r\nScreenshot 1: visible immediately. ![docker 407 1](https://f.cloud.github.com/assets/29565/378711/0b1c1d94-a557-11e2-907a-102625011ec7.png)\r\n\r\nScreenshot 2: appears 2 - 5 seconds after screenshot 1. Then every 3-5 seconds, it is re-printed. \r\n![docker 407 2](https://f.cloud.github.com/assets/29565/378712/0b383970-a557-11e2-89ec-b3fc7bc245ec.png)\r\n","This is a blocker for 0.2.\r\n\r\nMy best guess is some sort of interaction between aufs and lxc-start - maybe we unmount the rootfs too early for example?","@creack can you share the exact steps to reproduce with maximum certainty? That way we can all help with debugging, by each trying different revisions.\r\n","I pushed my script in contrib/crashTest.go\r\n\r\nYou need to update the docket path and just 'go run crashTest.go'\r\n\r\nOn Monday, April 15, 2013, Solomon Hykes wrote:\r\n\r\n\u003e @creack \u003chttps://github.com/creack\u003e can you share the exact steps to\r\n\u003e reproduce with maximum certainty? That way we can all help with debugging,\r\n\u003e by each trying different revisions.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/407#issuecomment-16395640\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n-- \r\nGuillaume J. Charmes","Thanks. What is the current range of good / bad revisions that you\r\nidentified?\r\n\r\n\r\nOn Mon, Apr 15, 2013 at 9:29 AM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e I pushed my script in contrib/crashTest.go\r\n\u003e\r\n\u003e You need to update the docket path and just 'go run crashTest.go'\r\n\u003e\r\n\u003e On Monday, April 15, 2013, Solomon Hykes wrote:\r\n\u003e\r\n\u003e \u003e @creack \u003chttps://github.com/creack\u003e can you share the exact steps to\r\n\u003e \u003e reproduce with maximum certainty? That way we can all help with\r\n\u003e debugging,\r\n\u003e \u003e by each trying different revisions.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/407#issuecomment-16395640\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e\r\n\u003e --\r\n\u003e Guillaume J. Charmes\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/407#issuecomment-16395821\u003e\r\n\u003e .\r\n\u003e","Things to try:\n- reproduce with hardened kernel (s3://\nget.docker.io/kernels/linux-headers-3.2.40-grsec-dotcloud_42~tethys_amd64.deb\n)\n- reproduce in such a way that we actually get the full backtrace (e.g. in\na Xen VM on our test machines at the office :-))\n- if the problem can be triggered in a Xen VM, extract the backtrace of the\nkernel (starting point: xenctx)\n\nYou mentioned that the problem happened on UP machines but not SMP. If\nthat's indeed the case, try with 1 core but with SMP code anyway (IIRC,\nkernel option noreplace-smp).","Memory use increases after every docker run. It looks like aufs has some kind of problem or there's some other problem within the kernel.\r\n\r\nI've just tried the script posted above with 10000 runs and I was able to get 3.8.7 with aufs3 to start swapping with 3GB of RAM. Memory never got released after running this script, it just kept growing and growing forever.\r\n","I installed a fresh ubuntu 13 with a kernel 3.8.0 and I wasn't able to reproduce (I let the script run for ~1h).\r\nHowever, as @unclejack said, it leaks.","After a lot of tests, I am pretty sure the leaks are due to #197 ","I've performed a few tests to try to reproduce this on 12.04 with stock kernels.\r\nIt didn't crash, nor leak.\r\n\r\ndocker was downloaded from docker.io to keep things simple\r\n```\r\ndocker version\r\nVersion:0.1.4\r\nGit Commit:\r\n```\r\n```\r\nuname -rv\r\n3.2.0-40-generic #64-Ubuntu SMP Mon Mar 25 21:22:10 UTC 2013\r\n```\r\n```\r\ncat /proc/cpuinfo | grep processor\r\nprocessor       : 0\r\n```\r\n```\r\ncat /proc/meminfo | grep Total\r\nMemTotal:         496260 kB\r\nSwapTotal:             0 kB\r\n```\r\n\r\nmemory after first test w/ 100 runs \u0026 before second test\r\n```\r\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\r\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\r\n 0  0      0 333512  29196  54776    0    0   214    38   41  213  3  2 94  1\r\n```\r\nmemory after the second test w/ 100 runs\r\n```\r\nprocs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----\r\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa\r\n 1  0      0 324360  30968  56548    0    0   182    46   47  283  4  2 93  1\r\n```","do you perform your test with @shykes command or from my script (in /contrib/crashTest.go) ?\r\nWhat version of the kernel and lxc are you using?","@creack I was trying the command @shykes has posted earlier.\r\n\r\nI'll try your crashTest script as well.\r\n\r\nlxc is the standard one from Ubuntu 12.04.","Getting the same issue, captured the output from VirtualBox here: https://gist.github.com/robknight/5430280 - it's pretty much the same thing reported by @shykes earlier.  Running Docker inside the standard Vagrant box, OSX 10.8 host.\r\n\r\nFor me this doesn't seem to have much to do with the length of time that the container is running for.  I'm trying to build an image using docker-build, and my build succeeds maybe 25% of the time while the other 75% results in the above crash, after which the Vagrant box becomes unresponsive and has to be restarted.\r\n\r\nMy docker-build changefile only has two lines:\r\nfrom\tbase:latest\r\ncopy\tdist/dbx.tar\t/tmp/dbx.tar\r\n\r\nThe file referenced here definitely exists, and the build does succeed sometimes.\r\n\r\nIdentical behaviour occurs when using a different base image, e.g. centos.","Also getting kernel panics running docker 0.1.5, 0.1.6, 0.1.7 on Ubuntu 12.10, Linux 3.5.0-27, bare metal Dell Latitude D830 w/ Intel Core 2 Duo and 4GB RAM.\r\n\r\nReproduced by running the example multiple (\u003c20) times:\r\n```\r\ndocker run base echo hello world\r\n```\r\n\r\nScreen photos (docker 0.1.7):\r\nhttps://f.cloud.github.com/assets/361379/406625/f4a5a682-aaa8-11e2-8add-2c965f5758b9.jpg\r\nhttps://f.cloud.github.com/assets/361379/406627/0581c620-aaa9-11e2-9f3d-18f0ec82aae6.jpg","It seems that for the time being Docker requires Linux \u003e3.8. This is unfortunate, but it seems earlier versions just can't handle spawning too many short-lived namespaced processes. And we couldn't pinpoint the exact change which caused the bug to strike more frequently...\r\n\r\nDocker now issues a warning on Linux kernels \u003c3.8.","The screenshot posted by @barryaustin shows that it's exactly the same problem with bare metal. That's very useful, because it rules out many potential side effects caused by virtualization.\r\n\r\nAre we sure we want to *close* this issue? People running Ubuntu in production will very probably run 12.04 LTS rather than 12.10 or 13.04, and 12.04 LTS might not be supporting 3.8 ever.","I don't mind keeping it open, but that would imply that there's something\r\nwe can do other than upgrading the kernel. Do you have any suggestions?\r\n\r\n\r\nOn Tue, Apr 23, 2013 at 10:03 AM, Jérôme Petazzoni \u003cnotifications@github.com\r\n\u003e wrote:\r\n\r\n\u003e The screenshot posted by @barryaustin \u003chttps://github.com/barryaustin\u003eshows that it's exactly the same problem with bare metal. That's very\r\n\u003e useful, because it rules out many potential side effects caused by\r\n\u003e virtualization.\r\n\u003e\r\n\u003e Are we sure we want to *close* this issue? People running Ubuntu in\r\n\u003e production will very probably run 12.04 LTS rather than 12.10 or 13.04, and\r\n\u003e 12.04 LTS might not be supporting 3.8 ever.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/407#issuecomment-16871722\u003e\r\n\u003e .\r\n\u003e","My plan would look like this:\r\n\r\n  * reproduce the issue using only lxc-start commands\r\n  * escalate to lxc mailing list\r\n  * reproduce the issue using only basic namespace code (unshare or just\r\nclone syscalls)\r\n  * escalate to kernel mailing list\r\n\r\n\r\nOn Tue, Apr 23, 2013 at 10:08 AM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I don't mind keeping it open, but that would imply that there's something\r\n\u003e we can do other than upgrading the kernel. Do you have any suggestions?\r\n\u003e\r\n\u003e\r\n\u003e On Tue, Apr 23, 2013 at 10:03 AM, Jérôme Petazzoni \u003c\r\n\u003e notifications@github.com\r\n\u003e \u003e wrote:\r\n\u003e\r\n\u003e \u003e The screenshot posted by @barryaustin \u003chttps://github.com/barryaustin\u003eshows\r\n\u003e that it's exactly the same problem with bare metal. That's very\r\n\u003e \u003e useful, because it rules out many potential side effects caused by\r\n\u003e \u003e virtualization.\r\n\u003e \u003e\r\n\u003e \u003e Are we sure we want to *close* this issue? People running Ubuntu in\r\n\u003e \u003e production will very probably run 12.04 LTS rather than 12.10 or 13.04,\r\n\u003e and\r\n\u003e \u003e 12.04 LTS might not be supporting 3.8 ever.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/issues/407#issuecomment-16871722\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/407#issuecomment-16872040\u003e\r\n\u003e .\r\n\u003e","I agree this would be great. I re-opened the issue and removed it from 0.2.\r\n\r\nWant to lead the charge? Let me know and I'll assign to you.","Per @creack requests here what happens for me on `apt-get update \u0026\u0026 apt-get install`:\r\n\r\nhttps://gist.github.com/lopter/5449001#file-dmesg-log\r\n\r\nI'm running Docker in daemon mode on Ubuntu 12.04 in Virtualbox:\r\n\r\n    louis@dotcloud-docker:~$ uname -a\r\n    Linux dotcloud-docker 3.2.0-40-generic #64-Ubuntu SMP Mon Mar 25 21:22:10 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\r\n    louis@dotcloud-docker:~$ lsb_release -a\r\n    No LSB modules are available.\r\n    Distributor ID: Ubuntu\r\n    Description:    Ubuntu 12.04.2 LTS\r\n    Release:        12.04\r\n    Codename:       precise\r\n    louis@dotcloud-docker:~$ \r\n","I've just tried the exact same setup as @lopter. It didn't crash at all, not even with CPU limit set to 40%.\r\n\r\nHowever, I was able to make the system leak memory when the memory cgroup didn't get mounted. That seems to happen once every other boot on ubuntu in virtualbox. This didn't seem to break the system even after running the script @shykes posted above with 10000 runs.\r\n\r\nI've used the precise64 box. I've updated the system to use the latest kernel (3.2.0.40).","It locked up by the time it reached the 1355th run with the script posted by @shykes.\r\n\r\n```\r\n[ 2692.120088] BUG: soft lockup - CPU#0 stuck for 23s! [lxc-start:27038]\r\n[ 2692.122073] Modules linked in: veth aufs xt_addrtype vboxvideo(O) drm vboxsf(O) ipt_MASQUERADE iptable_nat nf_nat nf_conntrack_ipv4 nf_conntrack nf_defrag_ipv4 ip_tables x_tables bridge stp vesafb ppdev i2c_piix4 psmouse serio_raw vboxguest(O) nfsd parport_pc nfs lockd fscache auth_rpcgss nfs_acl mac_hid sunrpc lp parport ext2\r\n[ 2692.123992] CPU 0\r\n[ 2692.124019] Modules linked in: veth aufs xt_addrtype vboxvideo(O) drm vboxsf(O) ipt_MASQUERADE iptable_nat nf_nat nf_conntrack_ipv4 nf_conntrack nf_defrag_ipv4 ip_tables x_tables bridge stp vesafb ppdev i2c_piix4 psmouse serio_raw vboxguest(O) nfsd parport_pc nfs lockd fscache auth_rpcgss nfs_acl mac_hid sunrpc lp parport ext2\r\n[ 2692.124053]\r\n[ 2692.124053] Pid: 27038, comm: lxc-start Tainted: G      D    O 3.2.0-40-generic #64-Ubuntu innotek GmbH VirtualBox/VirtualBox\r\n[ 2692.124053] RIP: 0010:[\u003cffffffff8103ebd5\u003e]  [\u003cffffffff8103ebd5\u003e] __ticket_spin_lock+0x25/0x30\r\n[ 2692.124053] RSP: 0018:ffff8800157937b8  EFLAGS: 00000297\r\n[ 2692.124053] RAX: 000000000000ca9e RBX: ffffffff8112525c RCX: 0000000100045ada\r\n[ 2692.124053] RDX: 000000000000ca9f RSI: ffffffff8117a8e0 RDI: ffff880017c10950\r\n[ 2692.124053] RBP: ffff8800157937b8 R08: 0000000000000001 R09: 0000000000000000\r\n[ 2692.124053] R10: ffff880014e69410 R11: 0000000000000001 R12: 000000018200017f\r\n[ 2692.124053] R13: ffff880012c02940 R14: 000000000000000c R15: 000000000000000c\r\n[ 2692.124053] FS:  0000000000000000(0000) GS:ffff880017c00000(0000) knlGS:0000000000000000\r\n[ 2692.124053] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\n[ 2692.124053] CR2: ffff880117c00001 CR3: 0000000001c05000 CR4: 00000000000006f0\r\n[ 2692.124053] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[ 2692.124053] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\r\n[ 2692.124053] Process lxc-start (pid: 27038, threadinfo ffff880015792000, task ffff880016ff1700)\r\n[ 2692.124053] Stack:\r\n[ 2692.124053]  ffff8800157937c8 ffffffff8119712e ffff8800157937e8 ffffffff81198f5d\r\n[ 2692.124053]  ffff880014e69400 0000000000000010 ffff8800157937f8 ffffffff8119904f\r\n[ 2692.124053]  ffff880015793848 ffffffff8117ad83 ffff880014e69410 ffff880016efbf00\r\n[ 2692.124053] Call Trace:\r\n[ 2692.124053]  [\u003cffffffff8119712e\u003e] vfsmount_lock_local_lock+0x1e/0x30\r\n[ 2692.124053]  [\u003cffffffff81198f5d\u003e] mntput_no_expire+0x1d/0xf0\r\n[ 2692.124053]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2692.124053]  [\u003cffffffff8117ad83\u003e] __fput+0x153/0x210\r\n[ 2692.124053]  [\u003cffffffff8117ae65\u003e] fput+0x25/0x30\r\n[ 2692.124053]  [\u003cffffffff81065a89\u003e] removed_exe_file_vma+0x39/0x50\r\n[ 2692.124053]  [\u003cffffffff81143039\u003e] remove_vma+0x89/0x90\r\n[ 2692.124053]  [\u003cffffffff81145b38\u003e] exit_mmap+0xe8/0x140\r\n[ 2692.124053]  [\u003cffffffff81065b42\u003e] mmput.part.16+0x42/0x130\r\n[ 2692.124053]  [\u003cffffffff81065c59\u003e] mmput+0x29/0x30\r\n[ 2692.124053]  [\u003cffffffff8106c5f3\u003e] exit_mm+0x113/0x130\r\n[ 2692.124053]  [\u003cffffffff810e5555\u003e] ? taskstats_exit+0x45/0x240\r\n[ 2692.124053]  [\u003cffffffff8165e785\u003e] ? _raw_spin_lock_irq+0x15/0x20\r\n[ 2692.124053]  [\u003cffffffff8106c77e\u003e] do_exit+0x16e/0x450\r\n[ 2692.124053]  [\u003cffffffff8165f620\u003e] oops_end+0xb0/0xf0\r\n[ 2692.124053]  [\u003cffffffff81644907\u003e] no_context+0x150/0x15d\r\n[ 2692.124053]  [\u003cffffffff81644adf\u003e] __bad_area_nosemaphore+0x1cb/0x1ea\r\n[ 2692.124053]  [\u003cffffffff816441e4\u003e] ? pud_offset+0x1a/0x20\r\n[ 2692.124053]  [\u003cffffffff81644b11\u003e] bad_area_nosemaphore+0x13/0x15\r\n[ 2692.124053]  [\u003cffffffff81662266\u003e] do_page_fault+0x426/0x520\r\n[ 2692.124053]  [\u003cffffffff81323730\u003e] ? zlib_inflate+0x1320/0x16d0\r\n[ 2692.124053]  [\u003cffffffff81318c41\u003e] ? vsnprintf+0x461/0x600\r\n[ 2692.124053]  [\u003cffffffff8165ebf5\u003e] page_fault+0x25/0x30\r\n[ 2692.124053]  [\u003cffffffff81198f68\u003e] ? mntput_no_expire+0x28/0xf0\r\n[ 2692.124053]  [\u003cffffffff81198f5d\u003e] ? mntput_no_expire+0x1d/0xf0\r\n[ 2692.124053]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2692.124053]  [\u003cffffffff8119addc\u003e] kern_unmount+0x2c/0x40\r\n[ 2692.124053]  [\u003cffffffff811d9ca5\u003e] pid_ns_release_proc+0x15/0x20\r\n[ 2692.124053]  [\u003cffffffff811de8f9\u003e] proc_flush_task+0x89/0xa0\r\n[ 2692.124053]  [\u003cffffffff8106b1e3\u003e] release_task+0x33/0x130\r\n[ 2692.124053]  [\u003cffffffff8131b1cd\u003e] ? __put_user_4+0x1d/0x30\r\n[ 2692.124053]  [\u003cffffffff8106b77e\u003e] wait_task_zombie+0x49e/0x5f0\r\n[ 2692.124053]  [\u003cffffffff8106b9d3\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 2692.124053]  [\u003cffffffff8106baa5\u003e] wait_consider_task+0x65/0x70\r\n[ 2692.124053]  [\u003cffffffff8106bbb1\u003e] do_wait+0x101/0x260\r\n[ 2692.124053]  [\u003cffffffff8106cf00\u003e] sys_wait4+0xa0/0xf0\r\n[ 2692.124053]  [\u003cffffffff8106a700\u003e] ? wait_task_continued+0x170/0x170\r\n[ 2692.124053]  [\u003cffffffff81666a82\u003e] system_call_fastpath+0x16/0x1b\r\n[ 2692.124053] Code: 90 90 90 90 90 90 55 b8 00 00 01 00 48 89 e5 f0 0f c1 07 89 c2 c1 ea 10 66 39 c2 74 13 66 0f 1f 84 00 00 00 00 00 f3 90 0f b7 07 \u003c66\u003e 39 d0 75 f6 5d c3 0f 1f 40 00 8b 17 55 31 c0 48 89 e5 89 d1\r\n[ 2692.124053] Call Trace:\r\n[ 2692.124053]  [\u003cffffffff8119712e\u003e] vfsmount_lock_local_lock+0x1e/0x30\r\n[ 2692.124053]  [\u003cffffffff81198f5d\u003e] mntput_no_expire+0x1d/0xf0\r\n[ 2692.124053]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2692.124053]  [\u003cffffffff8117ad83\u003e] __fput+0x153/0x210\r\n[ 2692.124053]  [\u003cffffffff8117ae65\u003e] fput+0x25/0x30\r\n[ 2692.124053]  [\u003cffffffff81065a89\u003e] removed_exe_file_vma+0x39/0x50\r\n[ 2692.124053]  [\u003cffffffff81143039\u003e] remove_vma+0x89/0x90\r\n[ 2692.124053]  [\u003cffffffff81145b38\u003e] exit_mmap+0xe8/0x140\r\n[ 2692.124053]  [\u003cffffffff81065b42\u003e] mmput.part.16+0x42/0x130\r\n[ 2692.124053]  [\u003cffffffff81065c59\u003e] mmput+0x29/0x30\r\n[ 2692.124053]  [\u003cffffffff8106c5f3\u003e] exit_mm+0x113/0x130\r\n[ 2692.124053]  [\u003cffffffff810e5555\u003e] ? taskstats_exit+0x45/0x240\r\n[ 2692.124053]  [\u003cffffffff8165e785\u003e] ? _raw_spin_lock_irq+0x15/0x20\r\n[ 2692.124053]  [\u003cffffffff8106c77e\u003e] do_exit+0x16e/0x450\r\n[ 2692.124053]  [\u003cffffffff8165f620\u003e] oops_end+0xb0/0xf0\r\n[ 2692.124053]  [\u003cffffffff81644907\u003e] no_context+0x150/0x15d\r\n[ 2692.124053]  [\u003cffffffff81644adf\u003e] __bad_area_nosemaphore+0x1cb/0x1ea\r\n[ 2692.124053]  [\u003cffffffff816441e4\u003e] ? pud_offset+0x1a/0x20\r\n[ 2692.124053]  [\u003cffffffff81644b11\u003e] bad_area_nosemaphore+0x13/0x15\r\n[ 2692.124053]  [\u003cffffffff81662266\u003e] do_page_fault+0x426/0x520\r\n[ 2692.124053]  [\u003cffffffff81323730\u003e] ? zlib_inflate+0x1320/0x16d0\r\n[ 2692.124053]  [\u003cffffffff81318c41\u003e] ? vsnprintf+0x461/0x600\r\n[ 2692.124053]  [\u003cffffffff8165ebf5\u003e] page_fault+0x25/0x30\r\n[ 2692.124053]  [\u003cffffffff81198f68\u003e] ? mntput_no_expire+0x28/0xf0\r\n[ 2692.124053]  [\u003cffffffff81198f5d\u003e] ? mntput_no_expire+0x1d/0xf0\r\n[ 2692.124053]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2692.124053]  [\u003cffffffff8119addc\u003e] kern_unmount+0x2c/0x40\r\n[ 2692.124053]  [\u003cffffffff811d9ca5\u003e] pid_ns_release_proc+0x15/0x20\r\n[ 2692.124053]  [\u003cffffffff811de8f9\u003e] proc_flush_task+0x89/0xa0\r\n[ 2692.124053]  [\u003cffffffff8106b1e3\u003e] release_task+0x33/0x130\r\n[ 2692.124053]  [\u003cffffffff8131b1cd\u003e] ? __put_user_4+0x1d/0x30\r\n[ 2692.124053]  [\u003cffffffff8106b77e\u003e] wait_task_zombie+0x49e/0x5f0\r\n[ 2692.124053]  [\u003cffffffff8106b9d3\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 2692.124053]  [\u003cffffffff8106baa5\u003e] wait_consider_task+0x65/0x70\r\n[ 2692.124053]  [\u003cffffffff8106bbb1\u003e] do_wait+0x101/0x260\r\n[ 2692.124053]  [\u003cffffffff8106cf00\u003e] sys_wait4+0xa0/0xf0\r\n[ 2692.124053]  [\u003cffffffff8106a700\u003e] ? wait_task_continued+0x170/0x170\r\n[ 2692.124053]  [\u003cffffffff81666a82\u003e] system_call_fastpath+0x16/0x1b\r\nvagrant@precise64:~$ dmesg | less\r\n[ 2720.112029]  [\u003cffffffff81644b11\u003e] bad_area_nosemaphore+0x13/0x15\r\n[ 2720.112029]  [\u003cffffffff81662266\u003e] do_page_fault+0x426/0x520\r\n[ 2720.112029]  [\u003cffffffff81323730\u003e] ? zlib_inflate+0x1320/0x16d0\r\n[ 2720.112029]  [\u003cffffffff81318c41\u003e] ? vsnprintf+0x461/0x600\r\n[ 2720.112029]  [\u003cffffffff8165ebf5\u003e] page_fault+0x25/0x30\r\n[ 2720.112029]  [\u003cffffffff81198f68\u003e] ? mntput_no_expire+0x28/0xf0\r\n[ 2720.112029]  [\u003cffffffff81198f5d\u003e] ? mntput_no_expire+0x1d/0xf0\r\n[ 2720.112029]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2720.112029]  [\u003cffffffff8119addc\u003e] kern_unmount+0x2c/0x40\r\n[ 2720.112029]  [\u003cffffffff811d9ca5\u003e] pid_ns_release_proc+0x15/0x20\r\n[ 2720.112029]  [\u003cffffffff811de8f9\u003e] proc_flush_task+0x89/0xa0\r\n[ 2720.112029]  [\u003cffffffff8106b1e3\u003e] release_task+0x33/0x130\r\n[ 2720.112029]  [\u003cffffffff8131b1cd\u003e] ? __put_user_4+0x1d/0x30\r\n[ 2720.112029]  [\u003cffffffff8106b77e\u003e] wait_task_zombie+0x49e/0x5f0\r\n[ 2720.112029]  [\u003cffffffff8106b9d3\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 2720.112029]  [\u003cffffffff8106baa5\u003e] wait_consider_task+0x65/0x70\r\n[ 2720.112029]  [\u003cffffffff8106bbb1\u003e] do_wait+0x101/0x260\r\n[ 2720.112029]  [\u003cffffffff8106cf00\u003e] sys_wait4+0xa0/0xf0\r\n[ 2720.112029]  [\u003cffffffff8106a700\u003e] ? wait_task_continued+0x170/0x170\r\n[ 2720.112029]  [\u003cffffffff81666a82\u003e] system_call_fastpath+0x16/0x1b\r\n[ 2720.112029] Code: 90 90 90 90 90 90 90 90 90 55 b8 00 00 01 00 48 89 e5 f0 0f c1 07 89 c2 c1 ea 10 66 39 c2 74 13 66 0f 1f 84 00 00 00 00 00 f3 90 \u003c0f\u003e b7 07 66 39 d0 75 f6 5d c3 0f 1f 40 00 8b 17 55 31 c0 48 89\r\n[ 2720.112029] Call Trace:\r\n[ 2720.112029]  [\u003cffffffff8119712e\u003e] vfsmount_lock_local_lock+0x1e/0x30\r\n[ 2720.112029]  [\u003cffffffff81198f5d\u003e] mntput_no_expire+0x1d/0xf0\r\n[ 2720.112029]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2720.112029]  [\u003cffffffff8117ad83\u003e] __fput+0x153/0x210\r\n[ 2720.112029]  [\u003cffffffff8117ae65\u003e] fput+0x25/0x30\r\n[ 2720.112029]  [\u003cffffffff81065a89\u003e] removed_exe_file_vma+0x39/0x50\r\n[ 2720.112029]  [\u003cffffffff81143039\u003e] remove_vma+0x89/0x90\r\n[ 2720.112029]  [\u003cffffffff81145b38\u003e] exit_mmap+0xe8/0x140\r\n[ 2720.112029]  [\u003cffffffff81065b42\u003e] mmput.part.16+0x42/0x130\r\n[ 2720.112029]  [\u003cffffffff81065c59\u003e] mmput+0x29/0x30\r\n[ 2720.112029]  [\u003cffffffff8106c5f3\u003e] exit_mm+0x113/0x130\r\n[ 2720.112029]  [\u003cffffffff810e5555\u003e] ? taskstats_exit+0x45/0x240\r\n[ 2720.112029]  [\u003cffffffff8165e785\u003e] ? _raw_spin_lock_irq+0x15/0x20\r\n[ 2720.112029]  [\u003cffffffff8106c77e\u003e] do_exit+0x16e/0x450\r\n[ 2720.112029]  [\u003cffffffff8165f620\u003e] oops_end+0xb0/0xf0\r\n[ 2720.112029]  [\u003cffffffff81644907\u003e] no_context+0x150/0x15d\r\n[ 2720.112029]  [\u003cffffffff81644adf\u003e] __bad_area_nosemaphore+0x1cb/0x1ea\r\n[ 2720.112029]  [\u003cffffffff816441e4\u003e] ? pud_offset+0x1a/0x20\r\n[ 2720.112029]  [\u003cffffffff81644b11\u003e] bad_area_nosemaphore+0x13/0x15\r\n[ 2720.112029]  [\u003cffffffff81662266\u003e] do_page_fault+0x426/0x520\r\n[ 2720.112029]  [\u003cffffffff81323730\u003e] ? zlib_inflate+0x1320/0x16d0\r\n[ 2720.112029]  [\u003cffffffff81318c41\u003e] ? vsnprintf+0x461/0x600\r\n[ 2720.112029]  [\u003cffffffff8165ebf5\u003e] page_fault+0x25/0x30\r\n[ 2720.112029]  [\u003cffffffff81198f68\u003e] ? mntput_no_expire+0x28/0xf0\r\n[ 2720.112029]  [\u003cffffffff81198f5d\u003e] ? mntput_no_expire+0x1d/0xf0\r\n[ 2720.112029]  [\u003cffffffff8119904f\u003e] mntput+0x1f/0x30\r\n[ 2720.112029]  [\u003cffffffff8119addc\u003e] kern_unmount+0x2c/0x40\r\n[ 2720.112029]  [\u003cffffffff811d9ca5\u003e] pid_ns_release_proc+0x15/0x20\r\n[ 2720.112029]  [\u003cffffffff811de8f9\u003e] proc_flush_task+0x89/0xa0\r\n[ 2720.112029]  [\u003cffffffff8106b1e3\u003e] release_task+0x33/0x130\r\n[ 2720.112029]  [\u003cffffffff8131b1cd\u003e] ? __put_user_4+0x1d/0x30\r\n[ 2720.112029]  [\u003cffffffff8106b77e\u003e] wait_task_zombie+0x49e/0x5f0\r\n[ 2720.112029]  [\u003cffffffff8106b9d3\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 2720.112029]  [\u003cffffffff8106baa5\u003e] wait_consider_task+0x65/0x70\r\n[ 2720.112029]  [\u003cffffffff8106bbb1\u003e] do_wait+0x101/0x260\r\n[ 2720.112029]  [\u003cffffffff8106cf00\u003e] sys_wait4+0xa0/0xf0\r\n[ 2720.112029]  [\u003cffffffff8106a700\u003e] ? wait_task_continued+0x170/0x170\r\n[ 2720.112029]  [\u003cffffffff81666a82\u003e] system_call_fastpath+0x16/0x1b\r\n(END)\r\n```","As another data point, I just ran the crashTest.go script on a Debian Wheezy VM running under Virtualbox on a dual-core i7 Macbook Air:\r\n\r\n```\r\n$ docker version\r\nVersion: 0.3.2\r\nGit Commit: e289308\r\nKernel: 3.2.0-4-amd64\r\nWARNING: No memory limit support\r\nWARNING: No swap limit support\r\n\r\n$ uname -rv\r\n3.2.0-4-amd64 #1 SMP Debian 3.2.41-2\r\n\r\n$ cat /proc/cpuinfo | grep processor\r\nprocessor\t: 0\r\n```\r\n\r\nThe script has been running for an hour without crashing, and has done just over 10,000 runs. Memory usage remained constant throughout (with between 4 and 6MB free out of 250MB the whole time).\r\n\r\n```\r\n$ sudo /usr/local/go/bin/go run crashTest.go \r\n2013/05/23 00:05:54 WARNING: You are running linux kernel version 3.2.0-4-amd64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.\r\n2013/05/23 00:05:54 WARNING: cgroup mountpoint not found for memory\r\n2013/05/23 00:05:54 Listening for RCLI/tcp on 127.0.0.1:4242\r\n2013/05/23 00:05:54 docker run base echo 3\r\n2013/05/23 00:05:54 docker run base echo 4\r\n...\r\n2013/05/23 01:05:59 docker run base echo 10153\r\n2013/05/23 01:05:59 docker run base echo 10154\r\n```\r\n\r\nI think this means either:\r\n\r\n * I've made a mistake somewhere\r\n * The bug is a regression introduced after 3.2.0\r\n * The bug only affects the Ubuntu kernel tree\r\n\r\nI hope some progress can be made on this issue. One of the things that I like about Docker is how easy it is to get started, requiring a 3.8 kernel makes that much harder in many environments.","Broadening kernel support is going to be a major priority for us in June. I'm also frustrated by the current kernel situation!\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 7:09 PM, Paul Hammond \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e As another data point, I just ran the crashTest.go script on a Debian Wheezy VM running under Virtualbox on a dual-core i7 Macbook Air:\r\n\u003e ```\r\n\u003e $ docker version\r\n\u003e Version: 0.3.2\r\n\u003e Git Commit: e289308\r\n\u003e Kernel: 3.2.0-4-amd64\r\n\u003e WARNING: No memory limit support\r\n\u003e WARNING: No swap limit support\r\n\u003e $ uname -rv\r\n\u003e 3.2.0-4-amd64 #1 SMP Debian 3.2.41-2\r\n\u003e $ cat /proc/cpuinfo | grep processor\r\n\u003e processor\t: 0\r\n\u003e ```\r\n\u003e The script has been running for an hour without crashing, and has done just over 10,000 runs. Memory usage remained constant throughout (with between 4 and 6MB free out of 250MB the whole time).\r\n\u003e ```\r\n\u003e $ sudo /usr/local/go/bin/go run crashTest.go \r\n\u003e 2013/05/23 00:05:54 WARNING: You are running linux kernel version 3.2.0-4-amd64, which might be unstable running docker. Please upgrade your kernel to 3.8.0.\r\n\u003e 2013/05/23 00:05:54 WARNING: cgroup mountpoint not found for memory\r\n\u003e 2013/05/23 00:05:54 Listening for RCLI/tcp on 127.0.0.1:4242\r\n\u003e 2013/05/23 00:05:54 docker run base echo 3\r\n\u003e 2013/05/23 00:05:54 docker run base echo 4\r\n\u003e ...\r\n\u003e 2013/05/23 01:05:59 docker run base echo 10153\r\n\u003e 2013/05/23 01:05:59 docker run base echo 10154\r\n\u003e ```\r\n\u003e I think this means either:\r\n\u003e  * I've made a mistake somewhere\r\n\u003e  * The bug is a regression introduced after 3.2.0\r\n\u003e  * The bug only affects the Ubuntu kernel tree\r\n\u003e I hope some progress can be made on this issue. One of the things that I like about Docker is how easy it is to get started, requiring a 3.8 kernel makes that much harder in many environments.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/407#issuecomment-18318033","Hi guys, sorry I wasn't aware of this issue when I did my write up for OStatic. I'll update the post with a link back here. I experienced what looks to be this bug on Ubuntu 12.04 LTS, 64bit. ","I had something very similar in the past and was related to the hardware/kernel pair. Please test it on different CPU families if you can to see correlations.","I'm closing this since it's not immediately actionable.","For the record, Josh Poimboeuf found something which might be related to this:\r\n\r\n\u003e I did some digging.  These panics seem to be caused by some race\r\n\u003e conditions related to removing a container's mounts.  I was easily able\r\n\u003e to recreate with:\r\n\u003e \r\n\u003e for i in `seq 1 100`; do docker run -i -t -d ubuntu bash; done |xargs docker kill\r\n\u003e\r\n\u003e The fixes needed for RHEL 6.4 (based on 2.6.32) are in the following two\r\n\u003e upstream kernel commits:\r\n\u003e\r\n\u003e - \"45a68628d37222e655219febce9e91b6484789b2\" (fixed in 2.6.39)\r\n\u003e - \"17cf22c33e1f1b5e435469c84e43872579497653\" (fixed in 3.8)","can we keep this open? still verified with 0.11 and kernel 3.2.0 (2 processors)\r\n\r\nhttps://gist.github.com/gdm85/9328ae13653e5683adda","Relevant Hacker News thread: https://news.ycombinator.com/item?id=5560576","Oh hey, posted the above HN comment.  Poking through the Mesos project I found an example for a mesos scheduler for haproxy using the python bindings: https://github.com/apache/mesos/tree/trunk/frameworks/haproxy+apache\r\nand a 'test' example:\r\nhttps://github.com/apache/mesos/blob/trunk/src/examples/python/test_framework.py\r\n\r\nActually seems fairly straightforward to adapt into a docker scheduler that pulls it's configuration out of redis or something to get real-time programmatic provisioning/scaling/monitoring of dockers across a mesos cluster.","If you end up doing this, use the zookeeper that comes with mesos.  Redis would be a poor fit.","I actually got a POC of this working plus an angular web GUI to add and remove apps and set # of instances(dockers in this case but it basically downloads and runs anything as a daemon).   I've also been using http://www.pgbovine.net/cde.html and http://megastep.org/makeself/ which is like a different way to achieve something similar to docker (without the LXC action though mesos can do that for you if desired).  \r\n\r\nSince I developed it for my current employer I can't share it at the moment but I'm going to try to get approval to open source it soon - it's really not much - less than 300 lines of code.   \r\n\r\nI like redis because it has better data primitives than zookeeper and ties in well with the other components I'm using:\r\nhttps://github.com/nicolasff/webdis -  RESTFUL interface to redis, Used by frontend GUI to set current App configurations.  (i.e no need to write a backend)\r\nhttps://github.com/dotcloud/hipache - nodejs distributed HTTP websocket proxy- made by the same folks as docker.   Basically this is a proxy service that reads it’s configuration out of redis for each request.  This allows us to dynamically map someapp.docker_cluster.example.com to a wildcard DNS *.docker_cluster.example.com to a VIP that terminates SSL and points to several hipache backends will look up and proxy to the correct mesos nodes and internal ports for the application.\r\n\r\nThough I agree since Mesos uses zookeeper already and redis is less clusterable it's probably a good idea to try and make the switch. ","Yeah, if you need a hand with zookeeper, let me know.  You write this in python, or what?","Let me throw out an opinion, which is that I'd write this in Java for now, because mesos interface is moving fast, and the python interfaces have been changing.  It'd be nice to compile and know you're not obviously broken.  Airbnb/chronos is in Scala.  I might try to adapt it.","I submitted the form to opensource what I've already created and can hopefully get it contributed soon.    I'm a fan of python for stuff like this (I'm using http://circus.readthedocs.org/en/0.7/ to manage the daemons from the mesos executor)   Circus gives you a lot of cool tools (and a decent API) to manage and monitor processes instead of having to roll all that yourself which is harder than it seems.   ","@siliconcow Any news on POC?","@siliconcow any other updates on this?","Haven't had time to work on this but basically there are three parts and some need to be detangled from proprietary bits:\r\n* Mesos Executor/Framework.  I can throw up a PR to /contrib since I can release it as whatever - written on my own time.   I've modified it to work with the latest 0.13 mesos python API but haven't had a chance to test it. \r\n\r\n* Chef cookbooks to bootstrap base components (docker, mesos masters, slaves, zk, java, python, node, hipache, etc).   A lot of this can't be distributed unfortunately since I used some in house chef stuff.   If I get some time I can switch 'em out with community versions which shouldn't require too much modification.  Some components can obviously be run as dockers but you still need something to dynamically configure the environment and I'm too used to chef to go back to writing bash scripts.   \r\n\r\n* Web UI - this is pretty trivial but has some parts I need to modify before I can distribute it. (it's just an interface to update redis items essentially, a stock redis admin UI could do the same).  \r\n\r\nThere are like at least two other initiatives that that are trying to do this same thing so it may not be worth pursuing this particular implementation (A pure go raft distributed scheduler sounds pretty rad). ","@siliconcow I'm very interested in the mesos executor/framework as opposed to pure docker schedulers in order to share the servers with other mesos frameworks.","I'm copying @fkautz who offered to work on unifying how docker integrates with orchestration tools.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, Aug 2, 2013 at 10:51 PM, Jordan Curzon \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @siliconcow I'm very interested in the mesos executor/framework as opposed to pure docker schedulers in order to share the servers with other mesos frameworks.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/410#issuecomment-22050277","Great stuff, catching up on this. I think adding mesos is a great idea, and one I was considering to attempt.\r\n\r\nWe should carefully investigate any implications using mesos would have when running containers. If we tightly couple an image to work only on mesos, we risk fragmenting the ecosystem.\r\n\r\nOne option that has come up is the concept of using plugins that are themselves docker containers that run with access to the original image. Ideally, service discovery would be provided as a standardized api or service that is transformed to an implementation such as zookeeper or etcd. In essence, a well built standards compliant container could then run in standalone, maestro, mesos, yarn, or custom systems without being tightly coupled to any.","@siliconcow Are you able to set up a repo with #1397 work committed and post the url here?","Those who need something like this should take a look at PR #1397. ","Haven't been able to find a conclusion for this work.","I believe the consensus was that mesos integration was outside of the scope of the docker project itself. That being said, mesos/docker integration is still a good idea and of value.\r\n\r\nBasically, #1397 should be the start of a new project that performs that integration. I haven't seen the upstream author recently though, but he/she would be a good person to ask about the state of the integration.","Thanks @fkautz for your quick answer. I asked since I see that no work has been merged from #1397 to master yet. I share the same opinion about the value of such integration.","Hey, I stopped working on this because the good people who wrote chronos wrote a better, more featureful version of what I wrote called marathon: https://github.com/mesosphere/marathon.   I haven't tried yet but you should be able to get marathon to throw up docker daemons.   ","Thanks for the update. I have connections to them, so I'll reach out.\r\nOn Sep 19, 2013 12:42 PM, \"siliconcow\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Hey, I stopped working on this because the good people who wrote chronos\r\n\u003e wrote a better, more featureful version of what I wrote called marathon:\r\n\u003e https://github.com/mesosphere/marathon. I haven't tried yet but you\r\n\u003e should be able to get marathon to throw up docker daemons.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/410#issuecomment-24767631\u003e\r\n\u003e .\r\n\u003e","I am new to this ecosystem, so I might be mistaken in what this issue was attempting to do, but it looks like the fine folks at Mesosphere wrote a Docker executor:\r\nhttp://mesosphere.io/2013/09/26/docker-on-mesos/\r\n\r\nNow Mesos knows how to launch Docker containers. Cool.\r\n\r\n","You also pretty much just use marathon out of the box to run dockers:\r\n![marathon](https://f.cloud.github.com/assets/908362/1405593/a19d12da-3d34-11e3-887f-f53cfdaa1404.png)\r\n","Oh wow @siliconcow. Seems obvious now, but I had no idea. Thanks for that!","PR #707 has made the changes needed for this issue. All future changes needed for multiple architecture support will be made and tracked via pull requests.","Fixed by #557 ","As discussed with @vieux, the right approach is probably to compute the hash when first unpacking the archive. So that would be implemented somewhere inside Graph.Register.\r\n\r\n@vieux ok with closing this one?","Thanks @vieux. This is very useful *but* it really slows down 'docker images' since you're walking every layer every time.. Instead maybe you could compute the size once at Register, and cache it somewhere?","Also, I crashed docker with 'docker ps -a'. See trace below:\r\n\r\n```\r\n2013/04/17 10:44:18 Listening for RCLI/tcp on 127.0.0.1:4242\r\n2013/04/17 10:44:20 docker ps -a\r\npanic: runtime error: invalid memory address or nil pointer dereference\r\n[signal 0xb code=0x1 addr=0x40 pc=0x452f7e]\r\n\r\ngoroutine 9 [running]:\r\ngithub.com/dotcloud/docker._func_017(0x7f0d5d849340, 0x4a0d6f, 0xf84019fc00, 0x7f0d0000005e, 0x0, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/container.go:764 +0x2c\r\npath/filepath.Walk(0xf84019fc00, 0x5e, 0xf8402f23c0, 0xf8402f23c0, 0x100000001, ...)\r\n\t/usr/lib/go/src/pkg/path/filepath/path.go:341 +0x98\r\ngithub.com/dotcloud/docker.(*Container).GetSize(0xf8400da500, 0xf8401e1e28, 0x6, 0xf8402f3d80)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/container.go:766 +0xb6\r\ngithub.com/dotcloud/docker.(*Server).CmdPs(0xf840114488, 0xf840152060, 0xf8401e3210, 0xf840152090, 0xf8400f11e0, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/commands.go:699 +0x7b1\r\n----- stack segment boundary -----\r\nreflect.Value.call(0x62bfa8, 0x434a28, 0x130, 0x68dc14, 0x6c6c614300000009, ...)\r\n\t/usr/lib/go/src/pkg/reflect/value.go:521 +0x135e\r\nreflect.Value.CallSlice(0x62bfa8, 0x434a28, 0x130, 0x7f0d5d849bf0, 0x400000004, ...)\r\n\t/usr/lib/go/src/pkg/reflect/value.go:347 +0x85\r\ngithub.com/dotcloud/docker/rcli._func_004(0xf8400f0730, 0xf8401e31e0, 0x457927, 0xf840152060, 0xf8401e30e0, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/types.go:165 +0x21e\r\ngithub.com/dotcloud/docker/rcli.LocalCall(0xf8401e2ae0, 0xf840114488, 0xf840152060, 0xf8401e30e0, 0xf8401f7000, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/types.go:134 +0x699\r\ngithub.com/dotcloud/docker/rcli.call(0xf8401e2ae0, 0xf840114488, 0xf840152060, 0xf8401e30e0, 0xf8401f7000, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/types.go:114 +0x89\r\ngithub.com/dotcloud/docker/rcli.Serve(0xf8401f7000, 0xf8400f11e0, 0xf8401e2ae0, 0xf840114488, 0x0, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/tcp.go:166 +0x2a8\r\ngithub.com/dotcloud/docker/rcli._func_001(0xf840151f20, 0xf8401f7000, 0xf8400f11e0, 0x0)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/tcp.go:146 +0xc7\r\ncreated by github.com/dotcloud/docker/rcli.ListenAndServe\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/tcp.go:150 +0x301\r\n\r\ngoroutine 1 [chan receive]:\r\nnet.(*pollServer).WaitRead(0xf8400ee580, 0xf8401f93f0, 0xf84007e6c0, 0xb, 0x1, ...)\r\n\t/usr/lib/go/src/pkg/net/fd.go:268 +0x73\r\nnet.(*netFD).accept(0xf8401f93f0, 0x504a0c, 0x0, 0xf84007b0f0, 0xf84008b040, ...)\r\n\t/usr/lib/go/src/pkg/net/fd.go:622 +0x20d\r\nnet.(*TCPListener).AcceptTCP(0xf8401141d0, 0xf8401f7000, 0x0, 0x0, 0x18, ...)\r\n\t/usr/lib/go/src/pkg/net/tcpsock_posix.go:320 +0x71\r\nnet.(*TCPListener).Accept(0xf8401141d0, 0x0, 0x0, 0x0, 0x0, ...)\r\n\t/usr/lib/go/src/pkg/net/tcpsock_posix.go:330 +0x49\r\ngithub.com/dotcloud/docker/rcli.ListenAndServe(0x68b9ec, 0x70637400000003, 0x69fcb4, 0x2e3732310000000e, 0xf8401e2ae0, ...)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/rcli/tcp.go:134 +0x226\r\nmain.daemon(0x69fbb4, 0x13, 0x0, 0x0, 0x0, ...)\r\n\t/home/sandbox/docker/docker/docker.go:102 +0x357\r\nmain.main()\r\n\t/home/sandbox/docker/docker/docker.go:51 +0x2db\r\n\r\ngoroutine 2 [syscall]:\r\ncreated by runtime.main\r\n\t/build/buildd/golang-1.0.2/src/pkg/runtime/proc.c:221\r\n\r\ngoroutine 3 [syscall]:\r\nos/signal.loop()\r\n\t/usr/lib/go/src/pkg/os/signal/signal_unix.go:20 +0x1c\r\ncreated by os/signal.init·1\r\n\t/usr/lib/go/src/pkg/os/signal/signal_unix.go:26 +0x2f\r\n\r\ngoroutine 4 [chan receive]:\r\nmain._func_001(0xf84008b448, 0xf840088ba0, 0x0, 0x0)\r\n\t/home/sandbox/docker/docker/docker.go:92 +0x31\r\ncreated by main.daemon\r\n\t/home/sandbox/docker/docker/docker.go:96 +0x2a5\r\n\r\ngoroutine 5 [select]:\r\ngithub.com/dotcloud/docker.(*IPAllocator).run(0xf8400f3820, 0x0)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/network.go:352 +0x345\r\ncreated by github.com/dotcloud/docker.newIPAllocator\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/network.go:393 +0xbd\r\n\r\ngoroutine 6 [chan send]:\r\ngithub.com/dotcloud/docker.(*PortAllocator).runFountain(0xf8400f3860, 0x0)\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/network.go:260 +0x46\r\ncreated by github.com/dotcloud/docker.newPortAllocator\r\n\t/home/sandbox/docker/.gopath/src/github.com/dotcloud/docker/network.go:299 +0x9a\r\n\r\ngoroutine 7 [finalizer wait]:\r\ncreated by runtime.gc\r\n\t/build/buildd/golang-1.0.2/src/pkg/runtime/mgc0.c:882\r\n\r\ngoroutine 8 [syscall]:\r\nsyscall.Syscall6()\r\n\t/build/buildd/golang-1.0.2/src/pkg/syscall/asm_linux_amd64.s:40 +0x5\r\nsyscall.EpollWait(0xf800000006, 0xf8400b80c0, 0xa0000000a, 0xffffffff, 0xc, ...)\r\n\t/usr/lib/go/src/pkg/syscall/zerrors_linux_amd64.go:1781 +0xa1\r\nnet.(*pollster).WaitFD(0xf8400b80b0, 0xf8400ee580, 0x0, 0x0, 0x0, ...)\r\n\t/usr/lib/go/src/pkg/net/fd_linux.go:146 +0x110\r\nnet.(*pollServer).Run(0xf8400ee580, 0x0)\r\n\t/usr/lib/go/src/pkg/net/fd.go:236 +0xe4\r\ncreated by net.newPollServer\r\n\t/usr/lib/go/src/pkg/net/newpollserver.go:35 +0x382\r\n```","I removed useless code as @dominikh pointed out.\r\nI'll now look at calculating the size on register as we discussed.\r\nJust one question, for the images already registered, should I still calcul the size in docker images (and store it) ?\r\n","I think you can just check if the size as already been calculated, if not do it.","Currently during a docker pull base, b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc is downloaded before 27cf784147099545 so I can't compute the size (or at least not in register)","So maybe we can still do the computation in docker images, but store the results to compute it only 1 time, and add a -s to disply the size, default it's not displayed.\r\n\r\nWhat do you think ?\r\n","Images are immutable, so they can ship their size in their config. Now, there is two ways to retrieve an image: Import and Pull. Maybe it would be more interesting to check if that data is there at this moment?\r\nAs you don't have the warranty to have the whole image tree while the pull, maybe you can compute the missing sizes at once the pull is finish?","As the code changed a lot with the remote API, I did another PR #594 ","why \"-s\" ? second?\r\nWouldn't it be beter -t or even better -timeout?","Yes you're right, I prefer to keep small flags with the current flag system. \n\nI'll update to -t asap ","@creack done (I edited the commit ;) )","Tests don't pass, I'm guessing because of the prototype change in Container.Stop","Related to #230 ","Would you happen to run lxc 0.9?","Yes I do.","For some reason lxc 0.9 drop the environment, I am working on it. Let's keep this ticket to track this issue.\r\nThe problem does not occur in lxc0.8","I think this change in the lxc-tools project is responsible:\r\n\r\nhttp://lxc.git.sourceforge.net/git/gitweb.cgi?p=lxc/lxc;a=commitdiff;h=799f96fdd8fc9c0685fffee5998aab2287ebc25f\r\n\r\nThey appear to have introduced environment variable clearing in 0.9.0.","Actually this commit would be more accurate as docker is using lxc-start rather than lxc-attach as far as I can tell.\r\n\r\nhttp://lxc.git.sourceforge.net/git/gitweb.cgi?p=lxc/lxc;a=commitdiff;h=964fe051e9dc21be6c52ccf5b9ff47a8aea396fc","Thanks you!!!!! I was pulling my hair on this all morning!","Unfortunately it seems that only lxc-attach implements a --keep-env flag.","fixes #416 ","Works on my end as well. +1","Works here as well.","I just got an identical error message on:\r\n\r\n```\r\nClient version: 0.4.8\r\nServer version: 0.4.8\r\nGo version: go1.1\r\n```","@jayd3e an error message identical to what?","We discussed this in person a few minutes ago, and actually, it seems to be\nbecause you applied a very low limit (5KB) and the container refused to\nstart.\n\nHowever, when providing a higher limit, we see a different issue: memsw.*\nfiles are not enabled on some kernels.\nMy suggestion is the following:\n- when \"docker -d\" starts, check which control groups are available (file\nmust exist and actually readable; existence and perm check is not enough);\nissue a warning when files can't be found\n- when starting a container, only include directives that are known to work\n(i.e. if we found that memsw doesn't work, don't include it)","When booting with cgroup_enable=memory swapaccount=1, everything works fine.","see #433 for graceful start while ignoring the unsupported capabilities.\r\n@mzdaniel is working on packaging, this will automatically change the kernel config (upon user opt-in)\r\nsee #437 for the documentation without packaging\r\nClosing.","Fixed in 13d9e26edd62228597cf8f060ed397f7ae00298a","cc @adamwiggins","+1 on changing the behavior of attach.\r\nIt is safe to say nobody relies on the current behavior as the attach restart does not work yet.\r\n","Either I don't understand this issue, or it no longer exists, or it doesn't repro for me. It seems like attach exits just fine when the process exits.\r\n\r\n```\r\n$ ID=$(docker run -d base /bin/bash -c 'for i in `seq 1 10`; do echo $i; sleep 1; done')\r\nWARNING:  Docker detected local DNS server on resolv.conf. Using default external servers: [8.8.8.8 8.8.4.4]\r\n$ docker attach $ID                                                                     \r\n4\r\n5\r\n6\r\n7\r\n8\r\n9\r\n10\r\n$ docker ps\r\nID                  IMAGE               COMMAND             CREATED             STATUS              PORTS\r\n```","Hi, Docker doesn't (yet) support 32-bit hosts. That's why there is no\r\n32-bit builds available. See\r\nhttps://github.com/dotcloud/docker/issues/136for details.\r\n\r\n\r\n\r\nOn Thu, Apr 18, 2013 at 10:53 AM, millisami \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Booted-up ubuntu 12.04 32-bit image. Then\r\n\u003e\r\n\u003e millisami@ubuntu-12:~$ wget http://get.docker.io/builds/$(uname -s)/$(uname -m)/docker-master.tgz\r\n\u003e --2013-04-18 23:33:38--  http://get.docker.io/builds/Linux/i686/docker-master.tgz\r\n\u003e Resolving get.docker.io (get.docker.io)... 205.251.242.194\r\n\u003e Connecting to get.docker.io (get.docker.io)|205.251.242.194|:80... connected.\r\n\u003e HTTP request sent, awaiting response... 404 Not Found\r\n\u003e 2013-04-18 23:33:40 ERROR 404: Not Found.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/423\u003e\r\n\u003e .\r\n\u003e","@shykes That did help. And this info should also be in the README.","Witnessed exactly the same traceback with 3.2.0-40-generic on our local domU testbed.","Was there any other oops/bug in dmesg before that one? Or was it the first symptom?","+1 for crash on digital ocean (probably superfluent, but I had this nearby anyways). Happy to try it again when things changed.\r\n\r\nThe crash happens after a few \u003c 5 commands in interactive mode.\r\n\r\nThis is quantal (3.5.0-17-generic) box on Blue Ocean \r\n\r\nuname -a\r\nLinux blue1 3.5.0-17-generic #28-Ubuntu SMP Tue Oct 9 19:31:23 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n```\r\n[ 2391.685489] Fixing recursive fault but reboot is needed!\r\n[ 2395.737388] BUG: unable to handle kernel NULL pointer dereference at 00000000000000ff\r\n[ 2395.738057] IP: [\u003cffffffff81199b50\u003e] d_hash_and_lookup+0x20/0x60\r\n[ 2395.738493] PGD 1a1c9067 PUD 1c95e067 PMD 0 \r\n[ 2395.738966] Oops: 0000 [#4] SMP \r\n[ 2395.739359] CPU 0 \r\n[ 2395.739460] Modules linked in: veth aufs xt_addrtype ipt_MASQUERADE iptable_nat nf_nat nf_conntrack_ipv4 nf_conntrack nf_defrag_ipv4 ip_tables x_tables bridge stp llc kvm_intel ppdev kvm microcode psmouse parport_pc serio_raw parport vmwgfx mac_hid ttm drm i2c_piix4 8139too 8139cp floppy\r\n[ 2395.740020] \r\n[ 2395.740020] Pid: 1406, comm: pip Tainted: G      D      3.5.0-17-generic #28-Ubuntu Bochs Bochs\r\n[ 2395.740020] RIP: 0010:[\u003cffffffff81199b50\u003e]  [\u003cffffffff81199b50\u003e] d_hash_and_lookup+0x20/0x60\r\n[ 2395.740020] RSP: 0018:ffff88001b25fcf8  EFLAGS: 00010202\r\n[ 2395.740020] RAX: 0000000000003631 RBX: ffff88001b25fd40 RCX: 0000000000000010\r\n[ 2395.740020] RDX: 0000000000000000 RSI: 0000000000000002 RDI: 0000000000003631\r\n[ 2395.740020] RBP: ffff88001b25fd08 R08: 000000000000000a R09: 000000000000fffd\r\n[ 2395.740020] R10: 0000000000000000 R11: 00000000001bc7ec R12: 00000000000000ff\r\n[ 2395.740020] R13: ffff8800197f5e20 R14: 0000000000000000 R15: ffff88001a26a580\r\n[ 2395.740020] FS:  00007f8002f37700(0000) GS:ffff88001f800000(0000) knlGS:0000000000000000\r\n[ 2395.740020] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\n[ 2395.740020] CR2: 00000000000000ff CR3: 000000001c84d000 CR4: 00000000000006f0\r\n[ 2395.740020] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[ 2395.740020] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\r\n[ 2395.740020] Process pip (pid: 1406, threadinfo ffff88001b25e000, task ffff88001c80c500)\r\n[ 2395.740020] Stack:\r\n[ 2395.740020]  ffff88001b25fd53 0000000000000001 ffff88001b25fd98 ffffffff811e79e9\r\n[ 2395.740020]  0000000000000286 ffff88001f8139c0 ffff88001a26a580 0000001000000010\r\n[ 2395.740020]  ffff88001f8139c0 0000000200003631 ffff88001b25fd53 003900363187c500\r\n[ 2395.740020] Call Trace:\r\n[ 2395.740020]  [\u003cffffffff811e79e9\u003e] proc_flush_task+0x99/0x1d0\r\n[ 2395.740020]  [\u003cffffffff81055f50\u003e] release_task+0x30/0x480\r\n[ 2395.740020]  [\u003cffffffff810866f4\u003e] ? thread_group_times+0x44/0xb0\r\n[ 2395.740020]  [\u003cffffffff81056c9d\u003e] wait_consider_task+0x8fd/0xb60\r\n[ 2395.740020]  [\u003cffffffff81057000\u003e] do_wait+0x100/0x250\r\n[ 2395.740020]  [\u003cffffffff810586f5\u003e] sys_wait4+0x75/0xf0\r\n[ 2395.740020]  [\u003cffffffff81055cf0\u003e] ? task_stopped_code+0x60/0x60\r\n[ 2395.740020]  [\u003cffffffff81689d29\u003e] system_call_fastpath+0x16/0x1b\r\n[ 2395.740020] Code: 66 66 2e 0f 1f 84 00 00 00 00 00 55 48 89 e5 41 54 53 0f 1f 44 00 00 48 89 f3 49 89 fc 8b 76 04 48 8b 7b 08 e8 62 34 ff ff 89 03 \u003c41\u003e f6 04 24 01 74 17 49 8b 44 24 60 49 8b 74 24 30 48 89 da 4c \r\n[ 2395.740020] RIP  [\u003cffffffff81199b50\u003e] d_hash_and_lookup+0x20/0x60\r\n[ 2395.740020]  RSP \u003cffff88001b25fcf8\u003e\r\n[ 2395.740020] CR2: 00000000000000ff\r\n[ 2395.760261] ---[ end trace e6dcfbff344dd463 ]---\r\n[ 2401.248047] docker0: port 2(vethn9dnmU) entered forwarding state\r\n```","Our VMs by default do not come with swap, have you enabled swap to see if you encounter the same behavior? \r\n\r\nJust thinking about the most common and likely possibility here.","+1\r\n\r\nI saw this with one container running.  The host is Ubuntu 12.04 running in a 512 meg KVM VM on DigitalOcean.  I had just started the container, done an apt-get update, then it crashed while running apt-get install nginx-extras.  I saw several oopses in a row.\r\n\r\n```\r\n[ 3039.694713] device vethJJrN0J entered promiscuous mode\r\n[ 3039.694822] ADDRCONF(NETDEV_UP): vethJJrN0J: link is not ready\r\n[ 3039.704065] ADDRCONF(NETDEV_CHANGE): vethJJrN0J: link becomes ready\r\n[ 3039.704164] docker0: port 1(vethJJrN0J) entering forwarding state\r\n[ 3039.704169] docker0: port 1(vethJJrN0J) entering forwarding state\r\n[ 3049.904100] vethJJrN0J: no IPv6 routers present\r\n[ 3050.024442] eth0: no IPv6 routers present\r\n[ 3054.752062] docker0: port 1(vethJJrN0J) entering forwarding state\r\n[ 3099.761298] BUG: unable to handle kernel NULL pointer dereference at 0000000000000008\r\n[ 3099.761511] IP: [\u003cffffffff8118ce01\u003e] d_hash_and_lookup+0x71/0x90\r\n[ 3099.761672] PGD 1db25067 PUD 1d5c9067 PMD 0 \r\n[ 3099.761798] Oops: 0000 [#1] SMP \r\n[ 3099.761890] CPU 0 \r\n[ 3099.761937] Modules linked in: veth aufs xt_addrtype ipt_MASQUERADE iptable_nat nf_nat nf_conntrack_ipv4 nf_conntrack nf_defrag_ipv4 ip_tables x_tables bridge stp dm_crypt ppdev psmouse parport_pc parport serio_raw mac_hid i2c_piix4 floppy 8139too 8139cp\r\n[ 3099.762625] \r\n[ 3099.762663] Pid: 1256, comm: apt-get Not tainted 3.2.0-23-virtual #36-Ubuntu Bochs Bochs\r\n[ 3099.762862] RIP: 0010:[\u003cffffffff8118ce01\u003e]  [\u003cffffffff8118ce01\u003e] d_hash_and_lookup+0x71/0x90\r\n[ 3099.763067] RSP: 0018:ffff88001d553cd8  EFLAGS: 00010202\r\n[ 3099.763188] RAX: 0000000000000000 RBX: ffff88001d553d00 RCX: 000000000000be14\r\n[ 3099.763349] RDX: ffff88001d553d00 RSI: 0000000000000000 RDI: ffff88001c932000\r\n[ 3099.763510] RBP: ffff88001d553ce8 R08: ffff88001d553d15 R09: 000000000000fffc\r\n[ 3099.763672] R10: 0000000000000000 R11: 0000000000dad6c2 R12: ffff88001c932000\r\n[ 3099.763834] R13: 000000000000001c R14: 000000000000001c R15: 000000000000001c\r\n[ 3099.764000] FS:  00007fdbf3763740(0000) GS:ffff88001f800000(0000) knlGS:0000000000000000\r\n[ 3099.764079] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\n[ 3099.764079] CR2: 0000000000000008 CR3: 000000001d608000 CR4: 00000000000006f0\r\n[ 3099.764079] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[ 3099.764079] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\r\n[ 3099.764079] Process apt-get (pid: 1256, threadinfo ffff88001d552000, task ffff88001c3a0000)\r\n[ 3099.764079] Stack:\r\n[ 3099.764079]  ffff88001d553d13 ffff88001dce4720 ffff88001d553d58 ffffffff811d5567\r\n[ 3099.764079]  ffff88001c275180 000000020001a22c ffff88001d553d13 0031003832d05b80\r\n[ 3099.764079]  ffff88001d553d80 00000000a1134d72 ffff88001d553d68 0000000000000002\r\n[ 3099.764079] Call Trace:\r\n[ 3099.764079]  [\u003cffffffff811d5567\u003e] proc_flush_task_mnt.isra.12+0x67/0x170\r\n[ 3099.764079]  [\u003cffffffff811d8dea\u003e] proc_flush_task+0x5a/0xa0\r\n[ 3099.764079]  [\u003cffffffff81068eb3\u003e] release_task+0x33/0x130\r\n[ 3099.764079]  [\u003cffffffff81069459\u003e] wait_task_zombie+0x4a9/0x5b0\r\n[ 3099.764079]  [\u003cffffffff81069663\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 3099.764079]  [\u003cffffffff81069735\u003e] wait_consider_task+0x65/0x70\r\n[ 3099.764079]  [\u003cffffffff81069841\u003e] do_wait+0x101/0x260\r\n[ 3099.764079]  [\u003cffffffff8106ab90\u003e] sys_wait4+0xa0/0xf0\r\n[ 3099.764079]  [\u003cffffffff81068400\u003e] ? wait_task_continued+0x170/0x170\r\n[ 3099.764079]  [\u003cffffffff8165d8c2\u003e] system_call_fastpath+0x16/0x1b\r\n[ 3099.764079] Code: 01 c8 48 01 f8 4c 39 c2 48 8d 0c 80 48 8d 3c 48 75 d8 89 3b 41 f6 04 24 01 74 1b 49 8b 44 24 60 48 89 da 49 8b 74 24 30 4c 89 e7 \u003cff\u003e 50 08 89 c2 31 c0 85 d2 78 0b 48 89 de 4c 89 e7 e8 19 ff ff \r\n[ 3099.764079] RIP  [\u003cffffffff8118ce01\u003e] d_hash_and_lookup+0x71/0x90\r\n[ 3099.764079]  RSP \u003cffff88001d553cd8\u003e\r\n[ 3099.764079] CR2: 0000000000000008\r\n[ 3099.773737] ---[ end trace bc78f466e60815ef ]---\r\n[ 3099.775732] BUG: unable to handle kernel NULL pointer dereference at 0000000000000008\r\n[ 3099.776713] IP: [\u003cffffffff8118ce01\u003e] d_hash_and_lookup+0x71/0x90\r\n[ 3099.777430] PGD 1dd44067 PUD 1caf4067 PMD 0 \r\n[ 3099.777585] Oops: 0000 [#2] SMP \r\n[ 3099.777585] CPU 0 \r\n[ 3099.777585] Modules linked in: veth aufs xt_addrtype ipt_MASQUERADE iptable_nat nf_nat nf_conntrack_ipv4 nf_conntrack nf_defrag_ipv4 ip_tables x_tables bridge stp dm_crypt ppdev psmouse parport_pc parport serio_raw mac_hid i2c_piix4 floppy 8139too 8139cp\r\n[ 3099.777585] \r\n[ 3099.777585] Pid: 1204, comm: bash Tainted: G      D      3.2.0-23-virtual #36-Ubuntu Bochs Bochs\r\n[ 3099.777585] RIP: 0010:[\u003cffffffff8118ce01\u003e]  [\u003cffffffff8118ce01\u003e] d_hash_and_lookup+0x71/0x90\r\n[ 3099.777585] RSP: 0018:ffff88001d0d3cd8  EFLAGS: 00010202\r\n[ 3099.777585] RAX: 0000000000000000 RBX: ffff88001d0d3d00 RCX: 000000000000bc84\r\n[ 3099.777585] RDX: ffff88001d0d3d00 RSI: 0000000000000000 RDI: ffff88001c932000\r\n[ 3099.777585] RBP: ffff88001d0d3ce8 R08: ffff88001d0d3d15 R09: 000000000000fffc\r\n[ 3099.777585] R10: 0000000000000000 R11: 000000000a665938 R12: ffff88001c932000\r\n[ 3099.777585] R13: 0000000000000017 R14: 0000000000000017 R15: 0000000000000017\r\n[ 3099.777585] FS:  00007fb5b101a700(0000) GS:ffff88001f800000(0000) knlGS:0000000000000000\r\n[ 3099.777585] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\n[ 3099.777585] CR2: 0000000000000008 CR3: 000000001d2f1000 CR4: 00000000000006f0\r\n[ 3099.777585] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[ 3099.777585] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\r\n[ 3099.777585] Process bash (pid: 1204, threadinfo ffff88001d0d2000, task ffff88001d915b80)\r\n[ 3099.777585] Stack:\r\n[ 3099.777585]  ffff88001d0d3d13 ffff88001dce4720 ffff88001d0d3d58 ffffffff811d5567\r\n[ 3099.777585]  ffff88001db6ca00 0000000200019ebc ffff88001d0d3d13 00360033323a0000\r\n[ 3099.777585]  ffff88001d0d3d80 00000000dbf6f6b3 ffff88001d0d3d68 0000000000000002\r\n[ 3099.777585] Call Trace:\r\n[ 3099.777585]  [\u003cffffffff811d5567\u003e] proc_flush_task_mnt.isra.12+0x67/0x170\r\n[ 3099.777585]  [\u003cffffffff811d8dea\u003e] proc_flush_task+0x5a/0xa0\r\n[ 3099.777585]  [\u003cffffffff81068eb3\u003e] release_task+0x33/0x130\r\n[ 3099.777585]  [\u003cffffffff81069459\u003e] wait_task_zombie+0x4a9/0x5b0\r\n[ 3099.777585]  [\u003cffffffff81069663\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 3099.777585]  [\u003cffffffff81069735\u003e] wait_consider_task+0x65/0x70\r\n[ 3099.777585]  [\u003cffffffff81069841\u003e] do_wait+0x101/0x260\r\n[ 3099.777585]  [\u003cffffffff81064f89\u003e] ? do_fork+0x159/0x2d0\r\n[ 3099.777585]  [\u003cffffffff8106ab90\u003e] sys_wait4+0xa0/0xf0\r\n[ 3099.777585]  [\u003cffffffff81068400\u003e] ? wait_task_continued+0x170/0x170\r\n[ 3099.777585]  [\u003cffffffff8165d8c2\u003e] system_call_fastpath+0x16/0x1b\r\n[ 3099.777585] Code: 01 c8 48 01 f8 4c 39 c2 48 8d 0c 80 48 8d 3c 48 75 d8 89 3b 41 f6 04 24 01 74 1b 49 8b 44 24 60 48 89 da 49 8b 74 24 30 4c 89 e7 \u003cff\u003e 50 08 89 c2 31 c0 85 d2 78 0b 48 89 de 4c 89 e7 e8 19 ff ff \r\n[ 3099.777585] RIP  [\u003cffffffff8118ce01\u003e] d_hash_and_lookup+0x71/0x90\r\n[ 3099.777585]  RSP \u003cffff88001d0d3cd8\u003e\r\n[ 3099.777585] CR2: 0000000000000008\r\n[ 3099.803716] ---[ end trace bc78f466e60815f0 ]---\r\n[ 3099.808450] docker0: port 1(vethJJrN0J) entering forwarding state\r\n[ 3099.808951] BUG: unable to handle kernel NULL pointer dereference at           (null)\r\n[ 3099.809623] IP: [\u003cffffffff8118cdea\u003e] d_hash_and_lookup+0x5a/0x90\r\n[ 3099.810031] PGD 1caea067 PUD 1c04b067 PMD 0 \r\n[ 3099.810520] Oops: 0000 [#3] SMP \r\n[ 3099.810923] CPU 0 \r\n[ 3099.811026] Modules linked in: veth aufs xt_addrtype ipt_MASQUERADE iptable_nat nf_nat nf_conntrack_ipv4 nf_conntrack nf_defrag_ipv4 ip_tables x_tables bridge stp dm_crypt ppdev psmouse parport_pc parport serio_raw mac_hid i2c_piix4 floppy 8139too 8139cp\r\n[ 3099.812207] \r\n[ 3099.812207] Pid: 1198, comm: lxc-start Tainted: G      D      3.2.0-23-virtual #36-Ubuntu Bochs Bochs\r\n[ 3099.812207] RIP: 0010:[\u003cffffffff8118cdea\u003e]  [\u003cffffffff8118cdea\u003e] d_hash_and_lookup+0x5a/0x90\r\n[ 3099.812207] RSP: 0018:ffff88001d97dcd8  EFLAGS: 00010246\r\n[ 3099.812207] RAX: 0000000000000313 RBX: ffff88001d97dd00 RCX: 0000000000000f5f\r\n[ 3099.812207] RDX: ffff88001d97dd14 RSI: ffff88001d97dd14 RDI: 00000000000021d1\r\n[ 3099.812207] RBP: ffff88001d97dce8 R08: ffff88001d97dd14 R09: 000000000000fffd\r\n[ 3099.812207] R10: 0000000000000000 R11: 000000000a66d038 R12: 0000000000000000\r\n[ 3099.812207] R13: 0000000000000001 R14: 0000000000000001 R15: 00000000000004b4\r\n[ 3099.812207] FS:  00007f2a22905700(0000) GS:ffff88001f800000(0000) knlGS:0000000000000000\r\n[ 3099.812207] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b\r\n[ 3099.812207] CR2: 0000000000000000 CR3: 000000001c178000 CR4: 00000000000006f0\r\n[ 3099.812207] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[ 3099.812207] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400\r\n[ 3099.812207] Process lxc-start (pid: 1198, threadinfo ffff88001d97c000, task ffff88001d482dc0)\r\n[ 3099.812207] Stack:\r\n[ 3099.812207]  ffff88001d97dd13 ffff88001dce4720 ffff88001d97dd58 ffffffff811d5567\r\n[ 3099.812207]  ffff88001c8fdb80 00000001000021d1 ffff88001d97dd13 0034300031915b80\r\n[ 3099.812207]  ffff88001d97dd80 000000003cadc430 ffff88001d97dd68 0000000000000002\r\n[ 3099.812207] Call Trace:\r\n[ 3099.812207]  [\u003cffffffff811d5567\u003e] proc_flush_task_mnt.isra.12+0x67/0x170\r\n[ 3099.812207]  [\u003cffffffff811d8dea\u003e] proc_flush_task+0x5a/0xa0\r\n[ 3099.812207]  [\u003cffffffff81068eb3\u003e] release_task+0x33/0x130\r\n[ 3099.812207]  [\u003cffffffff81069459\u003e] wait_task_zombie+0x4a9/0x5b0\r\n[ 3099.812207]  [\u003cffffffff81069663\u003e] wait_consider_task.part.9+0x103/0x170\r\n[ 3099.812207]  [\u003cffffffff81069735\u003e] wait_consider_task+0x65/0x70\r\n[ 3099.812207]  [\u003cffffffff81069841\u003e] do_wait+0x101/0x260\r\n[ 3099.812207]  [\u003cffffffff8106ab90\u003e] sys_wait4+0xa0/0xf0\r\n[ 3099.812207]  [\u003cffffffff81068400\u003e] ? wait_task_continued+0x170/0x170\r\n[ 3099.812207]  [\u003cffffffff8165d8c2\u003e] system_call_fastpath+0x16/0x1b\r\n[ 3099.812207] Code: 04 48 83 c2 01 0f b6 0e 48 89 d6 48 89 c8 48 c1 e9 04 48 c1 e0 04 48 01 c8 48 01 f8 4c 39 c2 48 8d 0c 80 48 8d 3c 48 75 d8 89 3b \u003c41\u003e f6 04 24 01 74 1b 49 8b 44 24 60 48 89 da 49 8b 74 24 30 4c \r\n[ 3099.812207] RIP  [\u003cffffffff8118cdea\u003e] d_hash_and_lookup+0x5a/0x90\r\n[ 3099.812207]  RSP \u003cffff88001d97dcd8\u003e\r\n[ 3099.812207] CR2: 0000000000000000\r\n[ 3099.833281] ---[ end trace bc78f466e60815f1 ]---\r\n[ 3099.834014] docker0: port 1(vethJJrN0J) entering disabled state\r\n```","Me too here. Anyone found the culprit?","This is a duplicate of #407.","What if you docker run $ID in an other term? This should start bash and bash will receive all input you gave while it was dead. Then you can ctrl-P ctrl-Q.\r\nHowever, you are right, we should be able to detach from this state without having to restart the container","Actually, by design it is not possible at the moment. It will be possible with a smart client though.\r\n\r\nIf you do the exact step you mentionned and try to detach `C-p C-q`, it will work. However, if you do anything else before, then the read pipe will unblock and try to write on the other side and as the process is not started, it hangs.\r\n\r\nAs it is a tty, we are in raw mode, ctrl-c is discarded.\r\n\r\nWIth a smart client, we can detect that the process is not running and therefore not set the raw mode.","Another way to run into the same problem:\r\nstart bash in container\r\nexit the container (with 'exit'), container STATUS should now be \"Exit 0\"\r\nattach to that container.\r\n\r\nDoesn't attach properly and needs to be killed manually. There should be some code to prevent that and inform the user that they'll probably want to 'start' the container before attaching.\r\n\r\nbtw, 'docker ps' columns are in wrong order. CREATED and STATUS are wrong way around.","Now that we can't attach to a stopped container, can we close this issue ?","It works! You can try it out with the following comand:\r\n\r\n```bash\r\nBOUNCER=$(docker run -d -u irc -p 6667 shykes/znc zncrun)\r\necho \"Publicly accessible port is $(docker port $BOUNCER 6667)\"\r\n```\r\n\r\nSource code is at http://github.com/shykes/docker-znc\r\n","I am using https://github.com/jimeh/docker-znc , which works pretty fine. ","I've updated all the issues. Preview is available here http://dockerwebsite-mrp.dotcloud.com/installation/","Thanks, reviewing.","I'd be interested in such a script, can you share it via pastebin or gist?","Solved by pull request #441 ","I'm guessing this is caused by the fact that Push currently involves buffering an entire layer's tar archive in memory... Which we already know is a terrible idea. I'll go ahead and fix that.","Fixed in baacae8345febd688579ac29832c200c41602ed2","Here's the fix:\r\nAdd this to your `/etc/fstab`:\r\n```\r\nnone        /cgroup        cgroup        defaults    0    0\r\n```\r\n\r\nThen:\r\n```\r\n$ sudo mkdir -p /cgroup\r\n$ sudo mount /cgroup\r\n```\r\n\r\nAnd off you go!","Thank you for pointing this out. As you discover, Debian does not mount the cgroup subtree. The proper place to mount cgroups is /sys/fs/cgroup. We are making adjustments in the debian packaging (/packaging/debian/lxc-docker.postinst) to overcome this issue.","This is also an issue on Sid at the time of this comment.","To add some background to @mzdaniel answer, check https://wiki.debian.org/LXC","Not complete yet. Please stick to high-level design discussion for now.","This is completely RPC, I'd prefer something closer to the RESTish API layout that I described in #21.","BTW, I'm still up for implementing the API, I just won't be able to get to it for a few weeks.","It will restify.",":heart:","Should this compile?  I get:\r\n\r\n    # github.com/dotcloud/docker\r\n    ../.gopath/src/github.com/dotcloud/docker/api.go:457: too many arguments to return\r\n    ../.gopath/src/github.com/dotcloud/docker/api.go:491: undefined: name\r\n    ../.gopath/src/github.com/dotcloud/docker/api.go:492: undefined: name\r\n     ../.gopath/src/github.com/dotcloud/docker/api.go:496: undefined: name\r\n\r\nI'm on ubuntu 12.10 with `go version` of \r\n\r\n    go version go1.0.2","@anotherjesse my bad, I forgot to push.\r\nKeep in mind it's still WIP ","@vieux It looks like this is coming along nicely. Ping me when you're ready for a preliminary review.","@vieux Thanks.  I'm now able to prototype my project before hack day.\r\n\r\nI like that container post returns the container id.  Is it possible to return the id without waiting for the cmd to finish?","The response to `/containers` returns a \"humanized\" string for how long it was created ago.  Perhaps a UTC time would be better so the client can determine how to present it?","Agreed. Also, I'm a big fan of integer Unix timestamps for time in APIs...\r\n\r\n\r\nOn Tue, Apr 30, 2013 at 12:25 AM, Jesse Andrews \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e The response to /containers returns a \"humanized\" string for how long it\r\n\u003e was created ago. Perhaps a UTC time would be better so the client can\r\n\u003e determine how to present it?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/432#issuecomment-17213138\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","also if /containers or /images is empty, return `[]` instead of `null`?","\u003e Agreed. Also, I'm a big fan of integer Unix timestamps for time in APIs...\r\n\r\n:+1: Time since the unix epoch in milliseconds works nicely in my experience.","@anotherjesse @progrium @titanous fixed null and added timestamps\r\n\r\nThe run will probably change soon. It'll display the id.","Would this be hard to bring up date with master?","@anotherjesse the run was refactored a little, now the client POST /container to create it, and has the container's id back, then it call /attach and /start","@vieux are there any documents that describe the API spec? If so, can we add them to the docs? If not, can we create them, and then add them to the docs? If you need help, just let me know.","the debug mode is broken, it looks like there is a raw mode on the server?","docker run -a stdin should output the container's ID","docker info in debug mode does not output the fds nor goroutines","``docker run -d -i -t base bash`` should not trigger the raw mode","when exiting ``docker run -i - t base bash`` (exit or ctrl-d), the client does not exit","The escape sequence ``Ctrl-p Ctrl-q`` does not work anymore","``cat Dockerfile| ./docker build`` exit the server, without any output, even in debug mode.\r\n\r\nDockerfile used:\r\n```\r\n# Firefox-vnc\r\n#\r\n# VERSION                       0.1\r\n# DOCKER-VERSION        0.2\r\n\r\nfrom    ubuntu:12.04\r\n# make sure the package repository is up to date\r\nrun     echo \"deb http://archive.ubuntu.com/ubuntu precise main universe\" \u003e /etc/apt/sources.list\r\nrun     apt-get update\r\n\r\n# Install vnc, firefox, etc\r\nrun     apt-get install -y x11vnc xvfb firefox\r\nrun     mkdir /.vnc\r\nrun     x11vnc -storepasswd 1234 ~/.vnc/passwd\r\nrun     bash -c 'echo \"firefox\" \u003e\u003e /.bashrc'\r\n```","docker pull shoudl return non zero code when failing:\r\n``./docker pull nonexisting || echo OK`` shoudl output OK","``./docker push non/existing`` throw a 404 + get stuck + 400 Bad request","Tests still fail on my 3.8 without support for memory limits, unless I set NO_MEMORY_LIMIT=1. Should they pass?","Nevermind - the only test which fails is TestRunDisconnectTty, and I think it's for an unrelated reason (and by the way where did that come from? Please make sure all tests pass before merging to master)","Confirming that TestRunDisconnectTty also fails in master (3b6c540fe8313035de0f0b00de52d7197f8bc665)","Yes, They should pass. Which test fails?\r\n\r\nOn Saturday, April 20, 2013, Solomon Hykes wrote:\r\n\r\n\u003e Tests still fail on my 3.8 without support for memory limits, unless I set\r\n\u003e NO_MEMORY_LIMIT=1. Should they pass?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/433#issuecomment-16714197\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n-- \r\nGuillaume J. Charmes","Look at the rest of my comments :)\r\n\r\n\r\nOn Sat, Apr 20, 2013 at 7:04 PM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e Yes, They should pass. Which test fails?\r\n\u003e\r\n\u003e On Saturday, April 20, 2013, Solomon Hykes wrote:\r\n\u003e\r\n\u003e \u003e Tests still fail on my 3.8 without support for memory limits, unless I\r\n\u003e set\r\n\u003e \u003e NO_MEMORY_LIMIT=1. Should they pass?\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/pull/433#issuecomment-16714197\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e\r\n\u003e --\r\n\u003e Guillaume J. Charmes\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/433#issuecomment-16714650\u003e\r\n\u003e .\r\n\u003e","Merged - I think we should stil look for a more elegant way which doesn't require polling, but this is definitely better than not being able to kill ghosts.\r\n\r\nThanks\r\n","If you add thouveng within your /etc/sudoer file, it should work fine :)","Not a bad idea ;) I was focused on using sudo group and didn't think to add thouveng group in /etc/sudoer\r\nThanks for the hint","As explained by @paultag in #30:\r\n\r\n\r\n\u003e Ubuntu is sync'd from Debian. Getting it into Debian gets it into Ubuntu by doing a `requestsync'.\r\n\u003e I can also help with that; I'm an Ubuntu member too.","The kernel needs both lxc and aufs. I don't think Debian has the aufs patches. If aufs isn't in sid's kernel, I don't think we should push lxc-docker. It'll give others the impression that docker is broken (which on debian would be correct.)","You don't necessarily need to get it on Debian first. It's completely fine to get into Ubuntu directly.","I'm on Debian and it has AUFS support, and Docker works perfectly.\r\nOn Aug 10, 2013 11:11 AM, \"Sidnei da Silva\" \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e You don't necessarily need to get it on Debian first. It's completely fine\r\n\u003e to get into Ubuntu directly.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/436#issuecomment-22444458\u003e\r\n\u003e .\r\n\u003e","Great, I recommend pushing it to sid then. :)","This is well underway and being managed by @paultag @tianon and @mzdaniel.\r\n\r\nI think this issue is redundant, closing.","I think it would be more interesting to focus on a smart client that would be able to do those operation instead of implementing this server side.\r\n\r\nRight now, when a client abort, the operation is not aborted server side. So if we had a smart client, we could 1) Detect more easily the abort, 2) 'Reattach' to the push/pull process","It feels like we're describing the same thing. The client needs the ability to re-attach to push/pull processes - and the server needs to allow re-attaching, as well as cancelling a background pull, detecting conflicts between pull jobs, etc.","@shykes The daemon already pulls or pushes, accessible via REST, do you think we should add an api to get the status of a push or pull?","This is planned for 1.0. Push, pull and all other engine operations will be exposed as regular processes. So all primitives which apply to processes - list, stop, restart, get status, attach  - will apply to push/pull as well.","Scheduling for 0.8.","Quick update: I am gradually porting the internals to a job-oriented API. As soon as 'push' and 'pull' are ported, this issue will be solved.","Can we close this?  This is completed.\r\n... Except maybe being able to see the status of a running pull.","Yes, status of running pulls will come later.","This is not completed. If you want we can open a new issue with a more clear description, like \"job control for push/pull\".","#111 has some discussion of specifying volumes with JSON and could be folded with this.","So 0.4 has just come out with the RESTful Remote API.   The JSON expressed here could be used in the POST request of container/(id)/start.\r\n\r\nAnother use case for changing the lxc_template for advanced networking configuration.  For instance, a given container may need to start with access to specific VLANs.  This may change between different starts of the container.","There is an ongoing pull request for this. Adding to 0.6 to keep track.","@crosbymichael @shykes   Hello, I'm coming up for air and able to revisit some of this work after Labor Day.  I see pull request #1560, which achieves much of what this issue is about.   I think it covers my specific use case.\r\n\r\nBut, it doesn't use JSON but rather command line args.  I had suggested JSON because of how it can work with a REST API.\r\n\r\nShall I abandon this line of work?   Or integrate JSON aspects once #1560 is accepted.  Give me some guidance and I'll try to help out.","@neomantra The CLI takes the data from the command line and creates JSON requests to the REST Api.  Everything supported on the CLI can be done directly via the REST Api.","Hey @destructuring, are you still working on this? I'd like to avoid duplicating your work if possible.","@shykes Yes, I need it yesterday ;p my schedule is open for two weeks, hoping to get something working.  It shouldn't stop anyone from writing something, though.  ","Can you make it on thursday? We could pair on it.\r\n\r\n\r\nOn Tue, Apr 30, 2013 at 4:19 PM, David Romulan \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @shykes \u003chttps://github.com/shykes\u003e Yes, I need it yesterday ;p my\r\n\u003e schedule is open for two weeks, hoping to get something working. It\r\n\u003e shouldn't stop anyone from writing something, though.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/440#issuecomment-17260369\u003e\r\n\u003e .\r\n\u003e","yes, I'll be there.  I'd better get cranking now .. heh\r\n\r\n\r\nOn Tue, Apr 30, 2013 at 4:20 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Can you make it on thursday? We could pair on it.\r\n\u003e\r\n\u003e\r\n\u003e On Tue, Apr 30, 2013 at 4:19 PM, David Romulan \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e\r\n\u003e \u003e @shykes \u003chttps://github.com/shykes\u003e Yes, I need it yesterday ;p my\r\n\u003e \u003e schedule is open for two weeks, hoping to get something working. It\r\n\u003e \u003e shouldn't stop anyone from writing something, though.\r\n\u003e \u003e\r\n\u003e \u003e —\r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003c\r\n\u003e https://github.com/dotcloud/docker/pull/440#issuecomment-17260369\u003e\r\n\u003e \u003e .\r\n\u003e \u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/440#issuecomment-17260414\u003e\r\n\u003e .\r\n\u003e","I managed to implement docker support with a shell script that calls docker + my vagrant-shell provider.  I'll make a vagrant-docker provider to wrap everything up in an easy to use gem.  It's basic functionality: up, ssh, destroy, for now.","Sweet!  I love your presentation last docker hackday and look forward seeing your code.","@destructuring any news one this ?","Look at https://github.com/destructuring/vagrant-shell\r\n\r\nIn the middle of reworking the demo (demo/docker)\r\n\r\n\r\nOn Mon, Jun 3, 2013 at 7:27 AM, Victor Vieux \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @destructuring \u003chttps://github.com/destructuring\u003e any news one this ?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/440#issuecomment-18844635\u003e\r\n\u003e .\r\n\u003e","@titanous: Thank you for pointing the issue of docker development. We had already introduced 'make hack' for addressing docker development. That includes a Vagrantfile for launching a development VM. Had you tried it?","No, I haven't, I'll take a look. A cursory glance indicates that it doesn't share the source directory in a proper Go workspace, is this the case?","Vagrantfile is already giving access to the full repo. Shouldn't the Makefile be responsible to setup the proper Go workspace?\r\n","@titanous: I looked more carefully at your comment and your code, and now I understand what you meant. Would you mind taking a look at https://github.com/dotcloud/docker/pull/493 ?\r\nCan we keep this conversation on https://github.com/dotcloud/docker/issues/374?","Nice! Didn't know about the wh: option :)","Could you add a regression test? Thanks.\r\n","I don't see any downside to btrfs (or zfs). It just makes some things more\r\ndifficult; not necessarily because of btrfs, but also to have aufs and\r\nbtrfs coexist.\r\n1. \"rebasing\" a layer would be more difficult: we would have to extract\r\nchanged files and re-apply the diff on another image, instead of merely\r\nstacking the layer with aufs. It means that injecting something into an\r\nimage (when containers are using the image) would be impossible.\r\n2. We would have to write a formal spec for the layer format (the current\r\nspec is \"we use whatever aufs uses\").\r\n3. It might ridicule the aufs format in some cases (i.e. when doing small\r\nchanges to big files, a btrfs diff will be small, while a aufs diff will\r\ninclude the whole changed files), prompting people to request for multiple\r\nformats (and the mess that comes with it).\r\n4. Commands to list diffs would be a bit more complicated, and maybe\r\ncostlier (note: I saw that you could list added/changed files, but didn't\r\nsee about deleted files).\r\n5. We might have to deal with file corruption and data loss instead of\r\n\"stale NFS handle\" ;-)\r\n\r\n\r\n\r\n\r\n\r\n\r\nOn Fri, Apr 19, 2013 at 5:40 PM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I have heard a lot of requests for supporting BTRFS as an alternative\r\n\u003e layering backend.\r\n\u003e\r\n\u003e I heard the following arguments:\r\n\u003e\r\n\u003e    -\r\n\u003e\r\n\u003e    \"BTRFS is part of upstream kernel, which means docker would be usable\r\n\u003e    on more systems\"\r\n\u003e    -\r\n\u003e\r\n\u003e    \"Performance is better in use cas X/Y/Z\"\r\n\u003e    -\r\n\u003e\r\n\u003e    My existing production system uses BTRFS, it would be easier to start\r\n\u003e    using docker\r\n\u003e    -\r\n\u003e\r\n\u003e    BTRFS's design is more elegant and sustainable than AUFS, which\r\n\u003e    patches the vfs layer\r\n\u003e    -\r\n\u003e\r\n\u003e    It would solve the \"stale NFS handle\" issue\r\n\u003e\r\n\u003e If you have an opinion on the matter, let me know!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/443\u003e\r\n\u003e .\r\n\u003e","It looks like AUFS won't be part of the 3.9 kernel series in Ubuntu, so it would be a good opportunity to look into alternatives. With BTRFS being available as part of upstream is one giant plus.","So far I have run into 3 issues with btrfs. I'm a btrfs newbie, so all 3\r\nmight be solvable.\r\n\r\n1) Multi-layer union mounts. I didn't find a way to do union mounts with an\r\narbitrary number of layers.\r\n\r\n2) File-based layers. Docker stores and moves layers as tarballs with a\r\nfull copy of all files changes, plus special \"whiteout\" metadata to express\r\nfile removal. On the other hand, btrfs stores snapshots at the block level.\r\nI *think* I know how to extract well-formed layers from btrfs snapshots\r\n(get list of files changed on a given snapshot, use that as a filter to\r\ncreate a partial tarball of the mountpoint), as well as the reverse\r\noperation (create snapshot, apply tarball). But I haven't tested it yet. It\r\nalso poses the problem of imperfect interop. Untar-ing layers on top of\r\neach other is not exactly the same as mounting them on top of each other\r\nwith aufs.\r\n\r\n3) Freedom of block-level filesystem. One great thing about aufs: it\r\ndoesn't care how your block devices are formatted. You can just drop\r\n/var/lib/docker on whatever filesystem happens to be there, and it should\r\njust work. Contrast this with btrfs, which requires a duly formatted block\r\ndevice. Would this mean Docker would *only* work on btrfs-formatted\r\ndevices? Seems like a harsh barrier to entry. Possible solutions:\r\n\r\n         a) Support both aufs and btrfs (interop would have to be perfect)\r\n         b) Support a degraded mode with regular copy (layers could not be\r\nreused, but this could be used for final use in production for example, or\r\non older kernels with no COW support)\r\n         c) Dev mode with loop-mounted sparse file. This could be great for\r\nbuilds \u0026 dev usage where disk IO is not critical.\r\n\r\n\r\nAll in all, it looks doable, although it would be non-trivial. But if we\r\nwant to expand the number of servers which can run Docker, we might not\r\nhave any other choice.\r\n\r\n\r\nOn Tue, Apr 30, 2013 at 12:09 AM, Pascal Hartig \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e It looks like AUFS won't be part of the 3.9 kernel series in Ubuntu, so it\r\n\u003e would be a good opportunity to look into alternatives. With BTRFS being\r\n\u003e available as part of upstream is one giant plus.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/443#issuecomment-17212624\u003e\r\n\u003e .\r\n\u003e","I've been using the \"docker pattern\" for years on btrfs, ZFS, and LVM snapshots. The big advantage of using CoW filesystems is that only block changes are tracked, which makes things like database snapshots and other large file systems viable.\r\n\r\nI haven't personally bothered to optimize image shipping. With (my) app roots well under a gigabyte, rsync tends to be a perfectly usable way to manage layers. I've messed with send/recv, git repos (works better than you'd think), and mostly just use rsync similar to this: https://gist.github.com/tobert/5491155  In other words, maybe you want to find a way to manage layers independent of various filesystem implementations (the LCD) then worry about specific optimizations after that's available. Maybe aufs is required to build images, but the could be deployed to any FS with varying degrees of optimization?\r\n\r\nIf you want to look at other prior art, look at Solaris Zones with ZFS. It has been around for many years and is used in production all over the place. Joyent and OmniTI won't shut up about it :)\r\n\r\nhttps://github.com/joyent/illumos-joyent/blob/master/usr/src/cmd/zoneadm/zfs.c","Re/ BTRFS:\r\n\r\n1) Multi-layer union mounts\r\n\r\nBTRFS (and ZFS) have different concepts. You can do this:\r\n- put a ubuntu base image somewhere\r\n- create a read-only snapshot of that \"somewhere\": now that's an image\r\n- out of that r-o image, create a r-w snapshot: that's a container rootfs\r\n(- repeat previous step as many times as necessary to instantiate multiple\r\ncontainers)\r\n- after running (/modifying) a container, create a r-o snapshot: that's a\r\nnew image\r\n- rinse and repeat as many times as necessary (you can stack as many\r\nsnapshots as you like)\r\nNote: the images can also be r-w, no problem with that. But when you modify\r\nan image, it obviously won't modify automatically the containers based on\r\nthe image.\r\nIn other words: with AUFS, you CAN modify the base image (and changes will\r\nbe visible in containers); with BTRFS, you CANNOT (well, you can, but\r\nchanges won't propagate).\r\n\r\n2) File-based layers\r\n\r\nYes, that's the main interop point; creating AUFS-style tarballs out of\r\nBTRFS subvolume snapshots (with find-new) or ZFS snapshots (with \"zfs\r\ndiff\"). If we leave pseudo-links and external inode translation issues on\r\nthe side, it should work like a charm (\"...famous last words!\"). We don't\r\nhave a real-world use-case for plinks and xino but we could think about it\r\nto see if we're about to lose something important.\r\n\r\n3) Freedom of block-level FS\r\n\r\nYes, btrfs requires its own block device. I think there is a kind of choice\r\nbetween:\r\n- running on my existing system but requiring custom kernel with AUFS\r\n- running my existing kernel but needing /var/lib/docker to be BTRFS\r\nI'm sure that we can find very vocal supporters for both propositions :)\r\n","For the record—current work in progress on BTRFS integration: https://github.com/jpetazzo/docker/tree/btrfs","Any plans to implement pluggable storage backends? (eg. aufs, btrfs, zfs, etc)","Yes, absolutely. If only because it will make the aufs/btrfs transition (or\r\ncohabitation) easier :-)\r\n","See https://github.com/dotcloud/docker/issues/172#issuecomment-18109009 for overlayfs","FWIW, having used both BTRFS and ZFS on Linux (ZoL) quite a bit over the past few years, I'd be much happier if ZoL was natively supported along with BTRFS. I've never had ZoL corrupt data, whereas that's happened multiple times to me with BTRFS.\r\n\r\nThese days, the capabilities relevant to Docker are nearly the same; just a matter of how they're invoked/used. But if you're looking at transitioning capability from AUFS, I'd ask that you take care to think about doing it in a way that makes both filesystems viable, because ZoL would be my clear preference, even though it is not shipped in an upstream kernel.","Jeff, absolutely. I am keeping that in mind and would like to see zfs support as well.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, Jun 27, 2013 at 6:42 AM, Jeff Mitchell \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e FWIW, having used both BTRFS and ZFS on Linux (ZoL) quite a bit over the past few years, I'd be much happier if ZoL was natively supported along with BTRFS. I've never had ZoL corrupt data, whereas that's happened multiple times to me with BTRFS.\r\n\u003e These days, the capabilities relevant to Docker are nearly the same; just a matter of how they're invoked/used. But if you're looking at transitioning capability from AUFS, I'd ask that you take care to think about doing it in a way that makes both filesystems viable, because ZoL would be my clear preference, even though it is not shipped in an upstream kernel.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/443#issuecomment-20119673","This is a plugin use case for 1.0. Tagged and closing.","Is the plugin API out in 1.0? Is there any documentation for it, or a roadmap?","We are only up to 0.8.1, with 0.9 coming next month.  A plugin system is in development but hasn't merged yet.  Also, recent versions do include an experimental btrfs driver.","Thank you, I understand it now. I was actually looking at using ZFS. Apparently there is an existing port by [@gurjeet](/gurjeet/docker/tree/zfs_driver), but are there any plans to have something officially supported? I would actually be interested in doing something myself, should I wait until the plugin API is out before making any plans?","I take it this has never happened? Why would this be closed just because it might be handleable as a plugin? Is there any relevant follow-up anywhere on this ticket?","it has been implemented as a storage driver :) I use it and love it","Whoop whoop! [First announced in 0.8](http://blog.docker.com/2014/02/docker-0-8-quality-new-builder-features-btrfs-storage-osx-support/) (February 2014). Thanks all. Sorry, was getting some noisiness in my search results that took some more time to pick through.","Fixed in 911925b54a42fffa0fed8bac2a3eeba14bf3ec4b\r\n","I am not 100% sure but in order to use upstart, you need to start the original /sbin/init (cf #223)\r\nAlso, it is not currently possible to run daemons within a container. If so, lxc-start will think all its children are gone and will destroy the cgroup namespace.\r\n\r\nYou can always run a ssh server by starting sshd in foreground mode: /usr/sbin/sshd -D.","Thanks for pointing me the issue about upstart. I will try to use the original /sbin/init. I don't understand exactly the issue about daemons and why lxc-start will think that but it's an interesting point and I will try to figure out what happens. I need more technical backgrounds ;)\r\n\r\nOtherwise, to be clear about what I'm trying to do, I'm trying to run [devstack](http://devstack.org) to run openstack in a docker container. Maybe I should open a use case to this?","Yes please do create a usecase! I would love to see a devstack/docker demo.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sun, Apr 21, 2013 at 4:17 AM, thouveng \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Thanks for pointing me the issue about upstart. I will try to use the original /sbin/init. I don't understand exactly the issue about daemons and why lxc-start will think that but it's an interesting point and I will try to figure out what happens. I need more technical backgrounds ;)\r\n\u003e Otherwise, to be clear about what I'm trying to do, I'm trying to run [devstack](http://devstack.org) to run openstack in a docker container. Maybe I should open a use case to this?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/446#issuecomment-16719979","Ok cool. In fact as I'm not a contributor of the project I can not create a usecase, only normal issue. But I will be happy to help and be a tester for deploying devstack into docker. I don't know what can be the more efficient way to help. Maybe I can post my use case on the docker-club mailing list and expose my issues?\r\n\r\nOtherwise, should I close this issue?","I think the right way to avoid the original issue is to configure invoke-rc.d, so daemons don't get auto started/restarted on install/upgrade:\r\n\r\n    cat \u003c\u003c EOF \u003e /usr/sbin/policy-rc.d\r\n    #!/bin/sh\r\n\r\n    exit 101\r\n    EOF\r\n    chmod +x /usr/sbin/policy-rc.d\r\n\r\nMore infos in [invoke-rc.d(8)](http://manpages.ubuntu.com/manpages/current/en/man8/invoke-rc.d.8.html) and [here](http://people.debian.org/~hmh/invokerc.d-policyrc.d-specification.txt).\r\n\r\n(This is actually mandatory if you want to upgrade a Debian based container over the time, without that you'll get stuck because postinstall steps will fail restarting daemons which aren't supposed to run).","The best thing to do is to create a normal issue, and I will tag it as a\r\nuse case. That way everyone interested in helping and participating will\r\nhave a central place to go.\r\n\r\n--\u003e I personally definitely want to help on this :)\r\n\r\n\r\nOn Wed, Apr 24, 2013 at 3:07 AM, thouveng \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Ok cool. In fact as I'm not a contributor of the project I can not create\r\n\u003e a usecase, only normal issue. But I will be happy to help and be a tester\r\n\u003e for deploying devstack into docker. I don't know what can be the more\r\n\u003e efficient way to help. Maybe I can post my use case on the docker-club\r\n\u003e mailing list and expose my issues?\r\n\u003e\r\n\u003e Otherwise, should I close this issue?\r\n\u003e\r\n\u003e —\r\n\u003e\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/446#issuecomment-16918090\u003e\r\n\u003e .\r\n\u003e\r\n\u003e","Ok cool :)\r\nI will open the new issue this week-end","I created the use case here https://github.com/dotcloud/docker/issues/483\r\nI hope that it may be useful\r\n@solomonstre ","Maybe I closed this issue too early before the other issue (see https://github.com/dotcloud/docker/issues/483) is marked as usecase. So I reopen it. If I missed something for the creation of the use case or if it doesn't fit well in the plans don't hesitate to tell me, I will close both issues.\r\n\r\nRegards,\r\nGuillaume","Is the current build process/script for the Ubuntu images available for viewing somewhere?  That would probably be a helpful starting point for someone looking to help out with this task.  I know that the busybox script was immensely0 helpful to me in turning a Gentoo stage3 tarball into an actual image, and I can't help but think that the Debian and Ubuntu image creation processes will be reasonably similar.","The ubuntu images were created with:\r\n\r\n\r\n    debootstrap precise --variant=minbase ./precise; tar -C ./precise -c | docker import -\r\n\r\n\r\n\r\n\r\nSame for quantal.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Mon, Apr 22, 2013 at 11:29 PM, Tianon Gravi \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Is the current build process/script for the Ubuntu images available for viewing somewhere?  That would probably be a helpful starting point for someone looking to help out with this task.  I know that the busybox script was immensely0 helpful to me in turning a Gentoo stage3 tarball into an actual image, and I can't help but think that the Debian and Ubuntu image creation processes will be reasonably similar.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/447#issuecomment-16841599","Seeing how easy debootstrap makes the process, I decided to try my hand at making an image for wheezy.  After creating a minbase bootstrapped directory, all I did was chroot into it to install iproute (for the ip command, which docker requires), and then installed iputils-ping (since it's a reasonably tiny package and is so useful for verifying proper connectivity).  I've pushed it up as tianon/debian with tags of wheezy and of course latest for anyone else who's interested in trying it to play with..  It would be ridiculously simple to automate builds of this one. :)","I was having fun, so I ended up creating and pushing a squeeze image too, and used the proper method of adding --include to debootstrap to include more packages instead of my chroot apt-get install after the fact.  I've added both to the \"public docker images\" wiki page so they can be more widely tested/enjoyed.","Nice Tianon!\r\ndebootstrap is a really great tool. Would you like to share your scripts for the docker repo somewhere under /contrib?","Absolutely.  In the process of making them more general (they were very specific to my own use), I ended up creating an image/tag for sid as well, which is being pushed up now.  I'll add it to the public wiki when that's finished, and I'll be sure to submit a pull request to include my script in contrib shortly.","@tianon Thank you for doing it! Your script looks really good and has been incorporated to mainline contrib. I tested it with the vbox at packaging/debian.\r\nWhat do you think about incorporating pinning on it?  I mean, when distros are released, iso images are build with major and minor revisions (eg: debian-6.0.7-amd64-netinst.iso) Then, we can be sure what software we are building, and properly label the official debian image.","That would be very cool, but debootstrap only supports using proper suite names that appear on the mirrors, and they only keep the \"latest\" on the mirrors.  I am thinking however, that we could use docker run to get into the instance after the fact to have it print out what version it is so that we can capture that and add a tag for it (ie, `docker run tianon/debian:wheezy cat /etc/debian_version` prints out `7.0`, which would make a swell tag).  I will work on enhancing the script to include that.\r\n\r\nAlso, it is fun to note that my images were actually created directly on Gentoo, since it has a package for debootstrap.  The script should also work just fine in Ubuntu, and really any distro that can have or does have the debootstrap tool, since it just grabs a standard \"debian-based\" repo off the mirror supplied (which in this case is the upstream Debian mirror itself).","After playing with this a little more, this plan will work very awesome for stable and testing (currently squeeze and wheezy), but for sid (unstable) the version number is the same as testing, since unstable never gets official releases, and is really just the proving grounds for packages that get pushed into testing proper.\r\n\r\nI see two possible fixes to this issue.  The most favorable fix would be to not generate the version number tag for unstable/sid.  The other possible fix is to not worry about these version number tags at all, which I think would be somewhat of a loss, since it would be kind of cool to be able to easily pull down an older version of debian, assuming someone (or some automated process) had tagged it nicely during the right timeframe.","As you can see, pull request is submitted.\r\n\r\nI'm also in the process of pushing up some rolling release versions of the images (under tianon/debian-roll), so that within the image, it becomes a simple process of `apt-get update \u0026\u0026 apt-get dist-upgrade` to be at the latest version of \"stable\", \"testing\", or \"unstable\", regardless of whether or not wheezy has switched to become the latest stable, for example.  I will update the wiki page again when those are pushed.","The solution you implemented certainly covered the goals of this issue. Thank you for doing it! I am recommending your latest PR gets merged into mainline asap.\r\nRegarding pinning, here is an idea: You can pass deboostrap a repo directory as a parameter. If you happen to have an official CD mounted there...","@tianon Is it by intention that the base debian images are missing the `procps` package with tools like `ps` and `top`. Other official base images like CentOS and Ubuntu include them by default.","@deeky666 yes","See also `docker top`, which is a generic version of \"ps\" that will work on any kind of container.","I know that I can use those commands provided by docker. I was just curious why debian images don't have those tools available inside a container by default whereas Ubuntu, CentOS and other images do. I encountered a problem with that when running the PHP testsuite (building PHP from source) inside a base Debian image container which expects `ps` to be installed in the system. Nothing critical here, just curious :)","fixed in acb546cd1bf45a248f4bb51637c795ef63feb6cb","On irc:\r\n\r\n\u003e adamjt [13:32:32] Can someone point me to the docs about listing available images in the registry server?\r\n","Is `docker search` enough ?\r\nIf so you can close the issue","CC-ing registry maintainers: @kencochrane @samalba @dhrp @shin- ","Fixed within the new registry (docker v0.3.0)","Fixed by 71b580661451c35f01ee3824506f572c52d86ac8. Can you confirm?","Fixed in #456 ","This will be fixed by the PR #454 ","I agree this would be cool. I encourage you to bring it up on the mailing list and show what you have in a blog post, screencast or lightning talk.\n\nClosing this issue for housekeeping to only keep open specific actionable improvements to docker.","Tested on Debian, and it appears that LXC is smart enough to do this by itself.","Would it be posisble to have a use case for this?","As I note in #439, cpusets can be used to pin processes to CPUs.  This practice is used in low-latency systems, e.g. to keep other work from interrupting it or to ensure being on the same NUMA node as another process.\r\n\r\nMore generally, cgroups can control many aspects of a process:\r\nhttp://doc.opensuse.org/documentation/html/openSUSE/opensuse-tuning/cha.tuning.cgroups.html#sec.tuning.cgroups.subsys\r\n\r\nAlthough it makes sense to make some common cgroup controls available easily from the command line, like -m to limit memory, there are a myriad of possible cgroup key/value pairs.  A JSON representation of them should integrate well with the REST interfaces that are docker is developing.\r\n\r\nAlthough it is not included in this changeset, I think JSON would be useful to express mount points to local system paths (as discussed in #111).","Hi @neomantra, sorry for the long delay. I would like to merge this, but we need to change the name to make it clear that it's an lxc-specific option.\r\n\r\nWhat I suggest:\r\n\r\n* Rename JsonMap to LxcConfig\r\n* Change -j to -lxc\r\n\r\nThat should make it more interesting.\r\n\r\n@jpetazzo, @schmatz, @ebastos, @creack, would this be useful to you for device access eg. Fuse and pci? (cf. #682 and #514)","Thanks @shykes    The patch needs a little reworking since it is a couple months old.   I re-explored it at the last  docker release and there appears to be no blockers.    I won't be able to hit it until the next week or so.","Sounds good. Do you mind if we close this one, and re-open it when you're\r\nready for review?\r\n\r\n\r\nOn Fri, Jun 14, 2013 at 12:17 PM, Evan \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Thanks @shykes \u003chttps://github.com/shykes\u003e The patch needs a little\r\n\u003e reworking since it is a couple months old. I re-explored it at the last\r\n\u003e docker release and there appears to be no blockers. I won't be able to hit\r\n\u003e it until the next week or so.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/460#issuecomment-19476271\u003e\r\n\u003e .\r\n\u003e","Closing this pull request in lieu of a future one.  More comments can be made on issue #439 ","Much simpler! Nice :)",":)   Almost forgot. There is a regression introduced in 1.2.0 and 1.2.1 (https://github.com/mitchellh/vagrant/issues/1613) that affects deployment of virtual boxes and requires the following workaround (cat /usr/bin/curl  \u003e /opt/vagrant/embedded/bin/curl) . This will be fix in the upcoming 1.2.2.","This conflicts with @dhrp's last pull request. Could you resolve and let me know when you're ready for merging?\r\n\r\nThanks.","Of course. Ready :)","Hi Quinton,\r\n\r\nThere's an HTTP/JSON api in the works. You can see progress here:\r\nhttps://github.com/dotcloud/docker/pull/432\r\n\r\nOnce it's ready, the client will switch to using that. Not mutually\r\nexclusive with a '-j' option, of course, but I suspect you'd rather work\r\nwith the API directly if possible.\r\n\r\n\r\nOn Tue, Apr 23, 2013 at 10:38 AM, Quinton Pike \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e This is VERY important for docker to be used with other\r\n\u003e languages/projects. The best way to interact with Docker on the server is\r\n\u003e via running commands via the CLI.\r\n\u003e\r\n\u003e When you give the option of example: ' -j ' to format the response in\r\n\u003e JSON, it makes writing other languages around Docker much more enticing\r\n\u003e\r\n\u003e docker images -j - would respond with all images in JSON format ( like\r\n\u003e docker inspect does ).\r\n\u003e\r\n\u003e Thanks,\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/468\u003e\r\n\u003e .\r\n\u003e","Thanks for the snappy response!\r\n\r\nYa I saw that in the Pull Requests, and I am OK with using that, as long as there is some way to limit access to the API. \r\n\r\nAny ETA on the API? Currently in the middle of writing a NodeJS CLI Wrapper, but the response parsing is killing me. ","+ the fact that aufs requires a patched kernel (even when built as a\r\nmodule).\r\n\r\nHowever, it looks like Linode should support custom kernels with pvgrub. If\r\nyou have a Linode box handy, ping me when I'm in the office so I can have a\r\nlook (or I can send you a pubkey).\r\nOn Apr 23, 2013 10:39 AM, \"Solomon Hykes\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I'm trying to run docker on Linode. Has anybody done this yet?\r\n\u003e\r\n\u003e Current status:\r\n\u003e\r\n\u003e    -\r\n\u003e\r\n\u003e    Kernel is 3.8.4 by default on all distros, which is great! No known\r\n\u003e    kernel/lxc bugs.\r\n\u003e    -\r\n\u003e\r\n\u003e    The kernel doesn't include aufs... And since the kernel is\r\n\u003e    host-defined, it doesn't match the guest distro versions, so installing it\r\n\u003e    is tricky.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/469\u003e\r\n\u003e .\r\n\u003e","I'm playing with Docker at Linode, the smallest server (1GB Ram), with Ubuntu 12.04.\r\n\r\n    root@li278-180:~# docker ps\r\n    ID             IMAGE         COMMAND                CREATED       STATUS       COMMENT \r\n    8938be57c3e0   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours   \r\n    7dccb4a0307e   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours   \r\n    8804143b13af   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours   \r\n    98161d5e8c3f   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours   \r\n    c0b65bad9e5f   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours   \r\n    17044e08c158   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours   \r\n    root@li278-180:~# uname -a\r\n    Linux li278-180 3.2.0-40-virtual #64-Ubuntu SMP Mon Mar 25 21:42:18 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nWhat you need to do is to follow this guide: http://www.linode.com/wiki/index.php/PV-GRUB#Ubuntu_12.04_Precise\r\nThen i installed Docker with \r\n\r\n    curl http://get.docker.io | sh\r\n\r\nand everything worked out of the box.\r\n\r\nNo memleaks so far, referring to #407 - i had a job running for 2 days, and i'm now trying multiple jobs on a small machine.","Thanks! I will try that right away.\r\n\r\n\r\nOn Tue, Apr 23, 2013 at 1:47 PM, Marco Borromeo \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I'm playing with Docker at Linode, the smallest server (1GB Ram), with\r\n\u003e Ubuntu 12.04.\r\n\u003e\r\n\u003e root@li278-180:~# docker ps\r\n\u003e ID             IMAGE         COMMAND                CREATED       STATUS       COMMENT\r\n\u003e 8938be57c3e0   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e 7dccb4a0307e   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e 8804143b13af   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e 98161d5e8c3f   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e c0b65bad9e5f   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e 17044e08c158   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e root@li278-180:~# uname -a\r\n\u003e Linux li278-180 3.2.0-40-virtual #64-Ubuntu SMP Mon Mar 25 21:42:18 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\r\n\u003e\r\n\u003e What you need to do is follow this guide:\r\n\u003e http://www.linode.com/wiki/index.php/PV-GRUB#Ubuntu_12.04_Precise\r\n\u003e Then i installed Docker with\r\n\u003e curl http://get.docker.io | sh\r\n\u003e and everything worked out of the box.\r\n\u003e\r\n\u003e No memleaks so far, referring to #407\u003chttps://github.com/dotcloud/docker/issues/407\u003e- i had a job running for 2 days, and i'm now trying multiple jobs on a\r\n\u003e small machine.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/469#issuecomment-16885426\u003e\r\n\u003e .\r\n\u003e","It worked! Awesome. Now let's see if I can get Raring's 3.8.0 kernel on\r\nthere.\r\n\r\n\r\nOn Tue, Apr 23, 2013 at 9:47 PM, Solomon Hykes\r\n\u003csolomon.hykes@dotcloud.com\u003ewrote:\r\n\r\n\u003e Thanks! I will try that right away.\r\n\u003e\r\n\u003e\r\n\u003e On Tue, Apr 23, 2013 at 1:47 PM, Marco Borromeo \u003cnotifications@github.com\u003ewrote:\r\n\u003e\r\n\u003e\u003e I'm playing with Docker at Linode, the smallest server (1GB Ram), with\r\n\u003e\u003e Ubuntu 12.04.\r\n\u003e\u003e\r\n\u003e\u003e root@li278-180:~# docker ps\r\n\u003e\u003e ID             IMAGE         COMMAND                CREATED       STATUS       COMMENT\r\n\u003e\u003e 8938be57c3e0   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e\u003e 7dccb4a0307e   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e\u003e 8804143b13af   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e\u003e 98161d5e8c3f   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e\u003e c0b65bad9e5f   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e\u003e 17044e08c158   base:latest   /bin/sh -c while tru   5 hours ago   Up 5 hours\r\n\u003e\u003e root@li278-180:~# uname -a\r\n\u003e\u003e Linux li278-180 3.2.0-40-virtual #64-Ubuntu SMP Mon Mar 25 21:42:18 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\r\n\u003e\u003e\r\n\u003e\u003e What you need to do is follow this guide:\r\n\u003e\u003e http://www.linode.com/wiki/index.php/PV-GRUB#Ubuntu_12.04_Precise\r\n\u003e\u003e Then i installed Docker with\r\n\u003e\u003e curl http://get.docker.io | sh\r\n\u003e\u003e and everything worked out of the box.\r\n\u003e\u003e\r\n\u003e\u003e No memleaks so far, referring to #407\u003chttps://github.com/dotcloud/docker/issues/407\u003e- i had a job running for 2 days, and i'm now trying multiple jobs on a\r\n\u003e\u003e small machine.\r\n\u003e\u003e\r\n\u003e\u003e —\r\n\u003e\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/469#issuecomment-16885426\u003e\r\n\u003e\u003e .\r\n\u003e\u003e\r\n\u003e\r\n\u003e",":+1: It works.","Confirmed it worked for me too. Thanks again.\r\n\r\n\r\nOn Thu, May 2, 2013 at 7:12 PM, Barry Allard \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e [image: :+1:] It works.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/469#issuecomment-17375530\u003e\r\n\u003e .\r\n\u003e","Since we now have a recipe for installing this on linode, we should add it to the docs, to share with others.","CPU limiting will be straightforward, thanks to the cpu.shares cgroup\r\nsetting.\r\nHowever, storage is trickier. Cgroups don't have hooks for that.\r\nSolutions include:\r\n1) use an underlying filesystem supporting per-directory quotas (eg XFS +\r\nproject quotas)\r\n2) switch AUFS vs btrfs or zfs, which support per-branch quotas\r\n3) meter usage on a regular basis (hourly, daily...) and flag containers\r\nfor abuse\r\nSolution (1) requires some hooks within container creation code.\r\nSolution (2) is obviously even more invasive.\r\nSolution (3) is expensive (I/O-wise) and can let a container fill a disk\r\nanyway (if it fills it faster than the check cycle).\r\n\r\n\r\nOn Wed, Apr 24, 2013 at 4:45 PM, Quinton Pike \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I see there is now Memory limiting\r\n\u003e\r\n\u003e I was curious on if/how/when we can limit CPU and Storage on the\r\n\u003e containers.\r\n\u003e\r\n\u003e Thanks,\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471\u003e\r\n\u003e .\r\n\u003e","Sounds like the storage limitation is a little ways off. \r\n\r\nAlso, is it possible to mount a sharable file/drive between containers. NFS shares or something?\r\n\r\nThanks,","Hmm, in which direction do you want the share to happen?\r\n\r\n\r\nOn Wed, Apr 24, 2013 at 4:55 PM, Quinton Pike \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Sounds like the storage limitation is a little ways off.\r\n\u003e\r\n\u003e Also, is it possible to mount a sharable file/drive between containers.\r\n\u003e NFS shares or something?\r\n\u003e\r\n\u003e Thanks,\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471#issuecomment-16979941\u003e\r\n\u003e .\r\n\u003e","So basically, to have a PaaS the nodes/drones need to be able to read/write to a central location. Obviously some choose object storage like S3 or GridFS. But for PHP and older applications, the apps usually use the disk to store things. \r\n\r\nSo basically I would do a docker run... and then mount the folder/drive/nfs share to that container at X mount point. And If I mount that same thing to another container, they can both see / read / write on it. \r\n\r\nThanks for the fast responses!","Indeed!\r\nThis is probably within the scope if persistent data storage (issue #111,\r\nhttps://github.com/dotcloud/docker/issues/111).\r\nWarning: this is a very long thread, I advise you to brace yourself before\r\nreading it in full!\r\n\r\n\r\nOn Wed, Apr 24, 2013 at 5:00 PM, Quinton Pike \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e So basically, to have a PaaS the nodes/drones need to be able to\r\n\u003e read/write to a central location. Obviously some choose object storage like\r\n\u003e S3 or GridFS. But for PHP and older applications, the apps usually use the\r\n\u003e disk to store things.\r\n\u003e\r\n\u003e So basically I would do a docker run... and then mount the\r\n\u003e folder/drive/nfs share to that container at X mount point. And If I mount\r\n\u003e that same thing to another container, they can both see / read / write on\r\n\u003e it.\r\n\u003e\r\n\u003e Thanks for the fast responses!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471#issuecomment-16980124\u003e\r\n\u003e .\r\n\u003e","Read this and #111. \r\n\r\n**Metering IOPS** (priorities, limits) to storage devices would be clearly awesome.\r\n\r\nMost of the time, apps aren't CPU nor network bound, most things being equal are usually IOPS bound, especially for boxen lacking SSDs or operating from non-local storage.","Regarding metered IOPS, there is the cgroups blkio controller.\r\nIt lets you define per-device limits in iops and bps, separately for read\r\nand writes.\r\nIt has one severe downside, though: it applies only to synchronous\r\noperations, which means that it will be wildly inaccurate:\r\n- most accesses done through mapped memory won't be accounted for,\r\n- even normal write() calls will only be accounted for once the dirty ratio\r\nis exceeded (and the kernel turns them into synchronous writes).\r\nHowever, this might improve in future kernel versions.\r\n\r\n\r\n\r\nOn Thu, May 2, 2013 at 7:49 PM, Barry Allard \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Read this and #111 \u003chttps://github.com/dotcloud/docker/issues/111\u003e.\r\n\u003e\r\n\u003e *Metering IOPS* (priorities, limits) could be challenging, but absolutely\r\n\u003e awesome.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471#issuecomment-17376305\u003e\r\n\u003e .\r\n\u003e","Probably should continue this part of the thread on the LKML and cc: zfsonlinux, Ts'o. \r\n\r\nOn 3 May 2013, at 11:36 AM, Jérôme Petazzoni wrote:\r\n\r\n\u003e Regarding metered IOPS, there is the cgroups blkio controller. \r\n\u003e It lets you define per-device limits in iops and bps, separately for read \r\n\u003e and writes. \r\n\u003e It has one severe downside, though: it applies only to synchronous \r\n\u003e operations, which means that it will be wildly inaccurate: \r\n\u003e - most accesses done through mapped memory won't be accounted for, \r\n\u003e - even normal write() calls will only be accounted for once the dirty ratio \r\n\u003e is exceeded (and the kernel turns them into synchronous writes). \r\n\u003e However, this might improve in future kernel versions. \r\n\u003e \r\n\u003e \r\n\u003e \r\n\u003e On Thu, May 2, 2013 at 7:49 PM, Barry Allard \u003cnotifications@github.com\u003ewrote: \r\n\u003e \r\n\u003e \u003e Read this and #111 \u003chttps://github.com/dotcloud/docker/issues/111\u003e. \r\n\u003e \u003e \r\n\u003e \u003e *Metering IOPS* (priorities, limits) could be challenging, but absolutely \r\n\u003e \u003e awesome. \r\n\u003e \u003e \r\n\u003e \u003e — \r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471#issuecomment-17376305\u003e \r\n\u003e \u003e . \r\n\u003e \u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.\r\n\u003e ","What's the status of setting CPU limits on containers?","@cantino: pull request #551 provides CPU quotas.","Awesome, thanks.  Looks like it got merged!","Indeed :) Closing.","In our product, we add disk and network limit for docker, the idea is from warden.\r\n\r\nfor disk limit:  we create a 'worker' user account in each container, and assign a user id for 'worker'; On the host  , we use setquota to limit this userid. \r\n\r\nfor network limit:  we use tc to control the host-side veth device.","@chenyf Can multiple users in Linux have the same username but different userids? When a user/userid is created in the container, isn't it in its own namespace? I'm curious if you could provide a little more detail because I need to address the same issue. Thx!","Hi,\r\n\r\nIn fact, you don't \"create a user\" on a UNIX system. When you \"create a\r\nuser\", it just means that you add an entry in `/etc/passwd`, to map the\r\nnumeric ID with the user name. But you can `chown` and `setuid`\r\nnumerically, even if the user id does not exist in the user database. In\r\nfact, when you `chown` with a user name, it will first resolve the user\r\nname to a numeric ID.\r\n\r\nIt also means that when you do e.g. `ls -l`, if will show the user name\r\n*according to the local database*. In other words, if UID 1000 is \"joe\" in\r\nyour host system, but \"jack\" in a container, when you do `ls -l` in the\r\ncontainer you will see that the files belong to \"jack\" but if you check the\r\nsame directory from within the host, it will show that they belong to\r\n\"joe\". For that reason, if you use `rsync` across chroot or container\r\nboundaries, it is strongly recommended to use `--numeric-ids` to avoid a\r\nuser mapping error.\r\n\r\nI don't know the specific details of the solution implemented by @chenyf;\r\nbut it is likely that they use the same username in each container, but\r\nmapped to a different numeric ID, with a different entry in `/etc/passwd`\r\nfor each container.\r\n\r\nNote: the newer \"user namespace\" lets you map container user IDs to\r\ndifferent host user IDs, using a translation mapping in `/etc/subuid` in\r\nthe host. It is another possibility.\r\n\r\n\r\n\r\nOn Sat, Aug 10, 2013 at 5:27 PM, Debnath Sinha \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @chenyf \u003chttps://github.com/chenyf\u003e Can multiple users in Linux have the\r\n\u003e same username but different userids? When a user/userid is created in the\r\n\u003e container, isn't it in its own namespace? I'm curious if you could provide\r\n\u003e a little more detail because I need to address the same issue. Thx!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471#issuecomment-22450065\u003e\r\n\u003e .\r\n\u003e","hi, actually the idea is from cloud foundy warden;  we mantain a UID pool, we get a uid from the pool when we create a container,  inside the container: we  create a user account with this uid; outside the container, we use setquota to set disk limit for this uid.  we return the uid to pool when we delete this container","jerome is correct;   each container can has same user account like 'worker' but with different uid. ","Thanks for the explanation!","Thanks for all the details! Was very helpful because I think I may need\r\nsomething similar in the future...\r\n\r\n\r\nOn Thu, Aug 15, 2013 at 11:08 AM, Jérôme Petazzoni \u003cnotifications@github.com\r\n\u003e wrote:\r\n\r\n\u003e Thanks for the explanation!\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/471#issuecomment-22718468\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nhttp://www.debnathsinha.com","My colleague just sent this to the mailing list:\r\n\u003e As a fun side project, some friends and I will be adding support for cpu resource limiting / guarantees through cgroups and cpuset.  The existing solution provides for relative cpu resource limiting, but we want absolute resource guarantees.  A sample use case for this (and indeed, our use case) is for creating environments in which to grade code for performance challenges; we want every container to have exactly 2 cpus and X memory (allowing extra cpu could artificially improve the performance of some programs, etc).","@chenyf, any chance you could elaborate or show how you track your UID pool? This sounds like a great workaround until true disk limits are in place, but I think this stuff is a bit over my head, so any other details or examples would be greatly appreciated.","Does anyone have any info on this? I think the right way would be to use user namespaces and then quotas. The problem is that I'm not seeing them enabled in stock debian/ubuntu kernels. :(","You can also use the devicemapper plugin; each container will be allowed to use up to a certain amount of disk space.","@Taytay   We have a daemon process which maintain a UID pool, and it will persistence this UID pool into disk. \r\neach time we create a container, we get a UID from this daemon;  \r\neach time we delete a container, we return the UID to this daemon;","@jpetazzo , If I use devicemapper, how can I setup the amount of disk space of each container","@kies, by default, each container will get 10 GB of total disk usage.\r\n\r\nIf you need to change that amount, you can check http://jpetazzo.github.io/2014/01/29/docker-device-mapper-resize/, section \"Growing containers\". (There are other and better ways to do it, but it will get you started in the right direction!)","jpetazzo, great write up on growing containers!!   Great docker class in San Fran as well :)","@jpetazzo , I followed your blog on growing containers and I am getting error while using resize2fs.\r\nfollowing is the error message:-\r\nresize2fs: Device or resource busy while trying to open /dev/mapper/docker-202:2-5113011-8c2ec367dbd416c013fbeecd2425cc515973742f74f7b0f73a7c6c78084527fe\r\nCouldn't find valid filesystem superblock.\r\n\r\nI am running docker on oracle linux VM. Please let me know how this can be solved!","We are trying the uid concept for limiting disk quotas. Since Swarm is the scheduler we use, the way I am trying to tackle is that having a mapping file of uid at swarm server level, and use constraints at the docker daemon level to let swarm choose containers of a specifc UID end up going to the node and thereby quota gets applied.Thoughts/Suggestions?","@shashankmjain the GitHub issue tracker is not a general discussion / support forum. Can you ask y question in the #docker IRC channel, on https://forums.docker.com or StackOverflow? Those are more suitable for those questions","This is great.  After making one small change (justone/docker@26ec7b2e77b557880112c39cc2dd47053847989e), I was able to use this to build an image with sshd using the following Dockerfile:\r\n\r\n```\r\nfrom    ubuntu\r\nrun     echo root:testpass | chpasswd\r\nrun     apt-get update\r\nrun     apt-get install openssh-server -y\r\nrun     mkdir -p /var/run/sshd\r\n```\r\n\r\nThanks for implementing this.","Thanks for catching that!","@justone:One detail though, for the moment, the builder uses /bin/sh -c for convenience, but soon, it will run the command directly, so if you need to pipe, you should do it with a shell: `run    /bin/sh -c 'echo root:testpass | chpasswd'`\r\n","Cool.  Thanks for the heads up.  I'll update my Dockerfile accordingly.  Having used the builder a couple times, I was wondering what you would think of these suggestions:\r\n\r\n1. At the end of the build run, the new image has a randomly generated name.  How about a new command to save the current state to a specific name?  Like this:\r\n```\r\nfrom    ubuntu\r\nrun     /bin/sh -c 'echo root:testpass | chpasswd'\r\nrun     apt-get update\r\nrun     apt-get install openssh-server -y\r\nrun     mkdir -p /var/run/sshd\r\nsave    justone/sshd\r\n```\r\n\r\n1. After I did a build run, there were N containers and N-1 images that I had to delete.  On success, could the `build` command remove those?\r\n\r\n1. Speaking of the switch away from using `/bin/sh -c`, could the builder detect shell metacharaters (like | and ;) and automatically wrap the command in a shell call?  Or is that a bit too much magic?","@justone to answer your questions:\r\n\r\n1. I think it makes more sense to let the build tool optionally tag your image under the name of your choice. You can also do this yourself with 'docker tag'\r\n\r\n2. Each layer is in fact a layer which depends on all the layers under it (just like a git commit). So you can't delete underlying layers or you'll break all the layers built on top of it. (Don't worry about storage space, each layer only stores the diff created by its build step).\r\n\r\n3. I think magically detecting shell meta-characters would be too magic. However it would be nice to allow direct execution of a command without inserting a shell. This requires parsing/lexing the command string with correct handling of space separators, quotes etc.\r\n","@shykes thanks for your answers.\r\n\r\nOn the second question, how about just removing the temporary containers?\r\n\r\nI've been practicing building images with this for a little while now and it's working quite well.  Two new questions:\r\n\r\n1. Is there a way to flatten an image's layers together?  Looks like there's already #332, but maybe an option to the builder?\r\n1. Is there a way to prune image trees that aren't needed anymore?  After building several iterations of an image, I only want to keep one and toss the other attempts.  It's not really necessary, but it would help keep the image list clean.\r\n\r\nThanks again.","I don't see any documentation, when we add/change features it would be nice if we had the documentation updated as part of the pull request as well.","@justone re: flattening. I think once #332 is implemented, we could make it an explicit build operation.","Re pruning unwanted branches - I agree there should be an easy way to do this. I hinted in that direction with the default behavior of 'docker images'. It only shows untagged \"top layers\" (with tag set as \"\u003cnone\u003e\") instead of every single untagged layer. The assumption is that if you want to keep a layer, you tag it. The next step is to make pruning easier - currently if you remove one of the untagged top layers, it will only remove that layer, and the underlying layer will show up instead.\r\n\r\nWould it make sense to have a command for \"Remove this layer, and all its dependencies, unless they are also the dependency of another layer\"? Could be an option to rmi, eg. \"docker rmi --deps\"","Hey @creack, I'm getting conflicts. Could you resolve them and let me know when you're ready for me to review? I think we can get this merged this week-end :)","@shykes I think your proposed solution (docker rmi --deps) sounds good.  That's exactly what I was thinking.","@brianm: Why do we need a new Ubuntu box?  Can't we use the official vagrant one and adding the right packages into it? (eg: aws needed linux-image-extra-3.2.0-40-virtual)","@mzdaniel that is what this does, notice that the box_url points at the standard vagrant precise64 box :-)",":) \r\nI just found out the dummy box lines are not relevant. so I will take them out.\r\nCould it be possible to take the config.vm.box config.vm.box_url from config.vm.provider :vmware_fusion do |vm| ?\r\nThis way the default image http://files.vagrantup.com/precise64.box will be used and any special required package can be explicitly added.","Thanks for catching that!","A significant amount of allocations could be saved by using `bufio` and `bytes` instead of reading the whole file into memory and using `strings`. That being said, I'm not sure if the file is big enough for the allocations to be a big deal.","titanous, this function is called once at startup. Saving a few dozen allocations isn't worth the extra LoC IMO. /proc/mounts is usually less than 2KiB. 1000 mounts would come out around 16KiB of text. This amount of memory is not worthy of optimization, except maybe in a very fast code path.","Makes sense, I am compelled to ask each time I see a file being read into memory.","@tobert there are Vagrant-related commits in there... I suppose this is because you've updated your master since submitting the PR?\r\n\r\nCould you confirm this will merge cleanly?","@tobert This is because the pull request was opened from master. I'd suggest rebasing the other commits off your master. In the future, make sure that you open pull requests from a feature branch.","My bad, it's a mistake. I updated my repo from origin/master and pushed to tobert/master which screwed up the PR. It should still merge cleanly since those commits are from upstream.\r\n\r\n","Will reopen with a clean PR.","There doesn't appear to be support in the ppa for 12.10 so this won't for it.  Either close this pull request or add a build for 12.10 in the ppa.","it would be nice to add a build for Raring Ringtail too","Hey Evan, Although this implementation is cleaner that an echo to source.list, I have a hard time depending on a package that doesn't even exist in 12.04. ","What do you mean it doesn't exist?  Do you change the apt sources or\r\nsomething?\r\n\r\nhttp://packages.ubuntu.com/precise/python-software-properties\r\nOn May 3, 2013 6:44 PM, \"Daniel Mizyrycki\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Hey Evan, Although this implementation is cleaner that an echo to\r\n\u003e source.list, I have a hard time depending on a package that doesn't even\r\n\u003e exist in 12.04.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/477#issuecomment-17422217\u003e\r\n\u003e .\r\n\u003e","Using `add-apt-repository` is the correct way of adding PPA sources to Ubuntu. It is used in launchpads official \"How to install\" help: https://launchpad.net/+help-soyuz/ppa-sources-list.html","@ehazlett: Strange name for a repository tool. As python-software-properties is not installed by default, we should update this PR, don't you think? We primarily target12.04 for official support.","That it's not installed by default on ubuntu server is actually a bug: https://bugs.launchpad.net/ubuntu/+source/ubuntu-meta/+bug/439566","@ulope: Right. Still we need to provide proper instructions how to deal with the issue being a bug or not. We can't expect users to do research in order to use docker.","Hi Evan, Docker PPA support for Quantal and Raring has been added. Would you like to try it and close this ticket if appropriate?","What is the intended result? Is the goal to avoid polluting your namespace with containers you already know you want to throw away? Or do you need privileged access to the underlying host?\r\n\r\nIf it's answer #1, would this do?\r\n\r\n```bash\r\n\r\n$ docker run --ephemeral $IMG do_something\r\n```\r\n","I'm currently trying to do something like this, in my case I'm trying to run a suite of tests of a client/server app with isolation so that I can run the tests in parallel. Our OS is ubuntu 12.04, so it would be nice to be able to run docker against the host OS to provide isolation only (or provide an easy way to clone the current OS as a container). Is this already possible?\r\n","You can easily import the host's filesystem as a new layer with 'docker\r\nimport'. For example:\r\n\r\ntar -C / -c . | docker import - ed/hostbase\r\ndocker run -i -t ed/hostbase bash\r\n\r\n\r\nOn Thu, May 2, 2013 at 11:52 AM, Ed \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I'm currently trying to do something like this, in my case I'm trying to\r\n\u003e run a suite of tests of a client/server app with isolation so that I can\r\n\u003e run the tests in parallel. Our OS is ubuntu 12.04, so it would be nice to\r\n\u003e be able to run docker against the host OS to provide isolation only (or\r\n\u003e provide an easy way to clone the current OS as a container). Is this\r\n\u003e already possible?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/479#issuecomment-17357090\u003e\r\n\u003e .\r\n\u003e","It looks like there are two different questions here.\r\n\r\n@treeder: are you looking for something like \"docker run -ephemeral ...\", which would essentially destroy the container once it's done running?\r\n\r\n@ehutchins: would @shykes ' proposal work for you? (It might need a few extra tar options to exclude docker directories and other things)","For ephemeral: @treeder would a simple \"docker run \u0026\u0026 docker rm\" do the\r\ntrick?\r\n\r\n\r\nOn Tue, Jun 25, 2013 at 7:23 PM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e It looks like there are two different questions here.\r\n\u003e\r\n\u003e @treeder \u003chttps://github.com/treeder\u003e: are you looking for something like\r\n\u003e \"docker run -ephemeral ...\", which would essentially destroy the container\r\n\u003e once it's done running?\r\n\u003e\r\n\u003e @ehutchins \u003chttps://github.com/ehutchins\u003e: would @shykes\u003chttps://github.com/shykes\u003e' proposal work for you? (It might need a few extra tar options to exclude\r\n\u003e docker directories and other things)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/479#issuecomment-20023612\u003e\r\n\u003e .\r\n\u003e","@jpetazzo I ended up writing my own bash script using lxc and overlayfs directly once I understood what it could do for me. I still think the \"give me a super-chroot version of the OS I'm currently running\" use-case is one that should be simpler to set up, but it's probably outside of docker's focus to provide it (I wanted to avoid creating/maintaining a system tarball which @shykes docker import solution requires).\r\n","@jpetazzo ya, maybe something like that. I'm not exactly sure how it should work technically, but maybe what  @shykes said would be sufficient. hmmmm... ","@treeder FYI I use this shell function:\r\n\r\n    function drun {\r\n        docker run \"$@\" \u0026\u0026 docker rm `docker ps -l -q` \u003e /dev/null\r\n    }\r\n\r\n\r\nLike this I can do `drun -i -t base bash` and it delete the container right after I quit it.","This would be very useful as a flag for `docker run`. Perhaps it could be `-r` (remove)?\r\n\r\nRight now, there's no way to get the container ID if we run `docker run -i` and want to stay attached until the container exits. This would help because we wouldn't have to run ```docker run ... \u0026\u0026 docker rm `docker ps -l -q` ```.\r\nIf another container is started on the host between the time we started the container and the time we want to remove it, ```docker run ... \u0026\u0026 docker rm `docker ps -l -q` ``` will remove another container.","There is a way to do that:\r\n​\r\nID=$(echo hello | docker run -i -a=stdin   IMG)\r\n\r\n​docker wait $ID\r\ndocker rm $ID\r\n\r\n\r\nWe could still do a flag. \r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sat, Jun 29, 2013 at 12:23 AM, unclejack \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e This would be very useful as a flag for `docker run`. Perhaps it could be `-r` (remove)?\r\n\u003e Right now, there's no way to get the container ID if we run `docker run -i` and want to stay attached until the container exits. This would help because we wouldn't have to run ```docker run ... \u0026\u0026 docker rm `docker ps -l -q` ```.\r\n\u003e If another container is started on the host between the time we started the container and the time we want to remove it, ```docker run ... \u0026\u0026 docker rm `docker ps -l -q` ``` will remove another container.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/479#issuecomment-20225842","@shykes You're right, that fixes stdin, but we really need to have a flag. We might want to run `docker run` under a process monitoring tool (upstart, systemd, supervisor) and this is pretty much needed.","Some sort of --ephemeral option could also take the further step of *ensuring* clean up happens.  I'm all for the unix way and strapping things together with a script over the top, but the problem with doing a run/wait/rm series is... what if that script gets a SIGINT?  Or docker-d gets kill -9'd?  Or the whole machine has a hard down?  That shouldn't cause someone's box to start filling with untracked artifacts if they're using nothing but --ephemeral mode.\r\n","You guys are right, this cannot be done cleanly by an outside tool. Ok for an ephemeral flag.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Tue, Jul 2, 2013 at 12:12 PM, Eric Myhre \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Some sort of --ephemeral option could also take the further step of *ensuring* clean up happens.  I'm all for the unix way and strapping things together with a script over the top, but the problem with doing a run/wait/rm series is... what if that script gets a SIGINT?  Or docker-d gets kill -9'd?  Or the whole machine has a hard down?  That shouldn't cause someone's box to start filling with untracked artifacts if they're using nothing but --ephemeral mode.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/479#issuecomment-20368534","I will send a PR which implements this soon.","Marking this as an easy-fix for adding a `-r` flag to `docker run`","**Steps:**\r\n* Add -r flag to commands.go\r\n* Add r query param to api.go\r\n* rm the container after it stops running when flag is passed\r\n* Write tests for above ^^\r\n* `gofmt -s -w` your code\r\n* Make sure the tests pass `sudo -E go test -v . ./...`\r\n\r\nIf you need help, jump into #docker on freenode.","started on this @ 0e6d6cce054896915bf305d44fc48725525a9800\r\n\r\n","@faizkhan00 I had just written above that I was going to send a PR soon.\r\n","Er, thats fine then, disregard ","Edited title for clarity.","Let's continue the discussion in PR #1589. I'm going to close this issue to lower the number of open issues.\r\nIf someone thinks the issue should stay open, please re-open it or ask me to do it.","Commenting out line 56 of Vagrantfile allowed the proper box to be downloaded.","@adamjt :  Thank you for catching this issue Adam!","This commit totally removes the provider, right? Will I still be able to use vmware or is that being axed?","The main issue is that PRs should not to break existing functionality.  Aside of that, if possible, it will be nice to depend on the same official precise64.box so others can understand better what it's needed to add new functionality.","@adamjt: The main Vagrantfile is official and has to be fully supported. Depending on the community interest for this feature, It might make more sense to add vmware support on contrib. What do you think?","@mzdaniel I think the box is officially supported, there was just a syntax problem in the Vagrantfile that was causing the URL to be set even when not using vmware_fusion as a provider. I'll see if I can find the bug when I have some free time.","@adamjt: We are moving this issue to #788. It would be great if we can keep improving it there.","This breaks if a) I commit a new layer using this version, then b) I run a new container on top of that layer.\r\n\r\nSee below:\r\n\r\n```bash\r\n$ C1=$(docker run -d busybox echo foo)\r\n$ docker wait $C1\r\n0\r\n$ IMG=$(docker commit $C1)\r\n$ docker run -d $IMG echo bar\r\nError: No command specified\r\n```\r\n","fixed","I tried to run the iscsid initiator daemon manually with foreground option \"-f\" and I can see that the problem is that the  scsi_transport_iscsi module is not loaded. In the config file provided to load lxc container, the capability to load a module is dropped. How can I enable it? I can modify the lxc_template but I guess that it is not the way to go?","One solution is to load the module from the host: **sudo modprobe scsi_transport_iscsi**\r\n\r\n  This allow me to continue the installation. I got a problem with no valid sudoers sources found. This error is due to an error in a new created file in **/etc/sudoers.d/cinder-rootwrap**. I removed this file. I don't know if it is the best solution but it allows me to continue the installation of devstack. I need to check why *stack.sh* script is creating cinder-rootwrap and if it will be missing for the next steps. The error was:\r\n```\r\nsudo: \u003e\u003e\u003e /etc/sudoers.d/cinder-rootwrap: syntax error near line 0 \u003c\u003c\u003c\r\nsudo: parse error in /etc/sudoers.d/cinder-rootwrap near line 0\r\nsudo: no valid sudoers sources found, quitting\r\nsudo: unable to initialize policy plugin\r\n```\r\n\r\n  So, I restart some services that are needed by openstack and that seems well installed by devstack:\r\n    **$ rabbitmq-server**\r\n    **$ mysqld**\r\n  And I rerun *stack.sh*\r\n\r\nThe problem now is that the *stack.sh* script needs to restart mysql. So now I have the error\r\n```\r\n+ sudo /usr/sbin/service mysql restart\r\nstop: Unable to connect to Upstart: Failed to connect to socket /com/ubuntu/upstart: Connection refused\r\nstart: Unable to connect to Upstart: Failed to connect to socket /com/ubuntu/upstart: Connection refused\r\n++ failed\r\n++ local r=1\r\n+++ jobs -p\r\n++ kill\r\n++ set +o xtrace\r\n```\r\n\r\nSo maybe one solution is to replace the */etc/init.d/mysql* to not use upstart service or maybe another one is to modified the *stack.sh* script to check if mysql is already running and not restart it...","Hey @thouveng, if you feel like writing this up as a tutorial, let me know! It would make for a great blog post.","Did this ever get written up as a tutorial or blog post?  I'd like to install openstack in a docker container...","any blog for this，interesting as well","Unfortunately I didn't blog about this but the good news is that someone else did it. It is Eric Windish and I think that you will find the link about  [dockenstack](https://github.com/ewindisch/dockenstack) interesting.","Try to see if this helps, https://wiki.openstack.org/wiki/Docker\r\n\r\n\r\nOn Tue, Jun 10, 2014 at 3:30 PM, thouveng \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Unfortunately I didn't blog about this but the good news is that someone\r\n\u003e else that did it. It is Eric Windish and I think that you will find the\r\n\u003e link about dockenstack \u003chttps://github.com/ewindisch/dockenstack\u003e\r\n\u003e interesting.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\r\n\u003e \u003chttps://github.com/dotcloud/docker/issues/483#issuecomment-45582003\u003e.\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nCheers!\r\n\r\nAlex Tu","\u003e Try to see if this helps, https://wiki.openstack.org/wiki/Docker\r\n\r\nIt is not exactly the same thing here (also interesting but different ;). The wiki explained how to start an instance in a docker container by using openstack while dockenstack installs an openstack into a container. And for information there is also an Heat resource (see this [blogpost](http://blog.docker.com/tag/heat/))  that you can use to start an instance into a docker container.","A few more details:\r\n\r\n- adduser/adduser.conf is fine;\r\n- no difference in the PAM configuration with the 12.10 image (which doesn't have this problem);\r\n- same problem on both 12.04 and 13.04 *hosts*.","@jpetazzo pointed out that it could be an issue between the layers and aufs, and indeed, when everything is in one layer (i.e: debootstrap + adduser) then it works.\r\n\r\nSo, it feels like something could be wrong and that / is not actually world-readable (even though it appears so).","Indeed, I just checked all my image history and found out that my base image had the wrong permission on its layer directory (700 instead of 750), which meant that / was actually 700. This wouldn't show up in the aufs mount (which is actually a known issue).\r\n\r\n3 weeks ago I remember that I had to fix my base image myself: the tarball I imported had a subdirectory (and then the filesystem) and docker didn't remove it. I remember going into /var/lib/docker to fix the situation myself, that's probably when I ended up with the wrong permissions on the layers directory.\r\n\r\nSince docker push take the whole image directory as it is, I basically generated a corrupt image.\r\n\r\nAt this point I'm unsure if:\r\n\r\n- we should improve import to handle tarball with a subdirectory;\r\n- add a sanity check on the layers directory in the images;\r\n- both;\r\n- nothing, I shouldn't have poked around /var/lib/docker;\r\n- obi wan kenobi.","Just to be clear, does the problem only occur when you make manual changes\r\nin /var/lib/docker?\r\n\r\nIe. what steps should I take to reproduce the problem?\r\n\r\n\r\nOn Mon, Apr 29, 2013 at 5:30 PM, Louis Opter \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Indeed, I just checked all my image history and found out that my base\r\n\u003e image had the wrong permission on its layer directory (700 instead of 750).\r\n\u003e This wouldn't show up in the aufs mount (which is actually a known issue).\r\n\u003e\r\n\u003e 3 weeks ago I remember that I had to fix my base image myself: the tarball\r\n\u003e I imported had a subdirectory (and then the filesystem) and docker didn't\r\n\u003e remove it. I remember going into /var/lib/docker to fix the situation\r\n\u003e myself, that's probably at this moment that I ended up with the wrong\r\n\u003e permissions on the layers directory.\r\n\u003e\r\n\u003e Since docker push take the whole image directory as it is, I basically\r\n\u003e generated a corrupt image.\r\n\u003e\r\n\u003e At this point I'm unsure if:\r\n\u003e\r\n\u003e    - we should improve import to handle tarball with a subdirectory;\r\n\u003e    - add a sanity check on the layers directory in the images;\r\n\u003e    - both;\r\n\u003e    - nothing, I shouldn't have poked around /var/lib/docker;\r\n\u003e    - obi wan kenobi.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/486#issuecomment-17203308\u003e\r\n\u003e .\r\n\u003e","Yes, this problem occurred because I fiddled around in /var/lib/docker/. Now, the reason why I made manual changes in /var/lib/docker/, is because `docker import` doesn't support tarballs that contain the fs in a subdirectory.","Ah :)\r\n\r\nAbout 'docker import' supporting a subdirectory: there was a discussion\r\nabout this (can't find it atm), and the conclusion was: there's no\r\npractical way to automatically \"correct\" tarballs with an extra level of\r\nsubdirectory. The reason for that, in short, is that a tarball with a\r\nsingle subdirectory is, in fact, a legal image. Docker wouldn't be able to\r\ndistinguish a user mistake from an intentional upload of an unusual yet\r\nperfectly functional image.\r\n\r\n\r\n\r\nOn Mon, Apr 29, 2013 at 6:08 PM, Louis Opter \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Yes, this problem occurred because I fiddled around in /var/lib/docker/.\r\n\u003e Now, the reason why I made manual changes in /var/lib/docker/, is because docker\r\n\u003e import doesn't support tarballs that contain the fs in a subdirectory.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/486#issuecomment-17204432\u003e\r\n\u003e .\r\n\u003e","Good catch. Thanks! Would you mind rebasing your PR?  (You submitted 2 PRs modifying common files. So the second one is merged into mainline, the other gets automatically diverged)","Sure! It's done.","I can't login:\r\n\r\n```\r\n$ docker login\r\n2013/04/30 16:16:29 docker login\r\nUsername (shykes): shykes\r\nError: Login:\r\n```","Same if I just press enter at login:\r\n\r\n```bash\r\n$ docker login\r\n2013/04/30 16:16:33 docker login\r\nUsername (shykes):\r\nError: Login:\r\n```","To facilitate testing, I uploaded a binary build of this branch: http://get.docker.io.s3.amazonaws.com/builds/Linux/x86_64/docker-registry-update.tgz\r\n\r\nDon't forget this is a staging registry, everything you upload with this build might be lost!","Is the new API documented anywhere?","Now I'm getting 500 internal server error\r\n\r\n```bash\r\n$ docker login\r\n2013/04/30 16:52:37 docker login\r\nUsername (shykes): shykes\r\nError: Unexpected status code [500] : \u003ch1\u003eServer Error (500)\u003c/h1\u003e\r\n```","Same when just pressing enter. Note: there is a 5-10 second delay before getting the response.\r\n\r\n```bash\r\n$ docker login\r\n2013/04/30 16:53:17 docker login\r\nUsername (shykes):\r\nError: Unexpected status code [500] : \u003ch1\u003eServer Error (500)\u003c/h1\u003e\r\n```","I received an email confirmation. After clicking on the link, it seems that login works.","The whole thing feels pretty slow.","Another problem when logging in as a different user:\r\n\r\n```bash\r\n$ docker login\r\nUsername (shykes): library\r\nPassword:\r\nEmail (solomon+docker@dotcloud.com): solomon+docker@dotcloud.com\r\nError: Server Error: [400] use of closed network connection\r\n```","Yet another error:\r\n\r\n```bash\r\n$ docker login\r\nUsername (shykes): library\r\nPassword:\r\nEmail (solomon+docker@dotcloud.com): solomon+library@dotcloud.com\r\nError: Server Error: unexpected EOF\r\n```","Ok, I managed to login successfully after hitting a bunch of different errors. Trying a pull next.","'docker pull' fails:\r\n\r\n```bash\r\n$ docker pull joffrey/base\r\n2013/04/30 17:16:41 docker pull joffrey/base\r\nPulling repository joffrey/base\r\n\r\n\r\n\r\n[debug] registry.go:180 Registry isn't responding: trying another registry endpoint\r\n2013/04/30 17:17:00 Error: Could not reach any registry endpoint\r\nError: Could not reach any registry endpoint\r\n```","I cant reproduce the problem above. When I tried again it started a pull, then failed with the following error:\r\n\r\n```bash\r\n$ docker pull joffrey/base\r\n2013/04/30 17:25:51 docker pull joffrey/base\r\nPulling repository joffrey/base\r\n[debug] registry.go:62 Ancestry: [\r\n    \"82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa\",\r\n    \"187062d10d084a0b\"\r\n]\r\nPulling 82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa metadata\r\n[debug] registry.go:23 Json string: {{\"container\": \"dbf761954fd5f32df928588b3d383f3cca95d754fce1d3ef7ecdc00bbc4f739b\", \"parent\": \"187062d10d084a0b\", \"created\": \"2013-04-25T09:11:08.56434-07:00\", \"container_config\": {\"Tty\": false, \"Cmd\": [\"/bin/bash\"], \"PortSpecs\": null, \"Image\": \"base\", \"Hostname\": \"dbf761954fd5\", \"StdinOnce\": true, \"Env\": null, \"Dns\": null, \"AttachStdin\": true, \"User\": \"\", \"MemorySwap\": 0, \"Memory\": 0, \"AttachStderr\": false, \"AttachStdout\": true, \"OpenStdin\": true}, \"docker_version\": \"0.1.4\", \"id\": \"82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa\"}}\r\n\r\nPulling 82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa fs layer\r\n2013/04/30 17:25:57 Error: use of closed network connection:\r\nError: use of closed network connection:\r\n```","3 tries, 3 different errors:\r\n\r\n```bash\r\n$ docker pull joffrey/base\r\n2013/04/30 17:28:52 docker pull joffrey/base\r\nPulling repository joffrey/base\r\n[debug] registry.go:62 Ancestry: [\r\n    \"82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa\",\r\n    \"187062d10d084a0b\"\r\n]\r\nPulling 82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa metadata\r\n[debug] registry.go:23 Json string: {{\"container\": \"dbf761954fd5f32df928588b3d383f3cca95d754fce1d3ef7ecdc00bbc4f739b\", \"parent\": \"187062d10d084a0b\", \"created\": \"2013-04-25T09:11:08.56434-07:00\", \"container_config\": {\"Tty\": false, \"Cmd\": [\"/bin/bash\"], \"PortSpecs\": null, \"Image\": \"base\", \"Hostname\": \"dbf761954fd5\", \"StdinOnce\": true, \"Env\": null, \"Dns\": null, \"AttachStdin\": true, \"User\": \"\", \"MemorySwap\": 0, \"Memory\": 0, \"AttachStderr\": false, \"AttachStdout\": true, \"OpenStdin\": true}, \"docker_version\": \"0.1.4\", \"id\": \"82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa\"}}\r\n\r\nPulling 82ddddca25764867965eafa75ba3434781d48faf46a9884bfad75752c10800aa fs layer\r\n2013/04/30 17:28:56 Error: exit status 1: bsdtar: Error opening archive: Lzma library error: Corrupted input data\r\n\r\nError: exit status 1: bsdtar: Error opening archive: Lzma library error: Corrupted input data\r\n```\r\n","For reference here's my docker version:\r\n\r\n```bash\r\n$ docker version\r\n2013/04/30 17:29:49 docker version\r\nVersion: 0.2.0\r\nGit Commit: 957c686\r\nKernel: 3.8.0-18-generic\r\nWARNING: No swap limit support\r\n```","@shykes `use of closed network connection` has been fixed in go1.0.3 upwards: https://code.google.com/p/go/issues/detail?id=4704","@titanous I think we have plans to release the API spec, will ask again","@titanous @shin- yes we plan on releasing the spec, I'm in the process of cleaning it up now, and then will submit a PR to add to docs.","@titanous @shin- @samalba  I added my pull request for adding the docker registry api see #492 ","Yeah I had that problem too. One common symptom is \"bad address\" when trying to resolve something inside the container, eg.\r\n\r\n```bash\r\n$ docker run busybox ping www.docker.io\r\nbad address: www.docker.io\r\n```\r\n\r\n(Not the exact error message, this is from memory)\r\n","The easy fix would be for Docker daemon to run a `sysctl -w net.ipv4.ip_forward=1` at startup","I think this is more the user's responsability. Docker already setup the iptables, but if the users does not have ip_forward enable, do we really want to enable it for him?","We discussed this a bit on #313 for Gentoo, and ended with just a warning in the ebuild (so it shows up at install time).  Perhaps we should look to add a similar warning to docker itself when it notices that IP Fowarding is disabled?  I think as long as we mention that it has security implications, then we'd be pk.  Looking around, I see that it looks like Go used to have a handy syscall.Sysctl* set of functions, but that they've since been removed, so this wouldn't be as \"simple\" as I was thinking, but still doable (especially since it's going to be a very common question).","I just spent ~2 hours figuring out why my install didn't work. Mentioning this somewhere in the docs would be very useful.","I am using an up to date Ubuntu 13.04 server instance inside VirtualBox to test docker.\r\nIP forwarding is enabled:\r\n```\r\n$ sysctl net.ipv4.ip_forward\r\nnet.ipv4.ip_forward = 1\r\n```\r\n\r\nbut the container still can't connect to the outside:\r\n```\r\n$ docker run busybox ping www.docker.io\r\nping: bad address 'www.docker.io'\r\n```\r\n\r\nwhat else could be the problem?","Could you try with the base image instead of busybox ?\r\n\r\n\r\nOn Thu, Jun 6, 2013 at 2:43 PM, niclashoyer \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I am using an up to date Ubuntu 13.04 server instance inside VirtualBox to\r\n\u003e test docker.\r\n\u003e IP forwarding is enabled:\r\n\u003e\r\n\u003e $ sysctl net.ipv4.ip_forward\r\n\u003e net.ipv4.ip_forward = 1\r\n\u003e\r\n\u003e but the container still can't connect to the outside:\r\n\u003e\r\n\u003e $ docker run busybox ping www.docker.io\r\n\u003e\r\n\u003e ping: bad address 'www.docker.io'\r\n\u003e\r\n\u003e what else could be the problem?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/490#issuecomment-19042404\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","sure. Output is as follows:\r\n\r\n```\r\n$ docker run base ping www.docker.io\r\nping: unknown host www.docker.io\r\n```","It's a dns issue, `docker run -dns 8.8.8.8 base ping www.docker.io` should\r\nsolve your issue.\r\n\r\n\r\nOn Thu, Jun 6, 2013 at 3:27 PM, niclashoyer \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e sure. Output is as follows:\r\n\u003e\r\n\u003e $ docker run base ping www.docker.io\r\n\u003e ping: unknown host www.docker.io\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/490#issuecomment-19044770\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","ok thank you. I stumbled upon this while using `docker build`, but docker build does not have the `-dns` switch. I think this is related to #759. I don't know why dns does not work inside the container. Maybe the IP of my local router is colliding with some IP ranges used for the containers.","Now, that most distributions make use of systemd, what about simply providing a corresponding sysctl.d file to enable IP forwarding?\r\n\r\n**/usr/lib/sysctl.d/docker-ip-forwarding.conf**\r\n\r\n    net.ipv4.ip_forward = 1\r\n\r\nThen the few remaining distributions which don't provide support for systemd (yet) would only have to actually take care about dealing with this.\r\n\r\nRegarding issue #313: The current Gentoo policy for installing systemd files is: they're always installed, independent from `USE=systemd`. For now this file could be shipped from `$FILESDIR`, once docker provides it itself, it can be dropped from `$FILESDIR`. A corresponding einfo what to do in case systemd is not used should only be displayed in case of `USE=-systemd`.","Well, the reason this was not automatically enabled by default in the first place was because enabling IP forwarding has security implications, so having it happen automatically when a package is installed is kind of a dangerous thing.  This is why the ebuild I've created and am maintaining for Gentoo includes a nice ewarn explaining how to enable it just until the next reboot or how to do so permanently (via `/etc/sysctl.d/`).  I still believe there would be some value in including a warning in docker itself, possibly with a link to some wiki page or similar explaining the implications of the setting, especially since docker can be used successfully without it, you just don't get internet access.","+1; I think docker should at least show a big obnoxious warning when IP forwarding is not enabled.","\u003e [..] Perhaps we should look to add a similar warning to docker itself when it notices that IP Fowarding is disabled?  [..] I still believe there would be some value in including a warning in docker itself...  \r\n\u003e @tianon\r\n\r\n--- \r\n\r\n\u003e I just spent ~2 hours figuring out why my install didn't work. Mentioning this somewhere in the docs would be very useful.  \r\n\u003e @c00w \r\n\r\n--- \r\n\r\nI also spent hours trying to figure out why the containers didn't have network access. Docker already checks for local `127.*` IPs in `resolv.conf`. It would be nice to print a warning if the host doesn't have IP forwarding set up as per @tianon comments.","The pull request to add the warning was merged 11 days ago.  I think we can close this issue now, thanks.","I still see that warning,\r\n\r\n```\r\nroot@dokku:~# docker run base echo hello\r\nWARNING: IPv4 forwarding is disabled.\r\nhello\r\n```\r\n\r\non,\r\n\r\n```\r\nDocker version 0.6.1, build 5105263\r\n```\r\n\r\nis it supposed to be fixed on new versions?","IP forwarding detection is currently broken. See #1659. You can make the warning go away by restarting Docker.","@dsissitka thanks for clarification.. could you plz tell me, how docker can be restarted? just with `service stop/start` ?","@alexanderbeletsky:\r\n```bash\r\nservice docker restart\r\n```","[Dockerized]!(https://github.com/dotcloud/docker/wiki/Public-docker-images#apache-couchdb)",":+1: ","What is the rationale behind a centralized index?","We're aiming for the same hosting model as Golang packages: decentralized hosting and references built-in, with a central trusted namespace for convenience.","But this isn't that. The \"trusted namespace\" consists of the standard library. Everything else is absolutely referenced.","I guess I don't see the justification for the complexity. The DotCloud registry can have a nice web UI, etc. without this additional layer of the \"index\".","The idea is to have N registries (some private, some public) instead of 1. It\r\n\r\n* Divides network traffic to multiple servers\r\n* Allows for private repositories","@shin- Yes, I understand that. There is no need for an index to meet those goals though. It's needless centralization.","A centralized index with N decentralized registries is *strictly less*\r\ncentralized than one big central registry, which was the alternative.\r\n\r\n\r\nOn Wed, May 1, 2013 at 10:34 AM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e @shin- \u003chttps://github.com/shin-\u003e Yes, I understand that. There is no\r\n\u003e need for an index to meet those goals though. It's needless centralization.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/492#issuecomment-17293930\u003e\r\n\u003e .\r\n\u003e","@shykes It doesn't matter how many decentralized registries there are. If there is a centralized component, the whole system is centralized.\r\n\r\nWhy is the alternative \"one big central registry\"? It seems like another option is just decentralized registries, no index.","With just decentralized registries, how do I get \"docker run ubuntu\" to work?","Docker defaults to the DotCloud registry, with an option to override via a command-line flag or absolute URL. \"ubuntu\" just means the ubuntu image from the current registry.","What if I want to add to the central namespace an image that is hosted by someone else? (a-la pypi)","Use a 301 redirect.","How do I guarantee the integrity of the layers I'm redirecting to? Ie. how do I guarantee clients are downloading the same thing that was originally uploaded?","Include a header with a hash in the redirect response.","How would we handle the case where a layer depends on other layers which are spread out across multiple registries?","How about this: layers are referenced by their absolute URL, something like REGISTRY_URL + IMAGE_NAME + LAYER_HASH. This solves both integrity and distributed linking.","I see, so a registry could optionally reference layers hosted elsewhere by passing these \"secure references\" to the client? The client would have to make sure it verifies the hash after following the reference, so that would have to be included into the pull protocol right?","Yep, exactly. The client should always verify hashes, no matter where the layer came from.","Also, these URLs would be the canonical reference for a layer, used whether the layer is coming from the same registry or a different one.","So, what we described is exactly what the index does :)","So why don't the registries do this instead of the index? It would remove the centralization, the complexity of the distributed authentication system, and a whole moving part.","They do. It's the same protocol. The index is just a lightweight registry\r\nwhich *only* references 3d-party registries (which keeps it lightweight),\r\nand we use it as a base for centralized search, account management etc.\r\n\r\n\r\nOn Wed, May 1, 2013 at 11:17 AM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e So why don't the registries do this instead of the index? It would remove\r\n\u003e the centralization, the complexity of the distributed authentication\r\n\u003e system, and a whole moving part.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/492#issuecomment-17296966\u003e\r\n\u003e .\r\n\u003e","It isn't *just* a lightweight registry though. The centralized account management/authentication system is my major issue with the system as proposed. As currently implemented and specified there's no easy way for me to do any type of authenticated actions with my own registry without involving DotCloud's centralized index. What is the rationale behind the complicated centralized authentication system? Why can't each registry handle that (if push or user-based access control is desired)?","By the way, this doesn't preclude DotCloud from implementing centralized auth with participating registries, I just don't see the point in specifying it in docker.","Auth on the registry will be pluggable. Having your registry call out to\r\nthe central index auth is just a reasonable default for convenience. The\r\nwhole point of open-sourcing the registry is that you can remove all\r\ndependencies on the central index if you don't want the convenience.\r\n\r\n\r\nOn Wed, May 1, 2013 at 11:35 AM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e It isn't *just* a lightweight registry though. The centralized account\r\n\u003e management/authentication system is my major issue with the system as\r\n\u003e proposed. As currently implemented and specified there's no easy way for me\r\n\u003e to do any type of authenticated actions with my own registry without\r\n\u003e involving DotCloud's centralized index. What is the rationale behind the\r\n\u003e complicated distributed authentication system? Why can't each registry\r\n\u003e handle that (if push or user-based access control is desired)?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/492#issuecomment-17297992\u003e\r\n\u003e .\r\n\u003e","The reason it's specified in docker is to facilitate the case where you\r\npush something to your registry *and* want to publish it on the central\r\nindex.\r\n\r\n\r\nOn Wed, May 1, 2013 at 11:41 AM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e By the way, this doesn't preclude DotCloud from implementing centralized\r\n\u003e auth with participating registries, I just don't see the point in\r\n\u003e specifying it in docker.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/492#issuecomment-17298308\u003e\r\n\u003e .\r\n\u003e","Sure, but that's just pushing the actual data to one registry and references to another, no need for any centralized auth to do that.","Again, it's just a reasonable default for an otherwise pluggable system. Out of the box you can use your registry as a multi-user system without having to manually create accounts. But you can if you want to.","This document states:\r\n\r\n\u003e We expect that there will be only one instance of the index, run and managed by dotCloud.\r\n\r\nAnd #489 has a constant for the dotCloud index, and expects to use it for all authentication.\r\n\r\nMaybe it's intended to be pluggable, but it isn't yet.\r\n\r\nI really don't see the point in centralizing the authentication in the separate \"index\" role. Why isn't auth done with the registry directly, with dotCloud's registry as the default in docker?","Yep, this is exactly what I was talking about. It looks like the buildbot port isn't forwarded?","@titanous: Not sure. I updated the documentation to make it more explicit. Did you tried http://192.168.33.21:8010/waterfall ?\r\n","Ah, got it. I'm used to Vagrant configs that for example forward localhost:8080 to the port in the VM. LGTM. :+1:","Thanks Jonathan","It would be better to fix this such that vmware works correctly, rather then removing the config.\r\n\r\nCan we re-open the ticket?","He Brian. It will be really nice to incorporate vmware into the official main Vagrantfile (PRs can always be made to contrib). The main difference between the two, is that official changes have to be fully supported. If you are interested, we can move this forward on #480","Awesome! Can generate graphviz file","Wow that is cool.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 1, 2013 at 10:33 PM, linquize \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Awesome! Can generate graphviz file\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/497#issuecomment-17321223","I think this should be an option to 'docker images' rather than a full-fledged top-level command. So I could call it with:\r\n\r\n```bash\r\n$ docker images -viz | dot -Tpng -o docker.png\r\n```\r\n\r\n@justone what do you think?","@shykes that makes sense. I'll rework the change to be part of the `images` subcommand.","@shykes How does it look now?","Awesome!","Why not use Go 1.1rc1?","@titanous I picked 1.0.3 when I suggested that the latest stable version should be used to build the official relases of docker. I believe Go 1.1 beta was out or it wasn't even out at the time.\r\n\r\nHowever, I can update the pull request to switch it to Go 1.1 RC1.","Correct, I would rather stick to stable releases of Golang. The minute 1.1 is stable, I will be happy to switch :)","I suggested it because it is stable (and has been for months):\r\n\r\n\u003e This release candidate should be stable and production-ready, but please exercise caution when deploying it to critical systems.\r\n\r\nhttps://groups.google.com/forum/#!topic/golang-nuts/9hEw6max1hU","Is this still an issue? How do they step on each other?","merging the changes. will also confirm with read the docs that these work as planned.","I still don't think SplitN is needed since Split is basically SplitN(s, sep, -1)\r\n-- Edit --\r\nActually, this would weed out lines that are somehow incorrectly formatted as well (using Split) since SplitN will guarantee 6 or less lines.","Thanks!",":+1: ","cc @dhrp\r\n\r\n\r\nOn Fri, May 31, 2013 at 8:09 AM, Victor Vieux \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e [image: :+1:]\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/502#issuecomment-18750748\u003e\r\n\u003e .\r\n\u003e","I'm on it.","It sounds like you have multiple processes running on a single host? Is this the case? My gut says that this would lead to races in standalone mode.","I know Velociraptor was designed before Docker, but if it were designed\r\nafter/with Docker it seems like there wouldn't be as much of a problem,\r\nright? Supervisor to manage Docker and other \"root\" services, and Docker to\r\nmanage \"user\" services/processes.\r\n\r\n\r\nOn Thu, May 2, 2013 at 4:14 PM, Jonathan Rudenberg \u003cnotifications@github.com\r\n\u003e wrote:\r\n\r\n\u003e It sounds like you have multiple processes running on a single host? Is\r\n\u003e this the case? My gut says that this would lead to races in standalone mode.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/503#issuecomment-17370626\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","\u003e It sounds like you have multiple processes running on a single host? Is this the case?\r\n\r\nDefinitely the case that I have multiple apps on a single host, and you're right that we'll need to avoid race conditions.  For my use case at least, I'm happy to resolve those things by having Docker do less (avoid writing logs, copying images, etc.)\r\n\r\nAnother way to phrase what I'm after is a super minimal way to launch a \"standard container\" under LXC.  If that part of Docker is well defined enough, I'm happy to write another Go utility that imports the bits I need, and have Supervisor call my-utility \u003capp\u003e instead of lxc-start \u003capp\u003e.\r\n\r\n\u003e if it were designed after/with Docker it seems like there wouldn't be as much of a problem, right?\r\n\r\nTheoretically yeah.  Supervisor has some nice hooks for plugging in your own event listeners and RPC interfaces that would be more work to reproduce in Docker.","I was attempting to run a docker image using supervisor with the command below (obviously) without success:\r\n\r\n```\r\ndocker run -i -t -e PORT=15000 -p 15000:15000 -b /srv/registry:/srv/registry baremetal/docker-registry /opt/docker-registry/run\r\n```\r\n\r\nIs there a recommended way to monitor a run so that it can be restarted if the process terminates?  Issue #26 suggests restarting child processes with the `-r` flag, but for example, this doesn't restart a container that I `kill -9`.\r\n","I believe the underlying motivation for this issue is better integration with process supervisors (specifically supervisord in the case of @btubbs).\n\nOne of the planned improvements for the next release (0.7) is precisely better integration with provess supervisors. Here are details from the last release announcement: http://blog.docker.io/2013/08/websockets-dockerfile-upgrade-better-registry-support-expert-mode-and-more/#better_integration_with_process_supervisors\n\nSince that improvement is covered by multiple issues, I'm going to close this. I recommend watching the 0.7 milestone for relevant issues.","There would be some serious bonus packagers points to be given here if this could also somehow work without root access.  For example, this would then allow me to use the standard DinD workflow to build docker inside itself for the Gentoo ebuild, and even optionally run the tests (for users who do that with the packages on their system) - currently we can't do this because running the tests requires root to launch a docker daemon.\r\n\r\nI know, pipe dream, but now it's recorded in case someone clever comes up with a way to implement it. :)","Are you thinking about #1034 (Running docker entirely as non-root (CONFIG_USER_NS)) or something else?","@jpetazzo well dang, I think you've nailed it.  A combination of #1034 and this standalone mode would probably/possibly do it (assuming we didn't have to shell out to `sudo` for anything that \"just building docker inside docker\" requires).  That would have some very interesting possibilities for packaging, IMHO. :+1:","As of 0.6.5 the docker client can now remotely \"proxy\" most of the application's behavior when attached, including signal handling and standard streams. So supervisord can now realistically pretend that 'docker run' or 'docker start'  are the actual application. In the case of velociraptor (which relies on supervisord APIs), it's now possible to use supervisord to orchestrate docker containers. The same goes for other process supervisors.\r\n","I'm not able to run supervisord with \"docker run\" as a command: https://gist.github.com/rgarcia/dfdf41844668d4cc13bc\r\n\r\nThe container continues running after sending KILL or TERM to the `docker run...` process.\r\n\r\nI'm running Docker version 1.1.2, build d84a070","@rgarcia please open a separate issue if you have sig-proxy issues, and please add the output of  `docker version` and `docker -D info`.","@tiborvass opened #7307","The issue is that stdout gets closed right after stdin closes. as you are using a shell pipe, stdin closed before the container starts and therefore the output is already closed when it does.\r\nLooking into it to find a solution","Awesome.  I'll also take a look at the code to see if there's a sensible alternative I might've missed.","I ran into this today as well.  Any solution?",":+1:  Might need a reader thread to bucket-brigade input when requested.\r\n\r\nIt would be nice to be able to handle things like `foo | docker`, `docker ... \u003c file` and `docker \u003c \u003c( bar )` without needing switches. [Looking at a C tty demo I busted out](https://gist.github.com/5530818), it would seem plausible in Go.\r\n\r\nMeta later on: I'm wondering if it's simpler to have switches for `force pseudo tty allocation` and `force non-interactive` to disambiguate command line similar to SSH.","```\r\n{18:03}~ ➭ echo \"ls /\" | bash\r\nWindows  boot  docker-ext4.img\thome  lib64  mnt  proc\trun   srv  tmp\tvar\r\nbin\t dev   etc\t\tlib   media  opt  root\tsbin  sys  usr\r\n{18:03}~ ➭ echo \"ls /\" | docker run -i -a stdin -a stdout base bash\r\n{18:03}~ ➭ \r\n```\r\n\r\nI'm reaching this issue right now, does something has been done to allow this ?","This happens because docker detects that the input has closed before\ngetting the chance to send the output.\nAs a (not very clean) workaround, you could do something like this: { echo\n\"ls /\" ; sleep 1 ; } | docker run -i -t base bash","See #1005 ","You might be affected by a kernel bug. See issue #24. May I ask which\r\nversion of the kernel you're running?\r\n\r\n\r\nOn Thu, May 2, 2013 at 7:37 PM, Ian Carroll \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Docker keeps killing my apt-get process on creation before it can finish.\r\n\u003e :\\\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506\u003e\r\n\u003e .\r\n\u003e","This is a 15 MB file it's downloading. OpenSSH, I might add. \r\n\r\nLogs: \r\n\r\nhttps://gist.github.com/snapapps/c8b67cac26ec960b0811","I've seen that particular bug triggered with that kind of transfer, on\r\ncertain versions of the kernel.\r\n\r\n\r\nOn Thu, May 2, 2013 at 7:40 PM, Ian Carroll \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e This is a 15 MB file it's downloading. OpenSSH, I might add.\r\n\u003e\r\n\u003e Logs:\r\n\u003e\r\n\u003e vagrant@vagrant-ubuntu-quantal-64:~$ docker logs 6eb59bf12ea6\r\n\u003e Reading package lists...\r\n\u003e Building dependency tree...\r\n\u003e The following extra packages will be installed:\r\n\u003e ca-certificates krb5-locales libedit2 libgssapi-krb5-2 libidn11\r\n\u003e libk5crypto3\r\n\u003e libkeyutils1 libkrb5-3 libkrb5support0 libwrap0 libx11-6 libx11-data\r\n\u003e libxau6\r\n\u003e libxcb1 libxdmcp6 libxext6 libxmuu1 ncurses-term openssh-client openssl\r\n\u003e ssh-import-id tcpd wget xauth\r\n\u003e Suggested packages:\r\n\u003e krb5-doc krb5-user ssh-askpass libpam-ssh keychain monkeysphere\r\n\u003e openssh-blacklist openssh-blacklist-extra rssh molly-guard ufw\r\n\u003e The following NEW packages will be installed:\r\n\u003e ca-certificates krb5-locales libedit2 libgssapi-krb5-2 libidn11\r\n\u003e libk5crypto3\r\n\u003e libkeyutils1 libkrb5-3 libkrb5support0 libwrap0 libx11-6 libx11-data\r\n\u003e libxau6\r\n\u003e libxcb1 libxdmcp6 libxext6 libxmuu1 ncurses-term openssh-client\r\n\u003e openssh-server openssl ssh-import-id tcpd wget xauth\r\n\u003e 0 upgraded, 25 newly installed, 0 to remove and 0 not upgraded.\r\n\u003e Need to get 4651 kB of archives.\r\n\u003e After this operation, 15.2 MB of additional disk space will be used.\r\n\u003e Get:1 http://archive.ubuntu.com/ubuntu/ quantal/main libedit2 amd64\r\n\u003e 2.11-20080614-5 [69.5 kB]\r\n\u003e Get:2 http://archive.ubuntu.com/ubuntu/ quantal/main libkrb5support0\r\n\u003e amd64 1.10.1+dfsg-2 [23.9 kB]\r\n\u003e Get:3 http://archive.ubuntu.com/ubuntu/ quantal/main libk5crypto3 amd64\r\n\u003e 1.10.1+dfsg-2 [83.1 kB]\r\n\u003e Get:4 http://archive.ubuntu.com/ubuntu/ quantal/main libkeyutils1 amd64\r\n\u003e 1.5.5-3 [7360 B]\r\n\u003e Get:5 http://archive.ubuntu.com/ubuntu/ quantal/main libkrb5-3 amd64\r\n\u003e 1.10.1+dfsg-2 [358 kB]\r\n\u003e Get:6 http://archive.ubuntu.com/ubuntu/ quantal/main libgssapi-krb5-2\r\n\u003e amd64 1.10.1+dfsg-2 [118 kB]\r\n\u003e Get:7 http://archive.ubuntu.com/ubuntu/ quantal/main libidn11 amd64\r\n\u003e 1.25-2 [119 kB]\r\n\u003e Get:8 http://archive.ubuntu.com/ubuntu/ quantal/main libxau6 amd64\r\n\u003e 1:1.0.7-1 [8592 B]\r\n\u003e Get:9 http://archive.ubuntu.com/ubuntu/ quantal/main libxdmcp6 amd64\r\n\u003e 1:1.1.1-1 [12.8 kB]\r\n\u003e Get:10 http://archive.ubuntu.com/ubuntu/ quantal/main libxcb1 amd64\r\n\u003e 1.8.1-1ubuntu1 [44.8 kB]\r\n\u003e Get:11 http://archive.ubuntu.com/ubuntu/ quantal/main libx11-data all\r\n\u003e 2:1.5.0-1 [181 kB]\r\n\u003e Get:12 http://archive.ubuntu.com/ubuntu/ quantal/main libx11-6 amd64\r\n\u003e 2:1.5.0-1 [771 kB]\r\n\u003e Get:13 http://archive.ubuntu.com/ubuntu/ quantal/main libxext6 amd64\r\n\u003e 2:1.3.1-2 [33.7 kB]\r\n\u003e Get:14 http://archive.ubuntu.com/ubuntu/ quantal/main libxmuu1 amd64\r\n\u003e 2:1.1.1-1 [11.0 kB]\r\n\u003e Get:15 http://archive.ubuntu.com/ubuntu/ quantal/main libwrap0 amd64\r\n\u003e 7.6.q-23 [50.1 kB]\r\n\u003e Get:16 http://archive.ubuntu.com/ubuntu/ quantal/main openssl amd64\r\n\u003e 1.0.1c-3ubuntu2 [525 kB]\r\n\u003e Get:17 http://archive.ubuntu.com/ubuntu/ quantal/main ca-certificates all\r\n\u003e 20120623 [177 kB]\r\n\u003e Get:18 http://archive.ubuntu.com/ubuntu/ quantal/main krb5-locales all\r\n\u003e 1.10.1+dfsg-2 [9308 B]\r\n\u003e Get:19 http://archive.ubuntu.com/ubuntu/ quantal/main openssh-client\r\n\u003e amd64 1:6.0p1-3ubuntu1 [944 kB]\r\n\u003e Get:20 http://archive.ubuntu.com/ubuntu/ quantal/main wget amd64\r\n\u003e 1.13.4-3ubuntu1 [280 kB]\r\n\u003e Get:21 http://archive.ubuntu.com/ubuntu/ quantal/main xauth amd64\r\n\u003e 1:1.0.7-1 [26.3 kB]\r\n\u003e Get:22 http://archive.ubuntu.com/ubuntu/ quantal/main ncurses-term all\r\n\u003e 5.9-10ubuntu1 [424 kB]\r\n\u003e Get:23 http://archive.ubuntu.com/ubuntu/ quantal/main openssh-server\r\n\u003e amd64 1:6.0p1-3ubuntu1 [340 kB]\r\n\u003e Get:24 http://archive.ubuntu.com/ubuntu/ quantal/main tcpd amd64 7.6.q-23\r\n\u003e [27.7 kB]\r\n\u003e Get:25 http://archive.ubuntu.com/ubuntu/ quantal/main ssh-import-id all\r\n\u003e 2.12-0ubuntu1 [6424 B]\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-17376118\u003e\r\n\u003e .\r\n\u003e","Linux version 3.5.0-27-generic","Is that one affected?","Nope - it's something else, no idea what. Do you have any error message, unusual output, etc?","Not really. I'm new to Docker. I'm going to fire up a new Vagrant box and see how it goes.","I just spawned an EC2 instance and it's failing as well, on the Get: 25","Everything I ran on the shell: https://gist.github.com/snapapps/4f1e619e5a42f7b69e74","I don't know if it's related to your interrupted command problem, but you\r\nneed to wait for your \"apt-get install openssh-server\" to complete before\r\nyou commit it, otherwise you will create an incomplete image.\r\n\r\n$ ID=$(docker run -d base apt-get -y install openssh-server)\r\n$ docker wait $ID\r\n$ docker commit $ID iancarrol/ssh\r\n\r\n\r\n\r\nOn Thu, May 2, 2013 at 9:04 PM, Ian Carroll \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Everything I ran on the shell:\r\n\u003e https://gist.github.com/snapapps/4f1e619e5a42f7b69e74\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-17377735\u003e\r\n\u003e .\r\n\u003e","Oh... I always thought that the command was run on container creation. Oops! I'll report back :0\r\n\r\nSent from my iBrick.\r\n\r\nOn May 3, 2013, at 12:25 AM, Solomon Hykes \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I don't know if it's related to your interrupted command problem, but you \r\n\u003e need to wait for your \"apt-get install openssh-server\" to complete before \r\n\u003e you commit it, otherwise you will create an incomplete image. \r\n\u003e \r\n\u003e $ ID=$(docker run -d base apt-get -y install openssh-server) \r\n\u003e $ docker wait $ID \r\n\u003e $ docker commit $ID iancarrol/ssh \r\n\u003e \r\n\u003e \r\n\u003e \r\n\u003e On Thu, May 2, 2013 at 9:04 PM, Ian Carroll \u003cnotifications@github.com\u003ewrote: \r\n\u003e \r\n\u003e \u003e Everything I ran on the shell: \r\n\u003e \u003e https://gist.github.com/snapapps/4f1e619e5a42f7b69e74 \r\n\u003e \u003e \r\n\u003e \u003e — \r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-17377735\u003e \r\n\u003e \u003e . \r\n\u003e \u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","Nope. It's failing. https://gist.github.com/snapapps/ba6aa9c00e49e89e95ef","Wait a sec — if I read correctly, you were running kernel 3.5, and I\r\n*think* it's\r\naffected as well.\r\nWould you mind trying again with kernel 3.8?\r\nOn EC2, if you need to locate the right AMI, I suggest checking\r\nhttp://cloud-images.ubuntu.com/locator/ec2/ and looking for a 13.04 image.\r\nTo upgrade an existing Ubuntu machine (on EC2 or elsewhere), you can check\r\nhttps://groups.google.com/forum/#!searchin/docker-club/xswat/docker-club/J0OXLI9zhYY/b6s6Yyzld6wJ\r\n.\r\nI hope this helps!\r\n\r\n\r\nOn Fri, May 3, 2013 at 11:37 AM, Ian Carroll \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Nope. It's failing. https://gist.github.com/snapapps/ba6aa9c00e49e89e95ef\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-17410878\u003e\r\n\u003e .\r\n\u003e","Ok. I'll do-release-upgrade it to 13.04\r\n\r\nSent from my iBrick.\r\n\r\nOn May 3, 2013, at 2:44 PM, Jérôme Petazzoni \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Wait a sec — if I read correctly, you were running kernel 3.5, and I \r\n\u003e *think* it's \r\n\u003e affected as well. \r\n\u003e Would you mind trying again with kernel 3.8? \r\n\u003e On EC2, if you need to locate the right AMI, I suggest checking \r\n\u003e http://cloud-images.ubuntu.com/locator/ec2/ and looking for a 13.04 image. \r\n\u003e To upgrade an existing Ubuntu machine (on EC2 or elsewhere), you can check \r\n\u003e https://groups.google.com/forum/#!searchin/docker-club/xswat/docker-club/J0OXLI9zhYY/b6s6Yyzld6wJ \r\n\u003e . \r\n\u003e I hope this helps! \r\n\u003e \r\n\u003e \r\n\u003e On Fri, May 3, 2013 at 11:37 AM, Ian Carroll \u003cnotifications@github.com\u003ewrote: \r\n\u003e \r\n\u003e \u003e Nope. It's failing. https://gist.github.com/snapapps/ba6aa9c00e49e89e95ef \r\n\u003e \u003e \r\n\u003e \u003e — \r\n\u003e \u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-17410878\u003e \r\n\u003e \u003e . \r\n\u003e \u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","and, that is horribly inefficient. Firing up a Vagrant box ","Yeah, it's failing on Raring as well. :\\","`debconf: (Can't locate Term/ReadLine.pm in @INC (@INC contains: /etc/perl /usr/local/lib/perl/5.14.2 /usr/local/share/perl/5.14.2 /usr/lib/perl5 /usr/share/perl5 /usr/lib/perl/5.14 /usr/share/perl/5.14 /usr/local/lib/site_perl .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7, \u003c\u003e line 9.)\r\ndebconf: falling back to frontend: Teletype\r\ndpkg-preconfigure: unable to re-open stdin: `","This is a duplicate of #407 .","I'm sorry if I don't see it as a duplicate... It isn't kernel panicking..,\r\n\r\nSent from my iBrick.\r\n\r\nOn May 16, 2013, at 2:37 PM, Jérôme Petazzoni \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e This is a duplicate of #407 .\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","Also, Jerome, if you could leave the closing of other people's issues to the project maintainers. Thanks.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, May 16, 2013 at 11:29 PM, Ian Carroll \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e I'm sorry if I don't see it as a duplicate... It isn't kernel panicking..,\r\n\u003e Sent from my iBrick.\r\n\u003e On May 16, 2013, at 2:37 PM, Jérôme Petazzoni \u003cnotifications@github.com\u003e wrote:\r\n\u003e\u003e This is a duplicate of #407 .\r\n\u003e\u003e \r\n\u003e\u003e —\r\n\u003e\u003e Reply to this email directly or view it on GitHub.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/506#issuecomment-18030359","OK, reopening then.\r\n\r\nFYI, it seems to be the same bug. The first occurrences of the bug are generally harmless, but seem to put the machine in a bad state, and further occurrences cause the machine to lock up with the kernel oopsing at regular intervals.\r\n\r\nThe other one (#407) is *not* a kernel panic. The machine is frozen, but what you see on the console is not a panic, it's a oops. The fact that it continues to happen after the freeze demonstrates it. After the panic, the kernel stops running, and doesn't output anything. After a oops, the kernel (tries to) keep running.\r\n","I wonder if there's a way to run a script that would notify in the event of a kernel panic... Yet again, it's a kernel panic.","Hmm, I don't see a kernel panic. Which one is a kernel panic?\r\nThanks.","I meant, it would be hard to have the script print if it was in a kernel panic because, well, it's locked up.","Ok, I just understood what you meant :-)\r\nWell, since the first events are kernels \"oopses\" (=non fatal), it is theoretically possible to detect them before the machine goes to a solid crash. But it is very hackish, and sometimes it will be a matter of seconds between the first symptom and the hard crash, meaning that notifying the user won't help much :-/","@snapapps Can you try again with docker v0.5.0?","ping @snapapps ","Ah, sorry! I will test this out tomorrow morning.\r\n\r\n\r\nOn Fri, Aug 2, 2013 at 8:11 PM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e ping @snapapps \u003chttps://github.com/snapapps\u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-22044615\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nIf you can see this, this email was sent from Ian Carroll's personal\r\naccount.\r\nThis email is not signed. The email must be signed by Comodo to the name of\r\nIan Carroll.\r\nYou are responsible for any damages if you transact under this unsigned\r\nemail and I cannot sign it for you.","ping @snapapps Can you try testing this issue again?","(thumbsup) worked! :D\r\n\r\n\r\nOn Mon, Aug 12, 2013 at 7:31 PM, Michael Crosby \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e ping @snapapps \u003chttps://github.com/snapapps\u003e Can you try testing this\r\n\u003e issue again?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/506#issuecomment-22533669\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nIf you can see this, this email was sent from Ian Carroll's personal\r\naccount.\r\nThis email is not signed. The email must be signed by Comodo to the name of\r\nIan Carroll.\r\nYou are responsible for any damages if you transact under this unsigned\r\nemail and I cannot sign it for you.","+1 Would love to have this for easy interaction with Upstart.","+1 for this, would also like to see support (ala #415) to control the SIGTERM ... SIGKILL interval.","I took a crack at implementing this, but failed quickly after getting lost in how `rcli` works.  From what I could tell, we need the CLI to intercept the signal and then somehow forward a `docker kill` to the daemon.\r\n\r\nI was planning on letting the remote API (#21) evolve a bit, then try again using that.\r\n","Another +1 for this. I'd love to be able to configure containers to run on boot with upstart similar to the way I'm sure @adamjt is looking to use it. At the moment this doesn't seem very doable. ","+1 I am also looking to manage containers with upstart and/or supervisor.  Thanks!","@unclejack's work in https://github.com/unclejack/dockrun builds this kind of signal handling over docker.","This functionality is going to be merged into docker, along with other needed features.\r\nI'll be sending a PR for this feature soon.","Thanks for catching that!","Would you mind opening an issue before submitting a PR to discuss this changes?  Some of the changes here will break existing functionality.","I'm thinking I probably have a misunderstanding of what the purpose of this Makefile is.  Is it the catch-all for all the different ways of building docker that it appears to be?  Just want to make sure I've got the right purposes in mind so that I can just drop and forget about changes that are out of scope. :)\r\n\r\nf211f59 is a simple one that is definitely a bug (and one that I ran into for other reasons, such as the symlink logic changing, which caused my \"go get\" to start downloading a new copy of the repo instead of using the one I've got cloned, hence my issues).\r\n\r\nI realize that 9af770e is probably the way it is on purpose (the GOPATH handling), but that's why I'd like to clarify the purpose of this Makefile a little more, since if it is for the general public to build a docker binary, then that's what my commit fixes, but if it's just for the docker developers or even an automated build process somewhere, then it's perfect as is and I'll drop that commit for sure.\r\n\r\nI asked on IRC what the best way to get comments on my tweaks were, and was told that a pull request is fine, so after getting more clarification on the purpose of the Makefile, I'll be very happy to open issue tickets for anything I see as problems that remain (and then individual pull requests to fix them). :)","Closing this pull request, as it's obviously not going to be merged en-masse. :)","For a little context, here's what I get currently (which will need some tweaks, and I'm happy to make them, but I want to make sure I'm on the right track first):\r\n```\r\n$ git clone http://github.com/dotcloud/docker\r\nCloning into 'docker'...\r\nremote: Counting objects: 5519, done.\r\nremote: Compressing objects: 100% (3070/3070), done.\r\nremote: Total 5519 (delta 2719), reused 4970 (delta 2225)\r\nReceiving objects: 100% (5519/5519), 5.21 MiB | 420 KiB/s, done.\r\nResolving deltas: 100% (2719/2719), done.\r\n$ cd docker\r\n$ make VERBOSE=1\r\n/bin/sh: line 0: cd: /home/tianon/go/src/github.com/dotcloud/docker/docker: No such file or directory\r\ngithub.com/dotcloud/docker (download)\r\ngithub.com/kr/pty (download)\r\ngo install: no install location for directory /home/tianon/downloads/docker outside GOPATH\r\nmake: *** [/home/tianon/go/src/github.com/dotcloud/docker] Error 1\r\n```\r\nWhere GOPATH=/home/tianon/go before running.","With a7c0e9a, the gist of these is in now - the only real change left is the GOROOT, and that one is understandable. :+1:","Hey Brian, we have packaged lxc-docker 0.2.1 and it is currently on the PPA. Want to test it?","Failed to fetch http://ppa.launchpad.net/dotcloud/lxc-docker/ubuntu/dists/raring/main/binary-amd64/Packages  404  Not Found\r\n","http://ppa.launchpad.net/dotcloud/lxc-docker/ubuntu/dists/ still only shows precise","Brian. Did you try it?","Yes, my above comments come from trying it.","Here is how I do it on a Raring VM\r\necho 'deb http://ppa.launchpad.net/dotcloud/lxc-docker/ubuntu precise main' \u003e/etc/apt/sources.list.d/lxc-docker.list\r\napt-get update\r\napt-get install lxc-docker\r\n\r\nCould you try it?","You are adding the *precise* repo. The issue is to publish one for *raring*.\r\n\r\nYes, the binary will work fine on either, but the apt repo requires manual\r\nmunging (i.e., cannot use normal apt repo management tools).\r\n\r\n\r\nOn Fri, May 3, 2013 at 6:39 PM, Daniel Mizyrycki\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Here is how I do it on a Raring VM\r\n\u003e echo 'deb http://ppa.launchpad.net/dotcloud/lxc-docker/ubuntu precise\r\n\u003e main' \u003e/etc/apt/sources.list.d/lxc-docker.list\r\n\u003e apt-get update\r\n\u003e apt-get install lxc-docker\r\n\u003e\r\n\u003e Could you try it?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/510#issuecomment-17425078\u003e\r\n\u003e .\r\n\u003e","Couple of things:\r\nThe goal of this ticket was to address the go issue you properly found in our PPA. My understanding is that we achieved it and will be good if you can verify it and if appropriate, close this ticket.\r\n\r\nYour later comments reflect a different issue. I suggest that if this is important to you, we create another issue, and ideally with ideas how to achieve it. There is already packaging/ubuntu in place for official support with the work done for precise PPA\r\n","You are right, I am conflating two tickets.","Created #530 for Quantal and Raring","This is a known bug with Kernels \u003c 3.8.\r\nAs you are use the daemon as a service, you can't see the log, but there is an actual big warning about this.\r\nIt would be nice to have a log file for this kind of things.\r\nI am closing this issue, please follow up on #407 ","Hmm let me see if I can upgrading to that kernel. This isn't a \"low memory VM,\" this is being run on Core 2 Duo with 4 gb ram, so might not be the same bug.","It is actually more linked to the amount of core you have than memory. But upgrading to 3.8.x should fix the bug :)","Yeah, 3.8 looks to have resolved it. Thanks, that'll do for now for my purposes :)","It should work out of the box, provided that you uncomment the relevant line in lxc-template.go :-)\r\n","Would you happen to know from the top of your head what capability needs to be enable and if it is safe to do so?","It's a mount, so you need CAP_SYS_ADMIN.\nIt's safe-ish to do it.\nIMHO there should be a flag of some kind to switch between restricted mode\n(paranoid, no caps) and trusted mode (enabling some useful caps, allowing\nFUSE, docker-in-docker, and other things).","Hi, Gentlemen.\r\n\r\nI'm trying to use gluster from a docker image and getting:\r\n\r\n[2013-06-12 08:59:06.191225] E [mount.c:598:gf_fuse_mount] 0-glusterfs-fuse: cannot open /dev/fuse (No such file or directory)\r\n\r\nIf I understand it correctly, looks like I need to uncomment something on the source code and maybe recompile it? Sorry for the beginner question, but I'm a sysadmin and not a developer. ;)","Hi Eri, yes, by default docker locks down privileges of containers to a minimum - in particular the host's device files are not accessible.\r\n\r\n\r\nThis can be changed by tweaking lxc_template.go and recompiling. We plan on allowing this kind of tweaking dynamically (feel free to make a PR if you're inspired!)\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, Jun 12, 2013 at 6:21 AM, Eri Bastos \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Hi, Gentlemen.\r\n\u003e I'm trying to use gluster from a docker image and getting:\r\n\u003e [2013-06-12 08:59:06.191225] E [mount.c:598:gf_fuse_mount] 0-glusterfs-fuse: cannot open /dev/fuse (No such file or directory)\r\n\u003e If I understand it correctly, looks like I need to uncomment something on the source code and maybe recompile it? Sorry for the beginner question, but I'm a sysadmin and not a developer. ;)\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/514#issuecomment-19324759","Specifically,. you need to uncomment `lxc.cgroup.devices.allow = c 10:229 rwm`[1] to allow access to the FUSE device; and then you need to remove `mknod` and `sys_admin` from the `lxc.cap.drop` line. Then everything should be fine.\r\n\r\n[1] https://github.com/dotcloud/docker/blob/master/lxc_template.go#L63\r\n[2] https://github.com/dotcloud/docker/blob/master/lxc_template.go#L89","I think what I am trying to do in #460 will help in this use case because you can dynamically change the LXC template.... except....  what does LXC do if a directive is listed twice?  Use only the last one?    \r\n\r\nIf it is not predictable (or it errors), then the patch in #460 would need to be modified to detect the presence of a JSON-configured `lxc.cap.drop` (or any other directive) and insert that instead.\r\n","This will be possible by manually relaxing the lxc restrictions, either individually, or wholesale with a \"privileged mode\" as discussed above. In the meantime, the current default behavior is correct for security reasons.","I am confused as to whether it is possible to relax restrictions now to use FUSE. I would suggest keeping this ticket open until that is the case.","As a workaround, in case your packages require fuse to be installed but do not actually use it, it suffices to install fuse without creating its device links. A short snippet to put into your Dockerfile can be found here: https://gist.github.com/henrik-muehe/6155333\r\n\r\nI successfully installed basex (which has jdk and therefore fuse as a dependency) this way and it 'works for me'.","Hi,\r\n\r\nTo the Docker team - what's the long-term solution to this problem?\r\n\r\nI'm currently hitting this issue when attempting to install openjdk-7-jdk, which pulls in fuse.\r\n\r\nUsing @henrik-muehe workaround works, however, it'd be nice if there was a more permanent fix, or official solution?\r\n\r\nCheers,\r\nVictor","\"docker build\" will support the required operations (namely, mknod).\r\nIf you want to contribute some code, the easiest path to get there is #2191 :-)","+1","@jpetazzo , \"docker build\" suffers form the same problem\r\nDocker version 0.6.7, build cb48ecc\r\n\r\nbtw, @henrik-muehe workaround works like a charm, thanks Henrik !","If you're not actually using the device file (but it's just part of a post-inst script as in the case with the fuse package), you can do:\r\n\r\n    fakeroot apt-get ... \r\n\r\nor:\r\n\r\n    dpkg-divert --local --rename --add /sbin/mknod \u0026\u0026 ln -s /bin/true /sbin/mknod`","Docker 0.7 quick solution \r\n \r\n```bash\r\ndocker run -i -t -privileged=true your/image /bin/bash\r\n```\r\n\r\n","dpkg-divert is a dangerous thing, seeing it more and more in vagrant files make me very concerned.\r\n\r\nYou ll have better to fix the offender package to patch it at build time not to access the blocked resource.\r\nThen you tell dpkg not to update it anymore.\r\n```\r\nTake an exemple for our vagrantfiles eg:\r\n    FROZEN_PACKAGES=\"fuse\"\r\n    for i in $FROZEN_PACKAGES;do\\\r\n      echo $i hold | dpkg --set-selections;\\\r\n    done\u0026\u0026\\\r\n    grep \"deb \" /etc/apt/sources.list|sed -re \"s/^deb /deb-src /g\" \u003e\u003e /etc/apt/sources.list \u0026\u0026\\\r\n    apt-get -q update \u0026\u0026 apt-get upgrade -y --force-yes \u0026\u0026\\\r\n    apt-get install -y --force-yes libfuse2 apt-utils \u0026\u0026\\\r\n    if [ ! -e \"/root/debbuild\" ];then mkdir -pv /root/debbuild;fi \u0026\u0026\\\r\n    mv /root/ntp_postinst /root/debbuild \u0026\u0026\\\r\n    cd /root/debbuild;\\\r\n    nf=/etc/network/interfaces;\r\n    for i in fuse;do \\\r\n      mkdir -p $i \u0026\u0026 cd $i \u0026\u0026\\\r\n      apt-get download -y $i \u0026\u0026\\\r\n      dpkg-deb -X $i*deb build \u0026\u0026\\\r\n      dpkg-deb -e $i*deb build/DEBIAN \u0026\u0026 \\\r\n      rm *deb \u0026\u0026 cd ..;done \u0026\u0026\\\r\n    cp /root/debbuild/ntp_postinst /root/debbuild/ntp/build/DEBIAN/postinst \u0026\u0026\\\r\n    echo \"#!/bin/bash\"   \u003e/root/debbuild/resolvconf/build/DEBIAN/postinst \u0026\u0026\\\r\n    echo \"exit 0\"       \u003e\u003e/root/debbuild/resolvconf/build/DEBIAN/postinst \u0026\u0026\\\r\n    echo \"\"             \u003e\u003e/root/debbuild/resolvconf/build/DEBIAN/postinst \u0026\u0026\\\r\n    echo \"#!/bin/bash\"   \u003e/root/debbuild/fuse/build/DEBIAN/postinst \u0026\u0026\\\r\n    echo \"#exit 0\"      \u003e\u003e/root/debbuild/fuse/build/DEBIAN/postinst \u0026\u0026\\\r\n    echo \"\"             \u003e\u003e/root/debbuild/fuse/build/DEBIAN/postinst \u0026\u0026\\\r\n    for i in fuse;do\\\r\n      cd /root/debbuild/$i/build\u0026\u0026\\\r\n      dpkg-deb -b . /root/debbuild/$i.deb;\\\r\n    done\u0026\u0026\\\r\n    for i in fuse;do\\\r\n      dpkg -i /root/debbuild/$i.deb\u0026\u0026\\\r\n      echo $i hold | dpkg --set-selections;\\\r\n    done\r\n```\r\n\r\nReal exemple here : ps://github.com/makinacorpus/vms/blob/master/docker/makinacorpus/ubuntu_template/","Thanks for the contribution @drnic !","+1\r\n\r\nMaintainers might like the package signing cert available https:// over somewhere (github repo perhaps? sans the pk of course) in addition to hkp/http keyserver.ubuntu.com.","Barry. As you mention in #554, add-apt-repository is a better way and had been included on 73321f2 :)","Awesome.","This will be a next step after the merge of #432 ","Looks like we can close this:\r\n\r\n```\r\n$ docker commit foo bar/baz\r\n2013/07/30 23:41:23 Error: No such container: foo\r\n$ echo $?\r\n1\r\n$\r\n```","@dsissitka thanks","Fixed by #520","This is still a problem in Docker 1.9 - when specifying a sub version of an image such as Centos 6.6, adding the period produces this error:\r\n\r\n    [root@localhost ~]# docker create -t --name Centoast -h Centoast -p 80 centos:6.6\r\n    Error response from daemon: No command specified\r\n    [root@localhost ~]# docker create -t --name Centoast -h Centoast -p 80 centos:6.6 /bin/bash\r\n    9ff53fd0c4829e534e4c6cdc6e4a763b946b1135077c6f25a59f53f0f83d2147\r\n    [root@localhost ~]#\r\n    [root@localhost ~]# docker --version\r\n    Docker version 1.9.0, build 76d6bc9\r\n\r\n","This will be possible as soon as we merge the remote API :) The current\r\nlimitation is that all processing is done on the server side, and the only\r\ncommunication channel available with the client is a dumb TCP which is\r\npiped to stdout. This also explains why stdout and stderr are not\r\ndifferentiated on the client.\r\n\r\n\r\nOn Sat, May 4, 2013 at 6:55 PM, Brian McCallister\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Curent behavior:\r\n\u003e\r\n\u003e $ docker pull padkjhkjhkj\r\n\u003e Pulling repository padkjhkjhkj\r\n\u003e Error: HTTP code: 404\r\n\u003e $ echo $?\r\n\u003e 0\r\n\u003e $\r\n\u003e\r\n\u003e If the image wasn't found, it should have a non-zero exit code\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/521\u003e\r\n\u003e .\r\n\u003e","Looks like we can close this:\r\n\r\n```\r\n$ docker pull foobarbaz\r\nPulling repository foobarbaz\r\n2013/07/30 23:43:01 Internal server error: 404 trying to fetch remote history for foobarbaz\r\n$ echo $?\r\n1\r\n$\r\n```","Thanks!","Why does it say \"Internal server error\" for a 404 'not found' ?","@anentropic it's not like this anymore","Tabs are the work of the devil and crusty old Makefiles.","I agree and this will be fixed :)\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sat, May 4, 2013 at 9:24 PM, Barry Allard \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Tabs are the work of the devil and crusty old Makefiles.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/522#issuecomment-17445716","This is related to a feature of AUFS, \"pseudo links\" (plinks).\r\nPseudo links happen when you do a hard link between AUFS branches.\r\nTypically, when you create a hard link pointing to a file located in an\r\nunderlying read-only branch.\r\nWhen you do that, AUFS cannot create a real hard link (since both branches\r\nmight be on different file systems; and with different mount permissions).\r\nIf the plink feature is enabled (default), AUFS will track in memory \"this\r\nfile is actually a hard link to that other file\". The copy-up (creating the\r\nfile \"for real\" on the read-write branch) will be done later, either\r\nexplicitly (when calling auplink), or implicitly (if you open the file for\r\nwriting, or when you unmount the filesystem). However, when using \"normal\"\r\numount instead of umount.aufs, the plink maintenance script is not called,\r\nand plinks are not flushed to disk, hence the warning.\r\n\r\nThe consequence is that some file (which was created by hard-linking) is\r\nprobably missing on your AUFS read-write layer.\r\n\r\nPossible workarounds:\r\n- don't use hardlinks between branches :-)\r\n- use umount.aufs instead of regular umount\r\n- invoke auplink manually before unmounting\r\n- disable plinks (AUFS will then do the copy-up immediately)\r\n\r\n\r\nOn Sun, May 5, 2013 at 4:15 AM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e After a few 'run docker-build and clear all containers' cycles, the kernel\r\n\u003e ran into a problem with aufs:\r\n\u003e\r\n\u003e [15815.575129] ------------[ cut here ]------------[15815.575140] WARNING: at fs/aufs/plink.c:446 au_plink_put+0x92/0xa0 [aufs]()[15815.575141] Hardware name: VMware Virtual Platform[15815.575142] pseudo-link is not flushed[15815.575143] Modules linked in: aufs xt_addrtype xt_nat veth xt_CLASSIFY sch_prio xt_DSCP xt_length xt_tcpudp iptable_mangle vmxnet(O) vmhgfs(O) openvswitch ipt_MASQUERADE iptable_nat nf_conntrack_ipv4 nf_defrag_ipv4 nf_nat_ipv4 nf_nat nf_conntrack ip_tables x_tables bridge stp llc deflate zlib_deflate ctr twofish_generic twofish_x86_64_3way twofish_x86_64 twofish_common camellia_generic camellia_x86_64 serpent_sse2_x86_64 serpent_generic ablk_helper cryptd xts lrw gf128mul glue_helper blowfish_generic blowfish_x86_64 blowfish_common cast5_generic cast_common des_generic xcbc rmd160 sha512_generic crypto_null af_key xfrm_algo bnep rfcomm bluetooth binfmt_misc snd_ens1371 snd_ac97_codec ac97_bus gameport snd_pcm snd_page_alloc snd_seq_midi snd_seq_midi_event snd_rawmidi snd_seq snd_seq_device snd_timer snd joydev soundcore mac_hid vmw_balloon lp coretemp ppdev psmouse i2c_piix4 shpchp serio_raw parport_pc microcode vmci(O) parport hid_generic usbhid hid floppy vmwgfx ttm mpt\r\n\u003e  sas vmxnet3 mptscsih mptbase scsi_transport_sas drm\r\n\u003e [15815.575248] Pid: 11874, comm: docker Tainted: G        W  O 3.8.11 #1\r\n\u003e [15815.575249] Call Trace:\r\n\u003e [15815.575255]  [\u003cffffffff81056e13\u003e] warn_slowpath_common+0x93/0xc0\r\n\u003e [15815.575257]  [\u003cffffffff81056efc\u003e] warn_slowpath_fmt+0x4c/0x50\r\n\u003e [15815.575261]  [\u003cffffffff8168df52\u003e] ? down_write+0x12/0x40\r\n\u003e [15815.575268]  [\u003cffffffffa04404b2\u003e] au_plink_put+0x92/0xa0 [aufs]\r\n\u003e [15815.575272]  [\u003cffffffffa0423cca\u003e] aufs_kill_sb+0xaa/0x150 [aufs]\r\n\u003e [15815.575276]  [\u003cffffffff811488d2\u003e] ? pcpu_free_area+0x192/0x1a0\r\n\u003e [15815.575280]  [\u003cffffffff811a9629\u003e] ? free_vfsmnt+0x39/0x40\r\n\u003e [15815.575282]  [\u003cffffffff8118e4a1\u003e] deactivate_locked_super+0x41/0x80\r\n\u003e [15815.575284]  [\u003cffffffff8118f0a5\u003e] deactivate_super+0x45/0x50\r\n\u003e [15815.575286]  [\u003cffffffff811a9eef\u003e] mntput_no_expire+0x13f/0x150\r\n\u003e [15815.575289]  [\u003cffffffff811ab07e\u003e] sys_umount+0x36e/0x3c0\r\n\u003e [15815.575291]  [\u003cffffffff81698399\u003e] system_call_fastpath+0x16/0x1b\r\n\u003e [15815.575293] ---[ end trace 227d09b8d937545b ]---\r\n\u003e [15897.701854] ------------[ cut here ]------------\r\n\u003e [15897.701865] WARNING: at fs/aufs/plink.c:446 au_plink_put+0x92/0xa0 [aufs]()\r\n\u003e [15897.701867] Hardware name: VMware Virtual Platform\r\n\u003e [15897.701868] pseudo-link is not flushed\r\n\u003e [15897.701869] Modules linked in: aufs xt_addrtype xt_nat veth xt_CLASSIFY sch_prio xt_DSCP xt_length xt_tcpudp iptable_mangle vmxnet(O) vmhgfs(O) openvswitch ipt_MASQUERADE iptable_nat nf_conntrack_ipv4 nf_defrag_ipv4 nf_nat_ipv4 nf_nat nf_conntrack ip_tables x_tables bridge stp llc deflate zlib_deflate ctr twofish_generic twofish_x86_64_3way twofish_x86_64 twofish_common camellia_generic camellia_x86_64 serpent_sse2_x86_64 serpent_generic ablk_helper cryptd xts lrw gf128mul glue_helper blowfish_generic blowfish_x86_64 blowfish_common cast5_generic cast_common des_generic xcbc rmd160 sha512_generic crypto_null af_key xfrm_algo bnep rfcomm bluetooth binfmt_misc snd_ens1371 snd_ac97_codec ac97_bus gameport snd_pcm snd_page_alloc snd_seq_midi snd_seq_midi_event snd_rawmidi snd_seq snd_seq_device snd_timer snd joydev soundcore mac_hid vmw_balloon lp coretemp ppdev psmouse i2c_piix4 shpchp serio_raw parport_pc microcode vmci(O) parport hid_generic usbhid hid floppy vmwgfx ttm mpt\r\n\u003e  sas vmxnet3 mptscsih mptbase scsi_transport_sas drm\r\n\u003e [15897.701922] Pid: 8213, comm: docker Tainted: G        W  O 3.8.11 #1\r\n\u003e [15897.701923] Call Trace:\r\n\u003e [15897.701928]  [\u003cffffffff81056e13\u003e] warn_slowpath_common+0x93/0xc0\r\n\u003e [15897.701930]  [\u003cffffffff81056efc\u003e] warn_slowpath_fmt+0x4c/0x50\r\n\u003e [15897.701934]  [\u003cffffffff8168df52\u003e] ? down_write+0x12/0x40\r\n\u003e [15897.701940]  [\u003cffffffffa04404b2\u003e] au_plink_put+0x92/0xa0 [aufs]\r\n\u003e [15897.701944]  [\u003cffffffffa0423cca\u003e] aufs_kill_sb+0xaa/0x150 [aufs]\r\n\u003e [15897.701947]  [\u003cffffffff811488d2\u003e] ? pcpu_free_area+0x192/0x1a0\r\n\u003e [15897.701950]  [\u003cffffffff811a9629\u003e] ? free_vfsmnt+0x39/0x40\r\n\u003e [15897.701954]  [\u003cffffffff8118e4a1\u003e] deactivate_locked_super+0x41/0x80\r\n\u003e [15897.701977]  [\u003cffffffff8118f0a5\u003e] deactivate_super+0x45/0x50\r\n\u003e [15897.701981]  [\u003cffffffff811a9eef\u003e] mntput_no_expire+0x13f/0x150\r\n\u003e [15897.701983]  [\u003cffffffff811ab07e\u003e] sys_umount+0x36e/0x3c0\r\n\u003e [15897.701986]  [\u003cffffffff81698399\u003e] system_call_fastpath+0x16/0x1b\r\n\u003e [15897.701988] ---[ end trace 227d09b8d937545c ]---\r\n\u003e [16069.831236] ------------[ cut here ]------------\r\n\u003e [16069.831247] WARNING: at fs/aufs/plink.c:446 au_plink_put+0x92/0xa0 [aufs]()\r\n\u003e [16069.831248] Hardware name: VMware Virtual Platform\r\n\u003e [16069.831249] pseudo-link is not flushed\r\n\u003e [16069.831250] Modules linked in: aufs xt_addrtype xt_nat veth xt_CLASSIFY sch_prio xt_DSCP xt_length xt_tcpudp iptable_mangle vmxnet(O) vmhgfs(O) openvswitch ipt_MASQUERADE iptable_nat nf_conntrack_ipv4 nf_defrag_ipv4 nf_nat_ipv4 nf_nat nf_conntrack ip_tables x_tables bridge stp llc deflate zlib_deflate ctr twofish_generic twofish_x86_64_3way twofish_x86_64 twofish_common camellia_generic camellia_x86_64 serpent_sse2_x86_64 serpent_generic ablk_helper cryptd xts lrw gf128mul glue_helper blowfish_generic blowfish_x86_64 blowfish_common cast5_generic cast_common des_generic xcbc rmd160 sha512_generic crypto_null af_key xfrm_algo bnep rfcomm bluetooth binfmt_misc snd_ens1371 snd_ac97_codec ac97_bus gameport snd_pcm snd_page_alloc snd_seq_midi snd_seq_midi_event snd_rawmidi snd_seq snd_seq_device snd_timer snd joydev soundcore mac_hid vmw_balloon lp coretemp ppdev psmouse i2c_piix4 shpchp serio_raw parport_pc microcode vmci(O) parport hid_generic usbhid hid floppy vmwgfx ttm mpt\r\n\u003e  sas vmxnet3 mptscsih mptbase scsi_transport_sas drm\r\n\u003e [16069.831327] Pid: 8216, comm: docker Tainted: G        W  O 3.8.11 #1\r\n\u003e [16069.831328] Call Trace:\r\n\u003e [16069.831334]  [\u003cffffffff81056e13\u003e] warn_slowpath_common+0x93/0xc0\r\n\u003e [16069.831336]  [\u003cffffffff81056efc\u003e] warn_slowpath_fmt+0x4c/0x50\r\n\u003e [16069.831340]  [\u003cffffffff8168df52\u003e] ? down_write+0x12/0x40\r\n\u003e [16069.831346]  [\u003cffffffffa04404b2\u003e] au_plink_put+0x92/0xa0 [aufs]\r\n\u003e [16069.831350]  [\u003cffffffffa0423cca\u003e] aufs_kill_sb+0xaa/0x150 [aufs]\r\n\u003e [16069.831353]  [\u003cffffffff811488d2\u003e] ? pcpu_free_area+0x192/0x1a0\r\n\u003e [16069.831356]  [\u003cffffffff811a9629\u003e] ? free_vfsmnt+0x39/0x40\r\n\u003e [16069.831359]  [\u003cffffffff8118e4a1\u003e] deactivate_locked_super+0x41/0x80\r\n\u003e [16069.831361]  [\u003cffffffff8118f0a5\u003e] deactivate_super+0x45/0x50\r\n\u003e [16069.831363]  [\u003cffffffff811a9eef\u003e] mntput_no_expire+0x13f/0x150\r\n\u003e [16069.831365]  [\u003cffffffff811ab07e\u003e] sys_umount+0x36e/0x3c0\r\n\u003e [16069.831368]  [\u003cffffffff81698399\u003e] system_call_fastpath+0x16/0x1b\r\n\u003e [16069.831370] ---[ end trace 227d09b8d937545d ]---\r\n\u003e\r\n\u003e The aufs version I've used was the one from the stable repository.\r\n\u003e\r\n\u003e \r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/524\u003e\r\n\u003e .\r\n\u003e","What solution would be the most desirable? Would umount.aufs be acceptable?\r\n","Either that, or run auplink before the umount.\r\n\r\n\r\nOn Sun, May 12, 2013 at 1:29 PM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e What solution would be the most desirable? Would umount.aufs be acceptable?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/524#issuecomment-17784749\u003e\r\n\u003e .\r\n\u003e","Does the umount2 syscall use file system specific ```umount.\u003cfs\u003e```? Go is using this syscall for the Unmount syscall.\r\n \r\n```umount``` looks for ```/sbin/umount.\u003cfilesystem\u003e``` and uses it by default if it's present.\r\n\r\nThis can be found in ```man umount```:\r\n```\r\n      -i     Don't call the /sbin/umount.\u003cfilesystem\u003e helper even  if  it  exists.  By  default\r\n              /sbin/umount.\u003cfilesystem\u003e helper is called if one exists.\r\n```\r\n\r\nWe don't get aufs-tools installed by default on Ubuntu. I've installed aufs-tools and then created some links of all types.\r\nThe kernel logs had to say this about the whole affair:\r\n```\r\n[14814.846761] aufs au_plink_put:442:docker[9544]: pseudo-link is not flushed\r\n[14848.753492] aufs au_plink_put:442:docker[9544]: pseudo-link is not flushed\r\n```\r\nAfter adding the code to flush via auplink, everything was OK and pseudo-link related messages stopped appearing.\r\n\r\nOnly 4 lines of code have to be added to mount.go, but we should decide how we want to handle the absence of auplink from the aufs-tools package. We could add code to detect the presence of auplink just like we're detecting the architecture.\r\n\r\nDo we want to error out and say we've failed to unmount if auplink is missing or do we want to print a warning and move on with the Unmount syscall?\r\n\r\n@creack What do you think?\r\n","This is going to be taken care of by #816.","fwiw i've seen this error message when given command script had a broken shebang, like `#/bin/bash` instead of `#!/bin/bash`","@svenfuchs you create a file with a broken shebang in a container, you commit it and you have a panic when you try to run it ?","Just wanted to confirm that this is exactly the issue I was having and fixing the shebang to be on the first line with no spaces around it solved it.\r\n\r\nSeparate: On the possibility that others have the same issue I did, which is a generated `.sh` file which had a preceeding blank line, this line of code will remove blank lines. \r\n\r\n`sed -i '/^\\s*$/d' outdir/main.sh`   -- this requires gnu-sed. If you're on mac, `brew install gnu-sed` and the command will be `gsed` instead.\r\n","@vieux sorry, i've missed your question before.\r\n\r\nso, yes, that's what i've seen (\"panic: exec format error\" on running a script with a broken shebang as a command). i've just mentioned it here for others who might find this through google, like i did.","Is this with apt-get install or via get.docker.io?","aptitude","Hmm. Sure, this can be improved, Kyle. Want to do it?","Done","Can you please try to upgrade docker?\r\nI think that this \"use of closed network connection\" means that you're\r\nusing a version of docker which was built against an older version of Go,\r\nwhich has problems with HTTP/1.1 connections.\r\n\r\n\r\n\r\nOn Mon, May 6, 2013 at 5:14 AM, Mikkel Kamstrup Erlandsen \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e Sample output of the docker daemon when running 'docker pull base' against\r\n\u003e it:\r\n\u003e\r\n\u003e $ sudo ~/go/bin/docker -d\r\n\u003e 2013/05/06 13:50:22 WARNING: Your kernel does not support cgroup swap\r\n\u003e limit.\r\n\u003e 2013/05/06 13:50:22 Listening for RCLI/tcp on 127.0.0.1:4242\r\n\u003e\r\n\u003e 2013/05/06 13:50:29 docker pull base\r\n\u003e 2013/05/06 13:50:48 Error: Failed to download json: use of closed network\r\n\u003e connection\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/528\u003e\r\n\u003e .\r\n\u003e","This is from git master as of right now, compiled with Go 1.0.2. I'll try with more newer Go.","Ok, it seems to work with Go tip. I don't know if there is a way to make 'go install foobar' err out on certain go versions. That would help out on a lot of confusion...","@shin- can you update the docs so that it lists the new search command as well?","Closing, will create another pull request for master.","/cc @mzdaniel ","https://launchpad.net/~dotcloud/+archive/lxc-docker  is already providing Precise, Quantal and Raring  :)","Closing this PR because it is not clean Will create another PR in a moment.","Also, I used these modifications to update my tianon/debian and tianon/debian-roll images, and updated the public images wiki page. :)","@mzdaniel can you take care of it? Thanks.","Would it be helpful if I rebased or merged against current master?","@tianon: Thanks alright in this case Tianon, Thanks for suggesting it anyway. \r\n@shykes: Done. ","did anyone else experience the slow down of the commit command since release 0.4.8 (or perhaps 0.4.7, not sure) ?","Yeah system almost crashed, when using docker commit","@omkar0001 Can you post the output of `docker info`, `docker version` and `uname -a`, please?","It happened(System crash) for me couple of times, but not every time. But there is a slowdown. Its taking longer time to commit.\r\n\r\nDocker info: Containers: 84\r\nImages: 249\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Dirs: 418\r\nExecution Driver: native-0.2\r\nKernel Version: 3.11.0-15-generic\r\nWARNING: No swap limit support\r\n\r\nDocker version: Client version: 0.11.1\r\nClient API version: 1.11\r\nGo version (client): go1.2.1\r\nGit commit (client): fb99f99\r\nServer version: 0.11.1\r\nServer API version: 1.11\r\nGit commit (server): fb99f99\r\nGo version (server): go1.2.1\r\nLast stable version: 1.0.1, please update docker\r\n\r\nuname -a\r\nLinux ubuntu 3.11.0-15-generic #25~precise1-Ubuntu SMP Thu Jan 30 17:39:31 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux","@omkar0001 You seem to be running Docker 0.11.1. That version isn't supported any more. Please upgrade to Docker 1.0.1.\r\n\r\nYou should also upgrade your kernel to the latest version of the 3.11 kernel provided by the Ubuntu repositories.","@unclejack Thanks for the info. Will try it out.","What about running \"env VAR=value cmd...\" instead of \"cmd...\"?\r\nOn May 6, 2013 7:43 PM, \"unclejack\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Right now, we don't have any way of doing the following things:\r\n\u003e\r\n\u003e    - set an environment variable to be available outside of the Dockerfile\r\n\u003e    - persist an environment variable the same way we can persist the\r\n\u003e    default command to run with cmd\r\n\u003e    - be able to use something like \"-e\" in docker run with the same\r\n\u003e    persistence a la cmd\r\n\u003e\r\n\u003e It should be possible to use the environment variable in:\r\n\u003e\r\n\u003e    - docker run (as if passed via -e)\r\n\u003e    - docker run -i -t bash (as if passed via -e)\r\n\u003e    - docker builder - during execution and in the resulting images /\r\n\u003e    containers (depending on how it gets implemented)\r\n\u003e\r\n\u003e We should probably differentiate between the ephemeral env and the\r\n\u003e persistent one. Perhaps the new one should be called setenv or something\r\n\u003e like that.\r\n\u003e Basically, env would be used for variables within Dockerfiles (run A, B\r\n\u003e and C with $myvar) and setenv would be used for real variables to be used\r\n\u003e within the docker containers.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/538\u003e\r\n\u003e .\r\n\u003e","@jpetazzo What would that do? Would it make cmd always run with VAR=value (like a hardcoded variable passed to something, e.g. 'CC=gcc make'), replace VAR with value within the stored cmd (Dockerfile level variable) or set VAR to that value, make it available to the cmd and allow that to be overridden (via docker run -e VAR=mynewvalue and through a new docker build)?\r\n\r\nEither way, being able to set environment variables would be useful. One such scenario would be:\r\n```\r\ndocker build \u003c Dockerfile1   \u003c- this would prepare everything and set default values for variables; we might not need a 'cmd'\r\ndocker tag image_id some_relevant_tag\r\ndocker  build \u003c Dockerfile2 \u003c- this could change / reuse environment variables set earlier\r\n```","Sorry, I think I initially answered out of my phone, so my example was a bit terse :-)\r\n\r\nI was suggesting the following:\r\n\r\n    docker run johndoe/myapp /usr/bin/env VAR1=value1 VAR2=value2 VAR3=value3 /usr/bin/run-my-service\r\n\r\nThis is equivalent to adding `-e VAR1=value` etc., but since it uses the normal command-line specification, it doesn't need extra features in the Dockerfile.\r\n\r\nIn other words, if you want to set the environment, you can do it with `/usr/bin/env` instead of running your program directly.\r\n\r\nBut now that I read it more carefully, I see that your message asks for something better than that.\r\n\r\nDo you think you could come up with a full example (if it's not asking too much)?","```env``` only sets a variable in a Dockerfile right now. This lets us do:\r\n```\r\nenv  myvar myvalue\r\nrun  do_something_really_smart myvar  \u003c- this would replace myvar with myvalue\r\nrun  do_something_else myvar \u003c- same as above\r\n```\r\nBasically, env doesn't do much right now. Please correct me if I'm wrong.\r\n\r\nWe also need real variables which actually get changed in the resulting container (the one we'd generate out of an image we're building with docker build). Let's say we need to change PATH and we want it to always work - when running a bash shell and when running anything which doesn't source any dotfiles.\r\n```\r\nsetenv  PATH /usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\r\n## now we can run docker run image_id go version\r\n## we can also run docker run -i -t image_id bash and then go version\r\ncmd  go version \u003c- this works now because go is on the path because we've just changed it above\r\n```\r\n\r\nsetenv should also exist outside of docker build to avoid having to create a Dockerfile just to change a single variable.\r\n\r\n","OK, so \"setenv\" would be a convenient shorthand for multiple \"-e\" arguments\nin \"run\". I agree that this can be very useful, and it shouldn't have much\nside-effects.\nIt could also be very convenient when a new Dockerfile \"importing\" another\none (and inheriting its variables).\n\nNow, \"env\" would define variables locally in the Dockerfile. This could\nalso lead to more concise and readable files (at the expense of the\nunavoidable confusion by people between \"env\" and \"setenv\"... Maybe\n\"setrunvar\" and \"setbuildvar\", and allow abbrevs, so that \"setr\" and \"setb\"\nwould work? Just a thought...)\n\nDo you also want to be able to do things like the following?\nsetrunvar USRSIZE \u003c\u003c run du -sm /usr\n(Completely random example, and the \u003c\u003c syntax is just a random thing)\n\n(Note that I'm still trying to figure out a use-case which would instantly\nconvince people that \"hell yes we should absolutely get variables!!!\", so\nif you have one, I'd love if you could share it!)","I agree that it might not be a good idea to call them setenv and env. I'm not sure if setenv == setrunvar or setenv == setbuildvar, so I'll use the original names below.\r\n\r\n\"setenv\" would be useful for injecting variables to be used all the time in the container's environment without having to specify them on every run. Let's say we're coworkers and you ask me to try out this really cool docker image. You forget to tell me I need to set variable A, B, C and D with some specific values and I just run without them. I have to get back to you and ask why the thing you provided me with doesn't work. Then I have to track those environment variables and always make sure I pass all of them by hand. This is wrong. This should behave the same way the default run command behaves when using cmd to configure it.\r\n\r\nThe first time I thought about this was when I modified the dockerbuilder Dockerfile to use go installed from a tarball. I've changed the shell script which builds docker to update the PATH so ```go``` could be found. However, changing the script wouldn't have been needed if docker had some way to persist the environment variables in the image.\r\nSo having this feature would allow us to avoid having to change scripts in images if we really don't want to pass -e MYVAR=value every time.\r\n\r\nThis feature would take standardization one step further.\r\n\r\nThis \"setenv\" should also be exposed as a docker command.\r\n\r\nOn a side note, we might also want to be able to unset a variable set in a container / image, so we have: set, unset and set would also modify it.\r\n\r\n```setrunvar USRSIZE \u003c\u003c run du -sm /usr``` this syntax would be useful in Dockerfiles. For example, we could use something like this to set an environment variable to identify a git revision of a repo which was used to build an image in a CI system:\r\n```\r\nenv REVISION \u003c\u003c /myapp/getrevision.sh\r\nsetenv MYAPP_REVISION REVISION\r\n``` \r\n","Right. \"runvar\" and \"buildvar\" can actually be confusing, since \"build\r\nsteps\" involve the \"run\" command as well.\r\nOn a second thought, I don't know if \"buildvar\" (=a variable that would be\r\navailable only in the dockerfile context) would be useful anyway.\r\nSo, we already have a way to store environment variables in an image (just\r\nlike we can store which command should run by default)[1].\r\nAll we need would be some way to expose that in the dockerfile. Oh wait,\r\nisn't that what \"env\" in dockerfile does [2] ?\r\nI could be wrong, but it looks like those variables are then exposed in the\r\ncontainer [3].\r\nSo, unless I overlooked something, we have almost everything, don't we?\r\n\r\n[1] http://docs.docker.io/en/latest/commandline/command/commit/\r\n[2] https://github.com/dotcloud/docker/blob/master/builder.go#L327\r\n[3] https://github.com/dotcloud/docker/blob/master/builder.go#L277\r\n\r\n\r\nOn Wed, May 8, 2013 at 9:04 AM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I agree that it might not be a good idea to call them setenv and env. I'm\r\n\u003e not sure if setenv == setrunvar or setenv == setbuildvar, so I'll use the\r\n\u003e original names below.\r\n\u003e\r\n\u003e \"setenv\" would be useful for injecting variables to be used all the time\r\n\u003e in the container's environment without having to specify them on every run.\r\n\u003e Let's say we're coworkers and you ask me to try out this really cool docker\r\n\u003e image. You forget to tell me I need to set variable A, B, C and D with some\r\n\u003e specific values and I just run without them. I have to get back to you and\r\n\u003e ask why the thing you provided me with doesn't work. Then I have to track\r\n\u003e those environment variables and always make sure I pass all of them by\r\n\u003e hand. This is wrong. This should behave the same way the default run\r\n\u003e command behaves when using cmd to configure it.\r\n\u003e\r\n\u003e The first time I thought about this was when I modified the dockerbuilder\r\n\u003e Dockerfile to use go installed from a tarball. I've changed the shell\r\n\u003e script which builds docker to update the PATH so go could be found.\r\n\u003e However, changing the script wouldn't have been needed if docker had some\r\n\u003e way to persist the environment variables in the image.\r\n\u003e So having this feature would allow us to avoid having to change scripts in\r\n\u003e images if we really don't want to pass -e MYVAR=value every time.\r\n\u003e\r\n\u003e This feature would take standardization one step further.\r\n\u003e\r\n\u003e This \"setenv\" should also be exposed as a docker command.\r\n\u003e\r\n\u003e On a side note, we might also want to be able to unset a variable set in a\r\n\u003e container / image, so we have: set, unset and set would also modify it.\r\n\u003e\r\n\u003e setrunvar USRSIZE \u003c\u003c run du -sm /usr this syntax would be useful in\r\n\u003e Dockerfiles. For example, we could use something like this to set an\r\n\u003e environment variable to identify a git revision of a repo which was used to\r\n\u003e build an image in a CI system:\r\n\u003e\r\n\u003e env REVISION \u003c\u003c /myapp/getrevision.sh\r\n\u003e setenv MYAPP_REVISION REVISION\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/538#issuecomment-17615657\u003e\r\n\u003e .\r\n\u003e","I don't really know what to expect from env, run, cmd and docker build in general.\r\n\r\nI've tried to run the following Dockerfile through docker build:\r\n```\r\nmaintainer      uj\r\nfrom    ubuntu:12.04\r\nenv     foo bar\r\nrun     true\r\n```\r\nThis has given me an image which shows this with inspect:\r\n```\r\ndocker inspect 468303cc2b19                                                \r\n{                                                                                                  \r\n    \"id\": \"468303cc2b1966ca3484a77029b4528c2a2a66e0214ab0bce4398351cc4ec2a5\",                      \r\n    \"parent\": \"8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\",                  \r\n    \"created\": \"2013-05-14T17:16:09.015161265+01:00\",                                              \r\n    \"container\": \"06f2f6dbc05fb9ea4a5732f3e5c7c92429055cac9ec450660162d685064abdce\",               \r\n    \"container_config\": {                                                                          \r\n        \"Hostname\": \"06f2f6dbc05f\",\r\n        \"User\": \"\",\r\n        \"Memory\": 0,\r\n        \"MemorySwap\": 0,\r\n        \"CpuShares\": 0,\r\n        \"AttachStdin\": false,\r\n        \"AttachStdout\": true,\r\n        \"AttachStderr\": true,\r\n        \"PortSpecs\": null,\r\n        \"Tty\": false,\r\n        \"OpenStdin\": false,\r\n        \"StdinOnce\": false,\r\n        \"Env\": [\r\n            \"foo=bar\"\r\n        ],\r\n        \"Cmd\": [\r\n            \"/bin/sh\",\r\n            \"-c\",\r\n            \"true\"\r\n        ],\r\n        \"Dns\": null,\r\n        \"Image\": \"8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\",\r\n        \"Volumes\": {},\r\n        \"VolumesFrom\": \"\"\r\n    },\r\n    \"docker_version\": \"0.3.2\",\r\n    \"author\": \"uj\"\r\n```\r\nThis means we should now be able to use $foo in the containers, right?\r\n```\r\ndocker run -i  468303cc2b19 bash -c 'echo $foo'\r\n\r\n```\r\n```\r\ndocker run -i -t 468303cc2b19 bash\r\nroot@3b628d6aa9e4:/# echo $foo\r\n\r\nroot@3b628d6aa9e4:/# \r\n```\r\n\r\nThis is really confusing. What is env supposed to do?","Yes, that last command should print \"bar\". Looks like a bug.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Tue, May 14, 2013 at 4:25 PM, unclejack \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e I don't really know what to expect from env, run, cmd and docker build in general.\r\n\u003e I've tried to run the following Dockerfile through docker build:\r\n\u003e ```\r\n\u003e maintainer      uj\r\n\u003e from    ubuntu:12.04\r\n\u003e env     foo bar\r\n\u003e run     true\r\n\u003e ```\r\n\u003e This has given me an image which shows this with inspect:\r\n\u003e ```\r\n\u003e docker inspect 468303cc2b19                                                \r\n\u003e {                                                                                                  \r\n\u003e     \"id\": \"468303cc2b1966ca3484a77029b4528c2a2a66e0214ab0bce4398351cc4ec2a5\",                      \r\n\u003e     \"parent\": \"8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\",                  \r\n\u003e     \"created\": \"2013-05-14T17:16:09.015161265+03:00\",                                              \r\n\u003e     \"container\": \"06f2f6dbc05fb9ea4a5732f3e5c7c92429055cac9ec450660162d685064abdce\",               \r\n\u003e     \"container_config\": {                                                                          \r\n\u003e         \"Hostname\": \"06f2f6dbc05f\",\r\n\u003e         \"User\": \"\",\r\n\u003e         \"Memory\": 0,\r\n\u003e         \"MemorySwap\": 0,\r\n\u003e         \"CpuShares\": 0,\r\n\u003e         \"AttachStdin\": false,\r\n\u003e         \"AttachStdout\": true,\r\n\u003e         \"AttachStderr\": true,\r\n\u003e         \"PortSpecs\": null,\r\n\u003e         \"Tty\": false,\r\n\u003e         \"OpenStdin\": false,\r\n\u003e         \"StdinOnce\": false,\r\n\u003e         \"Env\": [\r\n\u003e             \"foo=bar\"\r\n\u003e         ],\r\n\u003e         \"Cmd\": [\r\n\u003e             \"/bin/sh\",\r\n\u003e             \"-c\",\r\n\u003e             \"true\"\r\n\u003e         ],\r\n\u003e         \"Dns\": null,\r\n\u003e         \"Image\": \"8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\",\r\n\u003e         \"Volumes\": {},\r\n\u003e         \"VolumesFrom\": \"\"\r\n\u003e     },\r\n\u003e     \"docker_version\": \"0.3.2\",\r\n\u003e     \"author\": \"uj\"\r\n\u003e ```\r\n\u003e This means we should now be able to use $foo in the containers, right?\r\n\u003e ```\r\n\u003e docker run -i  468303cc2b19 bash -c 'echo $foo'\r\n\u003e ```\r\n\u003e ```\r\n\u003e docker run -i -t 468303cc2b19 bash\r\n\u003e root@3b628d6aa9e4:/# echo $foo\r\n\u003e root@3b628d6aa9e4:/# \r\n\u003e ```\r\n\u003e This is really confusing. What is env supposed to do?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/538#issuecomment-17879179","@shykes Ok, got it, then we don't need buildvar / runvar any more. env will be enough.\r\n\r\nI'll close this issue when the bug with env gets fixed.","This issue was opened because env wasn't really setting environment variables in the container.\r\nEnv is now setting environment variables properly, thanks to the commits merged from builder_client branch.","I'm running 0.6.5 (edit: on Ubuntu 12.10 LTS, docker installed according to the docs). ENV variables don't seem to persist outside of the Dockerfile 'scope'. Is it possible that this has regressed since this discussion?","Same here, \r\n\r\nI was using the following\r\n\r\nENV MYPATH /usr/local/myPath\r\nCMD [ \"ls\", \"-la\", \"$MYPATH\"]\r\n\r\nand I get \r\nls: cannot access $MYPATH: No such file or directory\r\n\r\nBut, if I used the other format\r\nCMD ls -la $MYPATH\r\n\r\nthen the listing is correct.\r\n\r\nCMD [ \"ls\", \"-la\", $NMMHOME ] simply doesn't work\r\n\r\nNow I also was trying something like this.\r\n\r\nENTRYPOINT [ \"$MYPATH/start.sh\"]\r\n\r\ndoesn't work. Some problem : unable to locate $MYPATH/start.sh\r\n\r\nBut similarly to CMD 'shell version'\r\n\r\nENTRYPOINT $MYPATH/start.sh\r\n\r\nworks fine.\r\n\r\nAlso the start.sh is referencing the $MYPATH as well and it sees the correct value.\r\n\r\nSo I think there is still a bug in specifying the environment variables within the CMD / ENTRYPOINT commands when using the exec like way (preferred method)\r\n\r\n\r\n\r\n","@djsly I figure you have since come across the solution, but just in case someone else comes here and has the same issue: The JSON format (\"exec version\" as per docs) of both CMD and ENTRYPOINT doesn't get run through bash/a shell and so there is no env var substitution happening of course. If you need that you can always use the shell version, i.e. `CMD ls -la $NMMHOME` instead of `CMD [\"ls\", \"-la\", ...`",":+1: Sounds good.","+1","@shykes: Needs thought work to sort out the ambiguity between url, username, repo, and tag.  e.g. `fizx/postgres` vs `fizx.com/postgres` vs `fizx.com/fizx.postgres:tag`  I don't care what color this bike shed is, but I think you should make a call.","Docker now has support for private registries. I think this use case is handled and the issue can be closed.","Correct! Here are details on how to do it: http://blog.docker.io/2013/07/how-to-use-your-own-registry/\n\nThanks.","The kernel segfault is a known bug with kernels \u003c 3.8 (cf #407).\r\n\r\nRegarding the internet access, can you look at your /etc/resolv.conf? It is most likely setup on a localhost. This works within the host but can't work within a container.\r\n\r\n2 solutions:\r\n1) Edit the /etc/resolv.conf from the host in order to use external dns (eg 8.8.8.8, 8.8.4.4)\r\n2) run docker with -dns option (eg docker run -dns 8.8.8.8 -dns 8.8.4.4 base ping google.com)\r\n","Maybe we should detect when /etc/resolv.conf is configured to use 127.*,\r\nshouldn't we?\r\n\r\n\r\nOn Tue, May 7, 2013 at 10:00 AM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e The kernel segfault is a known bug with kernels \u003c 3.8 (cf #407\u003chttps://github.com/dotcloud/docker/issues/407\u003e\r\n\u003e ).\r\n\u003e\r\n\u003e Regarding the internet access, can you look at your /etc/resolv.conf? It\r\n\u003e is most likely setup on a localhost. This works within the host but can't\r\n\u003e work within a container.\r\n\u003e\r\n\u003e 2 solutions:\r\n\u003e 1) Edit the /etc/resolv.conf from the host in order to use external dns\r\n\u003e (eg 8.8.8.8, 8.8.4.4)\r\n\u003e 2) run docker with -dns option (eg docker run -dns 8.8.8.8 -dns 8.8.4.4\r\n\u003e base ping google.com)\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/541#issuecomment-17555383\u003e\r\n\u003e .\r\n\u003e","Perhaps we could use the proxy from docker to proxy these requests to localhost? e.g.: use 172.16.42.1 within docker containers as the DNS server and use 127.0.0.1 as the real DNS","Well, IMHO, if we detect that the DNS server is 127.*, we should generate a\nresolv.conf file containing the address of the bridge, and bind it into the\nhosts.\n\nWe had lots of discussions with @creack a long time ago about this, so I\nthought it was already implemented, in fact :o","@jpetazzo Unfortunately dnsmasq isn't set up by default to accept requests on the IP of the docker0 bridge, even though it seems to be bound to 0.0.0.0. I've just verified whether dnsmasq allows DNS resolution when using the docker0 bridge IP address as the DNS server. Setting it up isn't an option, imo.\r\n\r\nWe could set up docker to look for an alternative resolv.conf file (e.g. /etc/resolv.docker). If 127.* is in resolv.conf, no resolv.docker exists and no -dns option was passed to docker -d or docker run, we could use public DNS and print a warning on the screen (!!! WARNING - docker is using public DNS because /etc/resolv.conf lists 127.0.0.1 as a DNS server).\r\n","Agreed!\r\n\r\n\r\nOn Tue, May 7, 2013 at 12:44 PM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @jpetazzo \u003chttps://github.com/jpetazzo\u003e Unfortunately, dnsmasq isn't set\r\n\u003e up by default to accept requests on the IP of the docker0 bridge, even\r\n\u003e though it seems to be bound to 0.0.0.0. I've just verified whether dnsmasq\r\n\u003e allows DNS resolution when using the docker0 bridge IP address as the DNS\r\n\u003e server. Setting it up isn't an option, imo.\r\n\u003e\r\n\u003e We could set up docker to look for an alternative resolv.conf file (e.g.\r\n\u003e /etc/resolv.docker). If 127.* is in resolv.conf, no resolv.docker exists\r\n\u003e and no -dns option was passed to docker -d or docker run, we could use\r\n\u003e public DNS and print a warning on the screen (!!! WARNING - docker is using\r\n\u003e public DNS because /etc/resolv.conf lists 127.0.0.1 as a DNS server).\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/541#issuecomment-17565591\u003e\r\n\u003e .\r\n\u003e","\u003e We could set up docker to look for an alternative resolv.conf file (e.g. /etc/resolv.docker). If 127.* is in resolv.conf, no resolv.docker exists and no -dns option was passed to docker -d or docker run, we could use public DNS and print a warning on the screen (!!! WARNING - docker is using public DNS because /etc/resolv.conf lists 127.0.0.1 as a DNS server).\r\n\r\nTo whatever extent possible I think containers shouldn't know about Docker, so injecting Docker-specific knowledge inside the container is something to avoid.\r\n\r\nIf I misunderstood you and you were instead proposing having the /etc/resolv.conf be _outside_ the containers with a fallback to hardcoded public DNS (but where `docker -dns` always takes priority). I think that's a good idea.","@fj It was about the /etc/resolv.conf and /etc/resolv.docker which would live on the host. Docker will still manage everything on its own when setting up the resolv.conf in the container, it would just pick a DNS using the rules I've described.","This is fixed in master. The docker daemon will detect that the host's resolv.conf points to localhost, and fallback to a public default (8.8.8.8). This can then be overridden by the admin with 'docker -d -dns'.\r\n","It seems that it’s not just the case of localhost.\r\n\r\n```\r\nmlebkowski@bob /etc\u003e head -3 resolv.conf \r\n# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)\r\n#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\r\nnameserver 172.17.4.1\r\n\r\nmlebkowski@bob /etc\u003e ifconfig eth0 | head -2\r\neth0      Link encap:Ethernet  HWaddr d4:3d:7e:dc:b2:db  \r\n          inet addr:172.17.4.41  Bcast:172.17.7.255  Mask:255.255.252.0\r\n\r\nmlebkowski@bob /etc\u003e ifconfig docker0 | head -2\r\ndocker0   Link encap:Ethernet  HWaddr fe:30:73:b4:77:2d  \r\n          inet addr:172.17.42.1  Bcast:0.0.0.0  Mask:255.255.0.0\r\n```\r\n \r\nIt seems that docker uses the same network as the host. I can’t really tell if this is a docker issue or my network configuration. Should I reopen the ticket?","Well, those networks are indeed overlapping, but that looks like it might be a separate issue, since Docker's automatic network detection code should've avoided exactly that, as far as I remember (it's been a while since I looked at that part of the code).\r\n\r\nI believe the exact DNS fix described here was that if your DNS server is anything in a \"local\" block, it gets remapped to 8.8.8.8, so even in your case it should've been remapped, as far as my understanding goes.  Perhaps someone with more knowledge of that specific part of the code will chime in here. :)","Maybe a better option, other than remap the nameserver to a public one would be to have an way to configure the 'default' nameserver for containers. I can get DNS working fine when I run it with the `-dns` flag. The problem I'm facing is how to have stuff installed when using `docker build` as apt-get/yum cannot resolve the repos URLs. Having a public nameserver doesn't work for me, since I'm inside a corporate netrwork where DNS traffic seems to be -somehow- restricted.","I can reply to my own question: https://github.com/dotcloud/docker/issues/815\r\n\u003e (..) in order to use dns server side (i.e. like doing -dns on each run automatically), you can start docker daemon with -dns x.x.x.x.\r\n\u003eEx: docker -d -D -dns 8.8.8.8 -dns 8.8.4.4","Puzzled newbie here... I am running Docker inside of a Vagrant vm\r\n\r\nYesterday I was able to `docker build .` an image successfully, today trying a different image (both are `FROM ubuntu:12.04`) I am getting the _\"Temporary failure resolving 'archive.ubuntu.com'\"_ errors when the image tries to do `apt-get` stuff\r\n\r\nI tried adding `RUN echo \"nameserver 8.8.8.8\" \u003e\u003e /etc/resolv.conf` to the Dockerfile but it errors (_\"returned a non-zero code: 2\"_)\r\n\r\nMy `/etc/resolv.conf` in the vm looks like:\r\n```\r\n# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)\r\n#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\r\nnameserver 10.0.2.3\r\n```\r\n\r\nWhat am I supposed to do to make it work?","and... rebooting the vagrant vm fixed it ","\u003e This is fixed in master. The docker daemon will detect that the host's resolv.conf points to localhost, and fallback to a public default (8.8.8.8). This can then be overridden by the admin with 'docker -d -dns'.\r\n\u003e \r\n\r\nThe 'fix' above excludes all production environments which deliberately run a caching nameserver on 127.0.0.1.\r\n\r\nOur resolv.conf reads:\r\n\r\n\tnameserver 127.0.0.1\r\n\tnameserver \u003cnon-local-ip-of-fallback-resolver#1\u003e\r\n\tnameserver \u003cnon-local-ip-of-fallback-resolver#2\u003e\r\n\r\nIs there a way to support environments which run a per-host caching-only dns recursive resolver?","I'm experiencing the exact same issue as tamsky - \r\nI'm running 12.04.3 with kernel 3.8.0-35 and docker version 0.7.5 (existed in docker version 0.7.3 as well)\r\n\r\nMy company does a caching nameserver at 127.0.0.1 and my resolv.conf reads the same as tamsky's. \r\n\r\nI've appended 'nameserver 8.8.8.8' to my resolv.conf, but it appears docker never checks that far down?\r\n\r\nIn my honest opinion, this kills the portability factor of docker, as currently the daemon has to be restarted using a specified dns server. It looks like there have been several issue threads discussing this problem - what is the possibility/probability of a docker.conf where we can specify instance variables like dns?\r\n\r\nThanks!","@Badger32d just as a point of interest, if all you need to \"fix\" this in your environment is a configuration file to specify `-dns` for the daemon, then \"/etc/default/docker\" is just such a thing (provided you use Upstart or SysV, which if you're on 12.04 you do).\r\n\r\nJust put something like this inside:\r\n```bash\r\nDOCKER_OPTS=\"-dns 8.8.8.8 -dns 8.8.4.4\"\r\n```\r\n\r\nThen `service docker restart` or restarting your system completely will make sure Docker starts up with `-dns` as specified.\r\n\r\nSo it's not exactly a solution to all the issues, but it's certainly a reasonable way to specify the workaround in a simple and persistent way.","Tianon: I didn't realize that was a possibility, thanks! That should solve it.","@Badger32d 's solution will not work on our network.\r\nOur machines do not have direct access to the full internet, but they can reach a nearby recursive dns resolver.\r\n\r\nI'm not sure what our workaround will be but it might involve having named listen on the docker0 interface, and setting the DOCKER_OPTS=\"-dns 172.17.42.1\"","@tamsky yes, you need to have your resolver bind on the docker0 bridge.  Then pass the -dns flag to the docker daemon with the bridge ip.  This ill make all container's created use the bridge as the resolver.","It sure would be nice if these issues could be addressed:\r\n  1. In order for our localhost bind nameserver to actually bind()/listen() on the bridge interface, dockerd must have already started, and successfully created and configure(number) the bridge interface.  This ordering requirement is sub-optimal.\r\n  2. There is no deterministic address that we can configure bind to listen() on, as it's dynamic.\r\n      - https://github.com/WarheadsSE/docker/blob/master/network.go#L100\r\n\r\nCan we, as part of our system networking startup configuration, create and configure the bridge interface before dockerd starts?\r\n\r\nIf so, that would resolve both issues.","@tamsky Absolutely!  If you create/configure the docker0 interface before starting Docker, Docker will pick up the network settings from the interface instead of making them up (for example, using the IP/mask on the bridge instead of trying to find a suitable one).\r\n\r\nYou can also use `-b` to change the bridge that Docker attaches to, or `--bip` to just change the bridge's IP/mask:\r\n```console\r\n$ docker -h\r\nUsage of docker:\r\n...\r\n  -b, --bridge=\"\": Attach containers to a pre-existing network bridge; use 'none' to disable container networking\r\n  --bip=\"\": Use this CIDR notation address for the network bridge's IP, not compatible with -b\r\n...\r\n```","I have installed docker on 1) Ubuntu 12.04 and 2) CentOS 6.4. I did this on my work laptop connected to our corporate VPN, as I was trying to demonstrate docker for a potential production use.\r\n\r\nHowever, I cannot connect to internet (if I had to run a `mvn install`) or `yum -y update` inside the image.\r\n\r\nDo you guys think it is related to the DNS issue?","@seshendra I think I'm facing the same problem:\r\n- I'm running ubuntu quantal\r\n- connected to the corporate VPN the containers have network access, can resolve hostnames;\r\n- on wlan0 the containers still have network access, but can't resolve names.\r\n\r\nAnd yes, I think it's DNS related :)","@dodev for now I solved this by doing two things \r\n\r\n1. dnsmasq (where I use custom DNS servers)\r\n2. I used bridged connection instead of NAT, on the host virtualbox VM (this also solved inter container communication issue that had earlier).\r\n\r\nI'm not exactly sure which one solved the DNS issue --- but working for now on CentOS. Haven't tried on Ubuntu yet.","@seshendra : Did you add any changes to /etc/resolv.conf file or set any env variable for this?\r\nor Proceed with  Mask DNS ?\r\nhttps://wiki.debian.org/HowTo/dnsmasq","@shafi - I've upgraded to docker 0.9 and everything seems to be working fine both on centos and Ubuntu.\r\n\r\n\r\n\r\nThanks!\r\nSeshendra Nalla.\r\n\r\n\u003e On Mar 18, 2014, at 10:18 PM, shafi \u003cnotifications@github.com\u003e wrote:\r\n\u003e \r\n\u003e @seshendra : Did you add any changes to /etc/resolv.conf file or set any env variable for this?\r\n\u003e or Proceed with Mask DNS ?\r\n\u003e https://wiki.debian.org/HowTo/dnsmasq\r\n\u003e \r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub.","I am going to use this trick on the docker host:\r\n1. Manually create docker-bridge\r\n2. sysctl net.ipv4.conf.docker-bridge.route_localnet=1\r\n3. iptables -t nat -I PREROUTING -d 192.168.0.1 -p tcp --dport 25 -j DNAT --to-destination 127.0.0.1:25\r\n\r\nThe 192.168.0.1 is the docker default gateway. You can now do \"nc 192.168.0.1 25\" to get the mail server. The same trick can be probably be used for DNS. You'll have to use \"-p udp\" instead, of course. I haven't tried this with DNS, so YMMV. And i guess you could take it one step further and add a DNAT rule inside the container to direct requests to 127.0.0.1:25 to 192.168.0.1:25 if you are hell bent on having the container talk to 127.0.0.1 instead of 192.168.0.1.","on Debian 7.6 i have the same issue...\r\n(1) Running docker 1.0.0\r\n(2) /etc/default/docker.io has the DOCKER_OPTS commented with the DNS servers.\r\n(3) my /etc/resolv.conf (generated by Connection Manager) points to the localhost as name server (though i believe that, thought bind9-host \u0026 dnsutils are installed, bind9 isn't).\r\n(4) i rewrote /etc/resolv.conf, placing my ISP's nameservers first, the docker-supplied nameservers 2nd, and the localhost nameserver last:\r\n____\r\n\\# Generated by Connection Manager\r\nnameserver 209.18.47.61\r\nnameserver 209.18.47.62\r\nnameserver 8.8.8.8\r\nnameserver 8.8.4.4\r\nnameserver 127.0.0.1\r\nnameserver ::1\r\n____\r\ndo i need bind9 (or some something slimmer) installed to resolve addresses for docker? If so, why doesn't everything else on my system seem to resolve addresses with no issue?\r\n","@shin- can you update the docs so that it lists the new search command there as well?","Docs look good, thank you for adding them.","thank you","duplicate of #544 closing. ","Thank you.","If a systemd unit file is shipped with docker (which I welcome very much), it shouldn't be installed to `/etc/systemd/system` which is supposed for user modified unit files, but to `/usr/lib/systemd/system/` instead. [See also the documentation on this topic](http://www.freedesktop.org/software/systemd/man/systemd.unit.html#Unit%20load%20path).","For the record, if someone is interested in contributing this, contrib/ would be the place to do it.\n\nSince it's been 3 months, I'm assuming nobody is currently interested. Feel free to ping and I will re-open.","Note: `docker run shykes/couchdb` works, so it might be related to the existence of a default command to run...","This is actually a merge issue. Fixed and added unit tests.","Oh :-)","As a workaround you can ``rm /var/lib/docker/.dockercfg``, then you will be able to enter the new password.\r\n\r\nIt would be interesting to see how npm does in order to handle this case.","If it is an invalid login the index should return a 401, when a 401 is returned if docker could prompt for new information, and then use that instead of the cache. If login succeeds then update .dockercfg\r\n\r\nIf index doesn't return a 401, let me know and I'll fix it. but looking at the code this should be the case.","Hello,\r\n\r\nI changed my password after the index came online and now I apparently can't login to the CLI tool, here's what happens:\r\n\r\n    $ docker login\r\n    Username (rnd42): rnd42\r\n    Error: Wrong login/password, please try again\r\n\r\nalso there doesn't seem to be a /var/lib/docker/.dockercfg file.\r\n\r\n    $ sudo rm /var/lib/docker/.dockercfg\r\n    rm: cannot remove ‘/var/lib/docker/.dockercfg’: No such file or directory","@rnd42 I see that you have changed your password and that your account is active, so that is good. looking at the logs doesn't tell me much. what version of docker are you using? you can use ``docker info``.","@rnd42 I did some more digging into the docker code, and assuming you are using the latest version, and there is no bugs in the docker code, you will get that error if you truly did enter a bad username or password. To confirm you have the right username and password try logging into https://index.docker.io/account/login/  and make sure you can login there. If not, you can reset your password here: https://index.docker.io/account/forgot-password/\r\n\r\nWhen you get the error that you got, it will also remove the .dockercfg file, so that explains why you didn't have one on your system after having a bad login. \r\n\r\nIf you try all this and it still doesn't work, let me know and I'll dig some more.","Hello,\r\n\r\nI logged out of index.docker.io and back in without issue so the username and password are correct.  I tried again on the CLI and received the same result.  It may be worth noting that the docker login command never even asks me for a password, it returns with exit code 0 and the message \"Error: Wrong login/password, please try again\" before even prompting for a password.\r\n\r\nHere's the output of docker info:\r\n\r\n    $ docker info\r\n    containers: 12\r\n    version: 0.3.0\r\n    images: 4\r\n\r\nThe version is installed on Ubuntu 13.04 via the DotCloud PPA.","Sorry, there was an update I just installed to get to release 0.3.2 and I am now able to login...  I should have tried updating first and didn't think of it...","@rnd42 glad to hear it is now working for you.","I have this problem too, and my password's size is 7.\r\n\r\n```\r\nvagrant@precise64:~$ docker info\r\ncontainers: 10\r\nversion: 0.3.3\r\nimages: 4\r\nGo version: go1.0.3\r\n```","are you using last master version ?\r\n\r\n\r\nOn Sun, May 26, 2013 at 7:20 PM, goofansu \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I have this problem too, and my password's size is 7.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/549#issuecomment-18466285\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","@vieux Yes, it's the last master version.","If you base64 decode the first line of /var/lib/docker/.dockercfg do you\r\nsee your username:password ?\r\n\r\n\r\nOn Mon, May 27, 2013 at 2:41 AM, goofansu \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @vieux \u003chttps://github.com/vieux\u003e Yes, it's the last master version.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/549#issuecomment-18473759\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","Hi @vieux, there is no /var/lib/docker/.dockercfg file in my system.\r\n\r\nI'm using mbp and installed with vagrant according to this [tutorial](http://docs.docker.io/en/latest/installation/vagrant/).","@goofansu even inside the vm ?","@vieux Yes. Anything else I can help?","If you do a `docker login`, you get:\r\n\r\n    Username ():\r\n\r\nof\r\n\r\n    Username (\u003cyour username\u003e):\r\n\r\n","Got\r\n\r\n```\r\nUsername (goofansu)\r\n```\r\n\r\nI reinstalled it with `vagrant destroy` and `vagrant up`. It works now.\r\n\r\nI found this error appeared when login succeeded and `docker login` again with `Username(\u003cyour username\u003e)`.","@goofansu can you still reproduce this ?","I can reproduce at version 0.3.3.\r\n\r\n\r\n2013/5/31 Victor Vieux \u003cnotifications@github.com\u003e\r\n\r\n\u003e @goofansu \u003chttps://github.com/goofansu\u003e can you still reproduce this ?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/549#issuecomment-18750675\u003e\r\n\u003e .\r\n\u003e","@goofansu and in 0.3.4 released last week ?","@vieux Upgraded to 0.4.0 and the issue went away.","@goofansu Great, thanks to letting us know","Nice!\r\nCould you please also update builder.mergeConfig?","Voilà!","Couldyou provide an usage example?\r\n\r\nI tried several -c value, but ``./docker run -c X base /bin/sh -c 'while true; do echo; done'`` and it always takes 100% of the cpu.\r\n\r\nOr maybe I misunderstand something?","It's expected. It's only *relative* weight. Read e.g.\r\nhttps://wiki.archlinux.org/index.php/Cgroups\r\n\r\n\r\nOn Tue, May 7, 2013 at 1:43 PM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e Couldyou provide an usage example?\r\n\u003e\r\n\u003e I tried several -c value, but ./docker run -c X base /bin/sh -c 'while\r\n\u003e true; do echo; done' and it always takes 100% of the cpu.\r\n\u003e\r\n\u003e Or maybe I misunderstand something?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/551#issuecomment-17569124\u003e\r\n\u003e .\r\n\u003e",":thumbsup: ","docs are ok, might be nice to have a bit more detail about how to use it, and an example, but since we don't really have that for any other params at this time, it is probably ok.","It should be returning a 403 error when your account isn't verified. Not sure if the index is returning the wrong code, or if the docker client is stepping on the response and changing the value. If it is in the index, i can fix if I have a good use case to duplicate.\r\n\r\n/cc @shin- ","Hi,\r\n\r\nActually I confused myself while trying to upload the image, I though that this was my problem, but trying again with another (verified) account I wasn't able to upload my image either. Maybe we should invalidate that issue.\r\n\r\nMy friend is having the same problem and opened a [thread on the mailing list](https://groups.google.com/forum/?fromgroups=#!topic/docker-club/DLAe-d-Li10). He posted the steps he took to perform the upload.\r\n\r\nThanks!","This might be fixed by pull request #568 I know @creack was seeing the same issue as you. If that pull request works, and fixes your problem, then we can close this ticket. Lets keep it open until then incase that still doesn't solve your problem.","Labelling as registry (cc @samalba)","@kencochrane do you know if this is still an issue after 0.6?","Pushing with unverified account:\r\n\r\n    # docker push tyara/test001\r\n    2013/08/30 23:56:16 POST /v1.4/images/tyara/test001/push\r\n    The push refers to a repository [tyara/test001] (len: 1)\r\n    Sending image list\r\n    2013/08/30 23:56:17 Error: Status 403 trying to push repository tyara/test001\r\n\r\nI think we're good, I'd maybe suggest adding a response body in the index for good measure.","403 makes sense, here. The error output needs to be improved, but this is a different issue (that I'll contribute a fix for).","Agreed; I don't know if we should use add-apt-repository, but\r\n/etc/apt/sources.list.d is a big win in any case.\r\n\r\n\r\nOn Tue, May 7, 2013 at 5:00 PM, Barry Allard \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Despite the popularity of instructions out there, /etc/apt/sources.list is\r\n\u003e far too commonly abused in a way that doesn't scale very far.\r\n\u003e\r\n\u003e Having a separate docker.list makes it easier to make idempotent changes,\r\n\u003e i.e., overwrite if needed, w/o worrying about messing up sources.list w/\r\n\u003e duplicate/conflicting sources.\r\n\u003e\r\n\u003e This way, people using chef/puppet can also just add a template file\r\n\u003e without having to worry about line editing sources.list, which is a huge\r\n\u003e pain.\r\n\u003e\r\n\u003e For existing deployments, it's just a matter of moving that one line into\r\n\u003e the other file.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/554\u003e\r\n\u003e .\r\n\u003e","+1 to add-apt-repository\r\n\r\n`sudo apt-get install python-software-properties` just before to be batteries-included.","Agreed too. add-apt-repository is replacing sources.list in Vagrantfiles. Could you explicitly spot the place(s) you are seeing for this replacement?",":cake: ","Love cakes. Thanks!","Hey Jordan, by default docker applies an lxc config with very restricted access to device files.\r\n\r\n\r\nIt might make sense to add a \"--device\" flag to docker run, to selectively give access. In the meantime if you feel like tweaking, you can edit lxc_template.go\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 8, 2013 at 9:05 AM, Jordan Sissel \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Environment:\r\n\u003e * host: ubuntu 12.10\r\n\u003e * docker: 0.2.0\r\n\u003e Details:\r\n\u003e ```\r\n\u003e % docker run -t -i ubuntu /bin/bash\r\n\u003e # apt-get install -y pbuilder\r\n\u003e ... succeess ...\r\n\u003e # pbuilder create\r\n\u003e W: //.pbuilderrc does not exist\r\n\u003e I: Distribution is precise.\r\n\u003e I: Building the build environment\r\n\u003e I: running debootstrap\r\n\u003e /usr/sbin/debootstrap\r\n\u003e mknod: `/var/cache/pbuilder/build/15008/./test-dev-null': Operation not permitted\r\n\u003e E: Cannot install into target '/var/cache/pbuilder/build/15008/.' mounted with noexec or nodev\r\n\u003e E: debootstrap failed\r\n\u003e W: Aborting with an error\r\n\u003e I: cleaning the build env \r\n\u003e I: removing directory /var/cache/pbuilder/build//15008 and its subdirectories\r\n\u003e ```\r\n\u003e Let me know what else I can provide!\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/555","There are actually multiple problems to solve.\r\n1. pbuilder tries to create a null device, but by default, docker doesn't\r\ngive the CAP_MKNOD. So regardless of the devices permissions given by the\r\ncgroup controller, the mknod() syscall fails. Solution: remove \"mknod\" from\r\nthe list of capabilities dropped by docker (in lxc_template.go).\r\n2. pbuilder then runs an extended debootstrap, which in turn, tries to\r\ncreate more devices, like kmem, loop, etc., which are not in the list of\r\nwhite-listed devices. Solution: white-list those devices (e.g. add\r\n\"lxc.cgroup.devices.allow = a *:* rwm\" in lxc_template.go, which grossly\r\novershoots, but works).\r\n3. pbuilder then tries to mount /proc in a chroot, but docker drops\r\nCAP_SYS_ADMIN, and therefore, mount() is not allowed. Solution: remove\r\n\"sys_admin\" from the list of capabilities dropped by docker (again, in\r\nlxc_template.go).\r\n\r\nI changed lxc_template.go, recompiled, restarted \"docker -d\", ran a basic\r\nubuntu container, apt-get install pbuilder in it ... and lo and behold:\r\n\r\nroot@3f449137b9cf:/# pbuilder create\r\nW: //.pbuilderrc does not exist\r\nI: Distribution is precise.\r\nI: Building the build environment\r\n[...some minutes later]\r\nI: new cache content busybox-initramfs_1%3a1.18.5-1ubuntu4_amd64.deb added\r\nI: new cache content build-essential_11.5ubuntu2_amd64.deb added\r\nI: unmounting /var/cache/pbuilder/ccache filesystem\r\nI: unmounting dev/pts filesystem\r\nI: unmounting proc filesystem\r\nI: creating base tarball [/var/cache/pbuilder/base.tgz]\r\nI: cleaning the build env\r\nI: removing directory /var/cache/pbuilder/build//15007 and its\r\nsubdirectories\r\n\r\nI could share the resulting container, but it wouldn't be very useful,\r\nsince you probably want to re-run \"pbuilder create\" at will.\r\n\r\nI think we need a special flag for \"docker run\", instructing docker to\r\ncreate a privileged container. It would solve this problem, and make\r\n\"docker in docker\" inception scenarios much easier as well. Something scary\r\nand explicit like \"docker run -insecure\", maybe. (Are long flags allowed in\r\nGo, and compatible with the way we parse our options?)\r\n\r\n\r\nOn Wed, May 8, 2013 at 12:13 AM, Solomon Hykes \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Hey Jordan, by default docker applies an lxc config with very restricted\r\n\u003e access to device files.\r\n\u003e\r\n\u003e\r\n\u003e It might make sense to add a \"--device\" flag to docker run, to selectively\r\n\u003e give access. In the meantime if you feel like tweaking, you can edit\r\n\u003e lxc_template.go\r\n\u003e —\r\n\u003e @solomonstre\r\n\u003e @getdocker\r\n\u003e\r\n\u003e On Wed, May 8, 2013 at 9:05 AM, Jordan Sissel \u003cnotifications@github.com\u003e\r\n\u003e wrote:\r\n\u003e\r\n\u003e \u003e Environment:\r\n\u003e \u003e * host: ubuntu 12.10\r\n\u003e \u003e * docker: 0.2.0\r\n\u003e \u003e Details:\r\n\u003e \u003e ```\r\n\u003e \u003e % docker run -t -i ubuntu /bin/bash\r\n\u003e \u003e # apt-get install -y pbuilder\r\n\u003e \u003e ... succeess ...\r\n\u003e \u003e # pbuilder create\r\n\u003e \u003e W: //.pbuilderrc does not exist\r\n\u003e \u003e I: Distribution is precise.\r\n\u003e \u003e I: Building the build environment\r\n\u003e \u003e I: running debootstrap\r\n\u003e \u003e /usr/sbin/debootstrap\r\n\u003e \u003e mknod: `/var/cache/pbuilder/build/15008/./test-dev-null': Operation not\r\n\u003e permitted\r\n\u003e \u003e E: Cannot install into target '/var/cache/pbuilder/build/15008/.'\r\n\u003e mounted with noexec or nodev\r\n\u003e \u003e E: debootstrap failed\r\n\u003e \u003e W: Aborting with an error\r\n\u003e \u003e I: cleaning the build env\r\n\u003e \u003e I: removing directory /var/cache/pbuilder/build//15008 and its\r\n\u003e subdirectories\r\n\u003e \u003e ```\r\n\u003e \u003e Let me know what else I can provide!\r\n\u003e \u003e ---\r\n\u003e \u003e Reply to this email directly or view it on GitHub:\r\n\u003e \u003e https://github.com/dotcloud/docker/issues/555\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/555#issuecomment-17590208\u003e\r\n\u003e .\r\n\u003e","This will be made possible with a \"privileged mode\" or something equivalent. In the meantime, device capabilities should remain locked down by default for a sane security baseline.","It's not only \\n, but also ^M\r\nThis should be purged in the registry, do you agree @shin-  ?","We need those in the index for formatting reasons, so if you can remove them client side that would be best.\r\n\r\nUnless you mean, the search API should strip them out in the reply, but once again, it depends on the client if they want them or not.. I would say we leave them in, and then let the client decide if they want them or not.","I agree for the \\n, but I think weird ^M could be purged.","OK, I added a ticket to docker-index to strip out the ^M's on the way in. I'll need to figure out how to remove the ones that are already in there.. ","Why don't we change the format to plain-text 160 chars? Or even just 80 chars.\r\n\r\nSince the launch of the index, two things have changed\r\n* Run instructions can now be embedded in the image itself\r\n* The use of a Dockerfile has become more prominent, and they clearly show what the image is made up of. \r\n\r\nAs a result, the description has become less important and I would  like to propose to change the description format to be plain-text only, max 160 (or 80) chars. I think that would work much more beautiful in the search results for the docker client (and website), and it seems to be sufficient to put some instructions as necessary.\r\n\r\nI checked and apt-get and friends have a 80 character limit.","@dhrp :+1: ","@dhrp I think that is a different issue, feel free to open another issue for talking about description length.. BTW I think instead of reducing description, instead we have two, one short description, another long, and search results via API will use the short, and the website can use the long. once again, that doesn't relate to this ticket, and should be moved into it's own issue for more discusion. ","@dhrp @kencochrane  I like the the idea of two descriptions fields, one\r\nshort and one long as it would support a use case that I've been\r\nsuggesting.  There's another discussion thread here where it may be\r\nrelevant to discuss this: https://github.com/dotcloud/docker-index/issues/45\r\n\r\nOn Fri, May 31, 2013 at 2:47 PM, Ken Cochrane \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @dhrp \u003chttps://github.com/dhrp\u003e I think that is a different issue, feel\r\n\u003e free to open another issue for talking about description length.. BTW I\r\n\u003e think instead of reducing description, instead we have two, one short\r\n\u003e description, another long, and search results via API will use the short,\r\n\u003e and the website can use the long. once again, that doesn't relate to this\r\n\u003e ticket, and should be moved into it's own issue for more discusion.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/556#issuecomment-18764089\u003e\r\n\u003e .\r\n\u003e","Ok. I've created a new issue on this topic. I think that if we can decide on that this issue will be easy to close because it will entail removing all newlines and tabs from search results.","Fixes #536 ","Hello,\r\n\r\nMost of thoses issues will be resolved with #432 ","Well, the docker daemon us running as root and anybody can connect to it, so yes, any user can affect containers.\r\n\r\nI guess we will add authentication on the Docker API at some point.","Or make it listen on a unix socket file, protected by standard unix directory permissions.","(functioning as linkbot)  Unix socket support as @masiulaniec suggests appears in #938.","Unix sockets are [supported as of 0.4.3](https://github.com/dotcloud/docker/blob/v0.4.3/CHANGELOG.md#043-2013-06-19). Closing.","Please go ahead :)","It's also worth noting that \"go get -d\" has the same behavior on go1.0 and go1.1, so this change doesn't break compatibility with go1.0, go1.1 just forces us use \"go get\" correctly, where go1.0 was more loose (this bit me on several of my own projects, too).","I don't know star, I didn't find it in the ubuntu packages nor on google. Do you have more detail regarding star?\r\n\r\nAnyhow, #557 should solve your issue with commit :)","http://linux.about.com/library/cmd/blcmdl1_star.htm\r\nhttp://packages.ubuntu.com/lucid/star","Good to know. However, the package is not available for Raring ringtail :(","@emblica, do you know why star would be faster? Since tar is just moving\r\nbytes around, I would be surprised if there were any difference between\r\nthem. But if it were the case, it would be a pleasant (and instructing)\r\nsurprise, indeed! :-)\r\n\r\n\r\nOn Wed, May 8, 2013 at 2:28 PM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e Good to know. However, the package is not available for Raring ringtail :(\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/563#issuecomment-17635104\u003e\r\n\u003e .\r\n\u003e","Star seems to use some magic buffering according this book:\r\nhttp://books.google.com/books?id=_i1sO47qNnMC\u0026lpg=PA142\u0026pg=PA142#v=onepage\u0026q\u0026f=false\r\n\r\nThere is also conversation about performance of star, but it should be tested with docker in real situation rather than just testing. It would be nice to know some real numbers with docker\r\n(updated the link, hope it works)\r\n\r\nAlso compressing archives docker should use multithreaded alternatives to bzip, gzip","Unfortunately, I can't access the link you posted (just shows blank pages\r\nhere...)\r\nRegarding compression, I agree, but unless you have a very fast network,\r\nthe bottleneck shouldn't be your CPU.\r\nAnd asking people to install pbzip and other special compressors might a\r\nbit harsh...\r\nBut it's a good optimization to keep in mind, for sure.\r\n\r\n\r\nOn Wed, May 8, 2013 at 4:41 PM, Emblica \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Also compressing archives docker should use multithreaded alternatives to\r\n\u003e bzip, gzip\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/563#issuecomment-17641059\u003e\r\n\u003e .\r\n\u003e","Not sure if Github notifies for updates, I replaced the link hope it works now.","Thanks!\r\nWell... This book seems to be kinda old. Definitely cracked a smile here\r\n...\r\n14 MB/s, even 10 years ago, my tar was faster than that. My local gnu tar\r\ndoes ~1 GB/s :-)\r\n\r\nHowever, you're right in the way that the upload should be made faster.\r\n@vieux drew my attention on the fact that we are using XZ (LZMA)\r\ncompression, which is su...per...slow... and if something is to be done, it\r\nwould probably around that area, IMHO!\r\n\r\n\r\nOn Wed, May 8, 2013 at 5:11 PM, Emblica \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Not sure if Github notifies for updates, I replaced the link hope it works\r\n\u003e now.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/563#issuecomment-17642067\u003e\r\n\u003e .\r\n\u003e","@jpetazzo  Why are the containers being compressed for computing the checksum during commit and then simply discarded? Switching to gzip or bzip2 will not help.\r\nIf I use dockerbuilder to build a dockerbuilder image and then upload it to the registry, bsdtar will have to run 2 times through all of the layers.\r\n\r\nEven if the checksum is computed asynchronously, this is extremely bad. On my quad core box, I can easily get the whole machine to slow down to a screeching halt during a docker build which is using the dockerbuilder Dockerfile.\r\n\r\n![docker_commit_regression_problem](https://f.cloud.github.com/assets/1409668/483078/ff5dc976-b8b1-11e2-8bd6-2dda6b3464d0.png)\r\n\r\nThe whole box becomes so slow that it's unusable for as long as the docker build runs. This would be a problem on production boxes which would build / push images for any purpose (deployment, backup, mirroring, etc).\r\n\r\nAlso, I don't think bsdtar / tar are guaranteed to be deterministic. \r\nin image.go, function Checksum() (string, error):\r\n```\r\nlayerData, err := Tar(layer, Xz)\r\nif err != nil {\r\nreturn \"\", err\r\n}\r\n\r\nh := sha256.New()\r\nif _, err := h.Write(jsonData); err != nil {\r\nreturn \"\", err\r\n}\r\nif _, err := h.Write([]byte(\"\\n\")); err != nil {\r\nreturn \"\", err\r\n}\r\n\r\nif _, err := io.Copy(h, layerData); err != nil {\r\nreturn \"\", err\r\n}\r\n\r\nhash := \"sha256:\" + hex.EncodeToString(h.Sum(nil))\r\nchecksums[img.Id] = hash\r\n```\r\nWe can see that the resulting compressed tar archive is used for computing the hash. However, no measures to make bsdtar deterministic were taken. bsdtar / tar aren't guaranteed to produce identical archives on multiple runs over the same data for any set of data.\r\n","I don't know; I wasn't involved in that part of the code... I hope that\n@creack or @vieux can chime in to give details.","See #568, Still need some improvment, but will merge it this morning.\r\n\r\n\r\nOn Thu, May 9, 2013 at 10:13 AM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I don't know; I wasn't involved in that part of the code... I hope that\r\n\u003e @creack or @vieux can chime in to give details.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/563#issuecomment-17676191\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nGuillaume J. Charmes","This has been fixed. I can confirm that commits take only a few seconds now. Compressing via tar takes very little time now.",":+1: ","We released lxc-docker 0.3.1 yesterday, could you try again with this version and if it is not working, give us the output of 'docker info' ?","It worked for some time with 0.3.2 from PPA. Now it does not again:\r\n```\r\nroot@vubu:~# docker -D pull base\r\nPulling repository base from https://index.docker.io/v1\r\nError: unexpected end of JSON input\r\nroot@vubu:~# docker info\r\ncontainers: 10\r\nversion: 0.3.2\r\nimages: 5\r\nGo version: go1.0.3\r\nroot@vubu:~# docker -D pull base\r\nPulling repository base from https://index.docker.io/v1\r\nError: unexpected end of JSON input\r\nroot@vubu:~# ps aux | grep docker\r\nroot       875  0.0  0.7 436584  7884 ?        Sl   May17   0:00 /usr/bin/docker -d\r\nroot      2831  0.0  0.0  13584   928 pts/2    S+   00:14   0:00 grep --color=auto docker\r\nroot@vubu:~# docker images\r\nREPOSITORY          TAG                 ID                  CREATED\r\nubuntu              12.04               8dbd9e392a96        5 weeks ago\r\nubuntu              quantal             b750fe79269d        7 weeks ago\r\nubuntu              12.10               b750fe79269d        7 weeks ago\r\nubuntu              latest              8dbd9e392a96        5 weeks ago\r\nubuntu              precise             8dbd9e392a96        5 weeks ago\r\nbase                ubuntu-12.10        b750fe79269d        7 weeks ago\r\nbase                latest              b750fe79269d        7 weeks ago\r\nbase                ubuntu-quantal      b750fe79269d        7 weeks ago\r\nbase                ubuntu-quantl       b750fe79269d        7 weeks ago\r\n\u003cnone\u003e              \u003cnone\u003e              370fed31f16a        7 weeks ago\r\n\r\n```","@Pipeliner It's working here. Are you still running into this problem?","Well, `strace -ff -tt -o docker -s 4096 docker pull base` + `more docker.* \u003e merged` gives the following:\r\n```\r\n::::::::::::::\r\ndocker.3252\r\n::::::::::::::\r\n20:31:52.910596 execve(\"/usr/bin/docker\", [\"docker\", \"pull\", \"base\"], [/* 21 vars */]) = 0\r\n20:31:52.911676 brk(0)                  = 0x368d000\r\n20:31:52.912135 access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)\r\n20:31:52.912690 mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf2ce000\r\n20:31:52.913253 access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory)\r\n20:31:52.913747 open(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\r\n20:31:52.914159 fstat(3, {st_mode=S_IFREG|0644, st_size=67342, ...}) = 0\r\n20:31:52.914574 mmap(NULL, 67342, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f03cf2bd000\r\n20:31:52.914974 close(3)                = 0\r\n20:31:52.915381 access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)\r\n20:31:52.915834 open(\"/lib/x86_64-linux-gnu/libpthread.so.0\", O_RDONLY|O_CLOEXEC) = 3\r\n20:31:52.916221 read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\200l\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\\20\\204\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0@\\0008\\0\\t\\0@\\0#\\0 \\0\\6\\0\\0\\0\\5\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\\370\\1\\0\\0\\0\\0\\0\\0\\370\\1\\0\\0\\0\\0\\0\\0\\10\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\4\\0\\0\\0\\200 \\1\\0\\0\\0\\0\\0\\200 \\1\\0\\0\\0\\0\\0\\200 \\1\\0\\0\\0\\0\\0\\34\\0\\0\\0\\0\\0\\0\\0\\34\\0\\0\\0\\0\\0\\0\\0\\20\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\5\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\u003ct\\1\\0\\0\\0\\0\\0\u003ct\\1\\0\\0\\0\\0\\0\\0\\0 \\0\\0\\0\\0\\0\\1\\0\\0\\0\\6\\0\\0\\0\\300{\\1\\0\\0\\0\\0\\0\\300{!\\0\\0\\0\\0\\0\\300{!\\0\\0\\0\\0\\0\\364\\6\\0\\0\\0\\0\\0\\0\\210H\\0\\0\\0\\0\\0\\0\\0\\0 \\0\\0\\0\\0\\0\\2\\0\\0\\0\\6\\0\\0\\0\\260}\\1\\0\\0\\0\\0\\0\\260}!\\0\\0\\0\\0\\0\\260}!\\0\\0\\0\\0\\0\\360\\1\\0\\0\\0\\0\\0\\0\\360\\1\\0\\0\\0\\0\\0\\0\\10\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\4\\0\\0\\0008\\2\\0\\0\\0\\0\\0\\0008\\2\\0\\0\\0\\0\\0\\0008\\2\\0\\0\\0\\0\\0\\0D\\0\\0\\0\\0\\0\\0\\0D\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\0\\0\\0\\0P\\345td\\4\\0\\0\\0\\234 \\1\\0\\0\\0\\0\\0\\234 \\1\\0\\0\\0\\0\\0\\234 \\1\\0\\0\\0\\0\\0L\\n\\0\\0\\0\\0\\0\\0L\\n\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\0\\0\\0\\0Q\\345td\\6\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\10\\0\\0\\0\\0\\0\\0\\0R\\345td\\4\\0\\0\\0\\300{\\1\\0\\0\\0\\0\\0\\300{!\\0\\0\\0\\0\\0\\300{!\\0\\0\\0\\0\\0@\\4\\0\\0\\0\\0\\0\\0@\\4\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\314\\210c\\260\\23 \\245\\203Z\\4\\303G\\307 \\256A\\306eo\\224\\4\\0\\0\\0\\20\\0\\0\\0\\1\\0\\0\\0GNU\\0\\0\\0\\0\\0\\2\\0\\0\\0\\6\\0\\0\\0\\30\\0\\0\\0\\0\\0\\0\\0\\345\\1\\0\\0P\\0\\0\\0 \\0\\0\\0\\v\\0\\0\\0\\31#\\2\\261\\1\\10\\20\\2@@a\\370\\3\\10\\10\\25\\200 \\0\\0\\0\\0\\200\\300\\321Q\\0\\0\\0\\22\\353\\3020D\\0\\10\\20A\\0\\2\\0\\2\\f\\1\\200\\v\\221\\1\\330\\240\\r\\240@\\230 \\244\\200\\21\\n\\202-l@g\\214V\\24\\0\\224 \\200$H\\200P(\\1\\22\\f\\311B\\240\\220\\22\\10\\f \\2ZdA\\245c\\4@\\n\\n\\2\\0\\2009\\1(\\314@\\204\\201@\\22\\10(\\fD\\0\\0\\0\\200Q\\10\\200\\35\\4B\\320\\2608A\\0\\1\\0\\0\\265\\0300\\0\\200`\\2\\20\\\"\\0\\tA\\20\\1\\5\\0P(\\251\\2\\7(\\0\\0\\202\\4\\230@\\4\\0\\20\\340T\\0\\2@\\2\\2\\20\\3010D\\26\\200\\0\", 832) = 832\r\n20:31:52.916798 fstat(3, {st_mode=S_IFREG|0755, st_size=135398, ...}) = 0\r\n20:31:52.917248 mmap(NULL, 2212936, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f03cee91000\r\n20:31:52.917685 mprotect(0x7f03ceea9000, 2093056, PROT_NONE) = 0\r\n20:31:52.918185 mmap(0x7f03cf0a8000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x7f03cf0a8000\r\n20:31:52.918629 mmap(0x7f03cf0aa000, 13384, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f03cf0aa000\r\n20:31:52.919071 close(3)                = 0\r\n20:31:52.919533 access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)\r\n20:31:52.919931 open(\"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3\r\n20:31:52.920369 read(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\200\\30\\2\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0\\30\\232\\33\\0\\0\\0\\0\\0\\0\\0\\0\\0@\\0008\\0\\n\\0@\\0#\\0\\\"\\0\\6\\0\\0\\0\\5\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0@\\0\\0\\0\\0\\0\\0\\0000\\2\\0\\0\\0\\0\\0\\0000\\2\\0\\0\\0\\0\\0\\0\\10\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\4\\0\\0\\0\\20D\\30\\0\\0\\0\\0\\0\\20D\\30\\0\\0\\0\\0\\0\\20D\\30\\0\\0\\0\\0\\0\\34\\0\\0\\0\\0\\0\\0\\0\\34\\0\\0\\0\\0\\0\\0\\0\\20\\0\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\5\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\\\@\\33\\0\\0\\0\\0\\0\\\\@\\33\\0\\0\\0\\0\\0\\0\\0 \\0\\0\\0\\0\\0\\1\\0\\0\\0\\6\\0\\0\\0\\0G\\33\\0\\0\\0\\0\\0\\0G;\\0\\0\\0\\0\\0\\0G;\\0\\0\\0\\0\\0\\200Q\\0\\0\\0\\0\\0\\0\\370\\235\\0\\0\\0\\0\\0\\0\\0\\0 \\0\\0\\0\\0\\0\\2\\0\\0\\0\\6\\0\\0\\0@{\\33\\0\\0\\0\\0\\0@{;\\0\\0\\0\\0\\0@{;\\0\\0\\0\\0\\0\\340\\1\\0\\0\\0\\0\\0\\0\\340\\1\\0\\0\\0\\0\\0\\0\\10\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\4\\0\\0\\0p\\2\\0\\0\\0\\0\\0\\0p\\2\\0\\0\\0\\0\\0\\0p\\2\\0\\0\\0\\0\\0\\0D\\0\\0\\0\\0\\0\\0\\0D\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\0\\0\\0\\0\\7\\0\\0\\0\\4\\0\\0\\0\\0G\\33\\0\\0\\0\\0\\0\\0G;\\0\\0\\0\\0\\0\\0G;\\0\\0\\0\\0\\0\\20\\0\\0\\0\\0\\0\\0\\0p\\0\\0\\0\\0\\0\\0\\0\\20\\0\\0\\0\\0\\0\\0\\0P\\345td\\4\\0\\0\\0,D\\30\\0\\0\\0\\0\\0,D\\30\\0\\0\\0\\0\\0,D\\30\\0\\0\\0\\0\\0th\\0\\0\\0\\0\\0\\0th\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\0\\0\\0\\0Q\\345td\\6\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\10\\0\\0\\0\\0\\0\\0\\0R\\345td\\4\\0\\0\\0\\0G\\33\\0\\0\\0\\0\\0\\0G;\\0\\0\\0\\0\\0\\0G;\\0\\0\\0\\0\\0\\0009\\0\\0\\0\\0\\0\\0\\0009\\0\\0\\0\\0\\0\\0\\1\\0\\0\\0\\0\\0\\0\\0\\4\\0\\0\\0\\24\\0\\0\\0\\3\\0\\0\\0GNU\\0\\202\\225\\257\\314\\367\\314A\\346)4vm\\226\\\"?\\347%\\200\\205N\\4\\0\\0\\0\\20\\0\\0\\0\\1\\0\\0\\0GNU\\0\\0\\0\\0\\0\\2\\0\\0\\0\\6\\0\\0\\0\\30\\0\\0\\0\\0\\0\\0\\0\\363\\3\\0\\0\\t\\0\\0\\0\\0\\1\\0\\0\\16\\0\\0\\0\\0000\\20D\\240 \\2\\1\\210\\3\\346\\220\\305E\\214\\0\\300\\0\\10\\0\\5\\200\\0`\\300\\200\\0\\r\\212\\f\\0\\4\\20\\0\\210D2\\10.@\\210P4, \\16\\\"H\u0026\\204\\300\\214\\4\\10\\0\\2\\2\\16\\241\\254\\32\\4f\\300\\0\\3002\\0\\300\\0P\\1 \\201\\10\\204\\v  ($\\0\\4 P\\0\\20X\\200\\312DB(\\0\\6\\200\\20\\30B\\0 @\\200\\0\\tP\\0Q\\212@\\20\\0\\0\\0\\0\\10\\0\\0\\21\\20\", 832) = 832\r\n20:31:52.920780 fstat(3, {st_mode=S_IFREG|0755, st_size=1811160, ...}) = 0\r\n20:31:52.921218 mmap(NULL, 3925240, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f03cead2000\r\n20:31:52.921643 mprotect(0x7f03cec87000, 2093056, PROT_NONE) = 0\r\n20:31:52.922064 mmap(0x7f03cee86000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b4000) = 0x7f03cee86000\r\n20:31:52.922498 mmap(0x7f03cee8c000, 17656, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f03cee8c000\r\n20:31:52.922946 close(3)                = 0\r\n20:31:52.923403 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf2bc000\r\n20:31:52.923840 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf2bb000\r\n20:31:52.924280 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf2ba000\r\n20:31:52.924737 arch_prctl(ARCH_SET_FS, 0x7f03cf2bb700) = 0\r\n20:31:52.925256 mprotect(0x7f03cee86000, 16384, PROT_READ) = 0\r\n20:31:52.925698 mprotect(0x7f03cf0a8000, 4096, PROT_READ) = 0\r\n20:31:52.926128 mprotect(0x7f03cf2d0000, 4096, PROT_READ) = 0\r\n20:31:52.926551 munmap(0x7f03cf2bd000, 67342) = 0\r\n20:31:52.927001 set_tid_address(0x7f03cf2bb9d0) = 3252\r\n20:31:52.927419 set_robust_list(0x7f03cf2bb9e0, 0x18) = 0\r\n20:31:52.927837 futex(0x7fff43edb1bc, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 1, NULL, 7f03cf2bb700) = -1 EAGAIN (Resource temporarily unavailable)\r\n20:31:52.928262 rt_sigaction(SIGRTMIN, {0x7f03cee97750, [], SA_RESTORER|SA_SIGINFO, 0x7f03ceea0cb0}, NULL, 8) = 0\r\n20:31:52.928712 rt_sigaction(SIGRT_1, {0x7f03cee977e0, [], SA_RESTORER|SA_RESTART|SA_SIGINFO, 0x7f03ceea0cb0}, NULL, 8) = 0\r\n20:31:52.929129 rt_sigprocmask(SIG_UNBLOCK, [RTMIN RT_1], NULL, 8) = 0\r\n20:31:52.929554 getrlimit(RLIMIT_STACK, {rlim_cur=8192*1024, rlim_max=RLIM_INFINITY}) = 0\r\n20:31:52.930158 sched_getaffinity(0, 128, {7, 0, 0, 0}) = 32\r\n20:31:52.930595 getrlimit(RLIMIT_AS, {rlim_cur=RLIM_INFINITY, rlim_max=RLIM_INFINITY}) = 0\r\n20:31:52.931514 mmap(0xf800000000, 65536, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xf800000000\r\n20:31:52.931908 munmap(0xf800000000, 65536) = 0\r\n20:31:52.932318 mmap(NULL, 131072, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf29a000\r\n20:31:52.932690 mmap(0xf840000000, 1048576, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xf840000000\r\n20:31:52.933075 mmap(0xf83fff0000, 65536, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xf83fff0000\r\n20:31:52.933475 mmap(NULL, 131072, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf27a000\r\n20:31:52.941468 mmap(NULL, 131072, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf25a000\r\n20:31:52.941848 sigaltstack({ss_sp=0xf840082000, ss_flags=0, ss_size=32768}, NULL) = 0\r\n20:31:52.942235 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.942602 rt_sigaction(SIGHUP, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.942957 rt_sigaction(SIGINT, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.943287 rt_sigaction(SIGQUIT, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.943585 rt_sigaction(SIGILL, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.943885 rt_sigaction(SIGTRAP, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.944180 rt_sigaction(SIGABRT, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.944473 rt_sigaction(SIGBUS, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.944852 rt_sigaction(SIGFPE, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.945188 rt_sigaction(SIGUSR1, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.946176 rt_sigaction(SIGSEGV, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.946494 rt_sigaction(SIGUSR2, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.946808 rt_sigaction(SIGPIPE, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.947134 rt_sigaction(SIGALRM, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.947454 rt_sigaction(SIGTERM, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.947767 rt_sigaction(SIGSTKFLT, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.948128 rt_sigaction(SIGCHLD, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.948449 rt_sigaction(SIGURG, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.948827 rt_sigaction(SIGXCPU, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.949150 rt_sigaction(SIGXFSZ, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.949501 rt_sigaction(SIGVTALRM, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.949841 rt_sigaction(SIGPROF, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.950157 rt_sigaction(SIGWINCH, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.950472 rt_sigaction(SIGIO, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.950786 rt_sigaction(SIGPWR, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.951109 rt_sigaction(SIGSYS, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.951424 rt_sigaction(SIGRTMIN, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.951737 rt_sigaction(SIGRT_2, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.952051 rt_sigaction(SIGRT_3, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.952385 rt_sigaction(SIGRT_4, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.952691 rt_sigaction(SIGRT_5, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.953000 rt_sigaction(SIGRT_6, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.953280 rt_sigaction(SIGRT_7, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.953599 rt_sigaction(SIGRT_8, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.953915 rt_sigaction(SIGRT_9, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.954255 rt_sigaction(SIGRT_10, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.954575 rt_sigaction(SIGRT_11, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.954906 rt_sigaction(SIGRT_12, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.955235 rt_sigaction(SIGRT_13, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.955556 rt_sigaction(SIGRT_14, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.955869 rt_sigaction(SIGRT_15, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.956196 rt_sigaction(SIGRT_16, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.956511 rt_sigaction(SIGRT_17, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.956832 rt_sigaction(SIGRT_18, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.957116 rt_sigaction(SIGRT_19, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.957430 rt_sigaction(SIGRT_20, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.957743 rt_sigaction(SIGRT_21, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.958059 rt_sigaction(SIGRT_22, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.958372 rt_sigaction(SIGRT_23, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.958689 rt_sigaction(SIGRT_24, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.959002 rt_sigaction(SIGRT_25, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.959325 rt_sigaction(SIGRT_26, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.959638 rt_sigaction(SIGRT_27, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.959952 rt_sigaction(SIGRT_28, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.960287 rt_sigaction(SIGRT_29, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.960652 rt_sigaction(SIGRT_30, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.960996 rt_sigaction(SIGRT_31, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.961348 rt_sigaction(SIGRT_32, {0x419d93, ~[], SA_RESTORER|SA_STACK|SA_RESTART|SA_SIGINFO, 0x419df1}, NULL, 8) = 0\r\n20:31:52.961737 mmap(NULL, 1048576, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf15a000\r\n20:31:52.962706 socket(PF_INET6, SOCK_STREAM, IPPROTO_TCP) = 3\r\n20:31:52.963124 brk(0)                  = 0x368d000\r\n20:31:52.963459 brk(0x36ae000)          = 0x36ae000\r\n20:31:52.963807 rt_sigprocmask(SIG_SETMASK, ~[RTMIN RT_1], [], 8) = 0\r\n20:31:52.964184 mmap(NULL, 8392704, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7f03ce2d1000\r\n20:31:52.964554 mprotect(0x7f03ce2d1000, 4096, PROT_NONE) = 0\r\n20:31:52.964869 clone(child_stack=0x7f03cead0ff0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7f03cead19d0, tls=0x7f03cead1700, child_tidptr=0x7f03cead19d0) = 3253\r\n20:31:52.965342 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.965579 setsockopt(3, SOL_IPV6, IPV6_V6ONLY, [0], 4) = 0\r\n20:31:52.965970 futex(0x838e20, FUTEX_WAIT, 0, NULL) = 0\r\n20:31:52.972736 bind(3, {sa_family=AF_INET6, sin6_port=htons(0), inet_pton(AF_INET6, \"::1\", \u0026sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, 28) = 0\r\n20:31:52.973200 socket(PF_INET6, SOCK_STREAM, IPPROTO_TCP) = 4\r\n20:31:52.973611 setsockopt(4, SOL_IPV6, IPV6_V6ONLY, [0], 4) = 0\r\n20:31:52.973973 bind(4, {sa_family=AF_INET6, sin6_port=htons(0), inet_pton(AF_INET6, \"::ffff:127.0.0.1\", \u0026sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, 28) = 0\r\n20:31:52.974359 close(4)                = 0\r\n20:31:52.974723 close(3)                = 0\r\n20:31:52.975093 open(\"/proc/sys/net/core/somaxconn\", O_RDONLY|O_CLOEXEC) = 3\r\n20:31:52.975442 read(3, \"128\\n\", 4096)  = 4\r\n20:31:52.975805 read(3, \"\", 4092)       = 0\r\n20:31:52.976681 close(3)                = 0\r\n20:31:52.977864 stat(\"/usr/local/sbin/docker\", 0xf8400b93f0) = -1 ENOENT (No such file or directory)\r\n20:31:52.978200 stat(\"/usr/local/bin/docker\", 0xf8400b9480) = -1 ENOENT (No such file or directory)\r\n20:31:52.978584 stat(\"/usr/sbin/docker\", 0xf8400b9510) = -1 ENOENT (No such file or directory)\r\n20:31:52.978945 stat(\"/usr/bin/docker\", {st_mode=S_IFREG|0755, st_size=4424000, ...}) = 0\r\n20:31:52.979332 stat(\"/usr/local/sbin/docker\", 0xf8400b9630) = -1 ENOENT (No such file or directory)\r\n20:31:52.979693 stat(\"/usr/local/bin/docker\", 0xf8400b96c0) = -1 ENOENT (No such file or directory)\r\n20:31:52.980053 stat(\"/usr/sbin/docker\", 0xf8400b9750) = -1 ENOENT (No such file or directory)\r\n20:31:52.980416 stat(\"/usr/bin/docker\", {st_mode=S_IFREG|0755, st_size=4424000, ...}) = 0\r\n20:31:52.980862 socket(PF_INET, SOCK_STREAM, IPPROTO_IP) = 3\r\n20:31:52.981288 fcntl(3, F_SETFD, FD_CLOEXEC) = 0\r\n20:31:52.981690 setsockopt(3, SOL_SOCKET, SO_BROADCAST, [1], 4) = 0\r\n20:31:52.982103 pipe([4, 5])            = 0\r\n20:31:52.982510 fcntl(4, F_SETFD, FD_CLOEXEC) = 0\r\n20:31:52.982916 fcntl(5, F_SETFD, FD_CLOEXEC) = 0\r\n20:31:52.983322 fcntl(4, F_GETFL)       = 0 (flags O_RDONLY)\r\n20:31:52.983727 fcntl(4, F_SETFL, O_RDONLY|O_NONBLOCK) = 0\r\n20:31:52.984136 fcntl(5, F_GETFL)       = 0x1 (flags O_WRONLY)\r\n20:31:52.984540 fcntl(5, F_SETFL, O_WRONLY|O_NONBLOCK) = 0\r\n20:31:52.984971 epoll_create1(O_CLOEXEC) = 6\r\n20:31:52.985396 epoll_ctl(6, EPOLL_CTL_ADD, 4, {EPOLLIN|0x2000, {u32=4, u64=4}}) = 0\r\n20:31:52.985822 rt_sigprocmask(SIG_SETMASK, ~[RTMIN RT_1], [], 8) = 0\r\n20:31:52.986267 mmap(NULL, 8392704, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7f03cd2cf000\r\n20:31:52.986765 mprotect(0x7f03cd2cf000, 4096, PROT_NONE) = 0\r\n20:31:52.987178 clone(child_stack=0x7f03cdaceff0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7f03cdacf9d0, tls=0x7f03cdacf700, child_tidptr=0x7f03cdacf9d0) = 3255\r\n20:31:52.987714 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.988109 fcntl(3, F_GETFL)       = 0x2 (flags O_RDWR)\r\n20:31:52.988506 futex(0x838e20, FUTEX_WAIT, 0, NULL) = 0\r\n20:31:52.989491 fcntl(3, F_SETFL, O_RDWR|O_NONBLOCK) = 0\r\n20:31:52.989905 connect(3, {sa_family=AF_INET, sin_port=htons(4242), sin_addr=inet_addr(\"127.0.0.1\")}, 16) = -1 EINPROGRESS (Operation now in progress)\r\n20:31:52.991090 epoll_ctl(6, EPOLL_CTL_ADD, 3, {EPOLLOUT|EPOLLONESHOT, {u32=3, u64=3}}) = 0\r\n20:31:52.991539 epoll_ctl(6, EPOLL_CTL_DEL, 3, NULL) = 0\r\n20:31:52.991924 futex(0xf8400a1368, FUTEX_WAKE, 1) = 1\r\n20:31:52.992442 epoll_wait(6, {{EPOLLIN|0x2000, {u32=3, u64=3}}}, 10, -1) = 1\r\n20:31:56.708500 epoll_ctl(6, EPOLL_CTL_DEL, 3, NULL) = 0\r\n20:31:56.709209 futex(0xf8400a1368, FUTEX_WAKE, 1) = 1\r\n20:31:56.710010 epoll_wait(6, ::::::::::::::\r\ndocker.3253\r\n::::::::::::::\r\n20:31:52.965280 set_robust_list(0x7f03cead19e0, 0x18) = 0\r\n20:31:52.965555 sigaltstack({ss_sp=0xf8400a4000, ss_flags=0, ss_size=32768}, NULL) = 0\r\n20:31:52.965773 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.966128 open(\"/sys/devices/system/cpu/online\", O_RDONLY|O_CLOEXEC) = 4\r\n20:31:52.966595 read(4, \"0-2\\n\", 8192)  = 4\r\n20:31:52.967099 close(4)                = 0\r\n20:31:52.967510 mmap(NULL, 134217728, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7f03c62d1000\r\n20:31:52.967975 munmap(0x7f03c62d1000, 30601216) = 0\r\n20:31:52.968450 munmap(0x7f03cc000000, 36507648) = 0\r\n20:31:52.968875 mprotect(0x7f03c8000000, 135168, PROT_READ|PROT_WRITE) = 0\r\n20:31:52.969354 rt_sigprocmask(SIG_SETMASK, ~[RTMIN RT_1], [], 8) = 0\r\n20:31:52.969826 mmap(NULL, 8392704, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7f03cdad0000\r\n20:31:52.970309 mprotect(0x7f03cdad0000, 4096, PROT_NONE) = 0\r\n20:31:52.970791 clone(child_stack=0x7f03ce2cfff0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7f03ce2d09d0, tls=0x7f03ce2d0700, child_tidptr=0x7f03ce2d09d0) = 3254\r\n20:31:52.971389 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.971858 futex(0x7f03cf25bf48, FUTEX_WAIT, 0, {60, 0}::::::::::::::\r\ndocker.3254\r\n::::::::::::::\r\n20:31:52.971302 set_robust_list(0x7f03ce2d09e0, 0x18) = 0\r\n20:31:52.971612 sigaltstack({ss_sp=0xf8400b0000, ss_flags=0, ss_size=32768}, NULL) = 0\r\n20:31:52.971945 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.972322 futex(0x838e20, FUTEX_WAKE, 1) = 1\r\n20:31:52.972681 futex(0x838510, FUTEX_WAIT, 0, NULL::::::::::::::\r\ndocker.3255\r\n::::::::::::::\r\n20:31:52.987653 set_robust_list(0x7f03cdacf9e0, 0x18) = 0\r\n20:31:52.988060 sigaltstack({ss_sp=0xf8400cc000, ss_flags=0, ss_size=32768}, NULL) = 0\r\n20:31:52.988456 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.988972 futex(0x838e20, FUTEX_WAKE, 1) = 1\r\n20:31:52.989434 epoll_wait(6, {{EPOLLOUT, {u32=3, u64=3}}}, 10, -1) = 1\r\n20:31:52.991486 futex(0xf8400a1368, FUTEX_WAIT, 0, NULL) = 0\r\n20:31:52.992392 getsockopt(3, SOL_SOCKET, SO_ERROR, [0], [4]) = 0\r\n20:31:52.992814 getsockname(3, {sa_family=AF_INET, sin_port=htons(36950), sin_addr=inet_addr(\"127.0.0.1\")}, [16]) = 0\r\n20:31:52.993254 getpeername(3, {sa_family=AF_INET, sin_port=htons(4242), sin_addr=inet_addr(\"127.0.0.1\")}, [16]) = 0\r\n20:31:52.993692 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0\r\n20:31:52.994136 write(3, \"[\\\"pull\\\",\\\"base\\\"]\\n\", 16) = 16\r\n20:31:52.994590 read(3, \"{\\\"RawTerminal\\\":false}\\nPulling repository base from https://index.docker.io/v1\\r\\n\", 4096) = 79\r\n20:31:52.995112 mmap(NULL, 131072, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f03cf13a000\r\n20:31:52.995636 mmap(NULL, 134217728, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7f03c0000000\r\n20:31:52.996035 munmap(0x7f03c4000000, 67108864) = 0\r\n20:31:52.996430 mprotect(0x7f03c0000000, 135168, PROT_READ|PROT_WRITE) = 0\r\n20:31:52.996903 rt_sigprocmask(SIG_SETMASK, ~[RTMIN RT_1], [], 8) = 0\r\n20:31:52.997330 mmap(NULL, 8392704, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7f03ccace000\r\n20:31:52.997754 mprotect(0x7f03ccace000, 4096, PROT_NONE) = 0\r\n20:31:52.998168 clone(child_stack=0x7f03cd2cdff0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7f03cd2ce9d0, tls=0x7f03cd2ce700, child_tidptr=0x7f03cd2ce9d0) = 3256\r\n20:31:52.998660 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.999066 write(1, \"Pulling repository base from https://index.docker.io/v1\\r\\n\", 57) = 57\r\n20:31:52.999940 read(3, 0xf8400d9000, 32768) = -1 EAGAIN (Resource temporarily unavailable)\r\n20:31:52.999986 epoll_ctl(6, EPOLL_CTL_ADD, 3, {EPOLLIN|EPOLLONESHOT|0x2000, {u32=3, u64=3}}) = 0\r\n20:31:53.000264 futex(0xf8400a1368, FUTEX_WAIT, 0, NULL) = 0\r\n20:31:56.709917 read(3, \"Error: unexpected end of JSON input\\n\", 32768) = 36\r\n20:31:56.710718 write(1, \"Error: unexpected end of JSON input\\n\", 36) = 36\r\n20:31:56.711717 read(3, \"\", 32768)      = 0\r\n20:31:56.712885 ioctl(0, SNDCTL_TMR_TIMEBASE or TCGETS, {B38400 opost isig icanon echo ...}) = 0\r\n20:31:56.713683 exit_group(0)           = ?\r\n::::::::::::::\r\ndocker.3256\r\n::::::::::::::\r\n20:31:52.998601 set_robust_list(0x7f03cd2ce9e0, 0x18) = 0\r\n20:31:52.998994 sigaltstack({ss_sp=0xf8400e4000, ss_flags=0, ss_size=32768}, NULL) = 0\r\n20:31:52.999312 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\r\n20:31:52.999883 read(0, \r\n```","That log is not of much interest however since it only seems to receive error message from `docker -d` and print it.. ","The root of my problem:\r\n```\r\n[pid  3317] 20:47:54.192043 open(\"/var/lib/docker/checksums\", O_RDONLY|O_CLOEXEC) = 8\r\n[pid  3317] 20:47:54.192924 fstat(8, {st_mode=S_IFREG|0600, st_size=0, ...}) = 0\r\n[pid  3317] 20:47:54.193905 read(8, \"\", 512) = 0\r\n[pid  3317] 20:47:54.194826 close(8)    = 0\r\n[pid  3317] 20:47:54.195545 write(2, \"2013/05/19 20:47:54 Error: unexpected end of JSON input\\n\"\r\n```\r\nThis file is empty.\r\nSetting its content to {} resolved this issue. However we have two more questions here:\r\n1. Could error messages be more verbose?\r\n2. How did checksums file cleared (well, that may be my fault, but I don't think so)?","When the file does not exists, docker creates it correctly. The only way I managed to reproduce is by manually emptying the file.\r\nA simple rm of the file solve the issue.",":+1:\r\nThese changes are really needed in order to make docker behave properly again.\r\n\r\nHowever, the number of bsdtar processes which are compressing layers should be controlled somehow. Right now, it looks like docker spawns a number of bsdtar process which is equal to the number of commits right away.\r\n\r\n![docker_commit_regression_problem](https://f.cloud.github.com/assets/1409668/483078/ff5dc976-b8b1-11e2-8bd6-2dda6b3464d0.png)\r\n\r\nThis problem was observed with master, I didn't get a chance to test with these changes yet.\r\n","Could you please rebase with the new command.go?","ok I see that there been major change in commands and right now it need to be done elsewhere (api). Just close this pull req. I'll prepare new one.","Hi,\r\n\r\nCould you give more information,\r\nWhat was this container ?\r\nI can't reproduce.","It's a customized Python container. I cannot share the image right now because I'm unable to push it :-(\r\n\r\nContainers created using this image do the following:\r\n\r\n1. put a public key in authorized_keys file\r\n1. clone a git repository\r\n1. install some python packages\r\n1. start sshd\r\n1. start circus\r\n\r\nI'm able to reproduce this since the first step. Even when removing the container before it goes live, I get the error message.\r\n","Just an update. I'm using docker from master and now I'm unable to reproduce this. I will reopen the issue in the future if I face it again.\r\n\r\nThank you.","Can you please rebase?","I am seeing If I can push --force to clean this with my rebased version.","Hi, its fixed in 17c1704f4a0be19c7a3e3c0d449aede2a6aae05b","The error is basically telling you that your image 27cf784147099545 was previously pushed to the repository with a different checksum then the one you are pushing now.  Since images shouldn't change it is giving you the error to let you know there might be an issue.\r\n\r\nWhat version of docker are you using? (use docker info command)\r\n\r\nCan you explain what you were doing when the error happened so that we can see if we can reproduce?\r\n\r\nWe recently changed some of the checksum logic, I wonder if this is what is causing the problem. /cc @creack \r\n","```\r\njonas:~ docker version\r\nVersion: 0.3.2\r\nGit Commit: \r\nKernel: 3.2.0-41-generic\r\n```\r\n\r\nIs there a way to force push this image? I didn't change this image on any other machine so I'm not sure how this could've happened.\r\n\r\nI changed the image a few days ago (with docker 0.2.something) and now tried to do another change (with 0.3.2) and it fails.","@ojii can you try to pull creack/firefox-vnc and then try again to push your branch?\r\n\r\nIt will update the checksums from the registry.","@ojii If @creack's advice doesn't help, let me know and I can manually update your image checksum so that you aren't stuck.","@ojii @kencochrane It was actually a path issue. I fixed it on master, could you try again to ``docker pull base`` + repush your repo?","@creack \r\n\r\n```\r\njonas:~ docker pull base\r\nPulling repository base from https://index.docker.io/v1\r\nResolving tag \"base:latest\" from [registry-1.docker.io]\r\nResolving tag \"base:ubuntu-quantl\" from [registry-1.docker.io]\r\nResolving tag \"base:ubuntu-12.10\" from [registry-1.docker.io]\r\nResolving tag \"base:ubuntu-quantal\" from [registry-1.docker.io]\r\njonas:~ docker push ojii/pybuilder\r\nProcessing checksums\r\nSending image list\r\nError: Error: Status 400 trying to push repository ojii/pybuilder: \"27cf784147099545 already has checksum (sha256:f2dc42755a6d005d7a5e4d0bd2aca99680415c618ea3f48f4ed184c5ef1759a6), cant change to sha256:8562b38e30c5d3914cb4366bac73fdcb94242c665610b7842f28dc72a8b603e2\"\r\n```","Found a very easy \"solution\" (read: hack) for my issue, just pushed it under a new name. So at least this issue is no longer blocking me, but it still persists for the original name and is puzzling me.","Labelling as registry (cc @samalba)","That's one of the issues the recent overhaul on checksums has fixed (in docker 0.6.1+)\r\n\r\nI am closing this, but feel free to reopen if you're still encountering problems.","Getting same error on push: `FATA[0204] Error pushing to registry: Server error: 400 trying to push systemapic/gis blob - sha256:fae00f18c2f9226b1fdcdfe0107623278fd0c55b8539eb5a3b637e73b83926f9`. \r\n\r\n`docker version`: \r\nClient version: 1.6.0\r\nClient API version: 1.18\r\nGo version (client): go1.4.2\r\nGit commit (client): 4749651\r\nOS/Arch (client): linux/amd64\r\nServer version: 1.6.0\r\nServer API version: 1.18\r\nGo version (server): go1.4.2\r\nGit commit (server): 4749651\r\nOS/Arch (server): linux/amd64\r\n\r\n`docker info`:\r\nContainers: 369\r\nImages: 1735\r\nStorage Driver: aufs\r\n Root Dir: /var/lib/docker/aufs\r\n Backing Filesystem: extfs\r\n Dirs: 2475\r\n Dirperm1 Supported: false\r\nExecution Driver: native-0.2\r\nKernel Version: 3.13.0-36-generic\r\nOperating System: Ubuntu 14.04.2 LTS\r\nCPUs: 8\r\nTotal Memory: 31.29 GiB\r\nName: Ubuntu-1404-trusty-64-minimal\r\nID: J43A:AWSS:GBDF:SOQO:MCA3:SP7M:BWHR:BB6K:VGKL:RRH2:3IUY:GH3B\r\nUsername: knutole\r\nRegistry: [https://index.docker.io/v1/]\r\nWARNING: No swap limit support","@knutole this is likely not the same problem.\r\n\r\nThis one is two years old, and was fixed.\r\n\r\nI would encourage you to open a new issue and/or provide a copy of your docker daemon logs (preferably in debug mode)","@shin- is it possible to add some documentation around the DOCKER_INDEX_URL env variable, so that people know about it ? If you need help, let me know.","@kencochrane Done! 2ce4bf94bc031a75690a1ee9d4f0362efd0b51e7","@shin- thanks, but it looks like you forgot to link the new page to the index.rst, so it won't show up on the website. ","Maybe we could rename the 'auth' package in 'registry' ?","@creack I'd advocate reworking packages and namespacing from the ground up personally. Just renaming `auth` to `registry` wouldn't make much sense because we would still have `registry.go` in `docker`. Then you want to move `registry.go` to the `registry` package but realize it's using protected values from the `docker` package... It's not worth it IMO unless you plan to fully rework it and have packages that make sense and separate modules properly.","So this PR was actually not a rebase at all. #581 finally does solve it. Sorry for noise.","Thanks for cleaning that up, I left a couple of comments, if we can get those fixed, then I'll merge the pull request. ","@kencochrane updated.","Looks good, thank you.","By the way, the redis example isn't working either because the shykes/redis repo doesn't exist (or is private)","Fixed by #597 ","Hello,\r\n\r\nYou can only export containers, not images\r\nI'll fix the error message not displaying on the client","@vieux Thank you, I had forgotten that one can only export a container. Having the error message show up would be great.","@vieux  would it make sense to update the docs and make it more obvious as well?","every gool","@jrenner is the HumanSize function ok for you know ?","looks good to me, but I noticed nothing uses HumanSize yet? I originally inteded it to be used in progress Reader. Just an idea.","@jrenner yes once it's merge I (or you ;) ) can do another PR to use the function when needed.\r\nI prefer to focus this PR on adding sizes in `the docker ps` and `docker images`","@shykes how do you feel about this ?","LGTM","This works really well and is super useful, thanks!\r\n\r\nOne small thing I noticed: there seems to be a quirk in how virtual size is computed. For example:\r\n\r\n```bash\r\n./bin/docker history shykes/znc  | sed -E -n '2~1s/^([a-f0-9]+) .*$/docker images -a | grep \\1/p'  | sh\r\nshykes/znc                 latest                                         b327c2b80b5f        12 days ago         16.39 kB (virtual 322.3 MB)\r\n[...]\r\n\u003cnone\u003e                     \u003cnone\u003e                                         1d9a5e97fa35        12 days ago         45.4 MB (virtual 276.7 MB)\r\n\u003cnone\u003e                     \u003cnone\u003e                                         4389f5666aeb        12 days ago         96.53 MB (virtual 180.1 MB)\r\nubuntu                     12.10                                          b750fe79269d        11 weeks ago        24.65 kB (virtual 180.1 MB)\r\nubuntu                     quantal                                        b750fe79269d        11 weeks ago        24.65 kB (virtual 180.1 MB)\r\n\u003cnone\u003e                     \u003cnone\u003e                                         27cf78414709        11 weeks ago        180.1 MB\r\n```\r\n\r\nMy expectation would be for image 4389f5666aeb to have a virtual size of 276.7 MB, not 180.1MB. It looks like the size of the top layer is missing from the calculation.\r\n","@shykes do you think it's ok to leave ParentSize in the api and to add the size in the client. Or should I change the API to return VirtualSize and do the add in the server ?","@vieux I'm not sure I understand the question, sorry :)","@shykes I answered my own question :) Does this looks better ?","Damn timezone difference! Will check asap.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, Jun 14, 2013 at 3:12 AM, Victor Vieux \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @shykes I answered my own question :) Does this looks better ?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/594#issuecomment-19449290","Merged :) Thanks again.","I'm closing this issue, discussing it can happen on #769 ","What is your docker version ?","ping :)","oh hey @vieux ; I was using docker built from master, and docker built from @jpetazzo btrfs branch. I'll provide versions here in a sec..","@fujin ping ? :)","@vieux thanks for the reminder\r\n\r\n```\r\n   ✘  ~  yaourt -Qs docker\r\nlocal/lxc-docker-btrfs-git 52d74cd-1\r\n    Docker - the Linux container runtime, built from Jérôme Petazzoni's btrfs branch\r\n  ~  docker version   \r\nVersion: 0.3.2\r\nGit Commit: 52d74cd\r\nKernel: 3.8.11-1-aufs_friendly\r\nWARNING: No swap limit support\r\n```\r\n\r\nPlease let me know any additional information you need","Going to try repro with plain 0.4 install","Looks to be fixed in 0.4\r\n\r\n```\r\n  ~/mnt  docker push fujin/precise\r\nUsername (): \r\n2013/06/04 11:16:25 error: Registration: \"Wrong username format (it has to match \\\"^[a-z0-9]{4,30}$\\\")\"\r\n```\r\n\r\nOk to close.","* The remote HTTP api has been released, and allows for setting the config JSON directly as you suggest\r\n\r\n* In your use case, I'm not sure if you're describing a) passing arbitrary outside information to the container, or b) allowing the container to introspect more information from the docker runtime environment, such as other container's ports etc.\r\n\r\nFor option a, the answer is: it's already possible, simply use command-line arguments, environment variables, stdin, or any other input method.\r\n\r\nFor option b, it is not yet possible but planned for 1.0.","Thank you, Daniel!. Good catch. This has been done in the Debian package, I'll correct this.","I had pretty much the same problem on Ubuntu 12.04.\r\n\r\nError\r\n```\r\n# apt-get purge lxc-docker \r\nReading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nThe following package was automatically installed and is no longer required:\r\n  bsdtar\r\nUse 'apt-get autoremove' to remove them.\r\nThe following packages will be REMOVED:\r\n  lxc-docker*\r\n0 upgraded, 0 newly installed, 1 to remove and 0 not upgraded.\r\nAfter this operation, 4,753 kB disk space will be freed.\r\nDo you want to continue [Y/n]? y\r\n(Reading database ... 235601 files and directories currently installed.)\r\nRemoving lxc-docker ...\r\nstop: Unknown instance: \r\ndpkg: error processing lxc-docker (--purge):\r\n subprocess installed pre-removal script returned error exit status 1\r\ndocker start/running, process 1841\r\nErrors were encountered while processing:\r\n lxc-docker\r\nlocalepurge: Disk space freed in /usr/share/locale: 0 KiB\r\nlocalepurge: Disk space freed in /usr/share/man: 0 KiB\r\nlocalepurge: Disk space freed in /usr/share/gnome/help: 0 KiB\r\nlocalepurge: Disk space freed in /usr/share/omf: 0 KiB\r\n\r\nTotal disk space freed by localepurge: 0 KiB\r\n\r\nE: Sub-process /usr/bin/dpkg returned an error code (1)\r\n```\r\n\r\nTo workaround it, I just did a dirty trick, commented out `/sbin/stop docker` in the pre-removal script `/var/lib/dpkg/info/lxc-docker.prerm` and it went through.","@dbanck, @terrywang could you verify the following patch works for you?\r\n\r\n41cdd9b","+1","There were some objections concerning how this feature works. I've written an article to document some needs concerning an alternative way to do this and a few things which would improve volumes to make them more useful when used during development and and when used in production:\r\n[Volumes \u0026 persistent data storage](https://github.com/dotcloud/docker/wiki/Volumes-\u0026-persistent-data-storage)","From an UI standpoint, I'm happy to merge this, except I would like to force /foo:/bar instead of allowing /foo, to make the workflow less host-specific.","@shykes Are you saying that you'd like /foo:/bar to work like the volumes? If so, we could save these bind mounts to the config of the image / container and reuse them.\r\n\r\nI'm not sure whether this PR could be moved to be merged into a new branch so that it could be developed further there. Of course, it'd also be possible to merge it into master and develop it further in a feature branch.","I would prefer not saving a host path in the container config, because that would break the portability of the container (\"ok, before you run this, make sure you create a directory in your host with the following structure...\")\r\n\r\n\r\nPRs can be updated by simply pushing to the same branch.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 31, 2013 at 12:19 AM, unclejack \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @shykes Are you saying that you'd like /foo:/bar to work like the volumes? If so, we could save these bind mounts to the config of the image / container and reuse them.\r\n\u003e I'm not sure whether this PR could be moved to be merged into a new branch so that it could be developed further there. Of course, it'd also be possible to merge it into master and develop it further in a feature branch.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/602#issuecomment-18727778","@shykes @gabrtv @unclejack is anyone actively working on this? Would love to see this in the next release :heart:","Obligatory +1.  Docker is gorgeous and I want to all-the-things with it, but this ticket and its predecessors are absolute blockers for me.\r\n\r\nBreaking container portability a bit with external mounts is an acceptable tradeoff, I think.  If I'm using this feature to keep a database on fast media for example, I don't necessarily expect the semantics of the process in the container to survive without that data anyway.  As long as the container can either make it through `docker run myimage /bin/bash`, or give me an error messages telling me which directories it expects, I'm happy.  (The former behavior could involve just mounting an unwritable empty filesystem in the container if it can't find the desired paths outside the container, perhaps?)","Yes, don't worry I want to get this in :) As soon as 0.4 is out the door with build and remote api, this comes next.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sun, Jun 2, 2013 at 1:28 PM, heavenlyhash \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Obligatory +1.  Docker is gorgeous and I want to all-the-things with it, but this ticket and its predecessors are absolute blockers for me.\r\n\u003e Breaking container portability a bit with external mounts is an acceptable tradeoff, I think.  If I'm using this feature to keep a database on fast media for example, I don't necessarily expect the semantics of the process in the container to survive without that data anyway.  As long as the container can either make it through `docker run myimage /bin/bash`, or give me an error messages telling me which directories it expects, I'm happy.  (The former behavior could involve just mounting an unwritable empty filesystem in the container if it can't find the desired paths outside the container, perhaps?)\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/602#issuecomment-18813166","Just to chime in with our usecase: we use docker for self-contained\nsoftware that we need to provide with input files and extract output\nfiles from it - workarounds like network transfer are possible, but\nmuch slower and rather complicated.\n\n(Also, if one of your examples is running Firefox in a container,\nwouldn't it be nice if you could download files in your Firefox and\nthen do something else with them on the host machine?)\n\nI'm glad for @shykes's positive stance to this; we are using a\ncustom-built docker with this patch for the time being.","As someone wiser than me once said: in software, no is temporary, yes is forever. When in doubt, say no, because you can change your mind later :)\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sun, Jun 2, 2013 at 2:28 PM, Petr Baudis \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Just to chime in with our usecase: we use docker for self-contained\r\n\u003e software that we need to provide with input files and extract output\r\n\u003e files from it - workarounds like network transfer are possible, but\r\n\u003e much slower and rather complicated.\r\n\u003e (Also, if one of your examples is running Firefox in a container,\r\n\u003e wouldn't it be nice if you could download files in your Firefox and\r\n\u003e then do something else with them on the host machine?)\r\n\u003e I'm glad for @shykes's positive stance to this; we are using a\r\n\u003e custom-built docker with this patch for the time being.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/602#issuecomment-18814264","Just playing around with this patch, as mounting an external location is important enough to me to try it without waiting for docker 0.5\r\n\r\nThought I'd share this note if anyone else decides to give it a spin.\r\n\r\nYou need to ensure the mount inside the container exists or else you'll get cryptic error.\r\n\r\nFor example if you execute\r\n\r\n```\r\ndocker run -b /dir1/dir2 \r\n```\r\nThe directory /dir1/dir2 must already exist in the container or else you'll receive\r\n\r\n```\r\nfailed to mount '/dir1/dir2' on '/usr/lib/lxc/root//dir1/dir2'\r\nlxc-start: failed to setup the mount entries for '24920f312c543a2cef6c76ab4fac7ae45345a54d938e3c0418ea71900a4dd42b'\r\nlxc-start: failed to setup the container\r\nlxc-start: invalid sequence number 1. expected 2\r\nlxc-start: failed to spawn '24920f312c543a2cef6c76ab4fac7ae45345a54d938e3c0418ea71900a4dd42b'\r\n```\r\n\r\nIt would be nice if the final versino of this feature was smart enough to create the mount points inside the container if they are missing.\r\n","Glad to see this bumped in priority!  I'm happy to continue working it.  It sounds like there are four things we should be addressing:\r\n\r\n 1. Force explicit source and destination arguments (e.g. /foo:/bar)\r\n 2. Improve error handling around missing paths (both source and dest)\r\n 3. Update the tests accordingly\r\n 4. Add documentation\r\n\r\nLet me know if you'd like me to continue on this, or you'd rather one of the core devs handle it. @shykes @unclejack","@gabrtv Please feel free to continue working on this. I've written above something about exploring other options concerning this PR in case you weren't interested in developing it further, but I'm happy to see that's not the case.\r\n\r\nThe list of changes you've proposed is reasonable.\r\n\r\nWe can also discuss on IRC if you need some input or just need to talk about something.\r\n\r\n\r\n","@unclejack Sorry I've been incommunicado on the PR.. just got back from a trip abroad without Internet access (wipes brow).  I hope to get back to this later this week after I catch up on vacation backlog.","@unclejack I've cleaned up the PR as follows:\r\n\r\n* Merged current master (0.4.0+)\r\n* Now forcing /foo:/bar per @shykes request above\r\n* Added a comment and fixed newlines in the LXC template\r\n* Clarified usage in run docs\r\n\r\nWith regard to error handling on missing host/container directories, I find the errors produced by `lxc-start` to be sufficient, but I'll let others be the judge..\r\n\r\nMissing host directory:\r\n\r\n    $ docker run -b /missing:/tmp -t -i lucid64 bash\r\n    lxc-start: No such file or directory - failed to mount '/missing' on '/usr/lib/lxc/root//tmp'\r\n    lxc-start: failed to setup the mount entries for '365878af00f71ee024692755c43a94d39c7bc7a0905186d9668f93897d564399'\r\n    lxc-start: failed to setup the container\r\n    lxc-start: invalid sequence number 1. expected 2\r\n    lxc-start: failed to spawn '365878af00f71ee024692755c43a94d39c7bc7a0905186d9668f93897d564399'\r\n\r\nMissing container directory:\r\n\r\n    $ docker run -b /tmp:/missing -t -i lucid64 bash\r\n    lxc-start: No such file or directory - failed to mount '/tmp' on '/usr/lib/lxc/root//missing'\r\n    lxc-start: failed to setup the mount entries for 'ddb1888e82f3a7672f365123e67559bca4b707afe2ca7e06da36ee8cfb24c75b'\r\n    lxc-start: failed to setup the container\r\n    lxc-start: invalid sequence number 1. expected 2\r\n    lxc-start: failed to spawn 'ddb1888e82f3a7672f365123e67559bca4b707afe2ca7e06da36ee8cfb24c75b'\r\n\r\nIt's important to note running the container in daemon mode (-d) swallows the error:\r\n\r\n    $ docker run -b /tmp:/missing -d lucid64 sleep 60\r\n    193bab2528b4\r\n    $ docker ps -a\r\n    ID                  IMAGE               COMMAND                CREATED              STATUS              PORTS\r\n    193bab2528b4        lucid64:latest      sleep 60               3 seconds ago        Exit 255            \r\n\r\n..however given the advanced nature of this feature, I can live with the current behavior.  ","Thanks Gabriel.\r\n\r\nThere's another problem: as currently implemented, external mount-binds are\r\nadded to the container's Config object, which will be inherited by any\r\nimage committed from it, and most likely used as a default by any other\r\nhost running it.\r\n\r\nIt's important that we keep host-specific mounts scoped to that one host,\r\notherwise it will introduce unwanted side effects and break the portability\r\nof containers.\r\n\r\n\r\nOn Fri, Jun 7, 2013 at 1:11 AM, Gabriel Monroy \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @unclejack \u003chttps://github.com/unclejack\u003e I've cleaned up the PR as\r\n\u003e follows:\r\n\u003e\r\n\u003e    - Merged current master (0.4.0+)\r\n\u003e    - Now forcing /foo:/bar per @shykes \u003chttps://github.com/shykes\u003erequest above\r\n\u003e    - Added a comment and fixed newlines in the LXC template\r\n\u003e    - Clarified usage in run docs\r\n\u003e\r\n\u003e With regard to error handling on missing host/container directories, I\r\n\u003e find the errors produced by lxc-start to be sufficient, but I'll let\r\n\u003e others be the judge..\r\n\u003e\r\n\u003e Missing host directory:\r\n\u003e\r\n\u003e $ docker run -b /missing:/tmp -t -i lucid64 bash\r\n\u003e lxc-start: No such file or directory - failed to mount '/missing' on '/usr/lib/lxc/root//tmp'\r\n\u003e lxc-start: failed to setup the mount entries for '365878af00f71ee024692755c43a94d39c7bc7a0905186d9668f93897d564399'\r\n\u003e lxc-start: failed to setup the container\r\n\u003e lxc-start: invalid sequence number 1. expected 2\r\n\u003e lxc-start: failed to spawn '365878af00f71ee024692755c43a94d39c7bc7a0905186d9668f93897d564399'\r\n\u003e\r\n\u003e Missing container directory:\r\n\u003e\r\n\u003e $ docker run -b /tmp:/missing -t -i lucid64 bash\r\n\u003e lxc-start: No such file or directory - failed to mount '/tmp' on '/usr/lib/lxc/root//missing'\r\n\u003e lxc-start: failed to setup the mount entries for 'ddb1888e82f3a7672f365123e67559bca4b707afe2ca7e06da36ee8cfb24c75b'\r\n\u003e lxc-start: failed to setup the container\r\n\u003e lxc-start: invalid sequence number 1. expected 2\r\n\u003e lxc-start: failed to spawn 'ddb1888e82f3a7672f365123e67559bca4b707afe2ca7e06da36ee8cfb24c75b'\r\n\u003e\r\n\u003e It's important to note running the container in daemon mode (-d) swallows\r\n\u003e the error:\r\n\u003e\r\n\u003e $ docker run -b /tmp:/missing -d lucid64 sleep 60\r\n\u003e 193bab2528b4\r\n\u003e $ docker ps -a\r\n\u003e ID                  IMAGE               COMMAND                CREATED              STATUS              PORTS\r\n\u003e 193bab2528b4        lucid64:latest      sleep 60               3 seconds ago        Exit 255\r\n\u003e\r\n\u003e ..however given the advanced nature of this feature, I can live with the\r\n\u003e current behavior.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/602#issuecomment-19080164\u003e\r\n\u003e .\r\n\u003e","Agreed. We certainly don't want this inherited. I'm happy to take a closer look, but in the meantime is there a different strategy you have in mind?","@solomonstre After taking a closer look, I can't see a quick \u0026 easy way to remove binds from the `Config` object.  The relevant code path seems to be:\r\n\r\n###### CLI\r\n* `func (cli *DockerCli) CmdRun(args ...string) error`\r\n  * `func ParseRun(args []string, capabilities *Capabilities) (*Config, *flag.FlagSet, error)`\r\n  * `func (cli *DockerCli) call(method, path string, data interface{}) ([]byte, int, error)`\r\n\r\n###### API\r\n* `func postContainersCreate(srv *Server, version float64, w http.ResponseWriter, r *http.Request, vars map[string]string)`\r\n  * `func (srv *Server) ContainerCreate(config *Config) (string, error)`\r\n     * `func (builder *Builder) Create(config *Config) (*Container, error)`\r\n* `func postContainersStart(srv *Server, version float64, w http.ResponseWriter, r *http.Request, vars map[string]string) error`\r\n  * `func (srv *Server) ContainerStart(name string) error`\r\n     * `func (container *Container) Start() error`\r\n\r\nI can see two options for achieving the goal you outlined:\r\n\r\n1. Keep Binds in the Config, but try to exclude them during ContainerCommit\r\n2. Introduce a new \"HostConfig\" used during container start operations\r\n\r\nThe second option would involve:\r\n\r\n * Changing ParseRun to return a new HostConfig containing bind mounts and anything else\r\n * Changing CmdRun to POST to /containers/:id/start with the HostConfig body (instead of the current nil body)\r\n * Changing postContainersStart to deserialize the HostConfig and pass it to srv.ContainerStart\r\n * Make srv.ContainerStart and container.Start take a HostConfig\r\n\r\nThoughts?  Am I missing something?\r\n","I agree with option 2. It makes sense to have a HostConfig that is separate from the image's config.\nLater this can be used as a foundation for a configuration system. HostConfig values could be defined\nin a cascading way, much like CSS: in a top-level configuration file, as command-line options to the daemon,\nas command-line options to the run (eg. the subject of this present conversation).\n\nOther things that I see applying to HostConfig:\n\n\t* DNS overrides (currently in 'docker run -dns')\n\t* Passing physical interfaces to a container (eg. eth0)\n\t* Exposing device files to a container (eg. /dev/fuse)\n\t* Middleware hooks\n\nTwo points to discuss:\n\n1. Should HostConfig fields have their own command-line flags, eg '-b' for bind-mount, '-dns' for dns config etc.? Or\nshould we define a single flag for setting the field of your choice, eg. '-o mounts/pgdata=/var/lib/postgres:/mnt/postgres-data'\nor '-o dns=8.8.8.8'. I'm thinking we stick to regular flags for now, and figure out a generic system later, when it's needed.\n\n\n2. Host mounts should always have a corresponding data volume (as created by -v). We can do that in 2 ways:\n\n\ta) -b must be preceded by an explicit -v, or it fails with \"No data volume declared at /var/lib/postgres, cannot mount\".\n\tb) -b creates the missing data volume on the fly when needed. This way listing a container's volumes will always yield\n\t\tthe expected result (which is to show all \"special\" persistent directories), and the next commit will inherit\n\t\tthe new data volume (without inheriting the host-specific part).\n\nLet me know if you'd like to get some help on this, this PR is high on the list so if we can parallelize, we should.\n\nThanks!","\u003e Should HostConfig fields have their own command-line flags\r\n\r\nTo me the distinction between what goes in HostConfig versus Config is an implementation detail that most users won't be concerned with.  I lean toward leaving regular flags.\r\n\r\n\u003e Host mounts should always have a corresponding data volume (as created by -v)\r\n\r\nFrom a UX standpoint having -b create the volume seems friendlier, but is it too magical?  To be honest, I'm not very familiar with the current volumes implementation.  I'll defer to others on what makes the most sense here.\r\n\r\nI understand the high priority and am happy to take a crack at the \"MVPR\", which to me excludes (for now):\r\n\r\n * Cascading configuration\r\n * Moving other Config items into HostConfig (e.g. -dns)\r\n\r\nand includes:\r\n\r\n\u003e Changing ParseRun to return a new HostConfig containing bind mounts\r\n\u003e Changing CmdRun to POST to /containers/:id/start with the HostConfig body (instead of the current nil body)\r\n\u003e Changing postContainersStart to deserialize the HostConfig and pass it to srv.ContainerStart\r\n\u003e Make srv.ContainerStart and container.Start take a HostConfig\r\n\r\n...as well as whatever we decide for '-v' requirements, plus fixing the multitude of tests that will be broken from changing function signatures for something like Container.Start.  \r\n\r\nWith regard to parallelization, it seems like the HostConfig struct, function signatures, and new Start implementations need to happen first.  \r\n\r\nThoughts @solomonstre?\r\n\r\n\r\n","Sounds good to me, I think we're on the same page. Go for it! I would recommend asking for feedback frequently to avoid wasting your time if we start diverging :)\r\n\r\nRe: magical interactions between -v and -b, what do you guys thing @creack @vieux @jpetazzo @unclejack (and anybody else with actual experience playing with docker + volumes)","@shykes I wouldn't worry about it too much right now, docker is not yet stable and production ready, so we'll be able to make fixes and changes.\r\n\r\nin my opinion, -v and -b should be able to work together for now. We can add some special checks later to prevent the nesting of bind mounts within volumes if that becomes a problem. \r\n\r\n","Merged with current master.  The relevant changes are in this commit: ffe794f5b01c68c5144a1b92f03f8818ea35cb35\r\n\r\nThis turned out to be fairly straightforward.  HostConfig is now passed through all container Start operations.  That's  where bind mount configuration is stored.  Should be fairly extensible.  Over to you @shykes!\r\n","This will require a bump of the remote API version (and the doc which goes with it)\r\n\r\nI know this is an expected behaviour, but would be nice if -b could create the directory in the container ?\r\n(have a working ` docker run -b /tmp:/missing -t -i lucid64 bash`)\r\n","@vieux that should handle creating missing directories.  I added test coverage too.\r\n\r\nWith regard to bumping API version and docs, is that something you'd like me to do in this PR?","@shykes your call about the api version,\r\nI say we can merge this PR, merge your PR about build and version 1.3, and add the doc of this PR in version 1.3 (not need to have api 1.3 for about 1/2 day(s) and jumping to 1.4)","@gabrtv could you bump to master and, regarding the doc:\r\n\r\nUpdate the what's new section for the 1.3 api in `docs/sources/api/docker_remote_api.rst`\r\nand update `docs/sources/api/docker_remote_api_v1.3.rst`\r\n\r\nThanks","@vieux docs updated and latest master merged.  Let me know if you need anything else on this PR.","@gabrtv thank it looks very good, one thing `docker run -b /:. -i -t base bash` fails (expected) but you can't quit the client. Is that possible for you to prevent this ?\r\n\r\nOtherwise LGTM","awesome, thanks","Neat. Thanks Creack!","As the README.rst explains this system is available on http://docker-ci.dotcloud.com/waterfall","Hey Diwaker. This has been already raised on #477. Lets keep the discussion there.","It seems like an awesome idea! Would it be possible to add documentation?","@mzdaniel I don't know where to put it, as you need to build docker from sources in the host (in my case mac)","??   Can you expand?","In the case I described, the docker images is run from the host, in my case mac os.\r\n\r\nSo you have to compile docker on mac, meaning installing go on your mac.\r\n\r\n","@vieux, Now that we have the remote API we don't need to build from sources anymore.\r\nAny progress with the python approach?","@mzdaniel it is in fact useful for all clients, for example if you want to use dockerui (the web interface) on safari while docker running in the vm, you will also need the port_forward.","LGTM I don't see any downside to enabling this.\r\n\r\n/cc @creack @mzdaniel for 2nd review","LGTM","After using this, when I run `docker ps` from my host machine I get:\r\n\r\n```\r\n$ docker ps\r\n2013/06/15 14:22:20 Get http://127.0.0.1:4243/v1.2/containers/json: EOF\r\n```\r\n\r\nAnd similarly:\r\n\r\n```\r\n$ curl -i \"http://127.0.0.1:4243/v1.2/containers/json\"\r\ncurl: (52) Empty reply from server\r\n```\r\n\r\nAny ideas?","Bu default, the docker daemon binds 127.0.0.1:4342, as your host and your\r\nVMs aren't the same, starting the daemon with `docker -d -H 0.0.0.0` should\r\nwork.\r\n\r\n\r\nOn Sat, Jun 15, 2013 at 8:25 PM, Bryan Helmkamp \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e After using this, when I run docker ps from my host machine I get:\r\n\u003e\r\n\u003e $ docker ps\r\n\u003e 2013/06/15 14:22:20 Get http://127.0.0.1:4243/v1.2/containers/json: EOF\r\n\u003e\r\n\u003e And similarly:\r\n\u003e\r\n\u003e $ curl -i \"http://127.0.0.1:4243/v1.2/containers/json\"\r\n\u003e curl: (52) Empty reply from server\r\n\u003e\r\n\u003e Any ideas?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/607#issuecomment-19501049\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","@vieux just ran into this. wouldn't forwarding port 4342 from host to VM effectively hit 127.0.0.1:4342 on the VM? \r\n\r\nIt works when running servers on other ports in the VM.","@MatthewMueller I just tested when I do a `docker images` from the host, it hit `10.0.2.2`, not `127.0.0.1`","oh interesting, do you think thats a vagrant thing or something that can be fixed in docker? \r\n\r\nI think having the port forwarding be as transparent as possible is a huge win (seems like the reason behind this PR in the first place)","@brynary i'm seeing the same issue, how did you resolve this?","You have to run:\r\n\r\n    docker -d -H=\"0.0.0.0:4243\" \u0026","This was fixed by #1312.","Exposing the API port was backed out in 34145f9840b62de85d385a65702f054962878cae because #1787, because #1417, because security. See also: #2064. The `FORWARD_PORTS` proposed in #3188 won't help you; Docker is no longer listening on a TCP port. \r\n\r\nAs far as I can make out, this means we can't use the docker CLI from outside Vagrant to control docker inside Vagrant. (According to mitchellh/vagrant#1719, we can't expose the domain socket.)\r\n","It looks like this includes `utils/utils.test`, which needs to be rebased out. I'd suggest adding `*.test` to `.gitignore`.","It should work, but there is a trick. When you start a container with\ndocker, docker will \"inject\" itself inside the container to perform some\nextra setup. Docker is a 64 bits binary, and requires some 64 bits\nlibraries. So you will need to either:\n- wait until we get rid of the injection\n- compile a 32 bits docker binary\n- install some 64 bits libraries in your 32 bits container\nThe last method has been confirmed to work by backjlack on the IRC channel,\na few days ago.\nYou might want to try to ask him some details. (Unfortunately I don't know\nhis github nickname so I don't know how to ping him here!)","/cc @unclejack ","Oh :-) For some reason, I thought that backjlack and unclejack were two\r\ndifferent persons. *facepalm*\r\nThanks Victor!\r\n\r\n\r\nOn Wed, May 15, 2013 at 7:26 AM, Victor Vieux \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e /cc @unclejack \u003chttps://github.com/unclejack\u003e\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/611#issuecomment-17941676\u003e\r\n\u003e .\r\n\u003e","I've had to add the following 64 bit libraries to the 32 bit image in order to get it to work with docker:\r\n```\r\n/lib/x86_64-linux-gnu/libpthread.so.0\r\n/lib/x86_64-linux-gnu/libc.so.6\r\n/lib64/ld-linux-x86-64.so.2\r\n```\r\n\r\nThe image was working afterwards.","Hmm, wish I'd seen this earlier :).  Anyway, I've had success building with a linux/386 go cross-compiler to get a 32bit docker to resolve the injection issue.  Also helps to run things with 'linux32', otherwise package tools get confused.\r\n\r\nI'd love to see (and would be happy to contribute to) first-class support for this sort of thing.","@dtzWill Would you mind sharing how you've made this work? I'm interested to know how you got docker 64bit to run docker 32bit in the container.","@unclejack sure thing.  'm not running any part of docker as 64bit, simply built docker as 32bit and disabled the amd64 check in server.go\r\n\r\nLonger-term I'd love to see a more pervasive concept of container architecture, but my original intended short-term plan for this was:\r\n* Add (optional?) 'architecture' field to image description datastructure\r\n* Modify build system to cross-compile docker-init to various architectures (requires go cross-compilers, which are fast and easy to generate).\r\n* Inject appropriate docker-init into container when launching\r\n\r\nHowever since simply building docker 32bit seems to work (and also works on 64bit containers I've tried so far, YMMV) I haven't pursued this.","While we're on the topic, for bonus points docker could support non-native architectures (say, ARM) using qemu-user-static, which apparently the ubuntu folks use with lxc-create [1].  I don't know how well this fits into the general goals of docker, but it might be relatively simple to implement and is something quite a few people would find rather useful.  Just a thought :).\r\n\r\n[1] https://help.ubuntu.com/12.04/serverguide/lxc.html","All of this fits in docker's goals :) Great stuff.\r\n\r\n\r\nA good and easy first step is to add the field in the image data. Someone let me know if you want to give it a try.\r\n\r\n\r\nCross-compile: also a good Par to make, the build environment is itself a docker container - you can play with the dockerfile in hack/dockerbuilder.\r\n\r\n\r\nInjecting right docker-init: is this necessary? The version running in the host and the version which will work as init should always be the same, no?\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 4:07 PM, Will Dietz \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e While we're on the topic, for bonus points docker could support non-native architectures (say, ARM) using qemu-user-static, which apparently the ubuntu folks use with lxc-create [1].  I don't know how well this fits into the general goals of docker, but it might be relatively simple to implement and is something quite a few people would find rather useful.  Just a thought :).\r\n\u003e [1] https://help.ubuntu.com/12.04/serverguide/lxc.html\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/611#issuecomment-18311269","I'll try to hack something up with qemu-user* and try to add that field.","For testing the use case described in this issue (which shouldn't require qemu), these two images I uploaded to the index might be useful:\r\n\r\nhttps://index.docker.io/u/wdtz/debian-6.0-x86/\r\nhttps://index.docker.io/u/wdtz/scientific-6-x86/\r\n\r\nThese execute with 32bit docker just fine, but ideally one wouldn't need a special build of docker for 32bit vs 64bit on a 64bit host.","This is an excellent thread, but it covers a lot of ground and is not immediately actionable so I'm closing the issue. Feel free to continue the discussion on the mailing list, or file specific improvement requests if needed.\r\n\r\n","@dtzWill @unclejack How did you **create** 32-bit docker containers? I'm trying to make 32-bit debian container. I took [contrib/mkimage-debian.sh](https://github.com/dotcloud/docker/blob/master/contrib/mkimage-debian.sh) and added `--arch=i386` option to `debootstrap`. But it was not enough. The resulting docker container is stll 64-bit according to `uname -m`. Did you use `lxc-create -a i386` to create it? If yes, then how did you import it to docker?","uname will always tell you 64 bits. Look at e.g. \"file /bin/sh\" to see the\r\nreal arch of the filesystem.\r\nOn Oct 9, 2013 3:03 PM, \"Alexey Shamrin\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @dtzWill \u003chttps://github.com/dtzWill\u003e @unclejack\u003chttps://github.com/unclejack\u003eHow did you\r\n\u003e *create* 32-bit docker containers? I'm trying to make 32-bit debian\r\n\u003e container. I took contrib/mkimage-debian.sh\u003chttps://github.com/dotcloud/docker/blob/master/contrib/mkimage-debian.sh\u003eand added\r\n\u003e --arch=i386 option to debootstrap. But it was not enough. The resulting\r\n\u003e docker container is stll 64-bit according to uname -m. Did you use lxc-create\r\n\u003e -a i386 to create it? If yes, then how did you import it to docker?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/611#issuecomment-26012959\u003e\r\n\u003e .\r\n\u003e","@jpetazzo You are right, `file /bin/bash` says it's 32-bit. Thank you! I was confused, because I compared with traditional chroot. I have schroot with linux32 \"personality\", where `uname -m` reports \"correct\" architecture.","Yup, personality is different (it goes in the way to \"pretend\" the kernel\r\nis 32 bits).\r\nOn Oct 9, 2013 3:21 PM, \"Alexey Shamrin\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @jpetazzo \u003chttps://github.com/jpetazzo\u003e You are right, file /bin/bashsays it's 32-bit. Thank you! I was confused, because I compared with\r\n\u003e traditional chroot. I have schroot with linux32 \"personality\", where uname\r\n\u003e -m reports \"correct\" architecture.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/611#issuecomment-26014128\u003e\r\n\u003e .\r\n\u003e","Pinging for a status update on being able to create 32 bit containers. @shamrin the link to the mkimage script is broken...","That'd be because mkimage-debian.sh got renamed to mkimage-debootstrap.sh (since it works equally well for Ubuntu), and even now has an undocumented -a flag to control the arch (undocumented because docker doesn't support any other arches yet).","Here's the link to make it easier to find: [mkimage-debootstrap.sh](https://github.com/dotcloud/docker/blob/master/contrib/mkimage-debootstrap.sh).\r\nOr follow Debian/Ubuntu link in documention: [Base Image Creation](http://docs.docker.com/articles/baseimages/).","Or use an existing 32-bit image, here's one for precise: https://index.docker.io/u/besn0847/ubuntu32/","I have 32-Bit Fedora 20 build of Docker.  The builds just completed about 10 mins ago.   You will have to tweak the init scripts to launch the daemon, but it works and tested.   Here, pick up a copy from my github repo: https://github.com/rcsavage/Docker-1.2.0-i686","For anyone coming across this, like I have.. it's always possible to run a command in 32 bit mode. Test it, by issuing `linux32 uname -a`. By prepending linux32, it runs in 32 bit mode.","How could I use linux32 command if I have 32bit container ([here my question about uname on SO](http://stackoverflow.com/questions/26490935/how-to-fake-cpu-architecture-in-docker-container))?","Ubuntu amd64 installations enable 32-bit foreign architecture by default, however the docker containers do not appear to feature that. I guess that is a request to the official ubuntu container providers to either add 32-bit support by default and/or provide alternative images with 32-bit runtime support built-in.","@xnox : \r\n\r\nWe have 32-bit containers here: https://github.com/docker-32bit\r\n\r\nIf you'd like to test, we could sure use any volunteers to confirm which 32-bit Ubuntu versions support Docker 32-bit (we're targeting LTS only).","@Kentoseth \r\nI think you are misunderstanding my request. Or rather a feature that Ubuntu supports.\r\n\r\nAll i386 releases of ubuntu should be able support docker-32bit.\r\n\r\nI'm asking to build: amd64 image of Ubuntu with 32-bit runtime support as part of the image, to be executed on an amd64 host, with an amd64 docker binary.\r\n\r\nThe same way that Ubuntu Desktop amd64 installations have i386 runtime support enabled which allows installation and execution of i386 packages (e.g. install hello:i386 on amd64 host to execute i386 version of hello, similarly for libraries, and even high-level apps like Skype).","@xnox \r\n\r\nI think I understand you now.\r\n\r\nUnfortunately I can't help concerning that.\r\n\r\nHope someone else can chime in.","@shamrin I have checked (in Ubuntu)\r\n\r\n  - host 64 bits (docker 1.4.1) \u003e container 32 bits \u003e ok\r\n  - host 64 bits (docker 1.0.1) \u003e container 32 bits \u003e ok\r\n  - host 32 bits (docker 1.0.1) \u003e container 32 bits \u003e ok\r\n\r\nSome 32bits images (Ubuntu 12.04 / 14.04)\r\n\r\n    docker pull ggrandes/ubuntu32\r\n    docker run -it --name=\"test32\" ggrandes/ubuntu32 /bin/bash\r\n","Anybody tested it with 1.5?","@dexterddit yes, works.\r\n\r\n  - host 64 bits (docker 1.5.0) \u003e container 32 bits \u003e ok\r\n","We can't rely on go1.1 at the moment. Ubuntu packaging still compiles with 1.0.3 and debian with 1.0.2.","@creack why? The only people that care about this are developers, and they can trivially use a PPA (or equivalent) or the Vagrant VM.","In order to create a PPA, we realy on Go. My understanding is that there is not yet Go1.1 package and therefore, the PPA couldn't be built with 1.1 specific.\r\n@mzdaniel Any input?","I may be missing something here, but Ubuntu PPAs [seem to support](https://help.launchpad.net/Packaging/PPA/BuildingASourcePackage#Depending_on_other_PPAs) other PPAs as build dependencies. [This Go PPA](https://launchpad.net/~gophers/+archive/go) is the one you want.","Hey Titanous. That's exactly the PPA and the package we are using (since we solved the issue that required go 1.0.3)! So the next release of the Ubuntu docker package will automatically get it :)\r\nFor debian, I checked and Go 1.1 in on Unstable. I'll do more research on this issue.\r\n","Preliminary result: Tried to run go test after installing go 1.1 from unstable on wheezy. Outcome: Docker unittests passed. Caveat: golang-go depends on libc6.","It will be easier to rewrite than to merge, too much change (the registry.go file has moved, a pain to diff)","For clarification: Are 1.1-only patches being accepted yet?","Unfortunately not yet, because of a limitation in the Ubuntu build chain.\r\n(go 1.1 amd64 is not available as a ppa and therefore canonical cannot\r\nbuild docker with go 1.1).\r\n\r\nI'm tired of waiting so we're going to bypass the entire Ubuntu build\r\nchain. We're going to switch to wrapping our own binary into a minimalist\r\n.deb, host it on our own .deb mirror, point people to that and call it a\r\nday. If we use FPM, we even get cross-distro support with minimal effort.\r\n\r\nOnce that is done (or once there's a go 1.1-64 ppa, whichever comes first),\r\nwe'll be able to accept 1.1-only patches.\r\n\r\n(cc @mzdaniel)\r\n\r\n\r\n\r\n\r\nOn Wed, Jun 12, 2013 at 6:04 PM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e For clarification: Are 1.1-only patches being accepted yet?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/612#issuecomment-19365824\u003e\r\n\u003e .\r\n\u003e","@vieux, can you bump to master? We are go1.1 now :)","See #907","@creack \r\n\r\n    $\u003edocker images\r\n    REPOSITORY          TAG                 ID                  CREATED\r\n    base                latest              b750fe79269d        7 weeks ago\r\n    base                ubuntu-12.10        b750fe79269d        7 weeks ago\r\n    base                ubuntu-quantal      b750fe79269d        7 weeks ago\r\n    base                ubuntu-quantl       b750fe79269d        7 weeks ago\r\n    vieux/base          latest              b750fe79269d        7 weeks ago\r\n\r\ndocker rmi base will search for all the repo with the ID b750fe79269d\r\nthe id b750fe79269d is found in another repo than base (vieux/base) only repo base is deleted\r\n\r\n====\r\n\r\n    $\u003edocker images\r\n    REPOSITORY          TAG                 ID                  CREATED\r\n    base                latest              b750fe79269d        7 weeks ago\r\n    base                ubuntu-12.10        b750fe79269d        7 weeks ago\r\n    base                ubuntu-quantal      b750fe79269d        7 weeks ago\r\n    base                ubuntu-quantl       b750fe79269d        7 weeks ago\r\n\r\ndocker rmi base will search for all the repo with the ID b750fe79269d\r\nthe id b750fe79269d is only found in the repo base, so the image b750fe79269d will be removed","@vieux Since you are working with the image deletion code, would you consider adding in someway of pruning un-tagged branches?  Perhaps one (or both) of the following:\r\n\r\n1. Add a `--deps` option that removes the layer, and all its dependencies, unless they are also the dependency of another layer (as mentioned in #472).\r\n1. Add a `--prune` option that removes all un-tagged heads and their dependencies.\r\n\r\nThese would help greatly in cleaning up a local docker image repository after a series of `docker build` runs.  For now, I've been running this command repeatedly until there are no more deletions:\r\n\r\n```\r\n$ docker images | ack \"\u003cnone\u003e\" | awk '{ print $3 }' | xargs -n1 docker rmi\r\n```\r\n\r\nThank you.","after messing around with build a lot I agree with @justone, some way to prune would be nice","We should define what the endpoint will return, here what I propose:\r\n\r\nHTTP STATUS:\r\n* image deleted : 200\r\n* image untagged (can't delete because it has children):  200\r\n* nothing (can't be delete because children and don't have tag): 409\r\n* no such image: 404\r\n\r\nCONTENT:\r\nA list of all images delete/untagged and their statuses:\r\n\r\nLets say you have base with only on children\r\n`docker rmi base` will only untag base as it's referenced by the child:\r\n\r\n    [\r\n     {\"untagged\":\"base\"}\r\n    ]\r\n\r\n`docker rmi base_children` will remove child, and base, as it is untagged and not used anymore\r\n\r\n    [\r\n     {\"deleted\":\"base_children\"},\r\n     {\"deleted\":\"base\"}\r\n    ]\r\n\r\n\r\nHow do you feel about this ?","Looks good to me.  Thanks.","@vieux can you rebump to master?","@creack done","LGTM","LGTM. This is so, so useful. Thanks a lot.","Thank you so much for this.  I just tried it out and it works beautifully.","Here are some more.\r\n\r\n**Blog post:**\r\n- http://gregoryszorc.com/blog/2013/05/19/using-docker-to-build-firefox/\r\n\r\n**Video Podcast:**\r\n- http://www.jupiterbroadcasting.com/37396/docker-containers-made-easy-las-s27e01/\r\n\r\n**Hacker news posts:**\r\n- https://news.ycombinator.com/item?id=5731706\r\n- https://news.ycombinator.com/item?id=5408002\r\n- https://news.ycombinator.com/item?id=5445387\r\n\r\nHacker News Search for Docker: https://www.hnsearch.com/search#request/all\u0026q=docker\r\n\r\n**Reddit:**\r\n- http://www.reddit.com/r/programming/comments/1emva0/docker_way_better_than_a_vm/\r\n- http://www.reddit.com/r/linux/comments/1emimx/docker_way_better_than_a_vm/\r\n- http://www.reddit.com/r/linux/comments/1b4u6h/docker_the_linux_container_runtime/\r\n- http://www.reddit.com/r/linux/comments/1d54wq/docker_020_released/\r\n","**Web Interface for docker**\r\nDockerUI: https://github.com/crosbymichael/dockerui\r\nVideo: https://www.youtube.com/watch?v=d4CCClXB_fs\r\nHN: https://news.ycombinator.com/item?id=5853033\r\n\r\n**Docker powered mini-Heroku. The smallest PaaS implementation you've ever seen.**\r\nDokku: https://github.com/progrium/dokku\r\nHN: https://news.ycombinator.com/item?id=5852911\r\n\r\n**Running Docker on Digital Ocean with Ubuntu**\r\nhttp://kencochrane.net/blog/2013/06/running-docker-on-digital-ocean/","Deploy Java Apps With Docker = Awesome:\r\nhttp://blogs.atlassian.com/2013/06/deploy-java-apps-with-docker-awesome/","Getting Docker to run on Linode:\r\nhttp://nick.stinemat.es/","**Getting docker running on chunkHost**: http://sbaronda.com/2013/05/05/getting-docker-on-chunkhost/\r\n\r\n**Deploying Django using Docker**: http://agiliq.com/blog/2013/06/deploying-django-using-docker/\r\n\r\n**Docker UI in Django**: https://github.com/ehazlett/shipyard\r\n\r\n**Docker UI in Ruby**: https://github.com/dynport/dockland\r\n\r\n","Blog post and screen cast for Dokku: http://progrium.com/blog/2013/06/19/dokku-the-smallest-paas-implementation-youve-ever-seen/","Blog post : Solomon Hykes Explains Docker\r\nhttp://www.activestate.com/blog/2013/06/solomon-hykes-explains-docker","MCollective Agent for the Docker API\r\nhttps://github.com/aschmidt75/mcollective-docker-agent","(japanese) http://apatheia.info/blog/2013/06/17/docker/","(japanese) http://2013.8-p.info/japanese/06-22-docker.html","(japanese) Tatsuhiko Miyagawa's Podcast \r\nhttp://podcast.bulknews.net/post/53587224871/ep14-docker-naoya-mizzy","docker api in ruby https://github.com/swipely/docker-api - 24 Jun\r\n(japanese) Docker remote api article http://d.hatena.ne.jp/naoya/20130621/1371790990 - 21 Jun","Building Docker on Openstack with Vagrant\r\nby Paul Czarkowski - 25 Jun, 2013\r\nhttps://github.com/paulczar/docker-rcbops-openstack","JiffyLab is a project to provide an entirely web based environment for the instruction, or lightweight use of, Python and UNIX shell environment with zero-configuration of the user's machine.\r\nby Preston Holmes\r\nhttps://github.com/ptone/jiffylab","http://jeelabs.org/2013/06/26/packaged-but-not-virtualised/","I moved this content [to a wiki page](https://github.com/dotcloud/docker/wiki/Docker-external-resources), so we can close this issue.\r\n\r\nIt would be great to include it into the docs! Assigning to @metalivedev ","Update from group. Forgot to mention but I've altered docker auth/auth.go and set INDEX_SERVER to my host. But this shouldn't change push with -registry option used. Revert this back to default, restart docker -d and result is same, 404. So +1 for \"-no-index\", I can try to add this if no one else is interested it this.","I have considered -no-index, but then it seemed a more natural choice to simply fallback in case index is not found rather than require the user to explicitly specify that there is no index. Is there an important reason for having that switch?","If you know that there is no index why wait for response? IMHO fallback is good option but switch can be used when user knows that he don't want to use index.","All right. However, I'm not so sure when/if I will personally get around\nto implementing also a -no-index commandline switch, so perhaps we can\nconsider this as a separate bugfix and an additional feature?","I think it can wait as long as pushing to private registry works without using index server. If I got some free time I'll test your change and write back.","@samalba I'm assigning to you since you're the registry maintainer.","It's not a Registry issue. Let me know what you expect and I'll do it.","+1\r\nHi guys!\r\nI uploaded [docker-registry](http://github.com/dotcloud/docker-registry) build it and run.\r\nbut how to upload images into it.\r\n1) configure the container\r\n2) `docker commit afc4065a8a44 vedmalex/nodejs`\r\n3) i want to upload it into local registry.\r\n `docker push  vedmalex/nodejs --registry http://localhost:5000`\r\nand this command too.\r\n `docker push  vedmalex/nodejs -registry http://localhost:5000`\r\n\r\ndocker's log shows 2013/05/23 17:51:58 POST /images/vedmalex/nodejs/push?registry=\r\n\r\nempty registry\r\nthe registry log also show nothing.\r\n\r\nam i doing somethings wrong?","Hi guys,\r\n\r\nI've been looking into this today and have some answers for you. Because the repository system relies a lot on the index to function, pushing to an independent registry should currently be done by image ID. \r\n\r\n    # docker commit 9f1c50949c09\r\n    6837f93e292c\r\n    # docker push -registry=\"http://registrystaging-docker.dotcloud.com\" 6837f93e292c\r\n    2013/05/24 07:04:14 Impossible to push a \"root\" repository. Please rename your repository in \u003cuser\u003e/\u003crepo\u003e (ex: joffrey/6837f93e292c)\r\n\r\nThis is definitely a bug and I'm going to push a fix for it today (if you're trying to push an image by its ID this message shouldn't appear).\r\n\r\nOther than that, I'm interested to hear what your guys are looking for in this feature, and basically how important it is for you to have full support of repositories with independent registries.","Also regarding the original comment by @samalba : \"When a custom registry is passed using the \"-registry\" argument, Docker considers this endpoint is also used for the Index\" -- this is not actually the case (it's been confirmed in the original thread on the mailing list that the person reporting the issue patched auth.go to point `INDEX_SERVER` to his registry host. Don't do that!)","For the record this is not what I agreed to when we discussed the specs of the new registry, I wish you guys had not deviated from that agreement. \r\n\r\n\r\nSpecifically, there wasn't supposed to be a separate index protocol! Only extensions to the registry protocol to allow decentralized hosting, proper authentication, etc. It was ok for those extensions to be reverse-incompatible.\r\n\r\nFrom docker's point of view \"the index\" should have simply been a registry at a special hardcoded URL, which happens to make heavy use of the decentralized hosting capabilities.\r\n\r\n\r\nIf you had stuck to this design, we wouldn't have to ask \"are you guys interested in a registry which supports repository names and custom authentication?\". YES everyone is interested in that, it's the reason we open-sourced a registry in the first place!\r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 7:43 AM, Joffrey F \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Hi guys,\r\n\u003e I've been looking into this today and have some answers for you. Because the repository system relies a lot on the index to function, pushing to an independent registry should currently be done by image ID. \r\n\u003e     # docker commit 9f1c50949c09\r\n\u003e     6837f93e292c\r\n\u003e     # docker push -registry=\"http://registrystaging-docker.dotcloud.com\" 6837f93e292c\r\n\u003e     2013/05/24 07:04:14 Impossible to push a \"root\" repository. Please rename your repository in \u003cuser\u003e/\u003crepo\u003e (ex: joffrey/6837f93e292c)\r\n\u003e This is definitely a bug and I'm going to push a fix for it today (if you're trying to push an image by its ID this message shouldn't appear).\r\n\u003e Other than that, I'm interested to hear what your guys are looking for in this feature, and basically how important it is for you to have full support of repositories with independent registries.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/615#issuecomment-18408989","Sorry -- I understand what you're saying. I don't think we're too far off to be honest, the only thing I'm not sure how to do is differentiate between pulling an image by ID and pulling a non-slashed repository.","Don't non-slashed repositories have a special library/$repo url path?\r\n\r\n\r\n\r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 8:25 AM, Joffrey F \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Sorry -- I understand what you're saying. I don't think we're too far off to be honest, the only thing I'm not sure how to do is differentiate between pulling an image by ID and pulling a non-slashed repository.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/615#issuecomment-18411612","They do - but there's no surefire way to detect which is what on the client side","If you're resolving the name locally (ie push) the canonical answer is that IDs shadow repositories.\r\n\r\nIf you're resolving remotely (ie pull) I would just follow the same rule: try downloading the id, if it fails try downloading the repository. Optionally there could be a remote call that does this lookup for you.\r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 8:36 AM, Joffrey F \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e They do - but there's no surefire way to detect which is which on the client side\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/615#issuecomment-18412340","Hmm, I just don't get why there is a split to index and registry. When registry code was released I hoped that it can be used exact same way like the public one. IMHO without this docker is incomplete as a whole. And that slows down it's adoption in industry as a standard. Hype on docker that was after release is burning down fast.","On Fri, May 24, 2013 at 10:05 AM, odk- \u003cnotifications@github.com\u003e wrote:\n\n\u003e Hmm, I just don't get why there is a split to index and registry. When\n\u003e registry code was released I hoped that it can be used exact same way like\n\u003e the public one. IMHO without this docker is incomplete as a whole. And that\n\u003e slows down it's adoption in industry as a standard.\n\u003e\nI agree and we're going to fix it. Want to help? :)\n\n\n\u003e Hype on docker that was after release is burning down fast.\n\u003e\nWell, that's encouraging :)\n\nI don't know about the hype. But by more tangible metrics like use cases,\ngithub stars and community contributions, the project seems to be doing\ngreat. For example we are currently in the Github weekly trending list\n(again) :)  https://github.com/explore/week\n\nIn any case, yes, the registry needs to be useful standalone, we will make\nthis happen, and anybody willing and able to help will be welcomed with\nopen arms.","I think https://github.com/dotcloud/docker/commit/3d92f2df634a653753c5b988bc23098b9e8a94bd is a step in the right direction, but haven't been able to fully test it yet (and I'm about to head out for a few hours). If you guys are able to test it and give me feedback, that will make it easier and faster to get to a satisfactory state.\r\n\r\nThanks!","The branch it lives in is called 615-pushbyid (misleading name, this commit should allow to push/pull repositories from an independent registry without hitting the index)","Ok, I managed to test change. It's better:\r\n./docker push -registry='docker-reg' b750fe79269d\r\n2013/05/25 22:40:36 GET /v1.000000/auth\r\n2013/05/25 22:40:36 POST /v1.000000/images/b750fe79269d/push?registry=docker-reg\r\nThe push refers to an image: [b750fe79269d]\r\nPushing b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc\r\n2013/05/25 22:40:36 http: multiple response.WriteHeader calls\r\nHTTP code 400 while uploading metadata: {\r\n    \"error\": \"Image depends on a non existing parent\"\r\n}\r\nSo error is gone, and pushin by id works.","@shin- can we close this ?","I'm stuck on this too. The way I see it, being able to use an independent registry is essential for production environment. Is #700 going to be merged? ","Closing since #700 has been merged, reopen if additional discussion is necessary!","Good point. fixed with #620, on both www.docker.io and documentation","Thanks for catching those!","In this case you can thank `go vet`. :smiley:","Looks good thanks, I'll pull it down and test it out in a little bit, and let you know if I have any questions/issues.","OK, just built it, it looks good, left two comments. if you can fix those two issues, I'll merge. Let me know if you have any questions.","Would it not make more sense to actually put this under \"Use\" because, pretty much everything in this guide is about how to setup containers (which is very cool btw), rather than the (mundane) how do I install Docker. ","I've added the note and changed the highlighting and updated the pull request.\r\n\r\nHappy to move this to use if you think that's a more suitable location?","@garethr The changes look good, thank you. \r\n\r\nCould you.\r\n\r\n1. merge master into your branch so it can resolve the pull request merge conflict.\r\n2. move this to the \"use\" section of the docs, I think @dhrp is right, it is probably better over there.\r\n3. merge (rebase) your commits down to one commit, for easier merging. \r\n\r\nThank you, sorry for all the hassle, let me know if you have any questions.","Closing in favour of #631 which has all the relevant changes in a single commit.","Hi @ulope ,\r\n\r\nThanks, you're right, the doc could be improved.\r\n\r\nIn the meantime you can look in the contrib folder: https://github.com/dotcloud/docker/tree/master/contrib\r\nThe two files *mkimage.sh* are what you are looking for.\r\n\r\n","cc @metalivedev ","This could be a new section in \"USE\" in the docs.\n\nScheduling for 0.7.","i searched around google and find some open source on how to [create an image](http://www.rasteredge.com/how-to/csharp-imaging/create-new-image/). it is one of the features of the [image sdk .net](http://www.rasteredge.com/dotnet-imaging/).   i am not sure about the working base image  but it creates various types of images. ","@nationmore sorry, that's not relevant. The kinds of \"image\" we're talking about here is a copy of a file system, not graphics images.","Basically the goal would be to install the OS Image to a local directory and then docker import from there. You've just gotta find the docs that show how to do it for the flavor of Linux that you want. Here are some instructions for Centos from (out of all things) OpenVZ's wiki: http://openvz.org/Creating_a_CentOS_6_Template","The current information on creating base images for Docker is here:\r\nhttp://docs.docker.io/en/latest/articles/baseimages/\r\n\r\nPlease file bugs and Pull Requests related to that doc.",":+1:","I think it's important to keep everything light in the Rest API. The daemon should always bind on localhost. And the recommended setting for prod (to export it publicly) must be an nginx (or apache or whatever) in front of it which implements auth and SSL.","Hey Victor, should we wait for you to re-open before reviewing?\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, May 16, 2013 at 7:29 PM, Sam Alba \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e I think it's important to keep everything light in the Rest API. The daemon should always bind on localhost. And the recommended setting for prod (to export it publicly) must be an nginx (or apache or whatever) in front of it which implements auth and SSL.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/623#issuecomment-18016031","Looks like my comment got ignored. You should close this pull request (without merging it).","@samalba not ignored but as @jpetazzo said in #661 we should discuss it.\r\nEven if it's not recommended, to export the api publicly, it could be useful to\r\nhave a basic auth even for you private network.\r\n\r\nAs the api don't support https, I believe that even if you add basic auth, it won't be used on production as exported.","As discussed offline with @creack and @vieux, I agree that adding auth here would be a slippery slope - to make it complete we would\nneed to add ssl etc.\n\nI think it's enough to print a big fat warning on docker -H for non-localhost addresses, and then leave the rest to a 3d-party proxy.","I am actually working on this right now :)\r\n\r\nHowever, for 'attach' operation, we still need to hijack as we need to be in canonical mode (ICANON).\r\n\r\nCf #625. It still needs some minor tweaks, but the idea is there","Wow cool!\r\nI will follow #625 to learn something new then ;)","@creack why must the connection be hijacked for canonical mode to work?","@jrydberg how do you handle input without hijacking? For the 'attach' mode, we need input/output streams","Are there any updates for this? I'm trying to stream via the Excon library in Ruby but that needs the Transfer-Encoding to be chunked.","nothing, expect the implementation of the HTTP client, says that you can't start processing the response while still sending the request. just as you do when you hijack the connection.  most client libraries doesn't support this though :(  \r\n\r\nregardless, sending data as chunked should be a no-brainer and easy fix (just wrap the streams in httputil.ChunkedReader and httputil.ChunkedWriter).\r\n","When running the tests, I get an error:\r\nregistry/registry_test.go:6: import \"github.com/dotcloud/docker\": package depends on \"github.com/dotcloud/docker/registry\" (import cycle)","@creack do you still have the issue ? Working on my side","@creack ping ?","yes, I still have the issue, Are you sure you are testing registry and not just docker?","@shin- should we close or rebase this ?","Ping guys, what do we do with this? @shin- @creack @samalba","Those tests are good but it's still functional testing. I'm working on mocking the Registry's API in this test on the side. I recommend leaving this branch open for now, so Joffrey and I can start from there to improve it with Mock'ed Registry. We can also close the pull request for now without merging. But please leave the branch as is (it's a really good start).","Yeah. I will create some nice 404 page. \r\n\r\nSomething else is that I want to remove the links to .html pages. Somehow sphinx creates a duplicate set of pages, with links to installation.html and to installation/ (index.html implied).","**So... Our options are very limited..**\r\n\r\nRead the docs does not support any form of setting redirects, nor 404 pages. \r\nhttps://github.com/rtfd/readthedocs.org/issues/353\r\n\r\nAnd the issue with duplicate pages.. It is not something just on our docs.  I can see it consistently in other projects' docs too. I asked on their IRC channel and got from the maintainer: \r\n\r\n 17:14 Wraithan: I don't actually have time to debug this at all and have higher priority things that need to be worked on, rather than pretty urls\r\n 17:14 Wraithan: if you can find the problem and send a patch, I'll happily review it\r\n\r\n\r\n**Pretty much our only options are to build and push the documentation ourselves, and host it on dotCloud, or submit some patches to ReadTheDocs**","I can take a look to see if I can figure out what is going on with readthedocs and try to submit a patch. @johncosta has some experience with readthedocs as well, maybe he can help if he has time.","Right now, there is also a problem that we cannot really remove the .html versions anymore because people are pointing at them. So if we solve the duplicate tree generation problem we also need to fix custom redirects otherwise many links will be broken.","Fixed another 404 -\u003e it was the link in this very issue!","fixed, closed. ","Ah! Literally figured it out as I was reviewing this ticket. Turns out if you install docker via apt with the linode fix, it won't work. You *have* to install it via the curl command: `curl http://get.docker.io | sh`","@ysimonson do you by chance have the notes you used to get it working, I would love to add some docs for getting it up and running on linode to the docker docs. I would do it myself, but I don't have a linode account, so it makes it hard until I get off my butt and go and create one :). If you can send me the notes I can clean them up and put them in the docs. ","Yep, it was pretty straight-forward.\r\n\r\n1) Followed the instructions here: https://www.linode.com/wiki/index.php/PV-GRUB#Ubuntu_12.04_Precise\r\n\r\nThe only thing that wasn't quite straight-forward about that was how to get to the options in the last step: \"Update your Linode profile, disable \"Xenify Distro\", and set the kernel to \"pv-grub-x86_32\" or \"pv-grub-x86_64\" depending on your installation, then reboot the profile.\"\r\n\r\nYou do this by going to the linode dashboard, and clicking \"edit\" next to the configuration profile:\r\n\r\n![screen shot 2013-05-17 at 6 28 45 pm](https://f.cloud.github.com/assets/127386/520657/401c3692-bf41-11e2-9582-14da08e17cfb.png)\r\n\r\n2) Boot the image back up and run `curl http://get.docker.io | sh`.\r\n\r\nThat was it.","@ysimonson awesome, thanks for the tips, that will be very helpful. /cc @jpetazzo ","Thanks @ysimonson !\r\n\r\nIn case anyone else is looking to do this, I documented the process all in one place, with both curl \u0026 \"getting started\" methods of installing Docker: http://coder1.com/node/87 ","Any idea how to set `cgroup_enable=memory swapaccount=1` on Linode?\r\nStandard method is not working, probably due to grub linode config.","got it:\r\n\r\nin /boot/grub/menu.lst\r\n```\r\n# defoptions=console=hvc0 rootflags=nobarrier cgroup_enable=memory swapaccount=1\r\n```\r\nthen run `update-grub-legacy-ec2`","Works with Debian Wheezy too: https://library.linode.com/custom-instances/pv-grub-howto#sph_debian-7-wheezy","awesome thanks..","Addresses #626. (I have to learn how to automatically link from the commit message :P)","Actually, wait a sec, I also have a blurb about the pre-3.8 issue that I'd like to add...","There!","Looks good, thanks @jpetazzo ","I don't think it's a good idea to make real calls to an actual 3d-party internet service as part of the unit tests.. We don't have guarantees over what that service is running, it breaks the ability to run tests offline, and it adds a bandwidth and availability burden on that service.\r\n\r\nWould it be a lot of work to get equivalent levels of coverage with mocks?","This would be an useful tool to be used to inspect running containers and to make changes, like you've said.\r\n\r\nWould this be made to work over the remote API as well to allow the client to do this when running on another machine? e.g. the shell is provided by docker via a chroot running under a tty provided by docker","Ah, I didn't think about the API; I was merely considering a simple wrapper around fork+chroot+exec, executing the heavy lifting on the client-side.\r\nDo you think I should directly aim for API integration?","It would be nice to be able to use 'docker chroot' from a client running on OS X. So you run your dev environment in a VM and connect to it remotely via docker chroot. It would become a sort of 'ssh light'.\r\n\r\nWe already know this would be really useful because there are a few persons who've said they're running sshd in the container.","That sounds cool, but is starting to sound a little bloaty. I guess maybe\r\nwe've already crossed that bridge?\r\n\r\n\r\nOn Sat, May 18, 2013 at 1:04 PM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e It would be nice to be able to use 'docker chroot' from a client running\r\n\u003e on OS X. So you run your dev environment in a VM and connect to it remotely\r\n\u003e via docker chroot. It would become a sort of 'ssh light'.\r\n\u003e\r\n\u003e We already know this would be really useful because there are a few\r\n\u003e persons who've said they're running sshd in the container.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/635#issuecomment-18107115\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nJeff Lindsay\r\nhttp://progrium.com","I'm not sure I want to add a top-level command for this. However with the upcoming support for pluggable runtimes, you will be able to hack a chroot runtime.\r\n\r\n\r\nJeff - any special concern re: bloat? I really want to keep things lean which is why I say no to so many feature requests.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sat, May 18, 2013 at 10:38 PM, Jeff Lindsay \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e That sounds cool, but is starting to sound a little bloaty. I guess maybe\r\n\u003e we've already crossed that bridge?\r\n\u003e On Sat, May 18, 2013 at 1:04 PM, unclejack \u003cnotifications@github.com\u003e wrote:\r\n\u003e\u003e It would be nice to be able to use 'docker chroot' from a client running\r\n\u003e\u003e on OS X. So you run your dev environment in a VM and connect to it remotely\r\n\u003e\u003e via docker chroot. It would become a sort of 'ssh light'.\r\n\u003e\u003e\r\n\u003e\u003e We already know this would be really useful because there are a few\r\n\u003e\u003e persons who've said they're running sshd in the container.\r\n\u003e\u003e\r\n\u003e\u003e —\r\n\u003e\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/635#issuecomment-18107115\u003e\r\n\u003e\u003e .\r\n\u003e\u003e\r\n\u003e -- \r\n\u003e Jeff Lindsay\r\n\u003e http://progrium.com\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/635#issuecomment-18107625","The 1.0 API will allow for a plugin replacing lxc with chroot.","I'm interested","Here is a blog post that show my steps and progress so far.\r\n\r\nhttp://kencochrane.net/blog/2013/05/running-docker-on-a-raspberrypi/\r\n\r\nI have compiled a linux kernel (3.6) with LXC and aufs. I install Go, and docker, but it doesn't run since docker doesn't support ARM or 32 bit.\r\n\r\nThe post is here. https://github.com/kencochrane/kencochrane.github.com/blob/master/content/docker-raspberrypi.rst feel free to fork and make pull requests to make it better.","Ken - do you know anyone who is working on getting docker running on a Beagle Bone Black ??\r\n\r\nhttp://beagleboard.org/Products/BeagleBone%20Black",":+1: ","@andyl I do not know of anyone trying to get docker running on the Beagle Bone. If I can get it up and running on the rPi, I'll move over to the BeagleBone if someone else hasn't done it yet. I'm assuming they will have the same problems, so once you solve one, hopefully the other should be fairly easy. I know they are using different ARM chips, but hopefully that isn't too bad.","This tells me it's time to deal with cross-arch support.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 9:50 AM, Ken Cochrane \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @andyl I do not know of anyone trying to get docker running on the Beagle Bone. If I can get it up and running on the rPi, I'll move over to the BeagleBone if someone else hasn't done it yet. I'm assuming they will have the same problems, so once you solve one, hopefully the other should be fairly easy. I know they are using different ARM chips, but hopefully that isn't too bad.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/636#issuecomment-18287749","@shykes both will need 32bit support as well, so I'm not sure if that is something we want to deal with now.","I'm intertest as well. I was wondering what's the fundamental reason that docker can't just recompile on and ARM system and run?","No fundamental reason. It's simply that we haven't even tried. We're keeping the surface area small to move faster, but will expand official support to more archs soon.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Mon, Jun 10, 2013 at 1:58 AM, Jimmy Yuen Ho Wong\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I'm intertest as well. I was wondering what's the fundamental reason that docker can't just recompile on and ARM system and run?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/636#issuecomment-19176517",":+1: ",":+1: ",":+1: Yes please!",":+1: ",":+1:",":+1: ","THUMBS UP :D ","I think Docker could have pretty awesome implications for the Raspberry Pi platform.\r\n\r\nCurrently much of software targeted for Raspberry Pi either require manual work to set up, or come bundled as entire Linux distributions — e.g. Raspbmc, IPFire, OpenELEC etc. A great step forward would be if people could run one common distribution and software makers could focus on just their thing, and then distribute them as containers.\r\n\r\nI envision you install a common image to the SD card, and then just upload and run different images for whatever you want to use it for, e.g.\r\n\r\n- Router\r\n- Media center\r\n- Home control\r\n- Teleporter",":+1: ",":+1: ",":+1: ",":thumbsup: ",":thumbsup:",":+1: ",":+1: gotta happen =)",":+1: ","This issue has received a lot of thumbs up because of all the attention and seems to be sending a lot of notifications to everyone who's watching the repository.\r\n\r\nPlease watch this issue instead.","+1",":+1: ",":+1: ","I'm working with a client that would love to use Docker in an ARM-based embedded environment; same chipset as the Beagle.\r\n\r\n:thumbsup: ","@rogaha is on it!","Maybe this could be added to the contrib directory and installed when setting up through vagrant.\r\n\r\nI wasn't sure where to put it, that's why I did a gist instead of a PR.","Nice! Very useful.\r\nLinked to #336 ","FYI the right kind of place for something like this would be the contrib/ directory. Thanks again!","Thanks, it was working a week ago, nice catch.","Hi,\r\n\r\nAgreed about `ApiContainer` and `ApiImage`.\r\n\r\nWhy not  moving the methods `call`, `stream` and `hijack` from commands.go to api_client.go ans use them ?\r\n\r\nAbout ListContainers, I also agree about not passing 4 arguments, I believe I prefer the reflect way.","Hi,\r\nI've changed ApiContainer and ApiImage, and changed queryString to use reflect.\r\n\r\nRegarding ``call``, ``stream`` and ``hijack``, I will add them to the client later today. I was trying to get the api right first.\r\n\r\nAnother naming issue: do you prefer APIClient or ApiClient?\r\n\r\nThanks!","I prefer APIClient, but it's up to you.","How about just `Client` in package `github.com/dotcloud/docker/client`?","sounds good to me.\r\n\r\n\r\nOn Wed, May 22, 2013 at 7:29 PM, Jonathan Rudenberg \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e How about just Client in package github.com/dotcloud/docker/client?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/640#issuecomment-18294285\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","And you can drop the `Api` prefix for everything if it's a separate package. Then external users can use it too.","I dislike the import path. Having a type ``Client`` inside a package ``client`` would force users of the package to write this kind of code:\r\n\r\n```\r\nimport \"github.com/dotcloud/docker/client\"\r\n\r\n...\r\n\r\ncl := client.NewClient(\"localhost:4243\")\r\n```\r\n\r\n``docker.NewClient(\"localhost:4243\")`` reads better, users would not ask themselves where that ``client`` namespace come from.\r\n\r\nOne of the points of this pull request is making the client usable for external users, so the import path is quite relevant.","Mixing the docker daemon and client bits in the same package feels really weird to me. These are also options (albeit not great):\r\n\r\n```\r\nimport docker \"github.com/dotcloud/docker/client\"\r\nimport \"github.com/dotcloud/docker/docker\"\r\n```\r\n\r\nIf the client is going to be the primary reason for importing the package, then it may make sense to move the non-client (daemon) stuff to a subdirectory, and just leave the client in the root.","I should add that a large part of my concern is that the godoc page that we point client users to should not include random parts of the daemon, just the client.","There is a third option: we can call the package ``docker`` and use the import path ``github.com/dotcloud/docker/client``, but that would be even worse.\r\n\r\nI like the idea of creating a new package for the daemon, but that would be a _larger_ change.","I don't actually have a problem with your third option, but it may be confusing for some.","I will go with the package ``docker`` in the import path ``github.com/dotcloud/docker/api-client``. It avoids some confusion (``api-client`` is not a valid package name, so it's a clue).","My 2 cents: as a developer my instinctive expectation would be to import something like \"docker/client\"\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 7:10 PM, Francisco Souza \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e I will go with the package ``docker`` in the import path ``github.com/dotcloud/docker/api-client``. It avoids some confusion (``api-client`` is not a valid package name, so it's a clue).\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/640#issuecomment-18318060","@shykes would you expect to use ``client.Client``, ``docker.Client`` (even importing \"docker/client\"), ``client.DockerClient`` or something else?","It would be nice to have a subpackage 'client' so, import docker/client and then use client.DockerClient\r\n\r\nThis should be an interface with client.dockerClient which implements it.\r\n\r\nThe CliDcoker struct should be in that subpackage.","@creack Why an interface? And I agree with @fsouza, having the package name be \"client\" is annoying when using it in non-docker code, as it's too generic.","client or dockerclient, I don't think it is really critical. Look at the 'json' package. It is alaso very generic and sometime a pain for variable names ^^.\r\n\r\nI'd like to have an interface to be a little bit like Go http client. Which is just an interface witht a default Client.\r\n\r\nThis way, it could allow anyone to use it in their program and to extend it at will for their specific needs.","@creack Can you make an example of what you're thinking for the interface? `http.Client` isn't an interface, it's a struct.","@creack regarding putting CliDocker in the new package, isn't the purpose of the package to provide an HTTP client for the Docker API?  Today, CliDocker is the client, but with this change, it will just be just a glue layer that parses command line arguments and invokes the HTTP client.\r\n\r\nReinforcing @titanous point: having CliDocker at godoc.org/github.com/dotcloud/docker/client would confuse users.","@fsouza I just think that CliDocker is client only, it has nothing to do with the server's code.\r\nWe could have a package client that has CliDocker and your new client which make it more convenient.\r\n\r\n@titanous I need to think about it ^^, I'll get back to you later. I don't remember what I wanted to do. Maybe just a struct would do the trick","@creack Sure, no worries. Remember that you can make an interface on the package user side that represents the Docker client and do DI for testing/mocking, etc.","@creack is CliDocker supposed to be reused in other packages? If the answer is no, I'd suggest moving it to the package main.","@fsouza do you need this reviewed for merge, or is it still work in progress?\r\n\r\n@vieux I'm re-assigning to you since you're the remote API maintainer.","@shykes sorry for the huge delay. Before asking for merge, I want to implement one or two other actions, and change code in commands to use the HTTP client. I'm doing it today.","@fsouza thanks","Okay, I believe the client package is now mergeable, but here come some problems from the integration with the CLI: currently, ``github.com/dotcloud/docker/client`` imports ``github.com/dotcloud/docker`` for the following types and constants:\r\n\r\n* VERSION: included in the User-Agent string\r\n* API_VERSION: used for URLs construction\r\n* ApiContainer: returned by ListContainers\r\n* Container: returned by InspectContainer\r\n\r\nFor now, I can just replicate them in the ``docker/client`` package, but that's bad. What do you think?\r\n\r\nIn the long term, we need a larger change:\r\n\r\n* move ApiContainer and Container to the client package (actually, I'd like to join these two types)\r\n* create another package that exports API_VERSION. This package would be imported by ``github.com/dotcloud/docker``  and ``github.com/dotcloud/docker/client``\r\n* receive the User-Agent string in the ``NewClient`` constructor. We can change it today.","@fsouza thanks, it's a good start but we won't merge until commands.go uses your client for every command, including stream and hijack\r\nNot sure about moving ApiContainer to the client package, as it's also used by the server to build responses\r\n","I'm sorry, I didn't write the motivation of my previous comment: it's impossible to use the Client in commands right now, because that would introduce a import cycle. ``github.com/dotcloud/docker/client`` **cannot** import ``github.com/dotcloud/docker``.\r\n\r\nShould I replicate ApiContainer, Container, VERSION and API_VERSION in the client package?\r\n\r\nMoving types to the client package does not mean that the server won't be able to use them to build responses, it just means that the server will have to use ApiContainer and Container from the client package.\r\n\r\nIdeally, the server would not import the client, and the client would not import the server, but that's not possible today because the server and the CLI are in the same package.","@fsouza Do you mind if we close this PR until it is ready to be submitted again?  It will really help us mange the amount of PRs and issues that we receive. ","@crosbymichael nope, I'm closing it :)\r\n\r\nThanks!","The 'failed to set flags' errors are about failing to use the metadata from the images downloaded from the registry.\r\nThis has been a known issue for non-EXT file systems. The images were prepared on EXT* and the metadata can only be restored on those file systems.\r\n\r\nYou'd have to prepare an image end to end on that system and then try out the possible fixes for AUFS.","#339 is related to this issue.","Thanks unclejack! That explains half of the issue. The other half is docker 'assumes'  certain underlying fs characteristics, in this case on /tmp. Given that docker 'depends' on /var/lib/docker, it might make sense to move there other dependencies (/tmp/.aufs.xino) so everything is in one place, and then check that /var/lib/docker underlying fs meets docker needs to start with.","We could fix the \"Failed to set file flags\" errors by extracting the images to a temporary ext4 file system and running rsync to move the files to their final location on the non-ext* FS.","I encountered the 'xino doesn't support /tmp/.aufs.xino(xfs)' issue. I managed to work around this with the following patch:\r\n\r\n    diff --git a/image.go b/image.go\r\n    index 342c0c9..71481ae 100644\r\n    --- a/image.go\r\n    +++ b/image.go\r\n    @@ -124,7 +124,7 @@ func MountAUFS(ro []string, rw string, target string) error {\r\n            for _, layer := range ro {\r\n                    roBranches += fmt.Sprintf(\"%v=ro+wh:\", layer)\r\n            }\r\n    -       branches := fmt.Sprintf(\"br:%v:%v\", rwBranch, roBranches)\r\n    +       branches := fmt.Sprintf(\"xino=/dev/shm/.aufs.xino,br:%v:%v\", rwBranch, roBranches)\r\n    \r\n            //if error, try to load aufs kernel module\r\n            if err := mount(\"none\", target, \"aufs\", 0, branches); err != nil {\r\n","Closing, please see #339 for followup","Just an extra datapoint.\r\n\r\nDocker version 0.8.1, build a1598d1 on a Debian Wheezy, on a 3.12-0.bpo.1-amd64, with 3.1.7+b1 xfsprogs, and I had to reboot to finally get the XFS unmounted, so I could reformat it as ext4.\r\n\r\nThere was no error message from docker, on a \"docker run\" client.go experienced a closed socket error from /var/run/docker...","/cc @mzdaniel can you take a look?","We are getting rid of the Makefile very shortly in favor of a docker build\r\n+ simple shell scripts. These scripts will rely on the container to setup\r\nGOPATH correctly. I don't think it's worth fixing this problem in the\r\nmeantime. Closing.\r\n\r\n\r\nOn Wed, Jul 24, 2013 at 10:43 AM, Guillaume J. Charmes \u003c\r\nnotifications@github.com\u003e wrote:\r\n\r\n\u003e /cc @mzdaniel \u003chttps://github.com/mzdaniel\u003e can you take a look?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/642#issuecomment-21502494\u003e\r\n\u003e .\r\n\u003e","Hi, I'm having the same problem, but after a kill on the docker daemon. All my containers (that I didn't stopped before killing docker) are presenting this problem.\r\n\r\nI was able to remove the containers moving all the files to another folder and renaming it (all files but the corrupted rootfs).\r\n\r\nDoes anyone have news on that?","@creack @victor have you been able to reproduce? Can we close or is this still in the wild?","@shykes I had this issue as well, but let me run a quick test to see if I can reproduce this on the latest version.\r\n\r\nUpdate:\r\nI was not able to reproduce this issue this time. The last time it happened is when I upgraded docker to 0.4.0 (during the daemon restart).\r\n\r\nJust now, I tortured the docker daemon (ghosting some containers in the process), but nothing I did caused the stale NFS issue. ","Unable to reproduce either. Closing.","Just encountered this also.  That's at least three reports and who knows how many unreported.\r\n\r\n\"Works for me\" is neither scientific nor a solution, and merely hurts a project's customer experience.  Even if it's FOSS, this still reflects on dotCloud and maintainers.\r\n\r\nI can give you a VM with this issue exactly as-is.","You're right @steakknife this should not be closed. Thanks for catching.","The VM (Fusion vmdk, should work with Workstation and ESXi) is suspended with this issue.\r\n\r\nIt's using ZoL ZFS for /var/lib/docker, which may or may not be a contributing factor.   NFS attribute for this ZVOL is disabled.\r\n\r\nAgain, I'll extend an offer upload this 9 GiB to mega if you'd like.  It's 100% clean-room sterile: no proprietary SSH keys or passwords, any customer data or IP.  Just a plain ol' Ubuntu box.\r\n\r\nThis is a show-stopper for us.","The VM (Fusion vmdk, should work with Workstation and ESXi) is suspended with this issue.\r\n\r\nIt's using ZoL ZFS for /var/lib/docker, which may or may not be a contributing factor.   NFS attribute for this ZVOL is disabled.\r\n\r\nAgain, I'll extend an offer upload this 9 GiB to mega if you'd like.  It's 100% clean-room sterile: no proprietary SSH keys or passwords, any customer data or IP.  Just a plain ol' Ubuntu box.\r\n\r\nThis is a show-stopper for us.","My apologies if I came across vociferous.  I'm only familiar with ridiculously awesome support from either side of the proverbial table.\r\n—\r\nSent from Mailbox for iPhone\r\n\r\nOn Mon, Jul 29, 2013 at 6:05 AM, Solomon Hykes \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e You're right @steakknife this should not be closed. Thanks for catching.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/643#issuecomment-21718171","Same issue today:\r\n\r\n```\r\nroot@dscape:~# docker ps -a\r\nID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\r\nb7ac0d3f3f79        b7814e399268        /bin/bash -c couchdb   About an hour ago   Exit 137\r\n7329c9be9795        b7814e399268        /bin/bash -c couchdb   About an hour ago   Exit 137\r\n3475243bbebb        90f93a5fc5e9        /bin/bash -c /start    21 hours ago        Up 21 hours         49154-\u003e49154\r\nfe2fc92e5d5b        app/tiny:latest     /bin/bash -c /start    22 hours ago        Up 22 hours         49153-\u003e49153\r\nroot@dscape:~# docker rm b7ac0d3f3f79\r\nError: Error destroying container b7ac0d3f3f79: stat /var/lib/docker/containers/b7ac0d3f3f79ae35883d09e796332726322e56bdd715e5484210bf84099cc513/rootfs: stale NFS file handle\r\n\r\nroot@dscape:~#\r\nroot@dscape:~# docker rm 7329c9be9795\r\nError: Error destroying container 7329c9be9795: stat /var/lib/docker/containers/7329c9be97957b187cdb6cbb825ab506e3a8610c01b4055ad5cc64fc58a6e985/rootfs: stale NFS file handle\r\n```\r\n\r\nVersion info:\r\n\r\n```\r\nroot@dscape:~# docker version\r\nClient version: 0.4.8\r\nServer version: 0.4.8\r\nGit commit: ??\r\nGo version: go1.1.1\r\n```","What does \"mount\" output look like?\r\n—\r\nSent from Mailbox for iPhone\r\n\r\nOn Wed, Jul 31, 2013 at 5:48 PM, Nuno Job \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Same issue today:\r\n\u003e ```\r\n\u003e root@dscape:~# docker ps -a\r\n\u003e ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\r\n\u003e b7ac0d3f3f79        b7814e399268        /bin/bash -c couchdb   About an hour ago   Exit 137\r\n\u003e 7329c9be9795        b7814e399268        /bin/bash -c couchdb   About an hour ago   Exit 137\r\n\u003e 3475243bbebb        90f93a5fc5e9        /bin/bash -c /start    21 hours ago        Up 21 hours         49154-\u003e49154\r\n\u003e fe2fc92e5d5b        app/tiny:latest     /bin/bash -c /start    22 hours ago        Up 22 hours         49153-\u003e49153\r\n\u003e root@dscape:~# docker rm b7ac0d3f3f79\r\n\u003e Error: Error destroying container b7ac0d3f3f79: stat /var/lib/docker/containers/b7ac0d3f3f79ae35883d09e796332726322e56bdd715e5484210bf84099cc513/rootfs: stale NFS file handle\r\n\u003e root@dscape:~#\r\n\u003e root@dscape:~# docker rm 7329c9be9795\r\n\u003e Error: Error destroying container 7329c9be9795: stat /var/lib/docker/containers/7329c9be97957b187cdb6cbb825ab506e3a8610c01b4055ad5cc64fc58a6e985/rootfs: stale NFS file handle\r\n\u003e ```\r\n\u003e Version info:\r\n\u003e ```\r\n\u003e root@dscape:~# docker version\r\n\u003e Client version: 0.4.8\r\n\u003e Server version: 0.4.8\r\n\u003e Git commit: ??\r\n\u003e Go version: go1.1.1\r\n\u003e ```\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/643#issuecomment-21907147","Same issue here:\r\n\r\n```\r\n$ docker ps -a\r\nID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\r\n8b09aa62d6c2        84e9c7681ae3        /srv/etcd/bin/etcd -   8 minutes ago       Exit 2\r\n\r\n$ docker rm 8b09aa62d6c2\r\nError: Error destroying container 8b09aa62d6c2: stat /var/lib/docker/containers/8b09aa62d6c21b3455ca095dc4258eb3d8c266d26513fc4945cd50e8ba874977/rootfs: stale NFS file handle\r\n\r\n$ mount\r\n/dev/xvda1 on / type ext4 (rw)\r\nproc on /proc type proc (rw,noexec,nosuid,nodev)\r\nsysfs on /sys type sysfs (rw,noexec,nosuid,nodev)\r\nnone on /sys/fs/fuse/connections type fusectl (rw)\r\nnone on /sys/kernel/debug type debugfs (rw)\r\nnone on /sys/kernel/security type securityfs (rw)\r\nudev on /dev type devtmpfs (rw,mode=0755)\r\ndevpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)\r\ntmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)\r\nnone on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)\r\nnone on /run/shm type tmpfs (rw,nosuid,nodev)\r\ncgroup on /sys/fs/cgroup type tmpfs (rw,relatime,mode=755)\r\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)\r\ncgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)\r\n/dev/xvda2 on /mnt type ext3 (rw)\r\n```","I'm seeing this as well - both in vagrant boxes on a laptop that has woken from sleep and on a server that has been up since I rebooted to bring the 3.8 kernel on line. The lsof output is new information, the rest is duplicates of what's been reported already.\r\n\r\n ✓ ⚡ ( 03:29:08 ) ⦿ root@vststaff\r\n  ~  uname -a\r\nLinux vststaff 3.8.0-27-generic #40~precise3-Ubuntu SMP Fri Jul 19 14:38:30 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\r\n ✓ ⚡ ( 03:29:19 ) ⦿ root@vststaff\r\n  ~  lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 12.04.2 LTS\r\nRelease:\t12.04\r\nCodename:\tprecise\r\n ✓ ⚡ ( 03:29:22 ) ⦿ root@vststaff\r\n  ~  alias dpa\r\ndpa='docker ps -a'\r\n ✓ ⚡ ( 03:29:30 ) ⦿ root@vststaff\r\n  ~  alias dcu\r\ndcu='docker ps -a|grep Exit| awk '\\''{print $1}'\\''|xargs docker rm'\r\n ✓ ⚡ ( 03:29:33 ) ⦿ root@vststaff\r\n  ~  dpa\r\nID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\r\nf3db7deb21ac        7f52e099ddb4        /bin/sh -c apt-get i   58 minutes ago      Exit 0\r\n4d6434477a13        52ab5d87fe8f        /bin/sh -c echo \"deb   58 minutes ago      Exit 0\r\n209ea8d5f82a        0bc1882c22b6        /bin/sh -c apt-get -   58 minutes ago      Exit 0\r\n9edbb8cfd199        52683385c7c1        /bin/sh -c apt-get i   59 minutes ago      Exit 0\r\nd95db9f81af5        8ea23905d9cc        /bin/sh -c echo \"deb   About an hour ago   Exit 0\r\n34909a13f171        1dccb256af50        /bin/sh -c apt-get -   About an hour ago   Exit 0\r\n4c7408ebd8ed        54ce31b8e28f        /bin/sh -c echo \"deb   About an hour ago   Exit 0\r\n5ed85984a2ab        fc96ecd8ab7e        /bin/sh -c apt-get -   About an hour ago   Exit 0\r\n ✓ ⚡ ( 03:29:35 ) ⦿ root@vststaff\r\n  ~  dcu\r\nError: Error destroying container f3db7deb21ac: stat /var/lib/docker/containers/f3db7deb21ac8c2882ec81d9e1e65e1b5ec78385485a322b604e84d628edca24/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 4d6434477a13: stat /var/lib/docker/containers/4d6434477a13770c456b74c063d63ca5404512a46d376e2b41fd5011f498afe4/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 209ea8d5f82a: stat /var/lib/docker/containers/209ea8d5f82aea9c0466343e9987f3981d2355ebadf89fd2a9fb9f3c4a82e8b8/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 9edbb8cfd199: stat /var/lib/docker/containers/9edbb8cfd199a99b503160528d3e5f7df290305f4fe098254179fd7e4ba18dd6/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container d95db9f81af5: stat /var/lib/docker/containers/d95db9f81af5f9b48fc8f2c34e31e190c2d609d0312dc618a62c9d430c952e34/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 34909a13f171: stat /var/lib/docker/containers/34909a13f171d663e5025e822ec293bb3287c5ff73db3d2a14b1660f98fa5d25/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 4c7408ebd8ed: stat /var/lib/docker/containers/4c7408ebd8ed1e5410d83fd54be220a8383f4d8059224baafb499e3a3dc0bcb3/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 5ed85984a2ab: stat /var/lib/docker/containers/5ed85984a2abb22ee44b5e59154d32a040e30d5699d330bb77a80951d40bbb4a/rootfs: stale NFS file handle\r\n\r\n ✓ ⚡ ( 03:29:36 ) ⦿ root@vststaff\r\n  ~  lsof|grep rootfs\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/5ed85984a2abb22ee44b5e59154d32a040e30d5699d330bb77a80951d40bbb4a/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/4c7408ebd8ed1e5410d83fd54be220a8383f4d8059224baafb499e3a3dc0bcb3/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/34909a13f171d663e5025e822ec293bb3287c5ff73db3d2a14b1660f98fa5d25/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/d95db9f81af5f9b48fc8f2c34e31e190c2d609d0312dc618a62c9d430c952e34/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/9edbb8cfd199a99b503160528d3e5f7df290305f4fe098254179fd7e4ba18dd6/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/209ea8d5f82aea9c0466343e9987f3981d2355ebadf89fd2a9fb9f3c4a82e8b8/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/4d6434477a13770c456b74c063d63ca5404512a46d376e2b41fd5011f498afe4/rootfs\r\n      Output information may be incomplete.\r\nlsof: WARNING: can't stat() aufs file system /var/lib/docker/containers/f3db7deb21ac8c2882ec81d9e1e65e1b5ec78385485a322b604e84d628edca24/rootfs\r\n      Output information may be incomplete.\r\n ✘ ⚡ ( 03:29:50 ) ⦿ root@vststaff\r\n  ~  mount\r\n/dev/mapper/vststaff-root on / type ext4 (rw,errors=remount-ro)\r\nproc on /proc type proc (rw,noexec,nosuid,nodev)\r\nsysfs on /sys type sysfs (rw,noexec,nosuid,nodev)\r\nnone on /sys/fs/fuse/connections type fusectl (rw)\r\nnone on /sys/kernel/debug type debugfs (rw)\r\nnone on /sys/kernel/security type securityfs (rw)\r\nudev on /dev type devtmpfs (rw,mode=0755)\r\ndevpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)\r\ntmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)\r\nnone on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)\r\nnone on /run/shm type tmpfs (rw,nosuid,nodev)\r\n/dev/sda1 on /boot type ext2 (rw)\r\nrpc_pipefs on /run/rpc_pipefs type rpc_pipefs (rw)\r\n172.18.61.37:/ifs/VST/vitalsource on /mnt/vitalsource type nfs (rw,noatime,nfsvers=3,rsize=32768,wsize=32768,intr,addr=172.18.61.37)\r\ncgroup on /sys/fs/cgroup type tmpfs (rw,uid=0,gid=0,mode=0755)\r\n\r\nVersion info:\r\n\r\n ✓ ⚡ ( 03:34:06 ) ⦿ root@vststaff\r\n  ~  docker version\r\nClient version: 0.5.1\r\nServer version: 0.5.1\r\nGo version: go1.1\r\n","Just adding that I'm seeing this as well. Steps to reproduce -\r\n\r\n* Launch Ubuntu 12.04 instance store AMI\r\n* ```apt-get update \u0026\u0026 apt-get dist-upgrade \u0026\u0026 apt-get install linux-image-generic-lts-raring linux-headers-generic-lts-raring```\r\n*  run script from get.docker.io\r\n* Create an image from a Dockerfile. I used something like this:\r\n\r\n```\r\nFROM ubuntu:12.04\r\nMAINTAINER Ben Whaley \r\nRUN apt-get install -y libmysqlclient-dev python-dev libxml2-dev libxslt-dev\r\nRUN apt-get install -y python-setuptools\r\nRUN easy_install pip\r\nADD local-tarball /remotedir\r\n```\r\n* ```docker -H localhost:8080 build -t my:image .```\r\n* Image builds successfully\r\n* Remove some of the resulting containers:\r\n\r\n```\r\ndocker -H localhost:8080 rm 26520b7ce8e7\r\n\r\nError: Error destroying container 26520b7ce8e7: stat \r\n/var/lib/docker/containers/26520b7ce8e79d511b095f8c85137df6056f03f0c24ea278520e5849aec94207/rootfs: stale \r\nNFS file handle\r\n```\r\n\r\nHappy to provide further debug/diagnostic info if that's useful.","@steakknife: I realize that it's been 15 days now, but do you happen to still have that snapshot around? (I'll still have to find a way to run it since I don't have VMWare here, but hopefully it won't be too complicated to set it up on my local box).\r\n\r\n@bwhaley: couldn't reproduce the issue with the steps you indicated; do they reproduce the bug each and every time for you?\r\n","Ahh, so I think it's really a user error, at least in my case. The ```stale NFS file handle``` error shows up if the images are deleted before the containers. ","Perhaps docker should prevent that from happening? i.e. not allow deletion of images that still have containers attached?","Same here. Not sure if it's related or easy to reproduce but in my case I was trying to build an image from a Dockerfile: it failed a few times before the end of the build because of a failing RUN command in the Dockerfile:\r\n1. after the 'docker build' failed I ran new container /bin/bash from the incomplete image to check/test what failed\r\n2. after that I removed the incomplete images (docker rmi)\r\n3. and now that my Dockerfile is debugged I'm cleaning the containers (docker rm) and I'm having errors for some of them (that were created from removed intermediary images).\r\n\r\nHope it helps!\r\n\r\nSome bash history showing the result before and after the cleanup of my containers:\r\n```shell\r\nvagrant@precise64:~$ docker ps -a\r\nID                  IMAGE                                 COMMAND                CREATED             STATUS              PORTS\r\n3d7c256bccc6        1d1462169f84                          /bin/sh -c #(nop) CM   4 minutes ago       Exit 0                                  \r\nb4cb22b1ef74        f162d989cebe                          /bin/sh -c #(nop) EX   4 minutes ago       Exit 0                                  \r\n704590aa77f2        fe5c707655a6                          /bin/sh -c cd /srv/t   9 minutes ago       Exit 0                                  \r\n11dbafe42b51        e9c63b58f321                          /bin/sh -c apt-get c   9 minutes ago       Exit 0                                  \r\n51bf064d703e        3d00715cc5da                          /bin/sh -c apt-get i   13 minutes ago      Exit 0                                  \r\n49bfaf58e265        2273bf793a1d                          /bin/sh -c cd /tmp/T   14 minutes ago      Exit 0                                  \r\n6c42e092f8d5        9ae8050e2591                          /bin/sh -c cd /tmp \u0026   14 minutes ago      Exit 0                                  \r\n6dabd929f9e5        8d0d4e1cc2ff                          /bin/sh -c cd /srv \u0026   14 minutes ago      Exit 0                                  \r\nab3dc1edf3c4        52aff0650680                          /bin/sh -c apt-get i   16 minutes ago      Exit 0                                  \r\n4c7ed5b01d41        e73482034aee                          /bin/sh -c apt-get u   17 minutes ago      Exit 0                                  \r\n6ddb1caa5ba8        c96ab34e5b92                          /bin/sh -c echo \"deb   17 minutes ago      Exit 0                                  \r\nd40e1b6bbc0a        ubuntu:12.04                          /bin/sh -c #(nop) MA   17 minutes ago      Exit 0                                  \r\n9e25cc8aec01        02ed5da0372a                          /bin/bash              21 minutes ago      Exit 1                                  \r\ncc881594319b        02ed5da0372a                          /bin/sh -c cd /tmp/T   23 minutes ago      Exit 1                                  \r\n0d95d8f0b0f3        71a47b6fc487                          /bin/sh -c cd /tmp \u0026   23 minutes ago      Exit 0                                  \r\n2a32ebc729c3        7fbc94013e5d                          /bin/sh -c cd /srv \u0026   23 minutes ago      Exit 0                                  \r\nc70e77c0f184        69c2b0ee4730                          /bin/sh -c apt-get i   25 minutes ago      Exit 0                                  \r\n6add2b585dfd        89a5a3e883db                          /bin/sh -c apt-get u   26 minutes ago      Exit 0                                  \r\n521f6d9854a8        b57638058bed                          /bin/sh -c echo \"deb   26 minutes ago      Exit 0                                  \r\n2e777a75153f        ubuntu:12.04                          /bin/sh -c #(nop) MA   26 minutes ago      Exit 0                                  \r\n2db4af6a8f79        8a2e8070a7f4                          /bin/bash              42 minutes ago      Exit 0                                  \r\na3ffadfc0542        8a2e8070a7f4                          /bin/sh -c curl http   48 minutes ago      Exit 1                                  \r\n597f2f723d02        7c5966b385b8                          /bin/sh -c apt-get i   50 minutes ago      Exit 0                                  \r\n53b30ce84576        5918fdab3d75                          /bin/sh -c apt-get u   50 minutes ago      Exit 0                                  \r\nacdd012245dc        caca567bfe56                          /bin/sh -c echo \"deb   50 minutes ago      Exit 0                                  \r\nb488cfde1d2c        ubuntu:12.04                          /bin/sh -c #(nop) MA   50 minutes ago      Exit 0                                  \r\n3f040b7dfc98        fc571870513f                          /bin/bash              52 minutes ago      Exit 0                                  \r\n0848fc45f13a        fc571870513f                          /bin/sh -c curl http   56 minutes ago      Exit 1                                  \r\n5904f1376489        df04e74e5bf6                          /bin/sh -c apt-get i   57 minutes ago      Exit 0                                  \r\n9f5c25defe51        61072b897f49                          /bin/sh -c apt-get u   58 minutes ago      Exit 0                                  \r\n2ab7a81ffe74        eeceb7a4e6db                          /bin/sh -c echo \"deb   58 minutes ago      Exit 0                                  \r\ne49fd9c35665        ubuntu:12.04                          /bin/sh -c #(nop) MA   58 minutes ago      Exit 0                                  \r\n809969c767c5        6e88c063fada                          /bin/bash              About an hour ago   Exit 130                                \r\naf84559fed09        6e88c063fada                          /bin/sh -c curl http   About an hour ago   Exit 1                                  \r\ne68dd250f468        73ca6995473b                          /bin/sh -c cd /srv/t   About an hour ago   Exit 0                                  \r\n259c5120eaed        e9d578ad6ace                          /bin/sh -c cd /srv \u0026   About an hour ago   Exit 0                                  \r\n86ff361cd090        c6b7447759c9                          /bin/sh -c apt-get c   About an hour ago   Exit 0                                  \r\ndb7a930ad6fd        65330e070f61                          /bin/sh -c apt-get i   About an hour ago   Exit 0                                  \r\ndc753a7762f5        1953fd1d62fe                          /bin/sh -c apt-get u   About an hour ago   Exit 0                                  \r\nab34404a5475        fbaefc5bdbc5                          /bin/sh -c echo \"deb   About an hour ago   Exit 0                                  \r\ne7ebc194184e        ubuntu:12.04                          /bin/sh -c #(nop) MA   About an hour ago   Exit 0                                  \r\n572012c079af        ubuntu:12.04                          /bin/bash              2 hours ago         Exit 0                                  \r\n547115acceaa        sguignot/test-py-rest-server:latest   /bin/bash              8 hours ago         Exit 0                                  \r\nba3b3bc1f31b        sguignot/test-py-rest-server:latest   python /mnt/REST-tut   15 hours ago        Exit -127           49165-\u003e5000         \r\n\r\nvagrant@precise64:~$ docker ps -a | grep Exit | cut -d' ' -f1 | xargs docker rm\r\nError: Error destroying container 0d95d8f0b0f3: stat /var/lib/docker/containers/0d95d8f0b0f36673b2b842259abf59d1736609ed517f323322cde1eae4ea1f87/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 2a32ebc729c3: stat /var/lib/docker/containers/2a32ebc729c3bb23da04d40ca52d800d803f88db30915f9ac6565dd866ba7c4f/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container c70e77c0f184: stat /var/lib/docker/containers/c70e77c0f1840f391af4676853d161d8a1575499a410589f4b728bab0c211a1a/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 6add2b585dfd: stat /var/lib/docker/containers/6add2b585dfd421c72359384c12da7ddfca8eab42df708be91e8921bafa9981f/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 521f6d9854a8: stat /var/lib/docker/containers/521f6d9854a86b069450cab2d15230ee920562f4269a29bc845fd20fed304014/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 597f2f723d02: stat /var/lib/docker/containers/597f2f723d02dfb39cba347ee7cc5277e64740cab58f1b074ab8e308ffe6cd16/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 53b30ce84576: stat /var/lib/docker/containers/53b30ce84576140858f724d37bf2613dd205fa1829170773125cfc01f038b988/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container acdd012245dc: stat /var/lib/docker/containers/acdd012245dc03546be2d8dad51707e89fe2360a96cef4986b883e9b7118dd8c/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 5904f1376489: stat /var/lib/docker/containers/5904f137648937dfa374a96c2796a5c2275b85a3a96668f701dc7ca858043e43/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 9f5c25defe51: stat /var/lib/docker/containers/9f5c25defe51e823a5061c81ae47cdf6bcb34d961d2ad7d7c3482b7d9fac6641/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 2ab7a81ffe74: stat /var/lib/docker/containers/2ab7a81ffe74fd381241858a58d0663b4a118f785e2dcbfb60d6def360dd4afe/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container e68dd250f468: stat /var/lib/docker/containers/e68dd250f4688afb9002e38996161fe9ec749fa5e4117f44fe69e67eaf5097f6/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 259c5120eaed: stat /var/lib/docker/containers/259c5120eaed8b2125c26d1475e34186adf9e40891ab08781cd4a77d9d34e7b0/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container 86ff361cd090: stat /var/lib/docker/containers/86ff361cd090825f471b46b68c3f63392f1e7dde0f2d45dc4fde2fb8c7137ea9/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container db7a930ad6fd: stat /var/lib/docker/containers/db7a930ad6fd6c6d148663eb99d247a54785f438bcd428ae57d6e1e790594185/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container dc753a7762f5: stat /var/lib/docker/containers/dc753a7762f575b83798e6a85c0b62b4a4f21c6bef382b6d3d050ae512375ff0/rootfs: stale NFS file handle\r\n\r\nError: Error destroying container ab34404a5475: stat /var/lib/docker/containers/ab34404a54752821079c19631109bcd9066d5f2889c426f9bfef0ee6c972064c/rootfs: stale NFS file handle\r\n\r\nvagrant@precise64:~$ docker ps -a\r\nID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\r\n66ab63549afb        55c15482cf09        python /srv/textblob   2 hours ago         Up 2 hours          49154-\u003e5000         \r\n0d95d8f0b0f3        71a47b6fc487        /bin/sh -c cd /tmp \u0026   2 hours ago         Exit 0                                  \r\n2a32ebc729c3        7fbc94013e5d        /bin/sh -c cd /srv \u0026   2 hours ago         Exit 0                                  \r\nc70e77c0f184        69c2b0ee4730        /bin/sh -c apt-get i   2 hours ago         Exit 0                                  \r\n6add2b585dfd        89a5a3e883db        /bin/sh -c apt-get u   2 hours ago         Exit 0                                  \r\n521f6d9854a8        b57638058bed        /bin/sh -c echo \"deb   2 hours ago         Exit 0                                  \r\n597f2f723d02        7c5966b385b8        /bin/sh -c apt-get i   3 hours ago         Exit 0                                  \r\n53b30ce84576        5918fdab3d75        /bin/sh -c apt-get u   3 hours ago         Exit 0                                  \r\nacdd012245dc        caca567bfe56        /bin/sh -c echo \"deb   3 hours ago         Exit 0                                  \r\n5904f1376489        df04e74e5bf6        /bin/sh -c apt-get i   3 hours ago         Exit 0                                  \r\n9f5c25defe51        61072b897f49        /bin/sh -c apt-get u   3 hours ago         Exit 0                                  \r\n2ab7a81ffe74        eeceb7a4e6db        /bin/sh -c echo \"deb   3 hours ago         Exit 0                                  \r\ne68dd250f468        73ca6995473b        /bin/sh -c cd /srv/t   3 hours ago         Exit 0                                  \r\n259c5120eaed        e9d578ad6ace        /bin/sh -c cd /srv \u0026   3 hours ago         Exit 0                                  \r\n86ff361cd090        c6b7447759c9        /bin/sh -c apt-get c   3 hours ago         Exit 0                                  \r\ndb7a930ad6fd        65330e070f61        /bin/sh -c apt-get i   3 hours ago         Exit 0                                  \r\ndc753a7762f5        1953fd1d62fe        /bin/sh -c apt-get u   3 hours ago         Exit 0                                  \r\nab34404a5475        fbaefc5bdbc5        /bin/sh -c echo \"deb   3 hours ago         Exit 0                                  \r\nvagrant@precise64:~$ docker ps -a | grep Exit | awk '!/ID/ {print $2}' | sort\r\n1953fd1d62fe\r\n5918fdab3d75\r\n61072b897f49\r\n65330e070f61\r\n69c2b0ee4730\r\n71a47b6fc487\r\n73ca6995473b\r\n7c5966b385b8\r\n7fbc94013e5d\r\n89a5a3e883db\r\nb57638058bed\r\nc6b7447759c9\r\ncaca567bfe56\r\ndf04e74e5bf6\r\ne9d578ad6ace\r\neeceb7a4e6db\r\nfbaefc5bdbc5\r\nvagrant@precise64:~$ docker images\r\nREPOSITORY                     TAG                 ID                  CREATED             SIZE\r\nbusybox                        latest              e9aa60c60128        4 months ago        6.825 MB (virtual 6.825 MB)\r\npython_test                    latest              c874393b4a1a        26 hours ago        12.29 kB (virtual 564.7 MB)\r\nsguignot/test-py-rest-server   latest              fdca7c1ad627        18 hours ago        19.46 kB (virtual 331.5 MB)\r\nshykes/pybuilder               latest              370fed31f16a        4 months ago        28.82 kB (virtual 559 MB)\r\nubuntu                         12.04               8dbd9e392a96        4 months ago        131.5 MB (virtual 131.5 MB)\r\nubuntu                         12.10               b750fe79269d        4 months ago        24.65 kB (virtual 180.1 MB)\r\nubuntu                         latest              8dbd9e392a96        4 months ago        131.5 MB (virtual 131.5 MB)\r\nubuntu                         precise             8dbd9e392a96        4 months ago        131.5 MB (virtual 131.5 MB)\r\nubuntu                         quantal             b750fe79269d        4 months ago        24.65 kB (virtual 180.1 MB)\r\nsguignot/textblob-api-server   latest              66c7e31b8cd7        2 hours ago         12.29 kB (virtual 768.2 MB)\r\nvagrant@precise64:~$ docker images | awk '!/ID/ {print $3}' | sort\r\n370fed31f16a\r\n66c7e31b8cd7\r\n8dbd9e392a96\r\n8dbd9e392a96\r\n8dbd9e392a96\r\nb750fe79269d\r\nb750fe79269d\r\nc874393b4a1a\r\ne9aa60c60128\r\nfdca7c1ad627\r\n```","FYI Restarting the VM using \"vagrant reload\" fixed the issue (I'm using a VirtualBox ubuntu VM since I'm running Mac OS X).\r\n```shell\r\nvagrant@precise64:~$ docker ps -a | grep Exit | cut -d' ' -f1 | xargs docker rm\r\n0d95d8f0b0f3\r\n2a32ebc729c3\r\nc70e77c0f184\r\n6add2b585dfd\r\n521f6d9854a8\r\n597f2f723d02\r\n53b30ce84576\r\nacdd012245dc\r\n5904f1376489\r\n9f5c25defe51\r\n2ab7a81ffe74\r\ne68dd250f468\r\n259c5120eaed\r\n86ff361cd090\r\ndb7a930ad6fd\r\ndc753a7762f5\r\nab34404a5475\r\nvagrant@precise64:~$ docker ps -a\r\nID                  IMAGE               COMMAND                CREATED             STATUS              PORTS\r\n66ab63549afb        55c15482cf09        python /srv/textblob   2 hours ago         Up 2 minutes        49153-\u003e5000         \r\n\r\n```","I had this same issue when running Docker on a 12.04 server. Rebooting the system resolved the issue.","@jpetazzo  I'm uploading it finally, after somehow missing your reply.  Yup, it's all my fault.\r\n    \r\n(edited) \r\n\r\nETA 7:10 pm Pacific","https://mega.co.nz/#F!WpwxkY5b!KHqdzQJkBx8tipoqfltW7g  (Dummy mega account, obviously)","If you are of the type to \"try before you buy,\" this looks completely legit:\r\nhttp://pastebin.com/3z3wigEJ","If you have a Linux or Windows box the VMware Workstation 10 Technology Preview is free until October 15th:\r\n\r\nhttps://communities.vmware.com/community/vmtn/beta/workstation_2013","Yup that works.  https://www.vmware.com/products/player/   Player ({L,W}in) is free, haven't tried it recently.","Downloading the thing. Will see how it goes.","@steakknife: sorry, but Chrome keeps crashing while downloading the VM image from mega.co.nz. I'm giving it a last try (it download a few gigs each time, then crashes), but is there a better way to download stuff from there?","I have a similar issue. Not sure if it's related to the strider/strider image failing to download.\r\n\r\n```\r\nClient version: 0.5.3\r\nServer version: 0.5.3\r\nGo version: go1.1\r\n```","Same issue here am running docker 0.5.3 and 12.04 Ubuntu on Vagrant Virtualbox (windows 7 host).\r\n\r\nAs soon as I restarted the vagrant (on a windows 7 host) - then I could:\r\n\r\n```bash\r\ndocker rm `docker ps -a -q`\r\n```\r\n\r\nIt chugged through very happy - before the restart it had the same 'stale NFS file handle' error.","A fix is being discussed on the dev mailing list. This is scheduled for 0.7.","Thank you.","@vieux can you confirm this is no longer available? If it isn't, I'll merge the PR. Thanks.","gool","@kencochrane You can merge, it's not available anymore.","Thank you.","Happy to help :)","@rvanlaar What version of Go are you using? You can use ```go version``` to find out what version of Go you're using.\r\n\r\nThere's a bug in Go 1.0.2 (and probably in older versions as well) which is being triggered by some HTTP headers.\r\nThis isn't a bug in Docker itself.","I am running Go 1.0.2. An upgrade to go 1.1 fixed it. Thanks.","good idea, but https://get.docker.io doesn't seem to be working. \r\n\r\nget.docker.io is mapped to an s3 bucket, and ssl doesn't work for that bucket with that url.\r\n\r\nWe could use https://get.docker.io.s3-website-us-east-1.amazonaws.com/ but that is too long, and it also has another issue. Because the bucket name has \".\" in it, the ssl certificate for s3 doesn't work because it thinks they are subdomains and they need their own SSL.\r\n\r\nhttp://stackoverflow.com/questions/3048236/amazon-s3-https-ssl-is-it-possible\r\nhttp://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html\r\n\r\nSo for now, we won't be able to merge this PR.\r\n\r\n/cc @jpetazzo - in case he has any other ideas.","No other idea for now :-(\r\nWe could arrange for the docker binary to be signed; but I don't know if there is a convenient way to sign a shell script!\r\nAt some point (maybe now?), we'll probably want to move get.docker.io off S3.","In short, yep.\r\n\r\nWhile I totally sympathise with the convenience of S3, I was pretty shocked to see this. You're in a position of trust, and DNS poisoning attacks (especially in the contexts where users might be installing this- like a hackathon) are trivial.\r\n\r\nIn the very short term, a pair of small instances running varnish with route53 and some ELB's would deal with the issue with a slight monetary overhead. I'd offer to help you set it up, but given that you're working on docker it seems a safe assumption that you're on the case :smile:","We could move this over to dotcloud easy enough.. @jpetazzo what else is on the get.docker.io repo, would it be a problem if it was a static site on dotcloud instead?","If we're going to host it, the rule is that it should run on docker :)\r\n\r\n\r\n-\u003e dogfood time!\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 8:40 AM, Ken Cochrane \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e We could move this over to dotcloud easy enough.. @jpetazzo what else is on the get.docker.io repo, would it be a problem if it was a static site on dotcloud instead?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/648#issuecomment-18282841","@shykes ok, where are the docker servers I can install it on?","I'll email you the credentials.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 9:00 AM, Ken Cochrane \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @shykes ok, where are the docker servers I can install it on?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/648#issuecomment-18284310","Where is the code for get.docker.io ?\r\n\r\nThe install script uses the http url and get.docker, which could at least be using SSL. If you can point me to it I'll open a PR.\r\n\r\nAll this plaintext (And blaze attitude to security) is pretty concerning. I'd love to work with you guys to get it a bit more inline with best practice.","Hi Richo,\r\n\r\n\r\nYou'll find it in contrib/install.sh. Thanks for offering. get.docker.io points to an s3 bucket which has limitation preventing us from using ssl.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sat, May 25, 2013 at 12:39 AM, Richo Healey \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Where is the code for get.docker.io ?\r\n\u003e The install script uses the http url and get.docker, which could at least be using SSL. If you can point me to it I'll open a PR.\r\n\u003e All this plaintext (And blaze attitude to security) is pretty concerning. I'd love to work with you guys to get it a bit more inline with best practice.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/648#issuecomment-18441185","I'm afraid that this won't work, unfortunately!\r\nI think we have two choices:\r\n- move https://get.docker.io/ to our own servers\r\n- move the install URL to something like https://getdocker.s3.amazonaws.com/ (not very sexy, indeed)\r\n\r\nI'll see what's involved for solution 1.","http://aws.typepad.com/aws/2013/06/custom-ssl-domain-names-root-domain-hosting-for-amazon-cloudfront.html","Hey @jpetazzo and @richo, same comment as for #717. If this requires changes to the project infrastructure, we should close this PR until the infrastructure allows for it.\r\n\r\nCan you let me know what we should do? I want to avoid leaving PRs in a deadlock state where everyone is waiting on everyone :)","There is an alternate URL that works with buckets that have dots in their names: https://s3.amazonaws.com/get.docker.io/\r\n\r\nExample complete URL: https://s3.amazonaws.com/get.docker.io/builds/Darwin/x86_64/docker-master.tgz","@kencochrane, should we close this ?","Hm.. I'd rather see this updated with the new HTTPS URL style - is that something @richo  can include in this PR?","Sure, as long as you don't mind that they'll be less pretty. I'll do it in a sec.\r\n\r\nI also updated my other PR that updates the script that get.docker.io returns to use the new style already","I don't personally mind, security should come before pretty","I've updated the PR, what's the file called in the bucket though? They don't support index pages when you address it withoutthe bare domain. I tried `contrib/install.sh` and `install.sh` to no avail.\r\n\r\nI'll need to update the PR again with the right path.","https://s3.amazonaws.com/get.docker.io/index","updated again. Sorry this took so long and thanks for looking at it.","@shykes what would you like to do for this. The ideal situation would be to move get.docker.io off of s3, but that won't right now, so the sort term solution of using the long s3 url, isn't pretty, but it works. If you want to up the priority of moving off s3, let me know. ","Could we keep the bucket, but point the url (https://get.docker.io) to a simple reverse proxy with a url rewrite rule? \r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, Jul 12, 2013 at 9:38 AM, Ken Cochrane \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @shykes what would you like to do for this. The ideal situation would be to move get.docker.io off of s3, but that won't right now, so the sort term solution of using the long s3 url, isn't pretty, but it works. If you want to up the priority of moving off s3, let me know. \r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/648#issuecomment-20888222","@mzdaniel would you like to give this a shot? https-enabled nginx container with a proxy_pass or redirect to the S3 url? Shoukd be pretty straight-forward.","@richo just in case feel like chipping in with a \"proxy-to-s3\" container, feel free :)","Good news, everyone: we finally got a viable solution to have get.docker.io over SSL.\r\n\r\nIt means that I can update the installation script to use https://get.docker.io/ without going through the ugly S3 URLs (which raised certificate warnings anyway).\r\n\r\nI'll deal with it now. Thanks everyone who helped!\r\n","\\o/\r\n\r\nThis is fabulous news. Thanks dudes.","Thanks! Note that the alternate URL (https://s3.amazonaws.com/get.docker.io/...) doesn't produce certificate warnings but a pretty one is still appreciated. ","Yeah, I still wanted to have HTTPS on get.docker.io itself... Sorry that it\ntook so long! But at least it's here, and it should be robust enough.`","Would you be able to give more details regarding the final solution your team went with?","Sure. In front: CloudFlare, with SSL setup. It acts as a CDN, and proxifies\nall HTTP/HTTPS requests to the origin, which is a cluster of HTTP load\nbalancers on dotCloud infrastructure on EC2 (running Hipache). Those load\nbalancers, in turn, send the requests to the original S3 bucket.\n\nThe only reason why we have those load balancers, is to allow SSL between\nCloudFlare and AWS. The only point where the communication is not encrypted\nis between the load balancers and S3, but since the load balancers are on\nEC2, it means that it remains within AWS network, and can reasonably be\ntrusted for that purpose.\n\nLet me know if you want more details!","@mlgx can you try again, I added the ability to have an underscore in the repo names to the docker-index","ping @mlgx Can you please test this issue again?","tested. works fine and even returns a descriptive error message.\r\n\r\nthanks and sorry for the late answer.","Awesome @mlgx , thanks for checking.  ","I think in this issue there is very similar to #156, except that ticket is regarding headers to the _registry_. @creack can you confirm this is in the planning? \r\n","@dhrp it is the same idea.. I could find the other ticket so I created a new one. if these features are available in #156 we can close this ticket.","Looks like in #1064 we didn't add the user agent strings to the auth/auth.go requests. Probably need a second pull request for that. @monnand want to take a crack at that, or would you like someone else to take a look?\r\n\r\nWhile we are at it, we should check if there are any other requests we forgot.","@kencochrane OK. No problem. I will work on it. ","@monnand awesome, thank you..\r\n\r\nIt got me wondering, would it make sense to have a request utility that wrapped the standard go http.NewRequest that automatically added the auth header, and then we just used that request util everywhere? This would give us one place where we set common things, and then we don't need to put it everywhere. Not sure if it is possible with current setup, just an idea.\r\n\r\n/cc @vieux @creack ","@kencochrane This sounds a better solution. Do you think we need to have some package, say ``github.com/dotcloud/docker/http``? I will try to first write such a package and change code in other places accordingly.","@monnand I'll defer to @creack @vieux and @shykes when it comes to docker packages, maybe one of them can give some suggestions on what they would like to see.","@kencochrane Sure. I'll be free next week after Tue. So feel free to leave a note here and I can work on it soon.","@monnand not sure about a new package, as it's only needed with the index, no need to send these headers when client communicates with the server or when we call `docker build remote_url`\r\n\r\nBut a new function/method in `registry.go` would be nice.","@vieux We need to also send it along with the auth commands (``auth/auth.go``) to the index, if we have it in ``registry.go`` would that still make sense, is there some other common location where it would make more sense?","@kencochrane I see, it's just IMO a new package would be too much. @creack what's your opinion on this ?","@vieux I agree new package might be too much, didn't know if maybe putting it in utils.go, or something similar might be better. ","@kencochrane , yes `utils/utils.go` with an explicit name works for me.","@vieux cool, thanks","Good. I will work on this from this Tuesday.","Please take a look at #1382","Just me 2ct, \r\n\r\nbut I think we should deprecate the use of the get.docker.io script. It was made in a time before PPA and this has now replaced it in a much cleaner way. Especially -X sh is like: just blindly trust me please. \r\n\r\nIf you care for the binaries, that is also well documented, just download them. \r\n\r\nBecause some external tutorials rely on in perhaps we should fix it for now and add a warning that this script is deprecated. ","@mzdaniel,@shykes any thoughts on this?","I didn't even have the chance to see the that famous script, but my understanding is that we deprecated or going to deprecate bsdtar really soon. Is this issue still valid?\r\n","Doubly so, bsdtar is deprecated *and* docker now sets tar's environment itself to guarantee UTF-8 behavior.\r\n\r\n\r\nThanks for the catch.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, Jun 20, 2013 at 12:00 AM, Daniel Mizyrycki\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e I didn't even have the chance to see the that famous script, but my understanding is that we deprecated or going to deprecate bsdtar really soon. Is this issue still valid?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/651#issuecomment-19733974","Thanks!","Eh, there are real limitations to read the docs:\r\n\r\nhttps://github.com/dotcloud/docker/issues/628#issuecomment-18184608","From IRC:\r\n\r\n18:40 Thatcher: am I correct setting custom 404 pages (and other redirects/nginx stuff) is not supported?\r\n18:55 Wraithan: yeah, not supported, we have an open issue about it but nothing decided","Fixed by hosting the entire documentation system on dotcloud.","Assigning to doc maintainer.","What's the status on this? Are we still planning on implementing this?","There are two ways to add search on Read the Docs (RTD), but I think both are broken.\r\n\r\n1. I started looking into how to tie into **their global, site-wide search tool** (and I couldn't find any hooks documented), but then when I decided to test whether we showed up at all, we didn't (try searching for \"docker\" on https://readthedocs.org/ )\r\nThe [current open issues around \"search\" for RTD](https://github.com/rtfd/readthedocs.org/search?q=search\u0026ref=cmdform\u0026state=open\u0026type=Issues) include [\"Project not indexed\"](https://github.com/rtfd/readthedocs.org/issues/332) which seems to be the same behavior I'm seeing.\r\n\r\n2. Alternatively one could try to **use the Sphinx javascript search engine**, but its not especially good when it works, and it seems like maybe it is broken on RTD builds ([per this issue](https://github.com/rtfd/readthedocs.org/issues/141) which is 2 years old)\r\n\r\nSo I am open to other mechanisms for search (maybe embedding a Google site search?)","@metalivedev maybe we can use something like https://swiftype.com/","Just an add on, mailgun also uses sphinx and they replaced the search with swiftype as described in their blog post here. http://blog.mailgun.com/post/weekly-product-update-mailgun-default-smtp-config-for-rackspace-managed-cloud-plus-better-search-on-docs/","We're using the Sphinx javascript search engine on http://deis.readthedocs.org and it seems fine. Docker has a relatively small (but excellent!) docset, so I think it would work. Just add something like this to docs/theme/docker/layout.html:\r\n```jinja\r\n{%- include \"searchbox.html\" %}\r\n```\r\nYou can tweak the search box's appearance by copying the default \"searchbox.html\" from the Sphinx distribution's \"basic\" theme into the docker theme dir.","Solved by https://github.com/dotcloud/docker/pull/1818","Non-issue.","@shykes are you ok with this change? You made the original example, so you would know best ","127.0.0.1 is a good catch, makes it clearer.\r\n\r\n\r\naptitude install curl makes the example debian-specific and will confuse non-debian users. Better to add a shell comment eg. \"or just open the url in your browser\"\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 8:39 AM, Ken Cochrane \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @shykes are you ok with this change? You made the original example, so you would know best \r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/657#issuecomment-18282763","Thanks @shykes , I agree, lets just add a comment that says, make sure curl is installed. Most people should know how to install curl on their own. This will keep it generic.\r\n\r\nAlso PR is now out of date, it needs to have master merged in to the branch to get it back up to date.","(This is my first time writing Go code so please let me know if I did anything too horrible. :-)","Does this conflict with #700, or are they complementary?\r\n","This will be fixed by #700 ","Hey guys,\r\n\r\nPlease keep in mind that the more complex the \"official\" client becomes, the harder it will be to replicate when implementing other clients. Having to issue *two* calls in *some* cases to complete authentication doesn't really seem that big of an issue. The cost of maintaining authentication state on the client side seems higher, to me at least. \r\n\r\nOf course, if there are other motives to this change, like multi-tenancy on a given docker instance, I can see how this makes sense, but don't do it for the sake of fixing what's not broken!","Yes, I think multi-tenancy is a valid concern. I do think it's important to stop storing user credentials in the daemon, because it makes it difficult for multiple users to use the same daemon.\r\n\r\nWhen we discussed this, @victor suggested that when the daemon gets a \"please authenticate\" HTTP response fro the registry, it could simply pass it through to the client. The client could then prompt the user for login/password (and optionally store the credentials locally for re-use), and make an authenticated request.\r\n\r\nIn addition to making multi-tenancy easier, this also feels like a cleaner separation between client and server.","I think we should not allow docker server to listen on something else than localhost. If we want to expose it, it should be via nginx/apache or other, so we do not need to handle SSL, login, etc.\r\nHowever, it is nice to be able to change the port and to select the host from the client.","Binding to localhost by default makes sense. However, requiring people to\nisntall nginx/socat/whatever to workaround an artificial limit would be\nlame, IMHO.","I agree with Jerome, seems convoluted for such a simple and expected capability.\r\n\r\n\r\nSeparately, it might be cool to have the option to inject the container of your choice in front of the api, for hackability :)\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Tue, May 21, 2013 at 10:44 AM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Binding to localhost by default makes sense. However, requiring people to\r\n\u003e isntall nginx/socat/whatever to workaround an artificial limit would be\r\n\u003e lame, IMHO.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/661#issuecomment-18224777","What ever we decide @vieux can you add some docs for the new features?","I think it's fine to allow this. A few requests:\r\n\r\n- Could you print a warning when listening on more than 127.0.0.1, to the tune of \"DON'T DO THIS IF YOU DON'T KNOW WHAT YOU'RE DOING\"\r\n\r\n- Could you combine the 2 flags in one, eg \"127.0.0.1:4243\", \":4243\" etc.\r\n\r\n- Could you call the flag -h, or another single-letter flag? I would prefer to avoid go-style long flags, as we already know we'll break them in the future - the less the better.\r\n\r\nThanks!","Hope you don't mind a comment, even though I'm just looking curiously around, waiting for btrfs support from docker or {overlay,au}fs/unioning support from upstream kernel...\r\n\r\nI'd dare suggest to keep the -h option for help, and use a -l option for the  \"listen\" address/port,\r\nor a -s for \"serve on\", using a ``URL`` format , as in:\r\n```\r\n    $\u003edocker -d -s docker://host[:port]                          # to serve with the internal protocol\r\n    $\u003edocker -d -s http://host[:port]                            # to serve with the RESTful http protocol\r\n    $\u003edocker -d -s http://host[:port] -s docker://host[:port]    # to serve with both protocols\r\n```\r\nhaving the client connect with \r\n```\r\n    $\u003edocker -s http://host[:port]       # for RESTful http protocol\r\n```\r\nSuch a scheme could later be extended to support something like\r\n```\r\n    $\u003edocker -d -s docker+unix:/path/to/socket\r\n```\r\nand\r\n```\r\n    $\u003edocker -d -s http+unix:/path/to/socket\r\n```\r\nwhich would greatly simplify local user selective authorization\r\n\r\nThank you very much.","@lmctv we use the same flag in both the client and the server, and for me -l or -s would apply only on the server.\r\nI believe we are good with -h as docker's help uses `docker help` or `--help`\r\n\r\nWe should keep in mind the `URL` thing.","I got this complaint from @progrium yesterday: \"-h is often synonymous for --help. Could you use -H instead?\"\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 5:23 AM, Victor Vieux \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e @lmctv we use the same flag in both the client and the server, and for me -l or -s would apply only on the server.\r\n\u003e I believe we are good with -h as docker's help uses `docker help` or `--help`\r\n\u003e We should keep in mind the `URL` thing.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/661#issuecomment-18401617","@solomonstre changed to -H","While I like -H better than -h, I still think -s as \"Serve on\" on the server side and as \"connect to server\" on the client side would have been a better shortcut.\r\n\r\nThank you very much!","related to #649 ","I'm assigning to @samalba since this is a registry problem.\r\n\r\nSam, we have the double problem of 1) the registry refusing _ in the repository name, which is a legal character, and 2) getting HTML output instead of a clear error message.\r\n\r\n","Right now, the repository names cannot include characters other than [a-z0-9-]. Please provide the new one and we'll update Index + Registry.","Just mirror what docker does.\r\n\r\nIf you want to suggest restrictions to image names, it has to be discussed\r\nin an issue here, and then applied to docker+registry at the same time.\r\n\r\n-\u003e I know you suggested forbidding \"_\" in user names, could you create an\r\nissue for that?\r\n\r\n\r\nOn Wed, May 22, 2013 at 1:40 PM, Sam Alba \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Right now, the repository names cannot include characters other than\r\n\u003e [a-z0-9-]. Please provide the new one and we'll update Index + Registry.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/662#issuecomment-18306341\u003e\r\n\u003e .\r\n\u003e","\"Just mirror what docker does.\"\r\n\r\nThere is no restriction right now on Docker, I think it answers my question. I'll open the issue.","https://github.com/dotcloud/docker/issues/679","Correct, the only limitation currently is \":\" which is reserved for tag\r\nseparation.\r\n\r\n\r\nOn Wed, May 22, 2013 at 2:49 PM, Sam Alba \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e \"Just mirror what docker does.\"\r\n\u003e\r\n\u003e There is no restriction right now on Docker, I think it answers my\r\n\u003e question. I'll open the issue.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/662#issuecomment-18306937\u003e\r\n\u003e .\r\n\u003e","Is it me, or should this have been resolved? Cause I just got the exact same 404 error when pushing an image named `jimeh/camper_van`.","@jimeh works fine here, can you tell us what version you are using ?","I've got 0.5.0:\r\n\r\n```\r\njimeh@devbox ~/Projects/docker-containers/camper_van (master)$ docker version\r\nClient version: 0.5.0\r\nServer version: 0.5.0\r\nGo version: go1.1\r\n```\r\n\r\nHere's the output when I try to push:\r\n\r\n```\r\njimeh@devbox ~/Projects/docker-containers/camper_van (master)$ docker push jimeh/camper_van\r\nThe push refers to a repository [jimeh/camper_van] (len: 1)\r\nProcessing checksums\r\nSending image list\r\n2013/08/05 09:45:30 Error: Status 404 trying to push repository jimeh/camper_van:\r\n\r\n\u003c!DOCTYPE html\u003e\r\n\u003c!--[if lt IE 7]\u003e      \u003chtml class=\"no-js lt-ie9 lt-ie8 lt-ie7\"\u003e \u003c![endif]--\u003e\r\n\u003c!--[if IE 7]\u003e         \u003chtml class=\"no-js lt-ie9 lt-ie8\"\u003e \u003c![endif]--\u003e\r\n\u003c!--[if IE 8]\u003e         \u003chtml class=\"no-js lt-ie9\"\u003e \u003c![endif]--\u003e\r\n\u003c!--[if gt IE 8]\u003e\u003c!--\u003e \u003chtml class=\"no-js\"\u003e \u003c!--\u003c![endif]--\u003e\r\n\r\n\u003chead\u003e\r\n    \u003cmeta charset=\"utf-8\"\u003e\r\n    \u003c!-- [if it IE]\u003e \u003cmeta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"\u003e \u003c![endif]--\u003e\r\n    \u003clink rel=\"shortcut icon\" href=\"/static/favicon.ico\" /\u003e\r\n    \u003ctitle\u003e\r\n         | Docker Index\r\n    \u003c/title\u003e\r\n    \u003cmeta name=\"description\" content=\"Docker Index, The linux Container Engine Image Index\" /\u003e\r\n    \u003cmeta name=\"keywords\" content=\"Docker Index, Docker, Linux Containers, Container\" /\u003e\r\n[...]\r\n```","@vieux are you pushing a repo with an \"_\" ? if so, can you give me the name. I'm pretty sure the index doesn't support _ in the name. It looks like if we made a fix, we might have updated the registry, but not the index.\r\n\r\n/cc @samalba \r\n\r\n","@kencochrane indeed, it didn't work, there was no error in the docker client...\r\n","I think it would be interesting to also forbid '.'","@creack as . os currently working, I left it, but if you prefer I could remove it. Maybe it will force people to add in version number in the tag and not the repo itself. But there are already some images with a .\r\nBefore changing this, we need to patch in the registry to change all . and _ to -  @shykes what do you think ?","Since it is common practice to name docker repos after github repos, at the very least we should support all the characters supported by Github. So that means supporting [.-_] in addition to alphanum.\r\n\r\nIn addition, let's forbid underscores (\"_\") and dots (\".\") on the LEFT side of the slash, to leave open the possibility to map usernames to hostnames.\r\n\r\nSo, in summary:\r\n\r\n- Repository name: [a-zA-Z0-9-_.]\r\n- User name [a-z0-9]\r\n\r\n(edited to remove uppercase from username)","I documented this in the registry API spec, see df23a1e675c7e3cbad617374d85c48103541ee14\r\n","So how do we handle this ? We first implement this in the registry and after in docker ? or the other way around ?","Docker first. Registry in parallel, hopefully!\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, May 30, 2013 at 5:37 AM, Victor Vieux \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e So how do we handle this ? We first implement this in the registry and after in docker ? or the other way around ?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/663#issuecomment-18677299","/cc @samalba\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, May 30, 2013 at 5:37 AM, Victor Vieux \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e So how do we handle this ? We first implement this in the registry and after in docker ? or the other way around ?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/663#issuecomment-18677299","updated to reflect the api, @samalba ping me when ready to merge.","Go ahead. However please make sure the format is also supported on the Index: https://github.com/dotcloud/docker-index/issues/28\r\n\r\n@kencochrane will be able to tell once it's ready.","LGTM","Assigning to @creack for second review.","LGTM","@kencochrane since we could take advantage of dotCloud's own docker build system, and you're responsible for that system, I'm tentatively assigning this to you. Let me know if you don't want it :)\r\n","@shykes Sure I'll own it.\r\n\r\n\u003e Question: how do we handle tags?\r\n\r\nI like the idea of putting it in the Dockerfile, it makes it really obvious, and we can have different tags for different images.\r\n\r\n\u003e Question: how do we handle bootstrapping? Currently base system containers are basically an external tarball. This could be handled by hosting the bootstrap tarball on a fixed URL, and referring to that URL with an INSERT command in the Dockerfile. Or, we could just stick to the status quo of a small number of base images being manually inserted, and everything else referring to them by source.\r\n\r\nNot sure what the second option means, do we create those bases and push them ourselves, and then the changes on top of those are done via the build process? \r\n\r\nEither way, both options leave us a little bit of unknown the beginning state. I'm currently leaning toward the first way, hosting a tarball somewhere, it makes it a little more easily reproducible. \r\n\r\n\r\n","Re: bootstrap layers. Yes, there will always be a weird turtle at the bottom :)\r\n\r\nIdeally we would keep a copy on disk of these bootstrap layers, in a layer format - something that can be re-injected into a registry or an individual docker, for bootstrapping purposes, while preserving IDs etc.\r\n","I like this Homebrew approach for adding top-level images. It elegantly provides a collaborate- and talk platform for vetting top-level images. \r\n\r\nFor search, basically this list of build files will be automatically added to the index. For non-top-level images people can do something similar, by manually adding the link to their buildfile to the index. \r\n\r\nRegarding the bootstrap layers: We could use a static url at \"FROM\", and require a sha1 to be included. e.g. ``FROM  https://repo.mine.net/tarfile.gz as9df876as95fs``  - The client will need to compute/verify it. \r\n\r\n- Question: Where do we set the repository description? We can extend the build file to include that so it will be available in the index and client ``docker search``. Descriptions of pre-built images would still need to be set at push time (#598)\r\n\r\n- Question: If each subdirectory is allowed to contain \"every content necessary\", how do we prevent this from getting out of hand? e.g. can I include an entire httpd.conf file?, Puppet scripts?. How do we prevent bloating the Docker repository? Perhaps we don't really need other files present, or we can force them to be included with an URL and sha1?\r\n","Another thing I just thought about. lets use Redis for an example. There are different version of redis (2.2.x, 2.4.x, 2.6.x, etc), and depending on the needs of your project you might need a specific version. \r\n\r\nIf we had everything like this\r\n\r\n/library/redis\r\n\r\nthen we would need multiple files for each release, so does it make sense to have\r\n\r\n(1)\r\n\r\n/library/redis/2.2/\r\n/library/redis/2.4/\r\n/library/redis/2.6/\r\n\r\nwith a Dockerfile for each, or would it be better to have it like this.\r\n\r\n(2)\r\n\r\n/library/redis_2.2/\r\n/library/redis_2.4/\r\n/library/redis_2.6/\r\n\r\nor\r\n\r\n(3)\r\n\r\n/library/redis/Dockerfile.v2.2\r\n/library/redis/Dockerfile.v2.4\r\n/library/redis/Dockerfile.v2.6\r\n\r\nI personally prefer option 1, because it will allow a nice seperation between the versions, and a place to put supporting files as well.\r\n\r\nAny opinions?","In option 1, would each version sub-directory (2.2, 2.4, 2.6 etc) be mapped\r\nto a docker tag?\r\n\r\n\r\nOn Thu, Jun 13, 2013 at 9:03 AM, Ken Cochrane \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e Another thing I just thought about. lets use Redis for an example. There\r\n\u003e are different version of redis (2.2.x, 2.4.x, 2.6.x, etc), and depending on\r\n\u003e the needs of your project you might need a specific version.\r\n\u003e\r\n\u003e If we had everything like this\r\n\u003e\r\n\u003e /library/redis\r\n\u003e\r\n\u003e then we would need multiple files for each release, so does it make sense\r\n\u003e to have\r\n\u003e\r\n\u003e (1)\r\n\u003e\r\n\u003e /library/redis/2.2/\r\n\u003e /library/redis/2.4/\r\n\u003e /library/redis/2.6/\r\n\u003e\r\n\u003e with a Dockerfile for each, or would it be better to have it like this.\r\n\u003e\r\n\u003e (2)\r\n\u003e\r\n\u003e /library/redis_2.2/\r\n\u003e /library/redis_2.4/\r\n\u003e /library/redis_2.6/\r\n\u003e\r\n\u003e or\r\n\u003e\r\n\u003e (3)\r\n\u003e\r\n\u003e /library/redis/Dockerfile.v2.2\r\n\u003e /library/redis/Dockerfile.v2.4\r\n\u003e /library/redis/Dockerfile.v2.6\r\n\u003e\r\n\u003e I personally prefer option 1, because it will allow a nice seperation\r\n\u003e between the versions, and a place to put supporting files as well.\r\n\u003e\r\n\u003e Any opinions?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/664#issuecomment-19401763\u003e\r\n\u003e .\r\n\u003e","@shykes yes that would be the goal, if possible.","+1 how's this issue shaping up? Right now, it seems like the contents of someone else's container in the registry are a complete mystery","## Regarding bootstrap layers: \r\n * I think we want to leverage the `docker import \u003cURL\u003e` feature to grab the base tarballs (ubuntu, busybox, centos...)\r\n * There is presently no way  (that I know of) to use this command from a Dockerfile.\r\n * We could extend `FROM` to trigger an import when presented with a URL as suggested by @dhrp, but because `docker pull URL` is valid now (with private registries) this could cause confusion\r\n * We could add an `IMPORT \u003cURL\u003e` command *(this is the option I favor)*\r\n * (Additionally, I remember having had problems with `docker import` before, could be a good occasion to see if there are any bugs lying around that need fixing there)\r\n\r\n## Regarding repository description: \r\nI think having the description inside the associated Dockerfile is a good idea. Probably requires an extension to the Dockerfile language too. Easy option: `DESCRIPTION A barebone ubuntu 12.04 container`. We could also do something similar to python's `\"\"\"`, i.e.\r\n\r\n    \"\"\"A barebone 12.04 container\r\n       spanning over multiple lines\"\"\"\r\n    IMPORT https://get.docker.io/library/ubuntu-12.04.tar.gz\r\n    ...\r\n\r\nSecond solution avoids having 200+ character lines in some Dockerfiles, but I don't know if that's desirable enough to justify the odd syntax. I'm pretty much impartial in that regard.\r\n\r\n## Regarding software versions:\r\nThe existing library branch seems to be using plain text files in a library/ subdirectory containing Git URLs pointing to the project that needs to be built (see https://github.com/dotcloud/docker/commit/bec70d7b1844e729a4364a883c35bfda0f4365df). We could use a syntax like the following instead:\r\n\r\n    12.04: git://github.com/dotcloud/ubuntu precise\r\n    12.10: git://github.com/dotcloud/ubuntu quantal\r\n    \u003cdocker tag\u003e: \u003cgit url\u003e \u003cgit branch or tag\u003e\r\n\r\nOr we could go one step further and use YAML syntax (or JSON or other equivalent)\r\n\r\n    repository: ubuntu\r\n    builds:\r\n        - tags: \r\n            - 12.04\r\n            - precise\r\n           git_url: git://github.com/dotcloud/ubuntu\r\n           git_tag: precise\r\n        - tags: \r\n            - 12.10\r\n            - quantal\r\n           git_url: git://github.com/dotcloud/ubuntu\r\n           git_tag: quantal\r\n\r\nThis makes for a more flexible system that can be extended later if need be, but maybe not as elegant.\r\n\r\n## Other thoughts:\r\n\r\n * Highland will probably be the platform of choice for automated building of library images. If so, it will need to support multi-tenancy (be able to switch user accounts).\r\n * Or we could grant the default highland user rights to update the library repositories, which would be a feature request for the index.\r\n * cc @kencochrane on the two points above -- if you have any thoughts on how best to achieve this I'd be glad to hear them!","@shin- I guess it depends on how you use highland, and how to trigger the builds. Highland wasn't built to handle multiple dockerfiles in the same repo, it can be changed but we need to figure out the best way. I mentioned to @shykes that we might be easier to keep docker and brew separate for now. It would cause duplication of some things, but that is fine, once we get them both working and stable, then we can find the duplicate parts and find a way to merge them. The one concern I have is that highland was built for one purpose and if we start to force it to do something different it might not work with the ideal case. Since highland isn't released yet, it isn't a big deal to make changes, but since it is ready to go out the door, I would hate to delay it any more then possible. \r\n\r\nre your second point, it shouldn't be a problem, I think we can give the highland permission to write to the library namespace, should be available now, we just need to verify it works. The repo would be owned by highland instead of library user, but I don't think that is an issue.\r\n\r\nI like the idea of the yaml file, if we can't add the same stuff to the dockerfile, then that seems to make it nice and clean and easy to follow.\r\n","Re: bootstrap layers. Take a look at\r\nhttps://github.com/dotcloud/ubuntu-quantal :)\r\n\r\nRe: highland. I agree that, for now, we should keep this in the form of a\r\nsimple, standalone program. This will leave us free to experiment and move\r\nthings around until we find the best form factor. We can always make it a\r\nsaas later, it it makes sense - and at that point we can integrate it into\r\nhighland if it makes sense.\r\n\r\nRe: yaml. let's try the simpler text files first. If we hit an actual\r\nlimitation, then we can start about more complex alternatives.\r\n\r\n\r\n\r\n\r\n\r\nOn Mon, Jul 8, 2013 at 10:19 AM, Ken Cochrane \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @shin- \u003chttps://github.com/shin-\u003e I guess it depends on how you use\r\n\u003e highland, and how to trigger the builds. Highland wasn't built to handle\r\n\u003e multiple dockerfiles in the same repo, it can be changed but we need to\r\n\u003e figure out the best way. I mentioned to @shykes\u003chttps://github.com/shykes\u003ethat we might be easier to keep docker and brew separate for now. It would\r\n\u003e cause duplication of some things, but that is fine, once we get them both\r\n\u003e working and stable, then we can find the duplicate parts and find a way to\r\n\u003e merge them. The one concern I have is that highland was built for one\r\n\u003e purpose and if we start to force it to do something different it might not\r\n\u003e work with the ideal case. Since highland isn't released yet, it isn't a big\r\n\u003e deal to make changes, but since it is ready to go out the door, I would\r\n\u003e hate to delay it any more then possible.\r\n\u003e\r\n\u003e re your second point, it shouldn't be a problem, I think we can give the\r\n\u003e highland permission to write to the library namespace, should be available\r\n\u003e now, we just need to verify it works. The repo would be owned by highland\r\n\u003e instead of library user, but I don't think that is an issue.\r\n\u003e\r\n\u003e I like the idea of the yaml file, if we can't add the same stuff to the\r\n\u003e dockerfile, then that seems to make it nice and clean and easy to follow.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/664#issuecomment-20621255\u003e\r\n\u003e .\r\n\u003e","Inline:\r\n\r\n\u003e The one concern I have is that highland was built for one purpose and if we start to force it to do something different it might not work with the ideal case.\r\n\r\nAbsolutely, my intention was not to shoehorn highland into doing something else -- it just felt like the most intuitive approach. If we're okay writing something more specific and potentially temporary for brew that's fine with me.\r\n\r\n\u003e Re: bootstrap layers. Take a look at\r\nhttps://github.com/dotcloud/ubuntu-quantal :)\r\n\r\nOh yeah, that's using the new contextual builder. I guess that makes sense -- it just means that I'll need to support it somehow in docker-py.\r\n\r\n\u003e Re: yaml. let's try the simpler text files first. If we hit an actual\r\nlimitation, then we can start about more complex alternatives.\r\n\r\nThe one I can think of right now is how do we handle multiple tags for one same image (for example the ubuntu repository has `12.10` and `quantal` tags mapped to the same image). I'm guessing a syntax like `12.10, quantal: git://github.com/dotcloud/ubuntu-quantal master` would do, but I don't find it particularly elegant and it becomes increasingly harder to read and modify the more tags there are. Perhaps not a problem though if we project that tags will be at most 2 or 3 for a single image.","What I would really like is for 'docker build' to automatically detect if\r\nit's building from a clean git revision or tag, and if so, apply that\r\nautomatically as a docker tag.\r\n\r\n\r\nOn Mon, Jul 8, 2013 at 10:39 AM, Joffrey F \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Inline:\r\n\u003e\r\n\u003e The one concern I have is that highland was built for one purpose and if\r\n\u003e we start to force it to do something different it might not work with the\r\n\u003e ideal case.\r\n\u003e\r\n\u003e Absolutely, my intention was not to shoehorn highland into doing something\r\n\u003e else -- it just felt like the most intuitive approach. If we're okay\r\n\u003e writing something more specific and potentially temporary for brew that's\r\n\u003e fine with me.\r\n\u003e\r\n\u003e Re: bootstrap layers. Take a look at\r\n\u003e https://github.com/dotcloud/ubuntu-quantal :)\r\n\u003e\r\n\u003e Oh yeah, that's using the new contextual builder. I guess that makes sense\r\n\u003e -- it just means that I'll need to support it somehow in docker-py.\r\n\u003e\r\n\u003e Re: yaml. let's try the simpler text files first. If we hit an actual\r\n\u003e limitation, then we can start about more complex alternatives.\r\n\u003e\r\n\u003e The one I can think of right now is how do we handle multiple tags for one\r\n\u003e same image (for example the ubuntu repository has 12.10 and quantal tags\r\n\u003e mapped to the same image). I'm guessing a syntax like 12.10, quantal:\r\n\u003e git://github.com/dotcloud/ubuntu-quantal master would do, but I don't\r\n\u003e find it particularly elegant and it becomes increasingly harder to read and\r\n\u003e modify the more tags there are. Perhaps not a problem though if we project\r\n\u003e that tags will be at most 2 or 3 for a single image.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/664#issuecomment-20622637\u003e\r\n\u003e .\r\n\u003e","Quick update: I added the first version of the brew script in the [contrib folder in the library branch.](https://github.com/dotcloud/docker/tree/library/contrib/brew) Next step is to populate the library with more repositories/images, and create the repositories that are missing (e.g. ubuntu-quantal, busybox, ...)\r\n\r\nAlso on my TODO list: \r\n\r\n- Add support for private registries (right now, the push option pushes to the official docker registry)\r\n- Fetch library definition files from a local path (right now, the only option is to fetch a git repository, which is cumbersome and unnecessary if all you want is to build from `../../library`)\r\n- Fill builder cache before starting a build (should speed up builds in the general case)\r\n- Error reporting / build summary","@shin- has a pull request for this ready for testing. It would be cool to include this in the 0.6 release.\r\n\r\n@vieux @creack @crosbymichael can you guys take a look?\r\n\r\n@shin- can you reference the PR here?","Sorry, missed your comment, I hadn't made the PR yet, but it's here now: #1361 !","Docker-brew has been merged, closing.","This is being caused by the fact that you have \"nameserver 127.0.0.1\" in /etc/resolv.conf.\r\n\r\nPlease take a look at #541. #541 will take care of this.\r\n\r\nIf you have \"127.0.0.1\" as the main and sole nameserver in /etc/resolv.conf, please close this issue (#665) and comment in #541.","This is indeed #541. I'll close here and make a comment as you suggested.","This was intended for @rogaha 's branch.","Silly Github. It does not do what it says it does! (pull request to another person's fork).","Thank you.","Nice catch, it was only in the documentation.\r\n\r\nhttps://github.com/dotcloud/docker/blob/master/api.go#L381\r\n\r\nThanks!","Still needed?","@creack what do you think ? This endpoint should stay private or other clients could use it ?","This endpoint is needed if clients wants to implement a docker build with cache. So I guess we could keep it.","Do we currently use this call? If not, I suggest we get rid of it, or at least undocument it. The less dead weight the better.","It is currently unused, we can remove it.","that's good.\r\n\r\nWill multiple versions be supported concurrently (i.e. when you release 1.1 will we still be able to hit /v1.0/info?)","+1 on versioning by url.\r\n\r\n\r\nI think we should make a reasonable effort to support as many old versions as possible, but eventually the internals might grow too different and we might drop support for older versions - when that happens we'll know we need to change major version number.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 9:48 AM, Joffrey F \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e that's good.\r\n\u003e Will multiple versions be supported concurrently (i.e. when you release 1.1 will we still be able to hit /v1.0/info?)\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/pull/673#issuecomment-18287625","@shin- yes\r\n@shykes exactly, and return a 405 maybe","Woah, this won't apply. Made this commit from a really old checkout. Closing.","I'm ok with moving the website out of the repo, as long as you don't move out any documentation content (including install instructions etc.) Currently some of these instructions are spread out across both the website and the docs, how would you go about solving that?\r\n\r\nSecondly, I don't think using Django is a good idea. It's just a static site. If you need templating, why not use a static site generator? We used one for the dotCloud website and it works great - you could take the opportunity to open-source and dockerize that setup :)","I agree with @shykes I love django, but it might be overkill for this website. Can we just use one of the many static site generators for this, and keep it fully static? \r\n\r\nI guess the one issue might be the forms, what kind of forms are you thinking?","My main argument is actually that it will be easier to maintain a dynamic site. \r\n\r\nBut, Yes indeed, forms. At the very least there is a form to signup for news. - The one currently in Wufoo. It should be changed to that it directly adds emails to mailchimp. For the eBook we published I used the Javascript version of posting to Mailchimp but it was a PITA because you cannot really do things from an https site to there. As we have a https certificate some clients are bound to be using https whether we want to or not. Mailchimp provides a nice backend solution, and I would much rather use that. \r\n\r\nIt also provides the option to upgrade it later with useful features as:\r\n- Adding press articles, use cases (now used by company XYZ) and such things through a web interface\r\n- Adding new cool tweets about docker through a web interface\r\n- Automatic inclusion of data\r\n - from the docs (e.g. getting started instructions)\r\n - docker index (most popular, number of updates, whatever from the index)\r\n - Data from github, \r\n - highland? \r\n\r\nTrue, many of these could be done using Javascript. But then, that's just moving the dynamic part around.. \r\n\r\nWith regards to the success on the dotCloud website: IMHO it created a lot of new problems, too. Part of the website was actually not static at all but provided from a another app through a proxy. This then also created problems with showing whether or not a user session existed, as that was then also fetched from another app. \r\n\r\nI don't really see the problem with having a dynamic site.. Are we worried about wasting a few cpu cycles? Most of us are much more familiar with Jinja2 and the powerful inheritance schema of Django, More than other static site generators. What we use on www.dotCloud.com (punch) is actually pretty clumsy. ","Would it make you (all Docker contributors) more happy if I use Flask? \r\nI could also make it in PHP perhaps :-)","There is literally no feature of this website that requires a dynamic app (including those you listed, they can all be done either with static generation or with a javascript embed).\r\n\r\nA static site is better because it has less moving parts, loads faster, can be hosted in more places and costs less to host. Add to that the fact that we have a ready-to-use system at dotCloud. I strongly advise you to use that.\r\n\r\nNow you know my opinion. You can follow it or not.\r\n\r\nBut above all please make sure that 1) you don't waste time re-writing for the sake of re-writing. and 2) the code remains clear, simple and easy to maintain by others. Otherwise we won't use it and you will have wasted your time.\r\n","This is now complete. The website can be found on http://github.com/dotcloud/www.docker.io","Related: #664\r\n","I don't know if I agree with forcing people to add a description when they create a repo. I think we should offer it as an option, but sometimes a description isn't always needed. what do other people think?","The way I think it would be nicest would be to do it git-style: present the user an editor.\r\n\r\nWhen pushing, the the client fetches any existing description (at authentication time) and then presents that to the user in an editor (vi). The user could leave it empty and just close it, accept the description that is already there, or comment on it / change it.. \r\n\r\nHaving descriptions vastly increases the chance that someone else will find and use your repository. Otherwise, if you put a somewhat cryptic name and no description the repository might as well be private. ","Having the description as a non-required option seems like a nice feature.\r\n Forcing a description might actually lead to poor or bad descriptions as\r\nwell (as seen with unmoderated commit messages).\r\n\r\nIt feels like it might be cumbersome to have to interact with the\r\ndescription for each commit.  Could it get confused with the commit message?\r\n\r\nI really like being able to edit the description on the web interface where\r\nI know how the output will be displayed and can adjust accordingly.\r\n\r\nOn Fri, May 24, 2013 at 1:40 PM, Thatcher \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e The way I think it would be nicest would be to do it git-style: present\r\n\u003e the user an editor.\r\n\u003e\r\n\u003e When pushing, the the client fetches any existing description (at\r\n\u003e authentication time) and then presents that to the user in an editor (vi).\r\n\u003e The user could leave it empty and just close it, accept the description\r\n\u003e that is already there, or comment on it / change it..\r\n\u003e\r\n\u003e Having descriptions vastly increases the chance that someone else will\r\n\u003e find and use your repository. Otherwise, if you put a somewhat cryptic name\r\n\u003e and no description the repository might as well be private.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/676#issuecomment-18419288\u003e\r\n\u003e .\r\n\u003e","Closing this in an effort to keep issues focused on more specific, actionable items.\n\nIt would be interesting to continue the discussion on the mailing list, in light of recent developments in the project.","So there are 3 problems here:\r\n\r\n1) My command hung for several minutes with a single cryptic message \"processing checksums\". What took so long and why am I not getting details about it?\r\n\r\n2) I can't push my images\r\n\r\n3) I'm getting HTML garbage instead of a clear explanation of what's going on.\r\n","Looks like this is the same as #662","I also battled this.  It seems that extending any image that didn't originate at dotcloud results in a valid upload that ends in 400.  I see all the images I pushed in my https://index.docker.io/account/repositories/ page.  They are listed as \"initialized\" but not \"active\".","First upload (ubuntu 12.04 debootstraped) works\r\n\r\n![screen shot 2013-05-28 at 9 57 22 am](https://f.cloud.github.com/assets/447/574968/68c78728-c7d3-11e2-864b-7c214eda89da.png)\r\n\r\nSecond upload (ubuntu 12.04 + base packages I need) fails\r\n\r\n![screen shot 2013-05-28 at 10 00 14 am](https://f.cloud.github.com/assets/447/574978/80858400-c7d3-11e2-853d-a1715b241a6a.png)\r\n","Yet the failed images show up in my account as 'Initialized'\r\n\r\n![screen shot 2013-05-28 at 10 17 32 am](https://f.cloud.github.com/assets/447/574993/c320e638-c7d3-11e2-8345-028d28639a35.png)\r\n","OK, I did some digging, and it looks like if there was an error during a push, it leaves the repo in a bad state, and all subsequent pushes will then fail. In @dysinger case, it is failing because there is no ``repositories/knewton/ubuntu-base/_images_list`` file, which causes an ``IOError`` when trying to load, which then causes it to return the 'This image does not belong to the repository' error. \r\n\r\nHow to fix.. short term, we can either remove the repo and start again, or better write the code so it is self healing, and can handle an error, and when it is repushed it will automatically fix it self.\r\n\r\n/cc @samalba \r\n\r\n ","If I successfully upload an image, I can never update it or it will blow out \u0026 be permanently broken\r\n\r\n![screen shot 2013-05-28 at 11 09 26 am](https://f.cloud.github.com/assets/447/575335/1767c0b6-c7db-11e2-9d44-59b54694e742.png)\r\n","Thanks for digging @kencochrane. @dysinger and all, I'll release a new version that addresses the problem before tomorrow.\r\n\r\nEDIT: (a new version version of the Registry)","After digging into this repos metadata, it looks like the file _images_list has been properly created. However the last image (ending with ...7e4e) does not exist in the list.\r\n\r\nIt might be because the image has not been advertised to the Index during the second push, or simply because Docker did not send it to the Index. I am investigating to know why, but it does not look like an error on the Registry. I will update this asap after reproducing the issue.","Ok, finally identified the issue with the help of @creack. Docker keeps the same Cookie forever (in-memory). On the second push, it advertises the image list to the Index and gets a new Token. This new Token should be exchanged for a new Cookie instead of using the old one.\r\n\r\nThis should be fixed shortly on master. For the one who use a stable release of Docker, the official workaround is to restart Docker's daemon the clear the Cookie in-memory.","awesome thanks guys!","hmm 1st try:\r\n\r\nubuntu@ip-10-4-26-172:~$ docker push knewton/ubuntu-12.04\r\nThe push refers to a repository [knewton/ubuntu-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\nPushing bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179\r\n134645760/134645760 (100%)\r\nPushing tags for rev [bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing 1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af\r\n28887040/28887040 (100%)\r\nPushing tags for rev [1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing 4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3\r\n10506240/10506240 (100%)\r\nPushing tags for rev [4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22\r\n94095360/94095360 (100%)\r\nPushing tags for rev [ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing e53fcb1ba246ad2125ed183b25de8628c65a2f54bc324b315f2a7b4e3e979e74\r\n693872640/693872640 (100%)\r\n\r\n    Received HTTP code 502 while uploading layer: \u003chtml\u003e\r\n      \u003chead\u003e\r\n        \u003ctitle\u003eError 502 - Application Not Responding\u003c/title\u003e\r\n        \u003cstyle\u003e\r\n          body { background-color: #dedede; margin: 0; }\r\n          h1 { padding: 280px 0 0 0; margin: 0; text-align: center; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 24px; font-weight: normal; }\r\n          h2 { padding: 5px 0 0 0; margin: 0; text-align: center; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; color: #999; font-weight: normal; }\r\n        \u003c/style\u003e\r\n      \u003c/head\u003e\r\n      \u003cbody\u003e\r\n        \u003ccenter\u003e\u003cdiv style=\"width: 530px; height: 434px; background-image: url(http://static.dotcloud.com/proxy/warning.png); margin: 25px auto;\"\u003e\r\n          \u003ch1\u003e\r\n            Application Not Responding\r\n          \u003c/h1\u003e\r\n          \u003ch2\u003e\r\n            Please try again in a few moments.\r\n          \u003c/h2\u003e\r\n        \u003c/div\u003e\u003c/center\u003e\r\n      \u003c/body\u003e\r\n    \u003c/html\u003e\r\n\r\nWill try again here in a bit","Looking at the Registry's logs, it looks like the your push got a \"graceful timeout\", which can whether be due to a low upload bandwidth on your side or a big layer.\r\n\r\nI increased this timeout to match the global worker timeout (from 30 to 120)[1]. Which is fine since we use async workers.\r\n\r\nCould you try again and tell me what you get?\r\n\r\n[1] https://github.com/dotcloud/docker-registry/commit/22974e7810e00b5587c3dc059b8b26570e2cd419","ubuntu@ip-10-4-26-172:~$ docker push knewton/ubuntu-12.04\r\nThe push refers to a repository [knewton/ubuntu-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\nPushing bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179\r\nImage bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179 already uploaded ; skipping\r\nPushing tags for rev [bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing 1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af\r\nImage 1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af already uploaded ; skipping\r\nPushing tags for rev [1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing 4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3\r\nImage 4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3 already uploaded ; skipping\r\nPushing tags for rev [4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22\r\nImage ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22 already uploaded ; skipping\r\nPushing tags for rev [ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing e53fcb1ba246ad2125ed183b25de8628c65a2f54bc324b315f2a7b4e3e979e74\r\nBuffering to disk 268584960/? (n/a)\r\n268584960/268584960 (100%)\r\nFailed to upload layer: unexpected EOF","another try (not changing anything)\r\n\r\nubuntu@ip-10-4-26-172:~$ docker push knewton/ubuntu-12.04\r\nThe push refers to a repository [knewton/ubuntu-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\nPushing bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179\r\nImage bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179 already uploaded ; skipping\r\nPushing tags for rev [bf00d81e339b64920b753c4c60eec18c3fc32847533d43f914724bfe7e4f9179] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing 1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af\r\nImage 1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af already uploaded ; skipping\r\nPushing tags for rev [1e49edddf0de5d6e0befeb11379c3283c73499ef6f18647df506ee94aac7b8af] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing 4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3\r\nImage 4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3 already uploaded ; skipping\r\nPushing tags for rev [4c121f1b7fab5f66729efa0707980657eb1fb405719df1b41eb3a2bb0f2e0bf3] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22\r\nImage ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22 already uploaded ; skipping\r\nPushing tags for rev [ca60d9fb37a5398549d51114a370f5320c841edf3a4cb6aa1d74856e43936d22] on {registry-1.docker.io/users/knewton/ubuntu-12.04/52}\r\nPushing e53fcb1ba246ad2125ed183b25de8628c65a2f54bc324b315f2a7b4e3e979e74\r\nBuffering to disk 268564480/? (n/a)\r\n268564480/268564480 (100%)\r\nReceived HTTP code 400 while uploading layer: {\r\n    \"error\": \"Checksum mismatch, ignoring the layer\"\r\n}","Client-side interruption this time. I need some time to investigate to figure out if there is any regression on the client side.","In the same time, do you have any information regarding your connection (like bandwidth on upload)? It looks like the layer having problem to be pushed is 256MB, how long did it take to reach the error message?","I rebuilt the image on a new slave \u0026 it worked\r\n\r\nubuntu@domU-12-31-39-04-6C-81:~$ docker push knewton/ubuntu-12.04\r\nThe push refers to a repository [knewton/ubuntu-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\nPushing 8a26affaefdde310c19dd5af5cf39a918133ee49d0579f7520a6e9a444a4e32f\r\n134645760/134645760 (100%)\r\nPushing tags for rev [8a26affaefdde310c19dd5af5cf39a918133ee49d0579f7520a6e9a444a4e32f] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\nPushing 993999c87946c5944511b895176cfa5bccad65d9d5a6b40761b486e2680e8bc8\r\n28887040/28887040 (100%)\r\nPushing tags for rev [993999c87946c5944511b895176cfa5bccad65d9d5a6b40761b486e2680e8bc8] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\nPushing 60e26d7172d1ff129ba196870114d8597e20e4988dff7c1abbcb010ef5820187\r\n10506240/10506240 (100%)\r\nPushing tags for rev [60e26d7172d1ff129ba196870114d8597e20e4988dff7c1abbcb010ef5820187] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\nPushing d6046d97c68a26a4421b60d009f9cffee8fb86f2339d7e39d8dfd84fd18fed16\r\n94095360/94095360 (100%)\r\nPushing tags for rev [d6046d97c68a26a4421b60d009f9cffee8fb86f2339d7e39d8dfd84fd18fed16] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\nPushing 4f69d3c92f8c23bc25f5849c25e32cf64d3e087aed0a364c9b85b30aeb02b9b1\r\n693872640/693872640 (100%)\r\nPushing tags for rev [4f69d3c92f8c23bc25f5849c25e32cf64d3e087aed0a364c9b85b30aeb02b9b1] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\nPushing 5cc435c1fcb6e885647ff4404ef1dbe6c15f0949bf3b3f90d76c0837c4f2bad7\r\n10240/10240 (100%)\r\nPushing tags for rev [5cc435c1fcb6e885647ff4404ef1dbe6c15f0949bf3b3f90d76c0837c4f2bad7] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\nPushing 97fdbb5fe009f5f8c4ee45fdfb5cbce793f3747307f3dfc79bae2c986cb94fbd\r\n81920/81920 (100%)\r\nPushing tags for rev [97fdbb5fe009f5f8c4ee45fdfb5cbce793f3747307f3dfc79bae2c986cb94fbd] on {registry-1.docker.io/users/knewton/ubuntu-12.04/latest}","What's the different with the new slave? what about the internet connection\r\nbetween both scenario?\r\n\r\n\r\nOn Wed, May 29, 2013 at 5:59 PM, Tim Dysinger \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e I rebuilt the image on a new slave \u0026 it worked\r\n\u003e\r\n\u003e ubuntu@domU-12-31-39-04-6C-81:~$ docker push knewton/ubuntu-12.04\r\n\u003e\r\n\u003e The push refers to a repository knewton/ubuntu-12.04\r\n\u003e Processing checksums\r\n\u003e Sending image list\r\n\u003e Pushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\n\u003e Pushing 8a26affaefdde310c19dd5af5cf39a918133ee49d0579f7520a6e9a444a4e32f\r\n\u003e 134645760/134645760 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [8a26affaefdde310c19dd5af5cf39a918133ee49d0579f7520a6e9a444a4e32f] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e Pushing 993999c87946c5944511b895176cfa5bccad65d9d5a6b40761b486e2680e8bc8\r\n\u003e 28887040/28887040 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [993999c87946c5944511b895176cfa5bccad65d9d5a6b40761b486e2680e8bc8] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e Pushing 60e26d7172d1ff129ba196870114d8597e20e4988dff7c1abbcb010ef5820187\r\n\u003e 10506240/10506240 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [60e26d7172d1ff129ba196870114d8597e20e4988dff7c1abbcb010ef5820187] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e Pushing d6046d97c68a26a4421b60d009f9cffee8fb86f2339d7e39d8dfd84fd18fed16\r\n\u003e 94095360/94095360 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [d6046d97c68a26a4421b60d009f9cffee8fb86f2339d7e39d8dfd84fd18fed16] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e Pushing 4f69d3c92f8c23bc25f5849c25e32cf64d3e087aed0a364c9b85b30aeb02b9b1\r\n\u003e 693872640/693872640 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [4f69d3c92f8c23bc25f5849c25e32cf64d3e087aed0a364c9b85b30aeb02b9b1] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e Pushing 5cc435c1fcb6e885647ff4404ef1dbe6c15f0949bf3b3f90d76c0837c4f2bad7\r\n\u003e 10240/10240 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [5cc435c1fcb6e885647ff4404ef1dbe6c15f0949bf3b3f90d76c0837c4f2bad7] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e Pushing 97fdbb5fe009f5f8c4ee45fdfb5cbce793f3747307f3dfc79bae2c986cb94fbd\r\n\u003e 81920/81920 (100%)\r\n\u003e Pushing tags for rev\r\n\u003e [97fdbb5fe009f5f8c4ee45fdfb5cbce793f3747307f3dfc79bae2c986cb94fbd] on {\r\n\u003e registry-1.docker.io/users/knewton/ubuntu-12.04/latest}\r\n\u003e\r\n\u003e  —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/678#issuecomment-18655745\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\n@sam_alba","The new slave was most likely (sans PPA resources I don't control/pin like docker) built with the same binaries.  It's just a new node.  that was the first push from that node right after my login.  the image was rebuilt on the new node (it's a jenkins slave).","I'm still having issues.  I think we should re-open this ticket.  If you don't want to do that then let's move to a new ticket.  There are still serious issues with pushing/pulling images UX.\r\n\r\nLast night I pushed knewton/ubuntu-12.04 and it went up ok but then you can't pull it (it's missing a base image hunk - why did it say the upload was good? - I just assumed it would push everything it needed.)  So then I pushed the base image I used to build knewton/ubuntu-12.04 (debootstrapped knewton/bootstrap-12.04) and it failed to upload. I tried a half dozen times.\r\n\r\nToday I rebuilt both the base bootstrap-12.04 \u0026 extended it with ubuntu-12.04 again (on jenkins).  The push of bootstrap-12.04 went up ok but ubuntu-12.04 failed.\r\n\r\nubuntu@domU-12-31-39-0C-DD-81:~$ docker images\r\nREPOSITORY                TAG                 ID                  CREATED\r\nknewton/ubuntu-12.04      latest              258d35bc06e3        8 minutes ago\r\nknewton/ubuntu-12.04      17                  258d35bc06e3        8 minutes ago\r\nknewton/bootstrap-12.04   latest              e673a92ae497        14 minutes ago\r\nknewton/bootstrap-12.04   17                  e673a92ae497        14 minutes ago\r\nubuntu@domU-12-31-39-0C-DD-81:~$ docker login\r\nUsername (): knewton\r\nPassword:\r\nEmail (): se@knewton.com\r\nLogin Succeeded\r\nubuntu@domU-12-31-39-0C-DD-81:~$ docker push knewton/bootstrap-12.04\r\nThe push refers to a repository [knewton/bootstrap-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/bootstrap-12.04 to registry-1.docker.io (2 tags)\r\nPushing e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5\r\n167280640/167280640 (100%)\r\nPushing tags for rev [e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5] on {registry-1.docker.io/users/knewton/bootstrap-12.04/latest}\r\nubuntu@domU-12-31-39-0C-DD-81:~$ docker push knewton/ubuntu-12.04\r\nThe push refers to a repository [knewton/ubuntu-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\nPushing e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5\r\nImage e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5 already uploaded ; skipping\r\nPushing tags for rev [e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5] on {registry-1.docker.io/users/knewton/ubuntu-12.04/17}\r\nPushing 73203d75b3d6c46a7d0bd787c597ee737c96c434a5479e77a59e92eaac47397f\r\nHTTP code 400 while uploading metadata: {\r\n    \"error\": \"This image does not belong to the repository\"\r\n}\r\nubuntu@domU-12-31-39-0C-DD-81:~$ docker push knewton/ubuntu-12.04\r\nThe push refers to a repository [knewton/ubuntu-12.04] (len: 2)\r\nProcessing checksums\r\nSending image list\r\nPushing repository knewton/ubuntu-12.04 to registry-1.docker.io (2 tags)\r\nPushing e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5\r\nImage e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5 already uploaded ; skipping\r\nPushing tags for rev [e673a92ae497918c849e2372bd38f367b1bd8f94872511fa759cf72baa5d0af5] on {registry-1.docker.io/users/knewton/ubuntu-12.04/17}\r\nPushing 73203d75b3d6c46a7d0bd787c597ee737c96c434a5479e77a59e92eaac47397f\r\nHTTP code 400 while uploading metadata: {\r\n    \"error\": \"This image does not belong to the repository\"\r\n}","FWIW, it looks like github allows [A-Za-z0-9_.-], and transforms all other\ncharacters to \"-\".","I support using Github's naming convention. I think it is natural for people to use them, and it's what we already see. Other places where I see the same convention are apt, npm and pip ","The registry API has been changed accordingly in df23a1e675c7e3cbad617374d85c48103541ee14.\r\n\r\nNow time to implement :)\r\n","Implemented already","I'm very much in favor of exposing devices to containers. All we need is a way for a developer to express \"I need device FOO\", where FOO always designates the right device for a given kernel.\r\n\r\n\r\nThis is to preserve portability of containers: all containers should work predictably on all docker runtimes. Of course not every device will be available on every host. But for all hoats where device FOO is available, the container requesting it should be able to access it in a repeatable way.\r\n\r\nThe question is: how do we express FOO?\r\n\r\n\r\nOption 1:  device filename. \"I depend on /dev/fuse\". But are these filenames guaranteed to be the same in all instances of a given kernel version? Is there a convention strong enough to standardize on? For all devices? Some devices?\r\n\r\n\r\nOption 2: major/minor number. This feels like it would be more guaranteed - but slightly less user-friendly.\r\n\r\n\r\nOption 3: another notation I'm not aware of which can be used to describe devices by capibilities?\r\n\r\n\r\nOption 4: obi-wan kenobi.\r\n\r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Wed, May 22, 2013 at 5:57 PM, schmatz \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e Hi guys,\r\n\u003e We're trying to use Docker as a part of a scientific computing workflow, and for this we need access to PCI devices such as GPUs and coprocessors. We visited the dotCloud office the other day, and while the team said that this would violate the goal of device independence , they did say that this probably could be done by implementing hardware dependencies for docker instances, or implementing an optional override option to allow Docker more extensive hardware permissions.\r\n\u003e Also, the team asked for a way of testing this. Amazon offers some GPU instances on which such functionality can be tested if you don't have a discrete graphics card on your machine. The following link will be helpful in configuration:\r\n\u003e http://sn0v.wordpress.com/2012/12/07/installing-cuda-5-on-ubuntu-12-04/\r\n\u003e If the drivers are successfully installed, then there are various samples included with the CUDA SDK which can be used to test the system. \r\n\u003e I imagine this is a pretty daunting task, but if you could take a look we'd be very grateful :smile: \r\n\u003e Thank you guys!\r\n\u003e Michael Schmatz and the NEMALOAD team\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/682","This will be possible with privileged mode (#1478) and \"expert mode\" lxc configuration (#1383). I'm closing this so we can focus on a generic solution.","I have read the issues #1478 and #1383. But I haven't figure it out how to run cuda in docker? Any suggestions? ","Please ignore my last comment. It turns out that there is nvidia driver mismatch between host and container. After solving mismatch, I applied privileged parameter in the run. I can run cuda under docker.","rickyzhang82,\r\n\r\nCan you please provide your steps for setting up your container so that it can access the nvidia GPU? I'd be very interested in trying this. ","First, run ubuntu 12.04 images with privileged=true. \r\n\r\nSecondly, install the same version of nvidia driver in container as your host. In my case, my host is Fedora 20 which installed 331.49 nvidia driver while my container is ubuntu 12.04 which used nvidia driver from cuda 6.0 RC package. The driver version mismatch caused problem. So when installing cuda zipped package from nvidia, extract the whole thing first. This will create three packages: cuda library, nvidia driver and cuda samples. Ignore nvidia driver and install the same driver as your host in your container. BTW, if you use ubuntu 12.04, you may need to install newer gcc to compile nvidia driver.\r\n\r\n","Thanks. I'll be testing this on RHEL 7 beta. I appreciate the help. Are you\r\nrunning and X server in the container?\r\nOn Apr 16, 2014 6:08 PM, \"Ricky Zhang\" \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e First, run ubuntu 12.04 images with privileged=true.\r\n\u003e\r\n\u003e Secondly, install the same version of nvidia driver in container as your\r\n\u003e host. In my case, my host is Fedora 20 which installed 331.49 nvidia driver\r\n\u003e while my container is ubuntu 12.04 which used nvidia driver from cuda 6.0\r\n\u003e RC package. The driver version mismatch caused problem. So when installing\r\n\u003e cuda zipped package from nvidia, extract the whole thing first. This will\r\n\u003e create three packages: cuda library, nvidia driver and cuda samples. Ignore\r\n\u003e nvidia driver and install the same driver as your host in your container.\r\n\u003e BTW, if you use ubuntu 12.04, you may need to install newer gcc to compile\r\n\u003e nvidia driver.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/682#issuecomment-40670638\u003e\r\n\u003e .\r\n\u003e","Yes, I did.","The standard way to fix this is to use \"-e myvar=myvalue\" for run.\r\nIf you're using docker build, you can set variables with: \"env myvar myvalue\".\r\n\r\nIt would be interesting to know whether you get this to work while referencing other variables, e.g.: get $PATH to be replaced by the old PATH in PATH=$PATH:/foo/bar.","Apologies for hopping in out of nowhere, but currently there are 2 options:\r\n\r\n1. Use a static `$PATH` via the `ENV` Dockerfile build instruction (yech)\r\n2. Wait for #1233 to be merged (formerly #1175, fixes #1136)\r\n\r\nActivity on #1233 is ~3d so I'd expect this will be added shortly now, at which point you can just add\r\n\r\n    env PATH /path/to/bin/folder:$PATH\r\n\r\nand be on your merry way.  Also looking forward to this myself, so thought I'd mention it in case you were discouraged by the wait a couple of months ago.","Thanks Matt :) Sometimes it's hard to keep up on so many issues, I'm glad you dug out this one!\r\n​ \r\nYes indeed, #1233 should be merged very soon. The bottleneck is just availablectime to review.\r\n\r\n\r\n​\r\nBy the way, we're recruiting maintainers :) Ping me if you're interested. \r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sun, Jul 28, 2013 at 8:27 PM, Matt Way \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e Apologies for hopping in out of nowhere, but currently there are 2 options:\r\n\u003e 1. Use a static `$PATH` via the `ENV` Dockerfile build instruction (yech)\r\n\u003e 2. Wait for #1233 to be merged (formerly #1175, fixes #1136)\r\n\u003e Activity on #1233 is ~3d so I'd expect this will be added shortly now, at which point you can just add\r\n\u003e     env PATH /path/to/bin/folder:$PATH\r\n\u003e and be on your merry way.  Also looking forward to this myself, so thought I'd mention it in case you were discouraged by the wait a couple of months ago.\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/684#issuecomment-21697781","ping @mway   #1233 has been merged! ","Sorry for necro-activity, but here's another thing you could do in such situation: run ```/bin/bash -l```, which invokes bash as a login session. Then, you can just modify ```/etc/profile``` as it's being invoked.","Hi,\r\n\r\ntianon/debian is a repository, when you pull tianon/debian you pull multiple images, 63f96daa5686 for exemple is debian wheezy you can see that during the pull:\r\n\r\n    $\u003edocker pull tianon/debian\r\n    Pulling repository tianon/debian from https://index.docker.io/v1\r\n    Pulling image 63f96daa5686bb9d6276ce64e288f6f5e439877def73c5cc72cffa0e2cb288af (wheezy) from tianon/debian\r\n    Pulling 63f96daa5686bb9d6276ce64e288f6f5e439877def73c5cc72cffa0e2cb288af metadata\r\n    Pulling 63f96daa5686bb9d6276ce64e288f6f5e439877def73c5cc72cffa0e2cb288af fs layer\r\n    Downloading 64614400/? (n/a)\r\n    Pulling image 6728ac917ad9156bfbd507a45ef4db56e7b7021cb4cd68dc86d2695f579747a2 () from tianon/debian\r\n    Pulling 6728ac917ad9156bfbd507a45ef4db56e7b7021cb4cd68dc86d2695f579747a2 metadata\r\n    Pulling 6728ac917ad9156bfbd507a45ef4db56e7b7021cb4cd68dc86d2695f579747a2 fs layer\r\n    Downloading 65392640/? (n/a)\r\n    Pulling image 739732273e64d3d9cd9928b0f66cd981950cc5f2f464d4ba3a54d91e5fe8b850 (sid) from tianon/debian\r\n    Pulling 739732273e64d3d9cd9928b0f66cd981950cc5f2f464d4ba3a54d91e5fe8b850 metadata\r\n    Pulling 739732273e64d3d9cd9928b0f66cd981950cc5f2f464d4ba3a54d91e5fe8b850 fs layer\r\n    Downloading 167280640/? (n/a)\r\n    Pulling image 764a253512097ba5d45b49c2a964ce40a790a6a5a061799f612113c9af8a0159 (squeeze) from tianon/debian\r\n    Pulling 764a253512097ba5d45b49c2a964ce40a790a6a5a061799f612113c9af8a0159 metadata\r\n    Pulling 764a253512097ba5d45b49c2a964ce40a790a6a5a061799f612113c9af8a0159 fs layer\r\n    ...\r\n","Why do they show up as unknown, though? They didn't have the proper data set?","What os your docker version ?\r\nDid you stop the download in the middle ?\r\n\r\nI just pull tianon/debian and here is what i got, more images and almost all tagged:\r\n\r\n    $\u003edocker images\r\n    REPOSITORY          TAG                 ID                  CREATED\r\n    tianon/debian       6.0.7               764a25351209        4 weeks ago\r\n    tianon/debian       7.0                 a1390ca6935c        6 days ago\r\n    tianon/debian       jessie              dfaad7f27638        6 days ago\r\n    tianon/debian       latest              63f96daa5686        4 weeks ago\r\n    tianon/debian       sid                 739732273e64        6 days ago\r\n    tianon/debian       squeeze             764a25351209        4 weeks ago\r\n    tianon/debian       wheezy              63f96daa5686        4 weeks ago\r\n    \u003cnone\u003e              \u003cnone\u003e              6728ac917ad9        3 weeks ago\r\n","yes that is exactly what happened, I killed with Ctrl-C.\r\nShould docker clean up in this instance?","Can you docker run -i -t 739732273e64 bash ? \r\n\r\nIf so docker should have tag the image.\r\n\r\nnot sure docker should clean, you can still \"resume\" by redoing the docker pull","resume seemed to fill in the info","Hi, I added such a function in this PR: #594 \r\nI'll keep you updated when the decision has been made on the PR.","Ah, you beat me to the punch! I added some comments, if you'd like to take a look.","@jrenner Yes I did some changes. \r\nLet's continue the discusion on the the PR.","it is ok :) in googlegroups i recieve next answer\r\n\r\nhttps://groups.google.com/d/msg/docker-club/cghRYeA8X3A/Er4yQN-x_8AJ\r\n\r\n\u003eHello Alex, \r\n\u003eThe remote API is still in development and available only from master. \r\n\u003eSo in order to try it, you would need to compile docker from sources. \r\n\u003eRegards, \r\n\u003eGuillaume J. Charmes\r\n\r\nso after i build docker from source it is working fine.","wow thanks ! maybe they should put that info somewhere :)","Thanks!","What version of Go are you using? I just tired on master without issue with Go1.1","I tried again and it worked. Any idea where the problem might come from?\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Thu, May 23, 2013 at 12:09 PM, Guillaume J. Charmes\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e What version of Go are you using? I just tired on master without issue with Go1.1\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/690#issuecomment-18361227","@shykes were you able to reproduce this recently ?","This is expected. Docker tries to lookup the tag e9aa60c60128 from the busybox repository. Which does not exists.\r\nImage Ids does not have scope, there are unique regarless of their repository.\r\n\r\nMaybe we could 'scope' the image Id?","@shykes what do you think, `docker run e9aa60c60128 true` is enough for me","We also need 'docker run ubuntu:e9aa60c60128', for example to allow forcing\r\na non-ambiguous version in your Dockerfile.\r\n\r\n\"FROM e9aa60c60128\" is non-ambiguous, but I lose name information\r\n\"FROM ubuntu\" has name information, but it's ambiguous.\r\n\r\n\r\nOn Mon, Jun 3, 2013 at 8:48 AM, Victor Vieux \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @shykes \u003chttps://github.com/shykes\u003e what do you think, docker run\r\n\u003e e9aa60c60128 true is enough for me\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/691#issuecomment-18850584\u003e\r\n\u003e .\r\n\u003e","There are some collision possible.\r\nHow do you feel about it ? we look into the ids, and if not found we try in tags ?\r\n","Yes, IDs first then tags.\r\n\r\n\r\nOn Mon, Jun 3, 2013 at 10:51 AM, Victor Vieux \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e There are some collision possible.\r\n\u003e How do you feel about it ? we look into the ids, and if not found we try\r\n\u003e in tags ?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/691#issuecomment-18858443\u003e\r\n\u003e .\r\n\u003e","First it seems to be an issue with the backjlack/armhf2 image I wasn't able to download it to @unclejack pushed it again on backjlack/armhf3.\r\n\r\nI got the same error, as said @unclejack  on IRC:\r\n\u003e It's an armhf image for docker. It relies on qemu-arm-static to run the processes. qemu-user-static and binfmt support packages have to be installed on the host for it to work.\r\n\r\nso a \r\n\r\n    $\u003esudo apt-get install qemu-user-static #on the host\r\nfixed the issue.\r\n\r\nI believe it's linked to #411 ","My issue is not with the \"panic: exec format error\" but the fact that docker crashes when it occurs.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 6:45 AM, Victor Vieux \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e First it seems to be an issue with the backjlack/armhf2 image I wasn't able to download it to @unclejack pushed it again on backjlack/armhf3.\r\n\u003e I got the same error, as said @unclejack  on IRC:\r\n\u003e\u003e It's an armhf image for docker. It relies on qemu-arm-static to run the processes. qemu-user-static and binfmt support packages have to be installed on the host for it to work.\r\n\u003e so a \r\n\u003e     $\u003esudo apt-get install qemu-user-static #on the host\r\n\u003e fixed the issue.\r\n\u003e I believe it's linked to #411 \r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/692#issuecomment-18405622","After the error message, is \"docker -d\" still running? I suppose it is, but\nit would be nice to confirm.\n\nNow I suppose that the crash comes from the docker that gets executed\nwithin the container.\n\nMy best bet is that it relies on libraries which aren't present (my\ninternet connection is too low right now to check the image and be sure).\n\nOne possible workaround would be to get rid of the docker init code path.\nDo you want me to open an issue about this, explaining what's involved ?","@jpetazzo The required libraries to run docker amd64 and qemu-arm-static amd64 are present in the image.\r\n\r\nThe armhf containers need qemu-arm-static within the container as well, so it wouldn't be possible to run the container when the host is set up properly if qemu-arm-static didn't exist and didnt have all the libraries in the image.","@jpetazzo No, the client crashed. The server is still up and running.","@jpetazzo it's the client inside the container.","OK. My gut feeling tells me that it's a library/qemu issue... Would it be\ninteresting to get rid of docker-init ? /cc @shykes","Sure, happy to discuss that in a separate issue, although it seems like a big change for this particular problem - we could just build docker statically for example.\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 9:00 AM, Jérôme Petazzoni\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e After the error message, is \"docker -d\" still running? I suppose it is, but\r\n\u003e it would be nice to confirm.\r\n\u003e Now I suppose that the crash comes from the docker that gets executed\r\n\u003e within the container.\r\n\u003e My best bet is that it relies on libraries which aren't present (my\r\n\u003e internet connection is too low right now to check the image and be sure).\r\n\u003e One possible workaround would be to get rid of the docker init code path.\r\n\u003e Do you want me to open an issue about this, explaining what's involved ?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/692#issuecomment-18413866","Oh, if it's easy to statically compile go, sure, that would be an easy fix!","The fix would be to integrate architecture detection, along with gh#411. If qemu-user-static is missing on the host, we should detect its absence.\r\n\r\n```exec format error``` is only the error message returned by syscall.Exec because binfmt_misc isn't set up to use qemu-arm-static.\r\n\r\n```\r\n        if err := syscall.Exec(path, args, os.Environ()); err != nil {\r\n                panic(err)\r\n        }\r\n```\r\n\r\nWe should detect this case in which qemu-user-static isn't installed and binfmt_misc isn't configured in one of the following ways:\r\n1) before we even try to execute the container by checking the architecture field and throwing a very useful error (image X is of architecture type Y. your system isn't configured to emulate foreign architecture Y)\r\n2) we can check within sysinit if err is exec format error and provide a more useful error\r\n\r\nI'll provide specs for multi-arch support so we can support most image architectures on most host architectures without requiring support for specific host architectures in the guest images (so there wouldn't be a need to have amd64-armhf, i386-armhf, i386-ppc images and so on).","We need to do something like #703.","I think we can close this in favor of #1150.","@dysinger I'm going to close this issue in favor of #1150.  Hopefully we will have a PR soon.","This is super unhelpful in an automated build of images.  I can't do anything with the 2nd build.","Still working on it, it will be fixed with 0.4 next week. There is still some issues with the cache. I'll try to push a fix this weekend","Hi guys, can you confirm that this problem is fixed? Thanks.","Tested it works fine. @dysinger Let me know if you still have issues with the build.","@jrenner in /var/lib/docler/.dockercfg you can see your password (just base64 decode the first line).\r\nMaybe there was an error on the store ?","decodes to \"user:password\", password is indeed greater than 5","@jrenner what version of docker are you using?","latest master\r\n\r\n\r\nOn Fri, May 24, 2013 at 9:52 PM, Ken Cochrane \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e @jrenner \u003chttps://github.com/jrenner\u003e what version of docker are you\r\n\u003e using?\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/697#issuecomment-18406022\u003e\r\n\u003e .\r\n\u003e","It's actually your username and your password, right ?\r\n\r\nNot \"password\" \r\n\r\nOn Fri, May 24, 2013 at 3:25 PM, Jon Renner \u003cnotifications@github.com\u003ewrote:\r\n\r\n\u003e decodes to \"user:password\", password is indeed greater than 5\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/issues/697#issuecomment-18404461\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","@jrenner oh I have the same issue\r\n","@vieux I'm seeing it in the server logs, but that code hasn't changed on the index for a while, maybe something broken on docker master?","@kencochrane yes the problem is in master I'll do a hotfix very soon\r\n","@jrenner thanks for noticing this one!","Are you sure that after rmi, the same id still appears? Is it not replaced by a new id?\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 4:25 AM, Unity Web \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e I kind of have a very weird situation.\r\n\u003e #docker images\r\n\u003e REPOSITORY          TAG                 ID                  CREATED\r\n\u003e \u003cnone\u003e              \u003cnone\u003e              ba3a958d59ee        21 hours ago\r\n\u003e \u003cnone\u003e              \u003cnone\u003e              d0fa307303d6        21 hours ago\r\n\u003e Whatever I do i cannot get rid of these images; #docker rmi does nothing, and why is these tags and repo empty ?\r\n\u003e A bug ?\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/698","yes it was actually; but after pulling some other images I was able to clean them up once and for all. It seems to me that this only happens when there are no other images but the '\u003cnone\u003e' once. \r\n\r\none more question; where does docker store all those images ? I couldn't find them in /var/lib/docker/","@unityweb the images are stored in /var/lib/docker/images/\u003cid\u003e/\r\n\r\nClosing this issue. Please see #610 (and #613) for followup. ","Actually /var/lib/docker/graph\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Fri, May 24, 2013 at 6:54 PM, Guillaume J. Charmes\r\n\u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e @unityweb the images are stored in /var/lib/docker/images/\u003cid\u003e/\r\n\u003e Closing this issue. Please see #610 (and #613) for followup. \r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/698#issuecomment-18438044","On the issue of deleting images - I have the same problem as described by unityweb\r\nHere is dump of my session\r\nroot@u1204:~# docker rmi b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc\r\nError: Conflict, b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc wasn't deleted\r\n\r\nBTW   ** The images do exist in /var/lib/docker/graph, also tried the shortened ID of image in rmi - same results  **\r\nroot@u1204:~# ls -al /var/lib/docker/graph\r\ntotal 28\r\ndrwx------ 6 root root 4096 Jun 28 22:04 .\r\ndrwx------ 5 root root 4096 Jun 28 22:01 ..\r\ndrwx------ 3 root root 4096 Jun 28 22:03 27cf784147099545\r\ndrwx------ 3 root root 4096 Jun 28 22:04 8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\r\ndrwx------ 3 root root 4096 Jun 28 22:04 b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc\r\n-rw------- 1 root root  376 Jun 28 22:13 checksums\r\ndrwx------ 2 root root 4096 Jun 28 22:04 :tmp:\r\n","This is probably because you have other tags pointing to the same image, directly or indirectly.\r\n​\r\nTry \"sudo cat /var/lib/docker/repositories | json_pp | grep $ID\"\r\n \r\n\r\n—\r\n@solomonstre\r\n@getdocker\r\n\r\nOn Sun, Jun 30, 2013 at 8:46 AM, Bachi Peachy \u003cnotifications@github.com\u003e\r\nwrote:\r\n\r\n\u003e On the issue of deleting images - I have the same problem as described by unityweb\r\n\u003e Here is dump of my session\r\n\u003e root@u1204:~# docker rmi b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc\r\n\u003e Error: Conflict, b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc wasn't deleted\r\n\u003e BTW   ** The images do exist in /var/lib/docker/graph, also tried the shortened ID of image in rmi - same results  **\r\n\u003e root@u1204:~# ls -al /var/lib/docker/graph\r\n\u003e total 28\r\n\u003e drwx------ 6 root root 4096 Jun 28 22:04 .\r\n\u003e drwx------ 5 root root 4096 Jun 28 22:01 ..\r\n\u003e drwx------ 3 root root 4096 Jun 28 22:03 27cf784147099545\r\n\u003e drwx------ 3 root root 4096 Jun 28 22:04 8dbd9e392a964056420e5d58ca5cc376ef18e2de93b5cc90e868a1bbc8318c1c\r\n\u003e drwx------ 3 root root 4096 Jun 28 22:04 b750fe79269d2ec9a3c593ef05b4332b1d1a02a62b4accb2c21d589ff2f5f2dc\r\n\u003e -rw------- 1 root root  376 Jun 28 22:13 checksums\r\n\u003e drwx------ 2 root root 4096 Jun 28 22:04 :tmp:\r\n\u003e ---\r\n\u003e Reply to this email directly or view it on GitHub:\r\n\u003e https://github.com/dotcloud/docker/issues/698#issuecomment-20249188","I'm also running into this issue: ![](https://i.cloudup.com/7izcygHh0K.png)","fixed for me","Hold off on merging, there shoud be more coming up","Linked to #659 ?\r\nIs this patch ready or do you need more time?","Yes this is similar to #659 but with a broader scope (i.e. supports push and pull, works with image IDs as well as repository names, and bypasses the index completely when a custom registry is passed)","@creack are you still reviewing this?","@shykes still on it.","@samalba @shin- @creack what's the status of this? At the last hack day there was discussion of maybe fixing the registry in another way.\r\n\r\nShould I close this, and if not, who are we waiting for?","I thought it was good to go but @creack commented saying he was still looking at it. I am not aware of any discussion about fixing this differently. Please keep me updated on the status of this","@creack ping\r\n@shin- could you bump to master please ?","Fully rebased and made some manual updates to make it work with the latest changes in master @creack @vieux.\r\n\r\nNote if you're testing it: some images were pushed on registry-1.docker.io with GZ compression, including \"busybox\" and \"ubuntu\". This messes up checksum caching if you try to push these images on a new registry, as it will try to push a XZ'd file with its GZ checksum. A somewhat shitty fix is to `rm /var/lib/docker/graph/checksums`. A less shitty fix would be to update these images in registry-1 to use XZ compression.","It would be nice to update the registry doc with the correct command, wsgi does not support chunks.\r\nOtherwise LGTM","I don't get it\r\n\r\n`docker push e9aa60c60128 -registry=\"http://myrepo.com\"` is not working because in https://github.com/dotcloud/docker/blob/3c946e12bb2a8453ccf09c8f9694289c7509ff37/commands.go#L737 there is a check  to see if there is a `/` event if you specify a custom registry.\r\n\r\nHow do you push by id ?","@vieux it has to be a real registry. Because `http://myrepo.com` doesn't exist, docker will try to push by ID and fail, and because of this, assume that it's supposed to push a repository named `e9aa60c60128 `. Except a repository needs to contain at least one `/` to be valid.\r\n\r\nI agree that the error shown to the user could be more accurate.","It's not too late to make it more clear :-)","@shin- The client doesn't even call the server, it stops here: https://github.com/dotcloud/docker/blob/3c946e12bb2a8453ccf09c8f9694289c7509ff37/commands.go#L737","My bad, it was possible before and I hadn't tested again for this use case in particular. --\r\n\r\nnvm","oh by rereading what I was writing a month ago, I guess the initial commit had it fixed but then the check was moved from server side to client side.","We could keep the check in then client, but only when using the regular\r\nregistry  (just add \u0026\u0026 registry != \"\" in commands.go), but I think we must\r\nadd the same test in the server for others clients.\r\n\r\n\r\nOn Thu, Jun 27, 2013 at 6:59 PM, Joffrey F \u003cnotifications@github.com\u003e wrote:\r\n\r\n\u003e oh by rereading what I was writing a month ago, I guess the initial commit\r\n\u003e had it fixed but then the check was moved from server side to client side.\r\n\u003e\r\n\u003e —\r\n\u003e Reply to this email directly or view it on GitHub\u003chttps://github.com/dotcloud/docker/pull/700#issuecomment-20137857\u003e\r\n\u003e .\r\n\u003e\r\n\r\n\r\n\r\n-- \r\nVictor VIEUX\r\nhttp://vvieux.com","Will merge this in the next hour unless there's anything else that needs reviewing/changing.",":+1: ","It looks like the issue with the pushing (#1022) is still there.\r\n\r\nI was able to verify with my registry/index hybrid which I put into a gist: \r\n\r\nhttps://gist.github.com/tobstarr/6f7660c13e54a88e428f\r\n\r\nAt least the problem with hardcoded https is now gone.\r\n\r\nSee README.md for details.","Thanks"]
